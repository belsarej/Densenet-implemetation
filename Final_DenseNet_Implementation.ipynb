{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Final_DenseNet_Implementation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4b412b2ee0ee4aa08fcd9efb3e0031f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4c8e54e55134429c8d23d4910b5e6fc3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7c669cdbb25a4e2ea7e75273f0709811",
              "IPY_MODEL_0bb2665c486d46a2b28e31c1ab38bf6b"
            ]
          }
        },
        "4c8e54e55134429c8d23d4910b5e6fc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c669cdbb25a4e2ea7e75273f0709811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_16e6e07726e3498c8931d061ed88842b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35fac651a20841729b77322f0e13a3d3"
          }
        },
        "0bb2665c486d46a2b28e31c1ab38bf6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4099fabfdfd047c8ada559b20fd74b0d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 95263115.77it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_de7633f1e2fd41caa60215f208c03ef2"
          }
        },
        "16e6e07726e3498c8931d061ed88842b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35fac651a20841729b77322f0e13a3d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4099fabfdfd047c8ada559b20fd74b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "de7633f1e2fd41caa60215f208c03ef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADixItTa6084"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, dropRate=0.0):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        self.droprate = dropRate\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(self.relu(self.bn1(x)))\n",
        "        if self.droprate > 0:\n",
        "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
        "        return torch.cat([x, out], 1)\n",
        "\n",
        "class BottleneckBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, dropRate=0.0):\n",
        "        super(BottleneckBlock, self).__init__()\n",
        "        inter_planes = out_planes * 4\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_planes, inter_planes, kernel_size=1, stride=1,\n",
        "                               padding=0, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(inter_planes)\n",
        "        self.conv2 = nn.Conv2d(inter_planes, out_planes, kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        self.droprate = dropRate\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(self.relu(self.bn1(x)))\n",
        "        if self.droprate > 0:\n",
        "            out = F.dropout(out, p=self.droprate, inplace=False, training=self.training)\n",
        "        out = self.conv2(self.relu(self.bn2(out)))\n",
        "        if self.droprate > 0:\n",
        "            out = F.dropout(out, p=self.droprate, inplace=False, training=self.training)\n",
        "        return torch.cat([x, out], 1)\n",
        "\n",
        "class TransitionBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, dropRate=0.0):\n",
        "        super(TransitionBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1,\n",
        "                               padding=0, bias=False)\n",
        "        self.droprate = dropRate\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(self.relu(self.bn1(x)))\n",
        "        if self.droprate > 0:\n",
        "            out = F.dropout(out, p=self.droprate, inplace=False, training=self.training)\n",
        "        return F.avg_pool2d(out, 2)\n",
        "\n",
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, nb_layers, in_planes, growth_rate, block, dropRate=0.0):\n",
        "        super(DenseBlock, self).__init__()\n",
        "        self.layer = self._make_layer(block, in_planes, growth_rate, nb_layers, dropRate)\n",
        "    def _make_layer(self, block, in_planes, growth_rate, nb_layers, dropRate):\n",
        "        layers = []\n",
        "        for i in range(nb_layers):\n",
        "            layers.append(block(in_planes+i*growth_rate, growth_rate, dropRate))\n",
        "        return nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "class DenseNet3(nn.Module):\n",
        "    def __init__(self, depth, num_classes, growth_rate=12,\n",
        "                 reduction=0.5, bottleneck=True, dropRate=0.0):\n",
        "        super(DenseNet3, self).__init__()\n",
        "        in_planes = 2 * growth_rate\n",
        "        n = (depth - 4) / 3\n",
        "        if bottleneck == True:\n",
        "            n = n/2\n",
        "            block = BottleneckBlock\n",
        "        else:\n",
        "            block = BasicBlock\n",
        "        n = int(n)\n",
        "        # 1st conv before any dense block\n",
        "        self.conv1 = nn.Conv2d(3, in_planes, kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        # 1st block\n",
        "        self.block1 = DenseBlock(n, in_planes, growth_rate, block, dropRate)\n",
        "        in_planes = int(in_planes+n*growth_rate)\n",
        "        self.trans1 = TransitionBlock(in_planes, int(math.floor(in_planes*reduction)), dropRate=dropRate)\n",
        "        in_planes = int(math.floor(in_planes*reduction))\n",
        "        # 2nd block\n",
        "        self.block2 = DenseBlock(n, in_planes, growth_rate, block, dropRate)\n",
        "        in_planes = int(in_planes+n*growth_rate)\n",
        "        self.trans2 = TransitionBlock(in_planes, int(math.floor(in_planes*reduction)), dropRate=dropRate)\n",
        "        in_planes = int(math.floor(in_planes*reduction))\n",
        "        # 3rd block\n",
        "        self.block3 = DenseBlock(n, in_planes, growth_rate, block, dropRate)\n",
        "        in_planes = int(in_planes+n*growth_rate)\n",
        "        # global average pooling and classifier\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc = nn.Linear(in_planes, num_classes)\n",
        "        self.in_planes = in_planes\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.bias.data.zero_()\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.trans1(self.block1(out))\n",
        "        out = self.trans2(self.block2(out))\n",
        "        out = self.block3(out)\n",
        "        out = self.relu(self.bn1(out))\n",
        "        out = F.avg_pool2d(out, 8)\n",
        "        out = out.view(-1, self.in_planes)\n",
        "        return self.fc(out)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQPepSVA7uO1",
        "outputId": "d7634749-f5f9-443b-ff54-fc3fb097d078"
      },
      "source": [
        "!pip install tensorboard_logger\n",
        "import argparse\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "#import densenet as dn\n",
        "\n",
        "# used for logging to TensorBoard\n",
        "from tensorboard_logger import configure, log_value\n",
        "\n",
        "#parser = argparse.ArgumentParser(description='PyTorch DenseNet Training')\n",
        "epochs=70\n",
        "start_epoch=1\n",
        "batch_size=64\n",
        "learn=0.1\n",
        "momentum=0.9\n",
        "weight_decay=1e-4\n",
        "print_freq=10\n",
        "layers=100\n",
        "growth=12\n",
        "droprate=0\n",
        "#parser.add_argument('--no-augment', dest='augment', action='store_false',\n",
        "                    #help='whether to use standard augmentation (default: True)')\n",
        "reduce=0.5\n",
        "#parser.add_argument('--no-bottleneck', dest='bottleneck', action='store_false',\n",
        "                    #help='To not use bottleneck block')\n",
        "resume=''\n",
        "name='DenseNet_BC_100_12'\n",
        "tensorboard = True\n",
        "bottleneck=True\n",
        "augment=True\n",
        "\n",
        "\n",
        "def main():\n",
        "    global best_prec1\n",
        "    #args = parser.parse_args()\n",
        "    if tensorboard: \n",
        "        configure(\"runs/%s\"%(name))\n",
        "    best_prec1 = 0\n",
        "    best_prec2 = 0\n",
        "    \n",
        "    # Data loading code\n",
        "    normalize = transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n",
        "                                     std=[x/255.0 for x in [63.0, 62.1, 66.7]])\n",
        "    if augment:\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "            ])\n",
        "    else:\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "            ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "        ])\n",
        "\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True}\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.CIFAR10('../data', train=True, download=True,\n",
        "                         transform=transform_train),\n",
        "        batch_size=batch_size, shuffle=True, **kwargs)\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        datasets.CIFAR10('../data', train=False, transform=transform_test),\n",
        "        batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "    # create model\n",
        "    model =DenseNet3(layers, 10,growth, reduction=reduce,\n",
        "                         bottleneck=bottleneck, dropRate=droprate)\n",
        "    \n",
        "    # get the number of model parameters\n",
        "    print('Number of model parameters: {}'.format(\n",
        "        sum([p.data.nelement() for p in model.parameters()])))\n",
        "    \n",
        "    # for training on multiple GPUs. \n",
        "    # Use CUDA_VISIBLE_DEVICES=0,1 to specify which GPUs to use\n",
        "    # model = torch.nn.DataParallel(model).cuda()\n",
        "    model = model.cuda()\n",
        "\n",
        "    # optionally resume from a checkpoint\n",
        "    if resume:\n",
        "        if os.path.isfile(resume):\n",
        "            print(\"=> loading checkpoint '{}'\".format(resume))\n",
        "            checkpoint = torch.load(resume)\n",
        "            start_epoch = checkpoint['epoch']\n",
        "            best_prec1 = checkpoint['best_prec1']\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
        "                  .format(resume, checkpoint['epoch']))\n",
        "        else:\n",
        "            print(\"=> no checkpoint found at '{}'\".format(resume))\n",
        "\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    # define loss function (criterion) and pptimizer\n",
        "    criterion = nn.CrossEntropyLoss().cuda()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), learn,\n",
        "                                momentum=momentum,\n",
        "                                nesterov=True,\n",
        "                                weight_decay=weight_decay)\n",
        "\n",
        "    for epoch in range(0,epochs):\n",
        "        adjust_learning_rate(optimizer, epoch)\n",
        "\n",
        "        # train for one epoch\n",
        "        prec2=train(train_loader, model, criterion, optimizer, epoch)\n",
        "        print(\"Training accuracy: \",prec2)\n",
        "\n",
        "        is_best2 = prec2 > best_prec2\n",
        "        best_prec2 = max(prec2,best_prec2)\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'best_prec2': best_prec2,\n",
        "        }, is_best2)\n",
        "        print('Best accuraacy: ',best_prec2)\n",
        "\n",
        "        # evaluate on validation set\n",
        "        prec1 = validate(val_loader, model, criterion, epoch)\n",
        "\n",
        "        # remember best prec@1 and save checkpoint\n",
        "        is_best = prec1 > best_prec1\n",
        "        best_prec1 = max(prec1, best_prec1)\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'best_prec1': best_prec1,\n",
        "        }, is_best)\n",
        "        print('Best accuracy: ', best_prec1)\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    \"\"\"Train for one epoch on the training set\"\"\"\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "        target = target.cuda(async=True)\n",
        "        input = input.cuda()\n",
        "        input_var = torch.autograd.Variable(input)\n",
        "        target_var = torch.autograd.Variable(target)\n",
        "\n",
        "        # compute output\n",
        "        output = model(input_var)\n",
        "        loss = criterion(output, target_var)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
        "        losses.update(loss.data, input.size(0))\n",
        "        top1.update(prec1, input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % print_freq == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                      loss=losses, top1=top1))\n",
        "    # log to TensorBoard\n",
        "    if tensorboard:\n",
        "        log_value('train_loss', losses.avg, epoch)\n",
        "        log_value('train_acc', top1.avg, epoch)\n",
        "    return top1.avg\n",
        "\n",
        "def validate(val_loader, model, criterion, epoch):\n",
        "    \"\"\"Perform validation on the validation set\"\"\"\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(val_loader):\n",
        "        target = target.cuda(async=True)\n",
        "        input = input.cuda()\n",
        "        input_var = torch.autograd.Variable(input, volatile=True)\n",
        "        target_var = torch.autograd.Variable(target, volatile=True)\n",
        "\n",
        "        # compute output\n",
        "        output = model(input_var)\n",
        "        loss = criterion(output, target_var)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
        "        losses.update(loss.data, input.size(0))\n",
        "        top1.update(prec1, input.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % print_freq == 0:\n",
        "            print('Test: [{0}/{1}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "                      i, len(val_loader), batch_time=batch_time, loss=losses,\n",
        "                      top1=top1))\n",
        "\n",
        "    print(' * Prec@1 {top1.avg:.3f}'.format(top1=top1))\n",
        "    # log to TensorBoard\n",
        "    if tensorboard:\n",
        "        log_value('val_loss', losses.avg, epoch)\n",
        "        log_value('val_acc', top1.avg, epoch)\n",
        "    return top1.avg\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    \"\"\"Saves checkpoint to disk\"\"\"\n",
        "    directory = \"runs/%s/\"%(name)\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    filename = directory + filename\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, 'runs/%s/'%(name) + 'model_best.pth.tar')\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 after 150 and 225 epochs\"\"\"\n",
        "    lr = learn * (0.1 ** (epoch // 150)) * (0.1 ** (epoch // 225))\n",
        "    # log to TensorBoard  \n",
        "    if tensorboard:\n",
        "        log_value('learning_rate', lr, epoch)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboard_logger\n",
            "  Downloading https://files.pythonhosted.org/packages/87/7a/ec0fd26dba69191f82eb8f38f5b401c124f45a207490a7ade6ea9717ecdb/tensorboard_logger-0.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboard_logger) (1.18.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from tensorboard_logger) (3.12.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard_logger) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboard_logger) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard_logger) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->tensorboard_logger) (50.3.2)\n",
            "Installing collected packages: tensorboard-logger\n",
            "Successfully installed tensorboard-logger-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4b412b2ee0ee4aa08fcd9efb3e0031f4",
            "4c8e54e55134429c8d23d4910b5e6fc3",
            "7c669cdbb25a4e2ea7e75273f0709811",
            "0bb2665c486d46a2b28e31c1ab38bf6b",
            "16e6e07726e3498c8931d061ed88842b",
            "35fac651a20841729b77322f0e13a3d3",
            "4099fabfdfd047c8ada559b20fd74b0d",
            "de7633f1e2fd41caa60215f208c03ef2"
          ]
        },
        "id": "WPPJaLx0uLwR",
        "outputId": "56d1f9c2-e8cd-4078-8ff4-61930d69ece5"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b412b2ee0ee4aa08fcd9efb3e0031f4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/cifar-10-python.tar.gz to ../data\n",
            "Number of model parameters: 769162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:156: UserWarning: This overload of cuda is deprecated:\n",
            "\tcuda(torch.device device, bool async, *, torch.memory_format memory_format)\n",
            "Consider using one of the following signatures instead:\n",
            "\tcuda(torch.device device, bool non_blocking, *, torch.memory_format memory_format) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [0][0/782]\tTime 1.343 (1.343)\tLoss 2.3983 (2.3983)\tPrec@1 7.812 (7.812)\n",
            "Epoch: [0][10/782]\tTime 0.159 (0.267)\tLoss 2.1170 (2.2903)\tPrec@1 26.562 (14.773)\n",
            "Epoch: [0][20/782]\tTime 0.161 (0.216)\tLoss 2.2971 (2.2517)\tPrec@1 20.312 (17.262)\n",
            "Epoch: [0][30/782]\tTime 0.160 (0.200)\tLoss 2.0005 (2.1657)\tPrec@1 34.375 (20.464)\n",
            "Epoch: [0][40/782]\tTime 0.161 (0.190)\tLoss 2.0393 (2.1033)\tPrec@1 26.562 (21.799)\n",
            "Epoch: [0][50/782]\tTime 0.160 (0.185)\tLoss 1.8510 (2.0658)\tPrec@1 26.562 (23.192)\n",
            "Epoch: [0][60/782]\tTime 0.161 (0.181)\tLoss 1.8997 (2.0375)\tPrec@1 29.688 (24.180)\n",
            "Epoch: [0][70/782]\tTime 0.161 (0.178)\tLoss 1.9079 (2.0091)\tPrec@1 29.688 (24.956)\n",
            "Epoch: [0][80/782]\tTime 0.164 (0.176)\tLoss 1.5819 (1.9857)\tPrec@1 43.750 (25.714)\n",
            "Epoch: [0][90/782]\tTime 0.161 (0.174)\tLoss 1.5532 (1.9575)\tPrec@1 39.062 (26.597)\n",
            "Epoch: [0][100/782]\tTime 0.161 (0.173)\tLoss 1.7891 (1.9489)\tPrec@1 31.250 (27.119)\n",
            "Epoch: [0][110/782]\tTime 0.162 (0.172)\tLoss 1.9138 (1.9402)\tPrec@1 26.562 (27.337)\n",
            "Epoch: [0][120/782]\tTime 0.160 (0.171)\tLoss 1.7764 (1.9199)\tPrec@1 23.438 (27.815)\n",
            "Epoch: [0][130/782]\tTime 0.163 (0.171)\tLoss 1.7635 (1.9025)\tPrec@1 28.125 (28.483)\n",
            "Epoch: [0][140/782]\tTime 0.162 (0.170)\tLoss 1.7581 (1.8908)\tPrec@1 35.938 (28.978)\n",
            "Epoch: [0][150/782]\tTime 0.163 (0.169)\tLoss 1.3626 (1.8746)\tPrec@1 48.438 (29.522)\n",
            "Epoch: [0][160/782]\tTime 0.161 (0.169)\tLoss 1.6077 (1.8604)\tPrec@1 34.375 (29.823)\n",
            "Epoch: [0][170/782]\tTime 0.162 (0.169)\tLoss 1.5256 (1.8472)\tPrec@1 45.312 (30.446)\n",
            "Epoch: [0][180/782]\tTime 0.162 (0.168)\tLoss 1.3746 (1.8289)\tPrec@1 48.438 (31.146)\n",
            "Epoch: [0][190/782]\tTime 0.166 (0.168)\tLoss 1.4549 (1.8147)\tPrec@1 46.875 (31.798)\n",
            "Epoch: [0][200/782]\tTime 0.163 (0.168)\tLoss 1.4137 (1.8064)\tPrec@1 43.750 (32.237)\n",
            "Epoch: [0][210/782]\tTime 0.164 (0.168)\tLoss 1.7565 (1.7966)\tPrec@1 34.375 (32.642)\n",
            "Epoch: [0][220/782]\tTime 0.163 (0.168)\tLoss 1.4428 (1.7827)\tPrec@1 50.000 (33.124)\n",
            "Epoch: [0][230/782]\tTime 0.168 (0.167)\tLoss 1.6113 (1.7747)\tPrec@1 42.188 (33.462)\n",
            "Epoch: [0][240/782]\tTime 0.165 (0.167)\tLoss 1.6888 (1.7656)\tPrec@1 43.750 (33.882)\n",
            "Epoch: [0][250/782]\tTime 0.165 (0.167)\tLoss 1.4521 (1.7525)\tPrec@1 42.188 (34.481)\n",
            "Epoch: [0][260/782]\tTime 0.168 (0.167)\tLoss 1.5897 (1.7405)\tPrec@1 51.562 (34.974)\n",
            "Epoch: [0][270/782]\tTime 0.164 (0.167)\tLoss 1.2457 (1.7282)\tPrec@1 51.562 (35.540)\n",
            "Epoch: [0][280/782]\tTime 0.164 (0.167)\tLoss 1.5413 (1.7168)\tPrec@1 50.000 (36.043)\n",
            "Epoch: [0][290/782]\tTime 0.166 (0.167)\tLoss 1.6368 (1.7086)\tPrec@1 42.188 (36.405)\n",
            "Epoch: [0][300/782]\tTime 0.165 (0.167)\tLoss 1.4548 (1.6993)\tPrec@1 53.125 (36.913)\n",
            "Epoch: [0][310/782]\tTime 0.165 (0.167)\tLoss 1.3006 (1.6905)\tPrec@1 54.688 (37.269)\n",
            "Epoch: [0][320/782]\tTime 0.164 (0.167)\tLoss 1.2322 (1.6798)\tPrec@1 50.000 (37.719)\n",
            "Epoch: [0][330/782]\tTime 0.165 (0.167)\tLoss 1.4119 (1.6679)\tPrec@1 48.438 (38.133)\n",
            "Epoch: [0][340/782]\tTime 0.165 (0.167)\tLoss 1.4273 (1.6567)\tPrec@1 43.750 (38.618)\n",
            "Epoch: [0][350/782]\tTime 0.165 (0.167)\tLoss 1.2803 (1.6499)\tPrec@1 48.438 (38.853)\n",
            "Epoch: [0][360/782]\tTime 0.164 (0.167)\tLoss 1.3038 (1.6410)\tPrec@1 56.250 (39.262)\n",
            "Epoch: [0][370/782]\tTime 0.167 (0.167)\tLoss 1.2368 (1.6331)\tPrec@1 53.125 (39.509)\n",
            "Epoch: [0][380/782]\tTime 0.163 (0.167)\tLoss 1.4545 (1.6248)\tPrec@1 43.750 (39.838)\n",
            "Epoch: [0][390/782]\tTime 0.164 (0.167)\tLoss 1.1977 (1.6176)\tPrec@1 59.375 (40.173)\n",
            "Epoch: [0][400/782]\tTime 0.162 (0.167)\tLoss 1.4060 (1.6100)\tPrec@1 45.312 (40.454)\n",
            "Epoch: [0][410/782]\tTime 0.163 (0.167)\tLoss 1.3924 (1.6031)\tPrec@1 51.562 (40.747)\n",
            "Epoch: [0][420/782]\tTime 0.166 (0.167)\tLoss 1.3094 (1.5963)\tPrec@1 56.250 (41.022)\n",
            "Epoch: [0][430/782]\tTime 0.164 (0.167)\tLoss 1.2223 (1.5891)\tPrec@1 51.562 (41.303)\n",
            "Epoch: [0][440/782]\tTime 0.164 (0.167)\tLoss 1.2169 (1.5818)\tPrec@1 51.562 (41.603)\n",
            "Epoch: [0][450/782]\tTime 0.165 (0.166)\tLoss 1.2160 (1.5736)\tPrec@1 60.938 (41.924)\n",
            "Epoch: [0][460/782]\tTime 0.164 (0.166)\tLoss 1.4420 (1.5652)\tPrec@1 45.312 (42.255)\n",
            "Epoch: [0][470/782]\tTime 0.163 (0.166)\tLoss 1.1208 (1.5584)\tPrec@1 56.250 (42.516)\n",
            "Epoch: [0][480/782]\tTime 0.164 (0.166)\tLoss 1.2719 (1.5525)\tPrec@1 54.688 (42.762)\n",
            "Epoch: [0][490/782]\tTime 0.165 (0.166)\tLoss 0.9888 (1.5442)\tPrec@1 64.062 (43.053)\n",
            "Epoch: [0][500/782]\tTime 0.164 (0.166)\tLoss 0.9488 (1.5368)\tPrec@1 70.312 (43.348)\n",
            "Epoch: [0][510/782]\tTime 0.163 (0.166)\tLoss 1.1123 (1.5297)\tPrec@1 59.375 (43.646)\n",
            "Epoch: [0][520/782]\tTime 0.162 (0.166)\tLoss 1.1970 (1.5233)\tPrec@1 59.375 (43.903)\n",
            "Epoch: [0][530/782]\tTime 0.166 (0.166)\tLoss 1.0968 (1.5164)\tPrec@1 57.812 (44.188)\n",
            "Epoch: [0][540/782]\tTime 0.161 (0.166)\tLoss 1.1076 (1.5092)\tPrec@1 62.500 (44.455)\n",
            "Epoch: [0][550/782]\tTime 0.163 (0.166)\tLoss 0.9841 (1.5015)\tPrec@1 62.500 (44.762)\n",
            "Epoch: [0][560/782]\tTime 0.165 (0.166)\tLoss 0.8708 (1.4937)\tPrec@1 65.625 (45.101)\n",
            "Epoch: [0][570/782]\tTime 0.162 (0.166)\tLoss 1.2125 (1.4873)\tPrec@1 48.438 (45.370)\n",
            "Epoch: [0][580/782]\tTime 0.162 (0.166)\tLoss 1.0568 (1.4812)\tPrec@1 65.625 (45.633)\n",
            "Epoch: [0][590/782]\tTime 0.163 (0.166)\tLoss 0.9300 (1.4741)\tPrec@1 65.625 (45.907)\n",
            "Epoch: [0][600/782]\tTime 0.171 (0.166)\tLoss 0.9100 (1.4676)\tPrec@1 64.062 (46.173)\n",
            "Epoch: [0][610/782]\tTime 0.162 (0.166)\tLoss 1.1669 (1.4614)\tPrec@1 54.688 (46.448)\n",
            "Epoch: [0][620/782]\tTime 0.163 (0.166)\tLoss 1.1624 (1.4548)\tPrec@1 50.000 (46.699)\n",
            "Epoch: [0][630/782]\tTime 0.163 (0.166)\tLoss 1.3382 (1.4501)\tPrec@1 59.375 (46.887)\n",
            "Epoch: [0][640/782]\tTime 0.164 (0.166)\tLoss 1.1466 (1.4446)\tPrec@1 48.438 (47.075)\n",
            "Epoch: [0][650/782]\tTime 0.164 (0.166)\tLoss 1.1272 (1.4403)\tPrec@1 59.375 (47.271)\n",
            "Epoch: [0][660/782]\tTime 0.163 (0.166)\tLoss 0.9014 (1.4355)\tPrec@1 67.188 (47.464)\n",
            "Epoch: [0][670/782]\tTime 0.163 (0.166)\tLoss 1.1527 (1.4309)\tPrec@1 53.125 (47.639)\n",
            "Epoch: [0][680/782]\tTime 0.163 (0.166)\tLoss 1.1742 (1.4260)\tPrec@1 60.938 (47.871)\n",
            "Epoch: [0][690/782]\tTime 0.164 (0.166)\tLoss 1.1566 (1.4194)\tPrec@1 56.250 (48.128)\n",
            "Epoch: [0][700/782]\tTime 0.165 (0.166)\tLoss 1.0333 (1.4141)\tPrec@1 62.500 (48.333)\n",
            "Epoch: [0][710/782]\tTime 0.164 (0.166)\tLoss 1.0873 (1.4082)\tPrec@1 64.062 (48.561)\n",
            "Epoch: [0][720/782]\tTime 0.162 (0.166)\tLoss 0.9360 (1.4027)\tPrec@1 64.062 (48.784)\n",
            "Epoch: [0][730/782]\tTime 0.164 (0.166)\tLoss 1.0118 (1.3967)\tPrec@1 67.188 (49.021)\n",
            "Epoch: [0][740/782]\tTime 0.163 (0.166)\tLoss 0.8727 (1.3912)\tPrec@1 68.750 (49.262)\n",
            "Epoch: [0][750/782]\tTime 0.164 (0.166)\tLoss 0.8696 (1.3858)\tPrec@1 62.500 (49.447)\n",
            "Epoch: [0][760/782]\tTime 0.165 (0.166)\tLoss 0.9677 (1.3797)\tPrec@1 62.500 (49.706)\n",
            "Epoch: [0][770/782]\tTime 0.164 (0.166)\tLoss 0.8517 (1.3749)\tPrec@1 68.750 (49.889)\n",
            "Epoch: [0][780/782]\tTime 0.162 (0.166)\tLoss 0.8354 (1.3695)\tPrec@1 76.562 (50.098)\n",
            "Training accuracy:  tensor(50.1060, device='cuda:0')\n",
            "Best accuraacy:  tensor(50.1060, device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:205: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:206: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: [19][490/782]\tTime 0.167 (0.168)\tLoss 0.5001 (0.3008)\tPrec@1 79.688 (89.619)\n",
            "Epoch: [19][500/782]\tTime 0.168 (0.168)\tLoss 0.3389 (0.3017)\tPrec@1 89.062 (89.586)\n",
            "Epoch: [19][510/782]\tTime 0.167 (0.168)\tLoss 0.1890 (0.3015)\tPrec@1 93.750 (89.582)\n",
            "Epoch: [19][520/782]\tTime 0.167 (0.168)\tLoss 0.3566 (0.3018)\tPrec@1 85.938 (89.572)\n",
            "Epoch: [19][530/782]\tTime 0.166 (0.168)\tLoss 0.1995 (0.3004)\tPrec@1 92.188 (89.627)\n",
            "Epoch: [19][540/782]\tTime 0.169 (0.168)\tLoss 0.2442 (0.2988)\tPrec@1 92.188 (89.689)\n",
            "Epoch: [19][550/782]\tTime 0.166 (0.168)\tLoss 0.3141 (0.2987)\tPrec@1 93.750 (89.701)\n",
            "Epoch: [19][560/782]\tTime 0.167 (0.168)\tLoss 0.2309 (0.2992)\tPrec@1 89.062 (89.684)\n",
            "Epoch: [19][570/782]\tTime 0.172 (0.168)\tLoss 0.2550 (0.2994)\tPrec@1 90.625 (89.678)\n",
            "Epoch: [19][580/782]\tTime 0.167 (0.168)\tLoss 0.2587 (0.2997)\tPrec@1 96.875 (89.676)\n",
            "Epoch: [19][590/782]\tTime 0.166 (0.168)\tLoss 0.3422 (0.2992)\tPrec@1 90.625 (89.686)\n",
            "Epoch: [19][600/782]\tTime 0.167 (0.168)\tLoss 0.4128 (0.2992)\tPrec@1 84.375 (89.686)\n",
            "Epoch: [19][610/782]\tTime 0.166 (0.168)\tLoss 0.2549 (0.2993)\tPrec@1 90.625 (89.674)\n",
            "Epoch: [19][620/782]\tTime 0.166 (0.168)\tLoss 0.3036 (0.2998)\tPrec@1 87.500 (89.659)\n",
            "Epoch: [19][630/782]\tTime 0.168 (0.168)\tLoss 0.2447 (0.2994)\tPrec@1 92.188 (89.679)\n",
            "Epoch: [19][640/782]\tTime 0.167 (0.168)\tLoss 0.3333 (0.2989)\tPrec@1 85.938 (89.694)\n",
            "Epoch: [19][650/782]\tTime 0.167 (0.168)\tLoss 0.3195 (0.2992)\tPrec@1 85.938 (89.699)\n",
            "Epoch: [19][660/782]\tTime 0.168 (0.168)\tLoss 0.1651 (0.2987)\tPrec@1 95.312 (89.708)\n",
            "Epoch: [19][670/782]\tTime 0.168 (0.168)\tLoss 0.3209 (0.2997)\tPrec@1 90.625 (89.689)\n",
            "Epoch: [19][680/782]\tTime 0.166 (0.168)\tLoss 0.6281 (0.3009)\tPrec@1 84.375 (89.652)\n",
            "Epoch: [19][690/782]\tTime 0.167 (0.168)\tLoss 0.5712 (0.3012)\tPrec@1 76.562 (89.639)\n",
            "Epoch: [19][700/782]\tTime 0.166 (0.168)\tLoss 0.2036 (0.3014)\tPrec@1 93.750 (89.642)\n",
            "Epoch: [19][710/782]\tTime 0.167 (0.168)\tLoss 0.3721 (0.3020)\tPrec@1 85.938 (89.636)\n",
            "Epoch: [19][720/782]\tTime 0.168 (0.168)\tLoss 0.3410 (0.3027)\tPrec@1 87.500 (89.598)\n",
            "Epoch: [19][730/782]\tTime 0.165 (0.168)\tLoss 0.2923 (0.3026)\tPrec@1 89.062 (89.597)\n",
            "Epoch: [19][740/782]\tTime 0.167 (0.168)\tLoss 0.4241 (0.3027)\tPrec@1 81.250 (89.585)\n",
            "Epoch: [19][750/782]\tTime 0.168 (0.168)\tLoss 0.2929 (0.3028)\tPrec@1 87.500 (89.574)\n",
            "Epoch: [19][760/782]\tTime 0.166 (0.168)\tLoss 0.3304 (0.3027)\tPrec@1 87.500 (89.578)\n",
            "Epoch: [19][770/782]\tTime 0.169 (0.168)\tLoss 0.4632 (0.3023)\tPrec@1 79.688 (89.600)\n",
            "Epoch: [19][780/782]\tTime 0.162 (0.168)\tLoss 0.3690 (0.3023)\tPrec@1 87.500 (89.595)\n",
            "Training accuracy:  tensor(89.5960, device='cuda:0')\n",
            "Best accuraacy:  tensor(89.5960, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.121 (0.121)\tLoss 0.5442 (0.5442)\tPrec@1 79.688 (79.688)\n",
            "Test: [10/157]\tTime 0.040 (0.049)\tLoss 0.2878 (0.4984)\tPrec@1 93.750 (84.233)\n",
            "Test: [20/157]\tTime 0.050 (0.046)\tLoss 0.5480 (0.5108)\tPrec@1 85.938 (84.226)\n",
            "Test: [30/157]\tTime 0.041 (0.046)\tLoss 1.1077 (0.5002)\tPrec@1 78.125 (84.375)\n",
            "Test: [40/157]\tTime 0.043 (0.045)\tLoss 0.4055 (0.5164)\tPrec@1 84.375 (83.689)\n",
            "Test: [50/157]\tTime 0.047 (0.045)\tLoss 0.2338 (0.5045)\tPrec@1 93.750 (84.038)\n",
            "Test: [60/157]\tTime 0.041 (0.045)\tLoss 0.6061 (0.4899)\tPrec@1 78.125 (84.349)\n",
            "Test: [70/157]\tTime 0.040 (0.045)\tLoss 0.4333 (0.4775)\tPrec@1 85.938 (84.463)\n",
            "Test: [80/157]\tTime 0.043 (0.045)\tLoss 0.2453 (0.4715)\tPrec@1 92.188 (84.606)\n",
            "Test: [90/157]\tTime 0.043 (0.045)\tLoss 0.4504 (0.4734)\tPrec@1 89.062 (84.512)\n",
            "Test: [100/157]\tTime 0.043 (0.045)\tLoss 0.4158 (0.4734)\tPrec@1 82.812 (84.468)\n",
            "Test: [110/157]\tTime 0.045 (0.044)\tLoss 0.2346 (0.4829)\tPrec@1 90.625 (84.375)\n",
            "Test: [120/157]\tTime 0.043 (0.044)\tLoss 0.4400 (0.4827)\tPrec@1 87.500 (84.401)\n",
            "Test: [130/157]\tTime 0.042 (0.044)\tLoss 0.3422 (0.4829)\tPrec@1 90.625 (84.363)\n",
            "Test: [140/157]\tTime 0.043 (0.044)\tLoss 0.6078 (0.4841)\tPrec@1 81.250 (84.375)\n",
            "Test: [150/157]\tTime 0.040 (0.044)\tLoss 0.6260 (0.4826)\tPrec@1 82.812 (84.375)\n",
            " * Prec@1 84.340\n",
            "Best accuracy:  tensor(86.6700, device='cuda:0')\n",
            "Epoch: [20][0/782]\tTime 0.280 (0.280)\tLoss 0.4596 (0.4596)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [20][10/782]\tTime 0.168 (0.179)\tLoss 0.3070 (0.3113)\tPrec@1 90.625 (88.210)\n",
            "Epoch: [20][20/782]\tTime 0.168 (0.174)\tLoss 0.3671 (0.2834)\tPrec@1 85.938 (89.360)\n",
            "Epoch: [20][30/782]\tTime 0.173 (0.173)\tLoss 0.3571 (0.2586)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [20][40/782]\tTime 0.167 (0.172)\tLoss 0.1675 (0.2527)\tPrec@1 93.750 (91.044)\n",
            "Epoch: [20][50/782]\tTime 0.169 (0.171)\tLoss 0.1947 (0.2523)\tPrec@1 96.875 (91.085)\n",
            "Epoch: [20][60/782]\tTime 0.170 (0.171)\tLoss 0.1782 (0.2580)\tPrec@1 90.625 (90.779)\n",
            "Epoch: [20][70/782]\tTime 0.168 (0.170)\tLoss 0.1787 (0.2573)\tPrec@1 96.875 (90.823)\n",
            "Epoch: [20][80/782]\tTime 0.168 (0.170)\tLoss 0.2585 (0.2509)\tPrec@1 93.750 (91.107)\n",
            "Epoch: [20][90/782]\tTime 0.167 (0.170)\tLoss 0.4556 (0.2618)\tPrec@1 89.062 (90.883)\n",
            "Epoch: [20][100/782]\tTime 0.170 (0.170)\tLoss 0.4298 (0.2679)\tPrec@1 85.938 (90.687)\n",
            "Epoch: [20][110/782]\tTime 0.168 (0.169)\tLoss 0.1765 (0.2730)\tPrec@1 93.750 (90.611)\n",
            "Epoch: [20][120/782]\tTime 0.168 (0.169)\tLoss 0.2293 (0.2770)\tPrec@1 92.188 (90.393)\n",
            "Epoch: [20][130/782]\tTime 0.166 (0.169)\tLoss 0.2694 (0.2796)\tPrec@1 87.500 (90.315)\n",
            "Epoch: [20][140/782]\tTime 0.168 (0.169)\tLoss 0.4916 (0.2853)\tPrec@1 82.812 (90.115)\n",
            "Epoch: [20][150/782]\tTime 0.170 (0.169)\tLoss 0.2209 (0.2836)\tPrec@1 90.625 (90.201)\n",
            "Epoch: [20][160/782]\tTime 0.168 (0.169)\tLoss 0.5279 (0.2863)\tPrec@1 84.375 (90.091)\n",
            "Epoch: [20][170/782]\tTime 0.167 (0.169)\tLoss 0.2237 (0.2868)\tPrec@1 90.625 (90.058)\n",
            "Epoch: [20][180/782]\tTime 0.169 (0.169)\tLoss 0.1731 (0.2849)\tPrec@1 93.750 (90.150)\n",
            "Epoch: [20][190/782]\tTime 0.167 (0.169)\tLoss 0.3786 (0.2829)\tPrec@1 90.625 (90.224)\n",
            "Epoch: [20][200/782]\tTime 0.167 (0.169)\tLoss 0.3609 (0.2848)\tPrec@1 92.188 (90.182)\n",
            "Epoch: [20][210/782]\tTime 0.167 (0.169)\tLoss 0.2298 (0.2833)\tPrec@1 93.750 (90.284)\n",
            "Epoch: [20][220/782]\tTime 0.167 (0.169)\tLoss 0.2597 (0.2817)\tPrec@1 92.188 (90.314)\n",
            "Epoch: [20][230/782]\tTime 0.165 (0.169)\tLoss 0.3951 (0.2844)\tPrec@1 87.500 (90.212)\n",
            "Epoch: [20][240/782]\tTime 0.167 (0.168)\tLoss 0.3332 (0.2851)\tPrec@1 90.625 (90.210)\n",
            "Epoch: [20][250/782]\tTime 0.165 (0.168)\tLoss 0.2587 (0.2846)\tPrec@1 93.750 (90.233)\n",
            "Epoch: [20][260/782]\tTime 0.167 (0.168)\tLoss 0.4081 (0.2852)\tPrec@1 82.812 (90.188)\n",
            "Epoch: [20][270/782]\tTime 0.167 (0.168)\tLoss 0.3935 (0.2855)\tPrec@1 84.375 (90.146)\n",
            "Epoch: [20][280/782]\tTime 0.173 (0.168)\tLoss 0.3228 (0.2859)\tPrec@1 92.188 (90.169)\n",
            "Epoch: [20][290/782]\tTime 0.170 (0.168)\tLoss 0.2731 (0.2858)\tPrec@1 90.625 (90.158)\n",
            "Epoch: [20][300/782]\tTime 0.167 (0.168)\tLoss 0.1712 (0.2862)\tPrec@1 95.312 (90.132)\n",
            "Epoch: [20][310/782]\tTime 0.166 (0.168)\tLoss 0.3177 (0.2862)\tPrec@1 90.625 (90.113)\n",
            "Epoch: [20][320/782]\tTime 0.168 (0.168)\tLoss 0.3400 (0.2866)\tPrec@1 87.500 (90.085)\n",
            "Epoch: [20][330/782]\tTime 0.167 (0.168)\tLoss 0.2391 (0.2862)\tPrec@1 89.062 (90.115)\n",
            "Epoch: [20][340/782]\tTime 0.167 (0.168)\tLoss 0.3241 (0.2866)\tPrec@1 87.500 (90.098)\n",
            "Epoch: [20][350/782]\tTime 0.166 (0.168)\tLoss 0.4539 (0.2862)\tPrec@1 87.500 (90.113)\n",
            "Epoch: [20][360/782]\tTime 0.167 (0.168)\tLoss 0.5965 (0.2871)\tPrec@1 82.812 (90.084)\n",
            "Epoch: [20][370/782]\tTime 0.167 (0.168)\tLoss 0.3442 (0.2869)\tPrec@1 89.062 (90.111)\n",
            "Epoch: [20][380/782]\tTime 0.167 (0.168)\tLoss 0.2447 (0.2891)\tPrec@1 93.750 (90.018)\n",
            "Epoch: [20][390/782]\tTime 0.169 (0.168)\tLoss 0.3846 (0.2896)\tPrec@1 87.500 (90.010)\n",
            "Epoch: [20][400/782]\tTime 0.165 (0.168)\tLoss 0.2788 (0.2893)\tPrec@1 90.625 (90.009)\n",
            "Epoch: [20][410/782]\tTime 0.168 (0.168)\tLoss 0.3413 (0.2898)\tPrec@1 93.750 (90.002)\n",
            "Epoch: [20][420/782]\tTime 0.168 (0.168)\tLoss 0.2547 (0.2890)\tPrec@1 92.188 (90.031)\n",
            "Epoch: [20][430/782]\tTime 0.166 (0.168)\tLoss 0.3584 (0.2889)\tPrec@1 89.062 (90.041)\n",
            "Epoch: [20][440/782]\tTime 0.167 (0.168)\tLoss 0.1876 (0.2886)\tPrec@1 93.750 (90.030)\n",
            "Epoch: [20][450/782]\tTime 0.167 (0.168)\tLoss 0.1867 (0.2879)\tPrec@1 93.750 (90.064)\n",
            "Epoch: [20][460/782]\tTime 0.166 (0.168)\tLoss 0.1676 (0.2875)\tPrec@1 95.312 (90.079)\n",
            "Epoch: [20][470/782]\tTime 0.167 (0.168)\tLoss 0.3363 (0.2880)\tPrec@1 84.375 (90.068)\n",
            "Epoch: [20][480/782]\tTime 0.167 (0.168)\tLoss 0.1791 (0.2875)\tPrec@1 92.188 (90.083)\n",
            "Epoch: [20][490/782]\tTime 0.166 (0.168)\tLoss 0.2414 (0.2874)\tPrec@1 92.188 (90.084)\n",
            "Epoch: [20][500/782]\tTime 0.167 (0.168)\tLoss 0.3949 (0.2886)\tPrec@1 87.500 (90.057)\n",
            "Epoch: [20][510/782]\tTime 0.167 (0.168)\tLoss 0.3912 (0.2886)\tPrec@1 87.500 (90.102)\n",
            "Epoch: [20][520/782]\tTime 0.167 (0.168)\tLoss 0.3173 (0.2892)\tPrec@1 87.500 (90.046)\n",
            "Epoch: [20][530/782]\tTime 0.166 (0.168)\tLoss 0.6094 (0.2904)\tPrec@1 82.812 (90.025)\n",
            "Epoch: [20][540/782]\tTime 0.168 (0.168)\tLoss 0.3417 (0.2903)\tPrec@1 87.500 (90.010)\n",
            "Epoch: [20][550/782]\tTime 0.167 (0.168)\tLoss 0.2866 (0.2904)\tPrec@1 90.625 (89.993)\n",
            "Epoch: [20][560/782]\tTime 0.167 (0.168)\tLoss 0.3316 (0.2904)\tPrec@1 84.375 (89.982)\n",
            "Epoch: [20][570/782]\tTime 0.166 (0.168)\tLoss 0.3118 (0.2897)\tPrec@1 89.062 (90.001)\n",
            "Epoch: [20][580/782]\tTime 0.173 (0.168)\tLoss 0.3470 (0.2903)\tPrec@1 89.062 (89.963)\n",
            "Epoch: [20][590/782]\tTime 0.166 (0.168)\tLoss 0.2722 (0.2901)\tPrec@1 93.750 (89.975)\n",
            "Epoch: [20][600/782]\tTime 0.165 (0.168)\tLoss 0.2617 (0.2906)\tPrec@1 90.625 (89.944)\n",
            "Epoch: [20][610/782]\tTime 0.170 (0.168)\tLoss 0.2396 (0.2910)\tPrec@1 92.188 (89.937)\n",
            "Epoch: [20][620/782]\tTime 0.165 (0.168)\tLoss 0.4627 (0.2914)\tPrec@1 87.500 (89.923)\n",
            "Epoch: [20][630/782]\tTime 0.166 (0.168)\tLoss 0.3405 (0.2910)\tPrec@1 89.062 (89.932)\n",
            "Epoch: [20][640/782]\tTime 0.167 (0.168)\tLoss 0.4130 (0.2917)\tPrec@1 82.812 (89.925)\n",
            "Epoch: [20][650/782]\tTime 0.168 (0.168)\tLoss 0.2460 (0.2927)\tPrec@1 93.750 (89.874)\n",
            "Epoch: [20][660/782]\tTime 0.166 (0.168)\tLoss 0.3446 (0.2929)\tPrec@1 85.938 (89.866)\n",
            "Epoch: [20][670/782]\tTime 0.166 (0.168)\tLoss 0.2861 (0.2936)\tPrec@1 89.062 (89.833)\n",
            "Epoch: [20][680/782]\tTime 0.168 (0.168)\tLoss 0.3682 (0.2941)\tPrec@1 89.062 (89.831)\n",
            "Epoch: [20][690/782]\tTime 0.168 (0.168)\tLoss 0.1305 (0.2938)\tPrec@1 95.312 (89.863)\n",
            "Epoch: [20][700/782]\tTime 0.168 (0.168)\tLoss 0.2921 (0.2938)\tPrec@1 87.500 (89.847)\n",
            "Epoch: [20][710/782]\tTime 0.167 (0.168)\tLoss 0.3200 (0.2942)\tPrec@1 90.625 (89.849)\n",
            "Epoch: [20][720/782]\tTime 0.167 (0.168)\tLoss 0.0983 (0.2939)\tPrec@1 98.438 (89.867)\n",
            "Epoch: [20][730/782]\tTime 0.168 (0.168)\tLoss 0.3271 (0.2943)\tPrec@1 92.188 (89.851)\n",
            "Epoch: [20][740/782]\tTime 0.166 (0.168)\tLoss 0.3464 (0.2951)\tPrec@1 92.188 (89.836)\n",
            "Epoch: [20][750/782]\tTime 0.166 (0.168)\tLoss 0.3910 (0.2954)\tPrec@1 84.375 (89.822)\n",
            "Epoch: [20][760/782]\tTime 0.169 (0.168)\tLoss 0.2529 (0.2953)\tPrec@1 93.750 (89.832)\n",
            "Epoch: [20][770/782]\tTime 0.166 (0.168)\tLoss 0.3144 (0.2951)\tPrec@1 82.812 (89.839)\n",
            "Epoch: [20][780/782]\tTime 0.163 (0.168)\tLoss 0.5009 (0.2952)\tPrec@1 87.500 (89.839)\n",
            "Training accuracy:  tensor(89.8360, device='cuda:0')\n",
            "Best accuraacy:  tensor(89.8360, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.122 (0.122)\tLoss 0.8707 (0.8707)\tPrec@1 73.438 (73.438)\n",
            "Test: [10/157]\tTime 0.039 (0.049)\tLoss 0.4896 (0.5828)\tPrec@1 85.938 (82.812)\n",
            "Test: [20/157]\tTime 0.051 (0.046)\tLoss 0.2208 (0.5484)\tPrec@1 93.750 (83.557)\n",
            "Test: [30/157]\tTime 0.044 (0.046)\tLoss 0.7982 (0.5688)\tPrec@1 78.125 (82.661)\n",
            "Test: [40/157]\tTime 0.041 (0.045)\tLoss 0.3070 (0.5533)\tPrec@1 89.062 (83.003)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.1948 (0.5418)\tPrec@1 92.188 (83.180)\n",
            "Test: [60/157]\tTime 0.043 (0.045)\tLoss 0.4996 (0.5428)\tPrec@1 81.250 (83.094)\n",
            "Test: [70/157]\tTime 0.041 (0.045)\tLoss 0.6362 (0.5543)\tPrec@1 79.688 (82.879)\n",
            "Test: [80/157]\tTime 0.042 (0.045)\tLoss 0.4595 (0.5586)\tPrec@1 84.375 (82.870)\n",
            "Test: [90/157]\tTime 0.044 (0.045)\tLoss 0.5498 (0.5592)\tPrec@1 79.688 (82.709)\n",
            "Test: [100/157]\tTime 0.044 (0.045)\tLoss 0.6647 (0.5577)\tPrec@1 82.812 (82.704)\n",
            "Test: [110/157]\tTime 0.044 (0.044)\tLoss 0.5459 (0.5531)\tPrec@1 84.375 (82.841)\n",
            "Test: [120/157]\tTime 0.043 (0.044)\tLoss 0.4877 (0.5557)\tPrec@1 81.250 (82.670)\n",
            "Test: [130/157]\tTime 0.041 (0.044)\tLoss 0.4018 (0.5595)\tPrec@1 82.812 (82.634)\n",
            "Test: [140/157]\tTime 0.046 (0.044)\tLoss 0.7153 (0.5575)\tPrec@1 79.688 (82.691)\n",
            "Test: [150/157]\tTime 0.053 (0.044)\tLoss 0.7069 (0.5575)\tPrec@1 78.125 (82.668)\n",
            " * Prec@1 82.700\n",
            "Best accuracy:  tensor(86.6700, device='cuda:0')\n",
            "Epoch: [21][0/782]\tTime 0.276 (0.276)\tLoss 0.1907 (0.1907)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [21][10/782]\tTime 0.168 (0.178)\tLoss 0.3399 (0.2826)\tPrec@1 87.500 (90.767)\n",
            "Epoch: [21][20/782]\tTime 0.167 (0.173)\tLoss 0.4374 (0.2976)\tPrec@1 81.250 (89.658)\n",
            "Epoch: [21][30/782]\tTime 0.169 (0.171)\tLoss 0.4989 (0.2928)\tPrec@1 82.812 (89.718)\n",
            "Epoch: [21][40/782]\tTime 0.168 (0.170)\tLoss 0.1594 (0.2834)\tPrec@1 93.750 (90.091)\n",
            "Epoch: [21][50/782]\tTime 0.167 (0.170)\tLoss 0.1790 (0.2907)\tPrec@1 95.312 (89.859)\n",
            "Epoch: [21][60/782]\tTime 0.166 (0.169)\tLoss 0.1981 (0.2822)\tPrec@1 90.625 (90.190)\n",
            "Epoch: [21][70/782]\tTime 0.168 (0.169)\tLoss 0.3170 (0.2752)\tPrec@1 90.625 (90.559)\n",
            "Epoch: [21][80/782]\tTime 0.167 (0.169)\tLoss 0.2197 (0.2728)\tPrec@1 90.625 (90.683)\n",
            "Epoch: [21][90/782]\tTime 0.168 (0.169)\tLoss 0.2282 (0.2718)\tPrec@1 93.750 (90.711)\n",
            "Epoch: [21][100/782]\tTime 0.167 (0.169)\tLoss 0.2566 (0.2697)\tPrec@1 92.188 (90.811)\n",
            "Epoch: [21][110/782]\tTime 0.169 (0.169)\tLoss 0.1839 (0.2660)\tPrec@1 92.188 (90.892)\n",
            "Epoch: [21][120/782]\tTime 0.166 (0.169)\tLoss 0.2677 (0.2677)\tPrec@1 90.625 (90.883)\n",
            "Epoch: [21][130/782]\tTime 0.172 (0.169)\tLoss 0.3304 (0.2691)\tPrec@1 85.938 (90.804)\n",
            "Epoch: [21][140/782]\tTime 0.167 (0.169)\tLoss 0.3078 (0.2700)\tPrec@1 85.938 (90.703)\n",
            "Epoch: [21][150/782]\tTime 0.165 (0.169)\tLoss 0.1980 (0.2670)\tPrec@1 93.750 (90.842)\n",
            "Epoch: [21][160/782]\tTime 0.171 (0.169)\tLoss 0.1819 (0.2671)\tPrec@1 93.750 (90.848)\n",
            "Epoch: [21][170/782]\tTime 0.166 (0.169)\tLoss 0.1805 (0.2681)\tPrec@1 90.625 (90.744)\n",
            "Epoch: [21][180/782]\tTime 0.166 (0.169)\tLoss 0.5329 (0.2672)\tPrec@1 78.125 (90.754)\n",
            "Epoch: [21][190/782]\tTime 0.172 (0.169)\tLoss 0.2589 (0.2657)\tPrec@1 89.062 (90.756)\n",
            "Epoch: [21][200/782]\tTime 0.167 (0.169)\tLoss 0.2451 (0.2653)\tPrec@1 92.188 (90.804)\n",
            "Epoch: [21][210/782]\tTime 0.166 (0.169)\tLoss 0.2945 (0.2663)\tPrec@1 89.062 (90.758)\n",
            "Epoch: [21][220/782]\tTime 0.166 (0.169)\tLoss 0.4084 (0.2706)\tPrec@1 81.250 (90.597)\n",
            "Epoch: [21][230/782]\tTime 0.167 (0.169)\tLoss 0.3811 (0.2716)\tPrec@1 85.938 (90.490)\n",
            "Epoch: [21][240/782]\tTime 0.166 (0.168)\tLoss 0.1688 (0.2707)\tPrec@1 90.625 (90.495)\n",
            "Epoch: [21][250/782]\tTime 0.167 (0.168)\tLoss 0.3299 (0.2749)\tPrec@1 89.062 (90.326)\n",
            "Epoch: [21][260/782]\tTime 0.167 (0.168)\tLoss 0.4245 (0.2745)\tPrec@1 87.500 (90.374)\n",
            "Epoch: [21][270/782]\tTime 0.168 (0.168)\tLoss 0.3801 (0.2775)\tPrec@1 82.812 (90.273)\n",
            "Epoch: [21][280/782]\tTime 0.171 (0.168)\tLoss 0.2357 (0.2787)\tPrec@1 89.062 (90.163)\n",
            "Epoch: [21][290/782]\tTime 0.168 (0.168)\tLoss 0.2258 (0.2807)\tPrec@1 93.750 (90.099)\n",
            "Epoch: [21][300/782]\tTime 0.166 (0.168)\tLoss 0.4199 (0.2809)\tPrec@1 82.812 (90.085)\n",
            "Epoch: [21][310/782]\tTime 0.166 (0.168)\tLoss 0.2547 (0.2811)\tPrec@1 93.750 (90.108)\n",
            "Epoch: [21][320/782]\tTime 0.166 (0.168)\tLoss 0.2805 (0.2801)\tPrec@1 87.500 (90.133)\n",
            "Epoch: [21][330/782]\tTime 0.167 (0.168)\tLoss 0.3227 (0.2794)\tPrec@1 89.062 (90.153)\n",
            "Epoch: [21][340/782]\tTime 0.168 (0.168)\tLoss 0.2200 (0.2786)\tPrec@1 92.188 (90.194)\n",
            "Epoch: [21][350/782]\tTime 0.167 (0.168)\tLoss 0.3676 (0.2796)\tPrec@1 89.062 (90.144)\n",
            "Epoch: [21][360/782]\tTime 0.167 (0.168)\tLoss 0.3998 (0.2800)\tPrec@1 84.375 (90.158)\n",
            "Epoch: [21][370/782]\tTime 0.166 (0.168)\tLoss 0.2197 (0.2793)\tPrec@1 90.625 (90.187)\n",
            "Epoch: [21][380/782]\tTime 0.169 (0.168)\tLoss 0.3102 (0.2798)\tPrec@1 90.625 (90.194)\n",
            "Epoch: [21][390/782]\tTime 0.167 (0.168)\tLoss 0.3257 (0.2798)\tPrec@1 89.062 (90.157)\n",
            "Epoch: [21][400/782]\tTime 0.167 (0.168)\tLoss 0.2917 (0.2804)\tPrec@1 90.625 (90.138)\n",
            "Epoch: [21][410/782]\tTime 0.167 (0.168)\tLoss 0.1968 (0.2823)\tPrec@1 95.312 (90.108)\n",
            "Epoch: [21][420/782]\tTime 0.169 (0.168)\tLoss 0.5004 (0.2828)\tPrec@1 79.688 (90.072)\n",
            "Epoch: [21][430/782]\tTime 0.166 (0.168)\tLoss 0.1598 (0.2818)\tPrec@1 95.312 (90.128)\n",
            "Epoch: [21][440/782]\tTime 0.166 (0.168)\tLoss 0.4076 (0.2823)\tPrec@1 84.375 (90.125)\n",
            "Epoch: [21][450/782]\tTime 0.170 (0.168)\tLoss 0.3650 (0.2838)\tPrec@1 87.500 (90.064)\n",
            "Epoch: [21][460/782]\tTime 0.166 (0.168)\tLoss 0.1555 (0.2834)\tPrec@1 96.875 (90.079)\n",
            "Epoch: [21][470/782]\tTime 0.167 (0.168)\tLoss 0.3143 (0.2832)\tPrec@1 85.938 (90.068)\n",
            "Epoch: [21][480/782]\tTime 0.170 (0.168)\tLoss 0.4470 (0.2837)\tPrec@1 81.250 (90.040)\n",
            "Epoch: [21][490/782]\tTime 0.168 (0.168)\tLoss 0.2446 (0.2840)\tPrec@1 92.188 (90.033)\n",
            "Epoch: [21][500/782]\tTime 0.167 (0.168)\tLoss 0.3100 (0.2840)\tPrec@1 87.500 (90.032)\n",
            "Epoch: [21][510/782]\tTime 0.168 (0.168)\tLoss 0.3402 (0.2848)\tPrec@1 81.250 (89.974)\n",
            "Epoch: [21][520/782]\tTime 0.168 (0.168)\tLoss 0.3524 (0.2854)\tPrec@1 84.375 (89.974)\n",
            "Epoch: [21][530/782]\tTime 0.167 (0.168)\tLoss 0.3522 (0.2857)\tPrec@1 92.188 (89.986)\n",
            "Epoch: [21][540/782]\tTime 0.168 (0.168)\tLoss 0.2097 (0.2856)\tPrec@1 92.188 (89.978)\n",
            "Epoch: [21][550/782]\tTime 0.167 (0.168)\tLoss 0.3582 (0.2849)\tPrec@1 87.500 (90.004)\n",
            "Epoch: [21][560/782]\tTime 0.167 (0.168)\tLoss 0.3910 (0.2853)\tPrec@1 87.500 (89.968)\n",
            "Epoch: [21][570/782]\tTime 0.167 (0.168)\tLoss 0.3763 (0.2859)\tPrec@1 81.250 (89.933)\n",
            "Epoch: [21][580/782]\tTime 0.167 (0.168)\tLoss 0.3011 (0.2852)\tPrec@1 87.500 (89.971)\n",
            "Epoch: [21][590/782]\tTime 0.166 (0.168)\tLoss 0.2380 (0.2853)\tPrec@1 92.188 (89.964)\n",
            "Epoch: [21][600/782]\tTime 0.172 (0.168)\tLoss 0.2715 (0.2856)\tPrec@1 90.625 (89.954)\n",
            "Epoch: [21][610/782]\tTime 0.167 (0.168)\tLoss 0.2930 (0.2864)\tPrec@1 87.500 (89.927)\n",
            "Epoch: [21][620/782]\tTime 0.166 (0.168)\tLoss 0.3044 (0.2871)\tPrec@1 87.500 (89.920)\n",
            "Epoch: [21][630/782]\tTime 0.168 (0.168)\tLoss 0.2392 (0.2884)\tPrec@1 93.750 (89.904)\n",
            "Epoch: [21][640/782]\tTime 0.168 (0.168)\tLoss 0.3483 (0.2883)\tPrec@1 85.938 (89.901)\n",
            "Epoch: [21][650/782]\tTime 0.166 (0.168)\tLoss 0.2826 (0.2883)\tPrec@1 89.062 (89.907)\n",
            "Epoch: [21][660/782]\tTime 0.170 (0.168)\tLoss 0.2455 (0.2888)\tPrec@1 89.062 (89.876)\n",
            "Epoch: [21][670/782]\tTime 0.167 (0.168)\tLoss 0.2770 (0.2886)\tPrec@1 90.625 (89.896)\n",
            "Epoch: [21][680/782]\tTime 0.168 (0.168)\tLoss 0.3929 (0.2889)\tPrec@1 85.938 (89.888)\n",
            "Epoch: [21][690/782]\tTime 0.167 (0.168)\tLoss 0.1754 (0.2886)\tPrec@1 93.750 (89.904)\n",
            "Epoch: [21][700/782]\tTime 0.170 (0.168)\tLoss 0.2207 (0.2887)\tPrec@1 90.625 (89.930)\n",
            "Epoch: [21][710/782]\tTime 0.167 (0.168)\tLoss 0.2244 (0.2884)\tPrec@1 90.625 (89.944)\n",
            "Epoch: [21][720/782]\tTime 0.167 (0.168)\tLoss 0.2000 (0.2878)\tPrec@1 92.188 (89.971)\n",
            "Epoch: [21][730/782]\tTime 0.167 (0.168)\tLoss 0.3088 (0.2880)\tPrec@1 85.938 (89.969)\n",
            "Epoch: [21][740/782]\tTime 0.168 (0.168)\tLoss 0.4426 (0.2890)\tPrec@1 87.500 (89.950)\n",
            "Epoch: [21][750/782]\tTime 0.167 (0.168)\tLoss 0.3100 (0.2892)\tPrec@1 92.188 (89.940)\n",
            "Epoch: [21][760/782]\tTime 0.167 (0.168)\tLoss 0.3004 (0.2896)\tPrec@1 92.188 (89.915)\n",
            "Epoch: [21][770/782]\tTime 0.166 (0.168)\tLoss 0.2073 (0.2896)\tPrec@1 90.625 (89.918)\n",
            "Epoch: [21][780/782]\tTime 0.161 (0.168)\tLoss 0.3010 (0.2893)\tPrec@1 89.062 (89.933)\n",
            "Training accuracy:  tensor(89.9300, device='cuda:0')\n",
            "Best accuraacy:  tensor(89.9300, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.122 (0.122)\tLoss 0.1767 (0.1767)\tPrec@1 95.312 (95.312)\n",
            "Test: [10/157]\tTime 0.042 (0.048)\tLoss 0.2434 (0.3277)\tPrec@1 89.062 (89.915)\n",
            "Test: [20/157]\tTime 0.049 (0.046)\tLoss 0.4637 (0.3419)\tPrec@1 85.938 (89.137)\n",
            "Test: [30/157]\tTime 0.044 (0.046)\tLoss 0.2903 (0.3770)\tPrec@1 89.062 (88.206)\n",
            "Test: [40/157]\tTime 0.043 (0.045)\tLoss 0.3569 (0.3832)\tPrec@1 89.062 (87.957)\n",
            "Test: [50/157]\tTime 0.046 (0.045)\tLoss 0.4092 (0.3757)\tPrec@1 82.812 (87.837)\n",
            "Test: [60/157]\tTime 0.044 (0.045)\tLoss 0.6387 (0.3834)\tPrec@1 78.125 (87.526)\n",
            "Test: [70/157]\tTime 0.042 (0.045)\tLoss 0.4179 (0.3848)\tPrec@1 87.500 (87.610)\n",
            "Test: [80/157]\tTime 0.043 (0.045)\tLoss 0.5578 (0.3808)\tPrec@1 79.688 (87.616)\n",
            "Test: [90/157]\tTime 0.044 (0.045)\tLoss 0.5374 (0.3830)\tPrec@1 89.062 (87.603)\n",
            "Test: [100/157]\tTime 0.043 (0.045)\tLoss 0.5985 (0.3846)\tPrec@1 84.375 (87.577)\n",
            "Test: [110/157]\tTime 0.043 (0.044)\tLoss 0.5694 (0.3943)\tPrec@1 84.375 (87.444)\n",
            "Test: [120/157]\tTime 0.043 (0.044)\tLoss 0.3609 (0.3963)\tPrec@1 85.938 (87.461)\n",
            "Test: [130/157]\tTime 0.043 (0.044)\tLoss 0.4831 (0.3957)\tPrec@1 82.812 (87.428)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.3614 (0.3957)\tPrec@1 89.062 (87.522)\n",
            "Test: [150/157]\tTime 0.043 (0.044)\tLoss 0.4193 (0.3935)\tPrec@1 87.500 (87.583)\n",
            " * Prec@1 87.570\n",
            "Best accuracy:  tensor(87.5700, device='cuda:0')\n",
            "Epoch: [22][0/782]\tTime 0.282 (0.282)\tLoss 0.2580 (0.2580)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [22][10/782]\tTime 0.166 (0.178)\tLoss 0.2699 (0.3051)\tPrec@1 90.625 (90.341)\n",
            "Epoch: [22][20/782]\tTime 0.167 (0.173)\tLoss 0.4230 (0.3077)\tPrec@1 85.938 (89.658)\n",
            "Epoch: [22][30/782]\tTime 0.170 (0.171)\tLoss 0.3821 (0.2963)\tPrec@1 87.500 (89.667)\n",
            "Epoch: [22][40/782]\tTime 0.167 (0.171)\tLoss 0.2650 (0.2989)\tPrec@1 93.750 (89.444)\n",
            "Epoch: [22][50/782]\tTime 0.167 (0.170)\tLoss 0.1523 (0.3003)\tPrec@1 95.312 (89.430)\n",
            "Epoch: [22][60/782]\tTime 0.167 (0.170)\tLoss 0.7265 (0.3056)\tPrec@1 75.000 (89.344)\n",
            "Epoch: [22][70/782]\tTime 0.166 (0.169)\tLoss 0.2238 (0.2972)\tPrec@1 89.062 (89.525)\n",
            "Epoch: [22][80/782]\tTime 0.166 (0.169)\tLoss 0.2232 (0.2913)\tPrec@1 89.062 (89.699)\n",
            "Epoch: [22][90/782]\tTime 0.168 (0.169)\tLoss 0.4365 (0.2895)\tPrec@1 85.938 (89.663)\n",
            "Epoch: [22][100/782]\tTime 0.168 (0.169)\tLoss 0.2348 (0.2870)\tPrec@1 90.625 (89.805)\n",
            "Epoch: [22][110/782]\tTime 0.169 (0.169)\tLoss 0.1991 (0.2890)\tPrec@1 93.750 (89.794)\n",
            "Epoch: [22][120/782]\tTime 0.169 (0.168)\tLoss 0.2818 (0.2854)\tPrec@1 90.625 (90.018)\n",
            "Epoch: [22][130/782]\tTime 0.167 (0.168)\tLoss 0.4008 (0.2842)\tPrec@1 87.500 (90.100)\n",
            "Epoch: [22][140/782]\tTime 0.168 (0.168)\tLoss 0.2408 (0.2814)\tPrec@1 92.188 (90.204)\n",
            "Epoch: [22][150/782]\tTime 0.167 (0.168)\tLoss 0.2729 (0.2795)\tPrec@1 92.188 (90.315)\n",
            "Epoch: [22][160/782]\tTime 0.166 (0.168)\tLoss 0.2572 (0.2778)\tPrec@1 90.625 (90.421)\n",
            "Epoch: [22][170/782]\tTime 0.168 (0.168)\tLoss 0.2201 (0.2766)\tPrec@1 95.312 (90.451)\n",
            "Epoch: [22][180/782]\tTime 0.167 (0.168)\tLoss 0.3485 (0.2761)\tPrec@1 92.188 (90.478)\n",
            "Epoch: [22][190/782]\tTime 0.167 (0.168)\tLoss 0.2010 (0.2768)\tPrec@1 93.750 (90.429)\n",
            "Epoch: [22][200/782]\tTime 0.166 (0.168)\tLoss 0.2538 (0.2778)\tPrec@1 90.625 (90.438)\n",
            "Epoch: [22][210/782]\tTime 0.168 (0.168)\tLoss 0.5797 (0.2817)\tPrec@1 78.125 (90.299)\n",
            "Epoch: [22][220/782]\tTime 0.167 (0.168)\tLoss 0.3692 (0.2809)\tPrec@1 90.625 (90.349)\n",
            "Epoch: [22][230/782]\tTime 0.167 (0.168)\tLoss 0.2452 (0.2802)\tPrec@1 90.625 (90.341)\n",
            "Epoch: [22][240/782]\tTime 0.169 (0.168)\tLoss 0.2881 (0.2812)\tPrec@1 84.375 (90.281)\n",
            "Epoch: [22][250/782]\tTime 0.166 (0.168)\tLoss 0.5319 (0.2828)\tPrec@1 79.688 (90.233)\n",
            "Epoch: [22][260/782]\tTime 0.167 (0.168)\tLoss 0.3689 (0.2845)\tPrec@1 81.250 (90.194)\n",
            "Epoch: [22][270/782]\tTime 0.167 (0.168)\tLoss 0.3339 (0.2847)\tPrec@1 87.500 (90.210)\n",
            "Epoch: [22][280/782]\tTime 0.167 (0.168)\tLoss 0.2123 (0.2855)\tPrec@1 95.312 (90.214)\n",
            "Epoch: [22][290/782]\tTime 0.170 (0.168)\tLoss 0.2191 (0.2855)\tPrec@1 92.188 (90.212)\n",
            "Epoch: [22][300/782]\tTime 0.168 (0.168)\tLoss 0.4813 (0.2868)\tPrec@1 84.375 (90.153)\n",
            "Epoch: [22][310/782]\tTime 0.169 (0.168)\tLoss 0.3483 (0.2877)\tPrec@1 87.500 (90.108)\n",
            "Epoch: [22][320/782]\tTime 0.171 (0.168)\tLoss 0.2091 (0.2877)\tPrec@1 93.750 (90.094)\n",
            "Epoch: [22][330/782]\tTime 0.166 (0.168)\tLoss 0.2390 (0.2869)\tPrec@1 89.062 (90.125)\n",
            "Epoch: [22][340/782]\tTime 0.166 (0.168)\tLoss 0.2044 (0.2864)\tPrec@1 90.625 (90.171)\n",
            "Epoch: [22][350/782]\tTime 0.166 (0.168)\tLoss 0.3364 (0.2862)\tPrec@1 89.062 (90.189)\n",
            "Epoch: [22][360/782]\tTime 0.169 (0.168)\tLoss 0.3202 (0.2861)\tPrec@1 92.188 (90.205)\n",
            "Epoch: [22][370/782]\tTime 0.166 (0.168)\tLoss 0.2591 (0.2850)\tPrec@1 89.062 (90.275)\n",
            "Epoch: [22][380/782]\tTime 0.167 (0.168)\tLoss 0.2003 (0.2851)\tPrec@1 93.750 (90.231)\n",
            "Epoch: [22][390/782]\tTime 0.170 (0.168)\tLoss 0.2969 (0.2855)\tPrec@1 93.750 (90.253)\n",
            "Epoch: [22][400/782]\tTime 0.167 (0.168)\tLoss 0.1962 (0.2855)\tPrec@1 93.750 (90.251)\n",
            "Epoch: [22][410/782]\tTime 0.168 (0.168)\tLoss 0.5850 (0.2864)\tPrec@1 76.562 (90.211)\n",
            "Epoch: [22][420/782]\tTime 0.168 (0.168)\tLoss 0.3110 (0.2864)\tPrec@1 90.625 (90.206)\n",
            "Epoch: [22][430/782]\tTime 0.166 (0.168)\tLoss 0.2452 (0.2857)\tPrec@1 90.625 (90.212)\n",
            "Epoch: [22][440/782]\tTime 0.167 (0.168)\tLoss 0.2258 (0.2857)\tPrec@1 93.750 (90.218)\n",
            "Epoch: [22][450/782]\tTime 0.166 (0.168)\tLoss 0.3515 (0.2855)\tPrec@1 90.625 (90.206)\n",
            "Epoch: [22][460/782]\tTime 0.169 (0.168)\tLoss 0.1721 (0.2858)\tPrec@1 93.750 (90.198)\n",
            "Epoch: [22][470/782]\tTime 0.167 (0.168)\tLoss 0.1922 (0.2851)\tPrec@1 90.625 (90.230)\n",
            "Epoch: [22][480/782]\tTime 0.166 (0.168)\tLoss 0.3353 (0.2855)\tPrec@1 85.938 (90.206)\n",
            "Epoch: [22][490/782]\tTime 0.165 (0.168)\tLoss 0.2135 (0.2862)\tPrec@1 92.188 (90.167)\n",
            "Epoch: [22][500/782]\tTime 0.167 (0.168)\tLoss 0.3315 (0.2862)\tPrec@1 89.062 (90.142)\n",
            "Epoch: [22][510/782]\tTime 0.166 (0.168)\tLoss 0.3108 (0.2856)\tPrec@1 85.938 (90.145)\n",
            "Epoch: [22][520/782]\tTime 0.167 (0.168)\tLoss 0.3566 (0.2855)\tPrec@1 89.062 (90.148)\n",
            "Epoch: [22][530/782]\tTime 0.168 (0.168)\tLoss 0.2720 (0.2856)\tPrec@1 90.625 (90.145)\n",
            "Epoch: [22][540/782]\tTime 0.167 (0.168)\tLoss 0.4085 (0.2855)\tPrec@1 84.375 (90.154)\n",
            "Epoch: [22][550/782]\tTime 0.167 (0.168)\tLoss 0.4025 (0.2860)\tPrec@1 85.938 (90.149)\n",
            "Epoch: [22][560/782]\tTime 0.166 (0.168)\tLoss 0.3029 (0.2859)\tPrec@1 90.625 (90.163)\n",
            "Epoch: [22][570/782]\tTime 0.167 (0.168)\tLoss 0.2231 (0.2861)\tPrec@1 90.625 (90.138)\n",
            "Epoch: [22][580/782]\tTime 0.167 (0.168)\tLoss 0.4128 (0.2860)\tPrec@1 87.500 (90.152)\n",
            "Epoch: [22][590/782]\tTime 0.166 (0.168)\tLoss 0.3650 (0.2863)\tPrec@1 85.938 (90.144)\n",
            "Epoch: [22][600/782]\tTime 0.168 (0.168)\tLoss 0.4113 (0.2857)\tPrec@1 85.938 (90.162)\n",
            "Epoch: [22][610/782]\tTime 0.173 (0.168)\tLoss 0.3183 (0.2861)\tPrec@1 87.500 (90.147)\n",
            "Epoch: [22][620/782]\tTime 0.168 (0.168)\tLoss 0.3186 (0.2863)\tPrec@1 90.625 (90.132)\n",
            "Epoch: [22][630/782]\tTime 0.167 (0.168)\tLoss 0.2799 (0.2862)\tPrec@1 87.500 (90.130)\n",
            "Epoch: [22][640/782]\tTime 0.170 (0.168)\tLoss 0.2519 (0.2861)\tPrec@1 92.188 (90.135)\n",
            "Epoch: [22][650/782]\tTime 0.168 (0.168)\tLoss 0.2428 (0.2857)\tPrec@1 87.500 (90.131)\n",
            "Epoch: [22][660/782]\tTime 0.166 (0.168)\tLoss 0.1171 (0.2858)\tPrec@1 98.438 (90.147)\n",
            "Epoch: [22][670/782]\tTime 0.169 (0.168)\tLoss 0.3491 (0.2864)\tPrec@1 87.500 (90.124)\n",
            "Epoch: [22][680/782]\tTime 0.168 (0.168)\tLoss 0.3922 (0.2868)\tPrec@1 89.062 (90.102)\n",
            "Epoch: [22][690/782]\tTime 0.167 (0.168)\tLoss 0.4935 (0.2873)\tPrec@1 76.562 (90.082)\n",
            "Epoch: [22][700/782]\tTime 0.168 (0.168)\tLoss 0.0949 (0.2870)\tPrec@1 100.000 (90.081)\n",
            "Epoch: [22][710/782]\tTime 0.167 (0.168)\tLoss 0.3240 (0.2873)\tPrec@1 87.500 (90.071)\n",
            "Epoch: [22][720/782]\tTime 0.167 (0.168)\tLoss 0.2055 (0.2875)\tPrec@1 92.188 (90.053)\n",
            "Epoch: [22][730/782]\tTime 0.170 (0.168)\tLoss 0.1981 (0.2872)\tPrec@1 92.188 (90.056)\n",
            "Epoch: [22][740/782]\tTime 0.168 (0.168)\tLoss 0.3515 (0.2872)\tPrec@1 90.625 (90.049)\n",
            "Epoch: [22][750/782]\tTime 0.167 (0.168)\tLoss 0.3313 (0.2880)\tPrec@1 90.625 (90.026)\n",
            "Epoch: [22][760/782]\tTime 0.166 (0.168)\tLoss 0.1299 (0.2878)\tPrec@1 96.875 (90.034)\n",
            "Epoch: [22][770/782]\tTime 0.167 (0.168)\tLoss 0.1625 (0.2876)\tPrec@1 93.750 (90.051)\n",
            "Epoch: [22][780/782]\tTime 0.161 (0.168)\tLoss 0.4988 (0.2879)\tPrec@1 81.250 (90.029)\n",
            "Training accuracy:  tensor(90.0260, device='cuda:0')\n",
            "Best accuraacy:  tensor(90.0260, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.125 (0.125)\tLoss 0.3816 (0.3816)\tPrec@1 89.062 (89.062)\n",
            "Test: [10/157]\tTime 0.042 (0.049)\tLoss 0.3695 (0.4299)\tPrec@1 89.062 (84.517)\n",
            "Test: [20/157]\tTime 0.044 (0.046)\tLoss 0.6249 (0.4324)\tPrec@1 82.812 (86.161)\n",
            "Test: [30/157]\tTime 0.042 (0.046)\tLoss 0.5289 (0.4441)\tPrec@1 75.000 (85.484)\n",
            "Test: [40/157]\tTime 0.042 (0.045)\tLoss 0.3022 (0.4247)\tPrec@1 90.625 (85.785)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.6524 (0.4210)\tPrec@1 82.812 (85.999)\n",
            "Test: [60/157]\tTime 0.039 (0.045)\tLoss 0.3810 (0.4342)\tPrec@1 85.938 (85.861)\n",
            "Test: [70/157]\tTime 0.043 (0.045)\tLoss 0.5624 (0.4303)\tPrec@1 79.688 (85.739)\n",
            "Test: [80/157]\tTime 0.050 (0.045)\tLoss 0.4579 (0.4302)\tPrec@1 84.375 (85.552)\n",
            "Test: [90/157]\tTime 0.045 (0.045)\tLoss 0.5661 (0.4343)\tPrec@1 82.812 (85.594)\n",
            "Test: [100/157]\tTime 0.043 (0.044)\tLoss 0.4582 (0.4386)\tPrec@1 82.812 (85.597)\n",
            "Test: [110/157]\tTime 0.044 (0.044)\tLoss 0.2775 (0.4341)\tPrec@1 87.500 (85.656)\n",
            "Test: [120/157]\tTime 0.043 (0.044)\tLoss 0.4281 (0.4291)\tPrec@1 79.688 (85.757)\n",
            "Test: [130/157]\tTime 0.043 (0.044)\tLoss 0.3684 (0.4301)\tPrec@1 89.062 (85.771)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.3982 (0.4260)\tPrec@1 85.938 (85.793)\n",
            "Test: [150/157]\tTime 0.051 (0.044)\tLoss 0.5289 (0.4261)\tPrec@1 82.812 (85.896)\n",
            " * Prec@1 85.780\n",
            "Best accuracy:  tensor(87.5700, device='cuda:0')\n",
            "Epoch: [23][0/782]\tTime 0.275 (0.275)\tLoss 0.3410 (0.3410)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [23][10/782]\tTime 0.167 (0.178)\tLoss 0.2452 (0.2697)\tPrec@1 89.062 (89.915)\n",
            "Epoch: [23][20/782]\tTime 0.167 (0.173)\tLoss 0.3833 (0.2681)\tPrec@1 85.938 (90.030)\n",
            "Epoch: [23][30/782]\tTime 0.169 (0.171)\tLoss 0.1915 (0.2749)\tPrec@1 93.750 (90.272)\n",
            "Epoch: [23][40/782]\tTime 0.166 (0.171)\tLoss 0.2492 (0.2596)\tPrec@1 92.188 (90.739)\n",
            "Epoch: [23][50/782]\tTime 0.167 (0.170)\tLoss 0.3322 (0.2680)\tPrec@1 90.625 (90.901)\n",
            "Epoch: [23][60/782]\tTime 0.168 (0.170)\tLoss 0.2314 (0.2690)\tPrec@1 90.625 (90.830)\n",
            "Epoch: [23][70/782]\tTime 0.166 (0.169)\tLoss 0.2252 (0.2604)\tPrec@1 90.625 (91.109)\n",
            "Epoch: [23][80/782]\tTime 0.166 (0.169)\tLoss 0.2421 (0.2681)\tPrec@1 93.750 (90.876)\n",
            "Epoch: [23][90/782]\tTime 0.167 (0.169)\tLoss 0.2309 (0.2661)\tPrec@1 89.062 (90.831)\n",
            "Epoch: [23][100/782]\tTime 0.167 (0.169)\tLoss 0.1838 (0.2701)\tPrec@1 93.750 (90.764)\n",
            "Epoch: [23][110/782]\tTime 0.167 (0.169)\tLoss 0.2460 (0.2731)\tPrec@1 87.500 (90.695)\n",
            "Epoch: [23][120/782]\tTime 0.167 (0.169)\tLoss 0.3917 (0.2802)\tPrec@1 85.938 (90.483)\n",
            "Epoch: [23][130/782]\tTime 0.173 (0.169)\tLoss 0.2968 (0.2798)\tPrec@1 89.062 (90.446)\n",
            "Epoch: [23][140/782]\tTime 0.166 (0.169)\tLoss 0.2369 (0.2797)\tPrec@1 95.312 (90.514)\n",
            "Epoch: [23][150/782]\tTime 0.168 (0.169)\tLoss 0.2870 (0.2798)\tPrec@1 90.625 (90.522)\n",
            "Epoch: [23][160/782]\tTime 0.171 (0.169)\tLoss 0.2041 (0.2803)\tPrec@1 93.750 (90.518)\n",
            "Epoch: [23][170/782]\tTime 0.166 (0.169)\tLoss 0.1279 (0.2796)\tPrec@1 96.875 (90.561)\n",
            "Epoch: [23][180/782]\tTime 0.167 (0.169)\tLoss 0.2029 (0.2808)\tPrec@1 92.188 (90.452)\n",
            "Epoch: [23][190/782]\tTime 0.167 (0.168)\tLoss 0.3926 (0.2824)\tPrec@1 84.375 (90.363)\n",
            "Epoch: [23][200/782]\tTime 0.167 (0.168)\tLoss 0.3872 (0.2834)\tPrec@1 84.375 (90.252)\n",
            "Epoch: [23][210/782]\tTime 0.167 (0.168)\tLoss 0.3655 (0.2843)\tPrec@1 90.625 (90.210)\n",
            "Epoch: [23][220/782]\tTime 0.168 (0.168)\tLoss 0.2136 (0.2841)\tPrec@1 92.188 (90.158)\n",
            "Epoch: [23][230/782]\tTime 0.166 (0.168)\tLoss 0.1653 (0.2842)\tPrec@1 93.750 (90.138)\n",
            "Epoch: [23][240/782]\tTime 0.168 (0.168)\tLoss 0.2492 (0.2834)\tPrec@1 92.188 (90.171)\n",
            "Epoch: [23][250/782]\tTime 0.169 (0.168)\tLoss 0.2284 (0.2845)\tPrec@1 92.188 (90.108)\n",
            "Epoch: [23][260/782]\tTime 0.166 (0.168)\tLoss 0.2911 (0.2851)\tPrec@1 87.500 (90.062)\n",
            "Epoch: [23][270/782]\tTime 0.167 (0.168)\tLoss 0.2434 (0.2846)\tPrec@1 92.188 (90.100)\n",
            "Epoch: [23][280/782]\tTime 0.168 (0.168)\tLoss 0.2943 (0.2841)\tPrec@1 90.625 (90.119)\n",
            "Epoch: [23][290/782]\tTime 0.167 (0.168)\tLoss 0.2927 (0.2816)\tPrec@1 89.062 (90.222)\n",
            "Epoch: [23][300/782]\tTime 0.167 (0.168)\tLoss 0.4875 (0.2813)\tPrec@1 85.938 (90.205)\n",
            "Epoch: [23][310/782]\tTime 0.168 (0.168)\tLoss 0.4050 (0.2822)\tPrec@1 84.375 (90.153)\n",
            "Epoch: [23][320/782]\tTime 0.166 (0.168)\tLoss 0.3098 (0.2818)\tPrec@1 85.938 (90.148)\n",
            "Epoch: [23][330/782]\tTime 0.166 (0.168)\tLoss 0.5551 (0.2811)\tPrec@1 81.250 (90.210)\n",
            "Epoch: [23][340/782]\tTime 0.169 (0.168)\tLoss 0.3003 (0.2799)\tPrec@1 84.375 (90.263)\n",
            "Epoch: [23][350/782]\tTime 0.167 (0.168)\tLoss 0.2103 (0.2785)\tPrec@1 92.188 (90.340)\n",
            "Epoch: [23][360/782]\tTime 0.166 (0.168)\tLoss 0.1950 (0.2804)\tPrec@1 93.750 (90.283)\n",
            "Epoch: [23][370/782]\tTime 0.170 (0.168)\tLoss 0.2856 (0.2813)\tPrec@1 92.188 (90.259)\n",
            "Epoch: [23][380/782]\tTime 0.166 (0.168)\tLoss 0.1797 (0.2806)\tPrec@1 89.062 (90.268)\n",
            "Epoch: [23][390/782]\tTime 0.169 (0.168)\tLoss 0.1553 (0.2813)\tPrec@1 93.750 (90.225)\n",
            "Epoch: [23][400/782]\tTime 0.170 (0.168)\tLoss 0.2465 (0.2807)\tPrec@1 92.188 (90.263)\n",
            "Epoch: [23][410/782]\tTime 0.166 (0.168)\tLoss 0.1954 (0.2803)\tPrec@1 92.188 (90.283)\n",
            "Epoch: [23][420/782]\tTime 0.167 (0.168)\tLoss 0.3195 (0.2803)\tPrec@1 89.062 (90.280)\n",
            "Epoch: [23][430/782]\tTime 0.167 (0.168)\tLoss 0.1873 (0.2797)\tPrec@1 92.188 (90.302)\n",
            "Epoch: [23][440/782]\tTime 0.168 (0.168)\tLoss 0.1643 (0.2804)\tPrec@1 92.188 (90.274)\n",
            "Epoch: [23][450/782]\tTime 0.167 (0.168)\tLoss 0.1502 (0.2808)\tPrec@1 93.750 (90.258)\n",
            "Epoch: [23][460/782]\tTime 0.165 (0.168)\tLoss 0.2603 (0.2799)\tPrec@1 89.062 (90.279)\n",
            "Epoch: [23][470/782]\tTime 0.167 (0.168)\tLoss 0.3760 (0.2801)\tPrec@1 84.375 (90.283)\n",
            "Epoch: [23][480/782]\tTime 0.167 (0.168)\tLoss 0.1790 (0.2797)\tPrec@1 90.625 (90.313)\n",
            "Epoch: [23][490/782]\tTime 0.167 (0.168)\tLoss 0.4808 (0.2800)\tPrec@1 84.375 (90.304)\n",
            "Epoch: [23][500/782]\tTime 0.167 (0.168)\tLoss 0.2375 (0.2795)\tPrec@1 90.625 (90.319)\n",
            "Epoch: [23][510/782]\tTime 0.171 (0.168)\tLoss 0.1392 (0.2784)\tPrec@1 95.312 (90.368)\n",
            "Epoch: [23][520/782]\tTime 0.167 (0.168)\tLoss 0.2412 (0.2786)\tPrec@1 89.062 (90.349)\n",
            "Epoch: [23][530/782]\tTime 0.167 (0.168)\tLoss 0.3062 (0.2778)\tPrec@1 90.625 (90.395)\n",
            "Epoch: [23][540/782]\tTime 0.170 (0.168)\tLoss 0.4163 (0.2789)\tPrec@1 84.375 (90.371)\n",
            "Epoch: [23][550/782]\tTime 0.166 (0.168)\tLoss 0.2353 (0.2783)\tPrec@1 90.625 (90.392)\n",
            "Epoch: [23][560/782]\tTime 0.169 (0.168)\tLoss 0.2272 (0.2781)\tPrec@1 93.750 (90.399)\n",
            "Epoch: [23][570/782]\tTime 0.167 (0.168)\tLoss 0.2587 (0.2783)\tPrec@1 92.188 (90.381)\n",
            "Epoch: [23][580/782]\tTime 0.166 (0.168)\tLoss 0.2141 (0.2782)\tPrec@1 92.188 (90.380)\n",
            "Epoch: [23][590/782]\tTime 0.167 (0.168)\tLoss 0.3157 (0.2781)\tPrec@1 89.062 (90.384)\n",
            "Epoch: [23][600/782]\tTime 0.169 (0.168)\tLoss 0.2407 (0.2789)\tPrec@1 93.750 (90.362)\n",
            "Epoch: [23][610/782]\tTime 0.166 (0.168)\tLoss 0.3484 (0.2792)\tPrec@1 87.500 (90.333)\n",
            "Epoch: [23][620/782]\tTime 0.168 (0.168)\tLoss 0.4166 (0.2797)\tPrec@1 85.938 (90.328)\n",
            "Epoch: [23][630/782]\tTime 0.173 (0.168)\tLoss 0.4368 (0.2806)\tPrec@1 85.938 (90.293)\n",
            "Epoch: [23][640/782]\tTime 0.168 (0.168)\tLoss 0.4536 (0.2803)\tPrec@1 87.500 (90.308)\n",
            "Epoch: [23][650/782]\tTime 0.167 (0.168)\tLoss 0.2450 (0.2794)\tPrec@1 93.750 (90.349)\n",
            "Epoch: [23][660/782]\tTime 0.167 (0.168)\tLoss 0.2418 (0.2795)\tPrec@1 89.062 (90.351)\n",
            "Epoch: [23][670/782]\tTime 0.166 (0.168)\tLoss 0.2794 (0.2802)\tPrec@1 93.750 (90.343)\n",
            "Epoch: [23][680/782]\tTime 0.168 (0.168)\tLoss 0.2337 (0.2801)\tPrec@1 90.625 (90.320)\n",
            "Epoch: [23][690/782]\tTime 0.168 (0.168)\tLoss 0.3637 (0.2807)\tPrec@1 85.938 (90.302)\n",
            "Epoch: [23][700/782]\tTime 0.167 (0.168)\tLoss 0.5768 (0.2811)\tPrec@1 84.375 (90.293)\n",
            "Epoch: [23][710/782]\tTime 0.166 (0.168)\tLoss 0.4449 (0.2816)\tPrec@1 82.812 (90.280)\n",
            "Epoch: [23][720/782]\tTime 0.168 (0.168)\tLoss 0.2727 (0.2817)\tPrec@1 89.062 (90.263)\n",
            "Epoch: [23][730/782]\tTime 0.168 (0.168)\tLoss 0.2043 (0.2815)\tPrec@1 92.188 (90.262)\n",
            "Epoch: [23][740/782]\tTime 0.167 (0.168)\tLoss 0.2671 (0.2820)\tPrec@1 89.062 (90.222)\n",
            "Epoch: [23][750/782]\tTime 0.168 (0.168)\tLoss 0.2443 (0.2819)\tPrec@1 85.938 (90.205)\n",
            "Epoch: [23][760/782]\tTime 0.168 (0.168)\tLoss 0.2168 (0.2813)\tPrec@1 93.750 (90.241)\n",
            "Epoch: [23][770/782]\tTime 0.167 (0.168)\tLoss 0.2397 (0.2813)\tPrec@1 90.625 (90.248)\n",
            "Epoch: [23][780/782]\tTime 0.162 (0.168)\tLoss 0.3339 (0.2815)\tPrec@1 89.062 (90.245)\n",
            "Training accuracy:  tensor(90.2440, device='cuda:0')\n",
            "Best accuraacy:  tensor(90.2440, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.122 (0.122)\tLoss 0.6369 (0.6369)\tPrec@1 78.125 (78.125)\n",
            "Test: [10/157]\tTime 0.043 (0.049)\tLoss 0.6353 (0.4947)\tPrec@1 81.250 (84.659)\n",
            "Test: [20/157]\tTime 0.050 (0.046)\tLoss 0.4795 (0.5598)\tPrec@1 84.375 (82.515)\n",
            "Test: [30/157]\tTime 0.043 (0.046)\tLoss 0.5746 (0.5595)\tPrec@1 78.125 (82.258)\n",
            "Test: [40/157]\tTime 0.043 (0.045)\tLoss 0.7409 (0.5466)\tPrec@1 78.125 (82.279)\n",
            "Test: [50/157]\tTime 0.044 (0.045)\tLoss 0.3670 (0.5623)\tPrec@1 89.062 (82.108)\n",
            "Test: [60/157]\tTime 0.041 (0.045)\tLoss 0.6511 (0.5534)\tPrec@1 79.688 (82.608)\n",
            "Test: [70/157]\tTime 0.043 (0.045)\tLoss 0.2921 (0.5421)\tPrec@1 93.750 (82.746)\n",
            "Test: [80/157]\tTime 0.043 (0.045)\tLoss 0.4604 (0.5418)\tPrec@1 84.375 (83.044)\n",
            "Test: [90/157]\tTime 0.044 (0.045)\tLoss 0.4746 (0.5329)\tPrec@1 82.812 (83.259)\n",
            "Test: [100/157]\tTime 0.043 (0.044)\tLoss 0.3213 (0.5245)\tPrec@1 87.500 (83.369)\n",
            "Test: [110/157]\tTime 0.046 (0.044)\tLoss 0.2647 (0.5153)\tPrec@1 87.500 (83.573)\n",
            "Test: [120/157]\tTime 0.043 (0.044)\tLoss 0.4576 (0.5103)\tPrec@1 87.500 (83.833)\n",
            "Test: [130/157]\tTime 0.045 (0.044)\tLoss 0.3850 (0.5066)\tPrec@1 84.375 (83.862)\n",
            "Test: [140/157]\tTime 0.045 (0.044)\tLoss 0.3688 (0.5070)\tPrec@1 89.062 (83.854)\n",
            "Test: [150/157]\tTime 0.044 (0.044)\tLoss 0.3202 (0.5019)\tPrec@1 89.062 (84.034)\n",
            " * Prec@1 84.040\n",
            "Best accuracy:  tensor(87.5700, device='cuda:0')\n",
            "Epoch: [24][0/782]\tTime 0.291 (0.291)\tLoss 0.2210 (0.2210)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [24][10/782]\tTime 0.167 (0.178)\tLoss 0.2030 (0.2814)\tPrec@1 95.312 (92.756)\n",
            "Epoch: [24][20/782]\tTime 0.169 (0.173)\tLoss 0.3070 (0.3002)\tPrec@1 89.062 (91.146)\n",
            "Epoch: [24][30/782]\tTime 0.169 (0.172)\tLoss 0.2385 (0.2912)\tPrec@1 93.750 (90.877)\n",
            "Epoch: [24][40/782]\tTime 0.168 (0.171)\tLoss 0.2577 (0.2851)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [24][50/782]\tTime 0.167 (0.171)\tLoss 0.1932 (0.2783)\tPrec@1 96.875 (90.839)\n",
            "Epoch: [24][60/782]\tTime 0.167 (0.170)\tLoss 0.4072 (0.2829)\tPrec@1 84.375 (90.548)\n",
            "Epoch: [24][70/782]\tTime 0.169 (0.170)\tLoss 0.3221 (0.2836)\tPrec@1 92.188 (90.603)\n",
            "Epoch: [24][80/782]\tTime 0.167 (0.170)\tLoss 0.1820 (0.2804)\tPrec@1 95.312 (90.721)\n",
            "Epoch: [24][90/782]\tTime 0.172 (0.170)\tLoss 0.1543 (0.2776)\tPrec@1 95.312 (90.745)\n",
            "Epoch: [24][100/782]\tTime 0.166 (0.170)\tLoss 0.1848 (0.2709)\tPrec@1 92.188 (91.043)\n",
            "Epoch: [24][110/782]\tTime 0.167 (0.169)\tLoss 0.2298 (0.2680)\tPrec@1 92.188 (91.104)\n",
            "Epoch: [24][120/782]\tTime 0.170 (0.169)\tLoss 0.1498 (0.2734)\tPrec@1 95.312 (90.896)\n",
            "Epoch: [24][130/782]\tTime 0.167 (0.169)\tLoss 0.1817 (0.2713)\tPrec@1 93.750 (90.864)\n",
            "Epoch: [24][140/782]\tTime 0.166 (0.169)\tLoss 0.3685 (0.2745)\tPrec@1 87.500 (90.780)\n",
            "Epoch: [24][150/782]\tTime 0.167 (0.169)\tLoss 0.2404 (0.2749)\tPrec@1 92.188 (90.791)\n",
            "Epoch: [24][160/782]\tTime 0.166 (0.169)\tLoss 0.2708 (0.2743)\tPrec@1 89.062 (90.751)\n",
            "Epoch: [24][170/782]\tTime 0.168 (0.169)\tLoss 0.3240 (0.2744)\tPrec@1 92.188 (90.762)\n",
            "Epoch: [24][180/782]\tTime 0.166 (0.169)\tLoss 0.2234 (0.2736)\tPrec@1 92.188 (90.772)\n",
            "Epoch: [24][190/782]\tTime 0.167 (0.169)\tLoss 0.2718 (0.2724)\tPrec@1 90.625 (90.821)\n",
            "Epoch: [24][200/782]\tTime 0.167 (0.169)\tLoss 0.1720 (0.2708)\tPrec@1 93.750 (90.850)\n",
            "Epoch: [24][210/782]\tTime 0.165 (0.169)\tLoss 0.3139 (0.2713)\tPrec@1 92.188 (90.840)\n",
            "Epoch: [24][220/782]\tTime 0.167 (0.169)\tLoss 0.2385 (0.2709)\tPrec@1 90.625 (90.830)\n",
            "Epoch: [24][230/782]\tTime 0.168 (0.169)\tLoss 0.2694 (0.2700)\tPrec@1 90.625 (90.862)\n",
            "Epoch: [24][240/782]\tTime 0.167 (0.169)\tLoss 0.2414 (0.2696)\tPrec@1 92.188 (90.878)\n",
            "Epoch: [24][250/782]\tTime 0.165 (0.169)\tLoss 0.3772 (0.2708)\tPrec@1 89.062 (90.830)\n",
            "Epoch: [24][260/782]\tTime 0.168 (0.169)\tLoss 0.3593 (0.2707)\tPrec@1 85.938 (90.811)\n",
            "Epoch: [24][270/782]\tTime 0.168 (0.168)\tLoss 0.1742 (0.2701)\tPrec@1 93.750 (90.850)\n",
            "Epoch: [24][280/782]\tTime 0.168 (0.168)\tLoss 0.2360 (0.2714)\tPrec@1 92.188 (90.786)\n",
            "Epoch: [24][290/782]\tTime 0.167 (0.168)\tLoss 0.2680 (0.2717)\tPrec@1 90.625 (90.770)\n",
            "Epoch: [24][300/782]\tTime 0.166 (0.168)\tLoss 0.1558 (0.2700)\tPrec@1 93.750 (90.827)\n",
            "Epoch: [24][310/782]\tTime 0.168 (0.168)\tLoss 0.3320 (0.2724)\tPrec@1 87.500 (90.776)\n",
            "Epoch: [24][320/782]\tTime 0.167 (0.168)\tLoss 0.3591 (0.2717)\tPrec@1 84.375 (90.800)\n",
            "Epoch: [24][330/782]\tTime 0.169 (0.168)\tLoss 0.3521 (0.2724)\tPrec@1 93.750 (90.828)\n",
            "Epoch: [24][340/782]\tTime 0.166 (0.168)\tLoss 0.2733 (0.2730)\tPrec@1 89.062 (90.804)\n",
            "Epoch: [24][350/782]\tTime 0.169 (0.168)\tLoss 0.1667 (0.2736)\tPrec@1 95.312 (90.821)\n",
            "Epoch: [24][360/782]\tTime 0.166 (0.168)\tLoss 0.4285 (0.2745)\tPrec@1 84.375 (90.789)\n",
            "Epoch: [24][370/782]\tTime 0.168 (0.168)\tLoss 0.3141 (0.2750)\tPrec@1 93.750 (90.777)\n",
            "Epoch: [24][380/782]\tTime 0.170 (0.168)\tLoss 0.1743 (0.2759)\tPrec@1 93.750 (90.719)\n",
            "Epoch: [24][390/782]\tTime 0.169 (0.168)\tLoss 0.3027 (0.2761)\tPrec@1 89.062 (90.717)\n",
            "Epoch: [24][400/782]\tTime 0.168 (0.168)\tLoss 0.2184 (0.2758)\tPrec@1 93.750 (90.715)\n",
            "Epoch: [24][410/782]\tTime 0.171 (0.168)\tLoss 0.4661 (0.2755)\tPrec@1 84.375 (90.712)\n",
            "Epoch: [24][420/782]\tTime 0.168 (0.168)\tLoss 0.3196 (0.2747)\tPrec@1 92.188 (90.747)\n",
            "Epoch: [24][430/782]\tTime 0.169 (0.168)\tLoss 0.1561 (0.2746)\tPrec@1 96.875 (90.766)\n",
            "Epoch: [24][440/782]\tTime 0.170 (0.168)\tLoss 0.3184 (0.2746)\tPrec@1 89.062 (90.763)\n",
            "Epoch: [24][450/782]\tTime 0.167 (0.168)\tLoss 0.3422 (0.2757)\tPrec@1 90.625 (90.722)\n",
            "Epoch: [24][460/782]\tTime 0.167 (0.168)\tLoss 0.3160 (0.2750)\tPrec@1 93.750 (90.754)\n",
            "Epoch: [24][470/782]\tTime 0.168 (0.168)\tLoss 0.3994 (0.2753)\tPrec@1 87.500 (90.734)\n",
            "Epoch: [24][480/782]\tTime 0.168 (0.168)\tLoss 0.4398 (0.2751)\tPrec@1 82.812 (90.758)\n",
            "Epoch: [24][490/782]\tTime 0.168 (0.168)\tLoss 0.4219 (0.2756)\tPrec@1 85.938 (90.740)\n",
            "Epoch: [24][500/782]\tTime 0.167 (0.168)\tLoss 0.1685 (0.2755)\tPrec@1 95.312 (90.728)\n",
            "Epoch: [24][510/782]\tTime 0.167 (0.168)\tLoss 0.2606 (0.2758)\tPrec@1 89.062 (90.689)\n",
            "Epoch: [24][520/782]\tTime 0.167 (0.168)\tLoss 0.2982 (0.2761)\tPrec@1 87.500 (90.676)\n",
            "Epoch: [24][530/782]\tTime 0.166 (0.168)\tLoss 0.1607 (0.2760)\tPrec@1 93.750 (90.707)\n",
            "Epoch: [24][540/782]\tTime 0.167 (0.168)\tLoss 0.3257 (0.2763)\tPrec@1 90.625 (90.674)\n",
            "Epoch: [24][550/782]\tTime 0.167 (0.168)\tLoss 0.3691 (0.2768)\tPrec@1 84.375 (90.639)\n",
            "Epoch: [24][560/782]\tTime 0.169 (0.168)\tLoss 0.4562 (0.2774)\tPrec@1 84.375 (90.633)\n",
            "Epoch: [24][570/782]\tTime 0.167 (0.168)\tLoss 0.3375 (0.2780)\tPrec@1 89.062 (90.611)\n",
            "Epoch: [24][580/782]\tTime 0.168 (0.168)\tLoss 0.2884 (0.2781)\tPrec@1 89.062 (90.609)\n",
            "Epoch: [24][590/782]\tTime 0.168 (0.168)\tLoss 0.2020 (0.2775)\tPrec@1 92.188 (90.617)\n",
            "Epoch: [24][600/782]\tTime 0.167 (0.168)\tLoss 0.2260 (0.2772)\tPrec@1 93.750 (90.607)\n",
            "Epoch: [24][610/782]\tTime 0.166 (0.168)\tLoss 0.2750 (0.2781)\tPrec@1 90.625 (90.561)\n",
            "Epoch: [24][620/782]\tTime 0.168 (0.168)\tLoss 0.2283 (0.2778)\tPrec@1 89.062 (90.555)\n",
            "Epoch: [24][630/782]\tTime 0.165 (0.168)\tLoss 0.1643 (0.2773)\tPrec@1 96.875 (90.551)\n",
            "Epoch: [24][640/782]\tTime 0.169 (0.168)\tLoss 0.2071 (0.2771)\tPrec@1 95.312 (90.571)\n",
            "Epoch: [24][650/782]\tTime 0.167 (0.168)\tLoss 0.2386 (0.2770)\tPrec@1 90.625 (90.565)\n",
            "Epoch: [24][660/782]\tTime 0.166 (0.168)\tLoss 0.3275 (0.2774)\tPrec@1 85.938 (90.556)\n",
            "Epoch: [24][670/782]\tTime 0.167 (0.168)\tLoss 0.2291 (0.2780)\tPrec@1 90.625 (90.525)\n",
            "Epoch: [24][680/782]\tTime 0.168 (0.168)\tLoss 0.1023 (0.2783)\tPrec@1 95.312 (90.499)\n",
            "Epoch: [24][690/782]\tTime 0.167 (0.168)\tLoss 0.5873 (0.2795)\tPrec@1 81.250 (90.453)\n",
            "Epoch: [24][700/782]\tTime 0.173 (0.168)\tLoss 0.2863 (0.2799)\tPrec@1 87.500 (90.442)\n",
            "Epoch: [24][710/782]\tTime 0.166 (0.168)\tLoss 0.2304 (0.2798)\tPrec@1 92.188 (90.423)\n",
            "Epoch: [24][720/782]\tTime 0.166 (0.168)\tLoss 0.1990 (0.2795)\tPrec@1 93.750 (90.436)\n",
            "Epoch: [24][730/782]\tTime 0.173 (0.168)\tLoss 0.4365 (0.2793)\tPrec@1 92.188 (90.456)\n",
            "Epoch: [24][740/782]\tTime 0.168 (0.168)\tLoss 0.2287 (0.2796)\tPrec@1 95.312 (90.454)\n",
            "Epoch: [24][750/782]\tTime 0.167 (0.168)\tLoss 0.3999 (0.2799)\tPrec@1 89.062 (90.446)\n",
            "Epoch: [24][760/782]\tTime 0.173 (0.168)\tLoss 0.1556 (0.2793)\tPrec@1 95.312 (90.485)\n",
            "Epoch: [24][770/782]\tTime 0.166 (0.168)\tLoss 0.2317 (0.2794)\tPrec@1 90.625 (90.485)\n",
            "Epoch: [24][780/782]\tTime 0.161 (0.168)\tLoss 0.2131 (0.2795)\tPrec@1 92.188 (90.477)\n",
            "Training accuracy:  tensor(90.4780, device='cuda:0')\n",
            "Best accuraacy:  tensor(90.4780, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.117 (0.117)\tLoss 0.4859 (0.4859)\tPrec@1 82.812 (82.812)\n",
            "Test: [10/157]\tTime 0.041 (0.048)\tLoss 0.3156 (0.4642)\tPrec@1 89.062 (84.517)\n",
            "Test: [20/157]\tTime 0.049 (0.046)\tLoss 0.5648 (0.4863)\tPrec@1 84.375 (84.301)\n",
            "Test: [30/157]\tTime 0.043 (0.046)\tLoss 0.3889 (0.4732)\tPrec@1 85.938 (84.879)\n",
            "Test: [40/157]\tTime 0.042 (0.045)\tLoss 0.3606 (0.4630)\tPrec@1 87.500 (85.023)\n",
            "Test: [50/157]\tTime 0.044 (0.045)\tLoss 0.7693 (0.4643)\tPrec@1 79.688 (84.988)\n",
            "Test: [60/157]\tTime 0.044 (0.045)\tLoss 0.4065 (0.4548)\tPrec@1 84.375 (85.143)\n",
            "Test: [70/157]\tTime 0.043 (0.045)\tLoss 0.3210 (0.4483)\tPrec@1 85.938 (85.255)\n",
            "Test: [80/157]\tTime 0.041 (0.045)\tLoss 0.2111 (0.4437)\tPrec@1 92.188 (85.532)\n",
            "Test: [90/157]\tTime 0.044 (0.045)\tLoss 0.3053 (0.4407)\tPrec@1 89.062 (85.594)\n",
            "Test: [100/157]\tTime 0.047 (0.045)\tLoss 0.5374 (0.4421)\tPrec@1 87.500 (85.659)\n",
            "Test: [110/157]\tTime 0.043 (0.045)\tLoss 0.2499 (0.4371)\tPrec@1 90.625 (85.684)\n",
            "Test: [120/157]\tTime 0.044 (0.045)\tLoss 0.5600 (0.4357)\tPrec@1 85.938 (85.795)\n",
            "Test: [130/157]\tTime 0.045 (0.044)\tLoss 0.3230 (0.4378)\tPrec@1 85.938 (85.675)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.4493 (0.4337)\tPrec@1 84.375 (85.716)\n",
            "Test: [150/157]\tTime 0.041 (0.044)\tLoss 0.8643 (0.4414)\tPrec@1 73.438 (85.534)\n",
            " * Prec@1 85.510\n",
            "Best accuracy:  tensor(87.5700, device='cuda:0')\n",
            "Epoch: [25][0/782]\tTime 0.270 (0.270)\tLoss 0.3942 (0.3942)\tPrec@1 82.812 (82.812)\n",
            "Epoch: [25][10/782]\tTime 0.168 (0.178)\tLoss 0.3851 (0.2926)\tPrec@1 89.062 (89.205)\n",
            "Epoch: [25][20/782]\tTime 0.173 (0.174)\tLoss 0.3367 (0.2712)\tPrec@1 89.062 (89.955)\n",
            "Epoch: [25][30/782]\tTime 0.168 (0.172)\tLoss 0.2392 (0.2685)\tPrec@1 90.625 (90.423)\n",
            "Epoch: [25][40/782]\tTime 0.166 (0.172)\tLoss 0.2805 (0.2726)\tPrec@1 89.062 (90.320)\n",
            "Epoch: [25][50/782]\tTime 0.172 (0.171)\tLoss 0.2337 (0.2786)\tPrec@1 89.062 (90.349)\n",
            "Epoch: [25][60/782]\tTime 0.169 (0.171)\tLoss 0.4238 (0.2757)\tPrec@1 84.375 (90.574)\n",
            "Epoch: [25][70/782]\tTime 0.167 (0.170)\tLoss 0.3070 (0.2752)\tPrec@1 90.625 (90.735)\n",
            "Epoch: [25][80/782]\tTime 0.171 (0.170)\tLoss 0.1457 (0.2671)\tPrec@1 96.875 (90.972)\n",
            "Epoch: [25][90/782]\tTime 0.169 (0.170)\tLoss 0.3170 (0.2675)\tPrec@1 93.750 (90.917)\n",
            "Epoch: [25][100/782]\tTime 0.168 (0.170)\tLoss 0.2353 (0.2684)\tPrec@1 93.750 (90.965)\n",
            "Epoch: [25][110/782]\tTime 0.171 (0.170)\tLoss 0.2275 (0.2664)\tPrec@1 92.188 (91.047)\n",
            "Epoch: [25][120/782]\tTime 0.167 (0.170)\tLoss 0.2784 (0.2668)\tPrec@1 89.062 (90.987)\n",
            "Epoch: [25][130/782]\tTime 0.168 (0.170)\tLoss 0.2311 (0.2666)\tPrec@1 90.625 (91.031)\n",
            "Epoch: [25][140/782]\tTime 0.167 (0.170)\tLoss 0.2659 (0.2656)\tPrec@1 89.062 (91.102)\n",
            "Epoch: [25][150/782]\tTime 0.167 (0.169)\tLoss 0.4936 (0.2683)\tPrec@1 82.812 (91.008)\n",
            "Epoch: [25][160/782]\tTime 0.166 (0.169)\tLoss 0.3441 (0.2669)\tPrec@1 89.062 (91.081)\n",
            "Epoch: [25][170/782]\tTime 0.168 (0.169)\tLoss 0.2798 (0.2661)\tPrec@1 90.625 (91.100)\n",
            "Epoch: [25][180/782]\tTime 0.168 (0.169)\tLoss 0.3700 (0.2685)\tPrec@1 90.625 (90.988)\n",
            "Epoch: [25][190/782]\tTime 0.169 (0.169)\tLoss 0.2299 (0.2671)\tPrec@1 93.750 (90.993)\n",
            "Epoch: [25][200/782]\tTime 0.167 (0.169)\tLoss 0.1805 (0.2698)\tPrec@1 92.188 (90.936)\n",
            "Epoch: [25][210/782]\tTime 0.168 (0.169)\tLoss 0.1773 (0.2695)\tPrec@1 95.312 (90.906)\n",
            "Epoch: [25][220/782]\tTime 0.165 (0.169)\tLoss 0.3480 (0.2705)\tPrec@1 89.062 (90.851)\n",
            "Epoch: [25][230/782]\tTime 0.168 (0.169)\tLoss 0.4204 (0.2711)\tPrec@1 87.500 (90.808)\n",
            "Epoch: [25][240/782]\tTime 0.167 (0.169)\tLoss 0.2373 (0.2701)\tPrec@1 90.625 (90.807)\n",
            "Epoch: [25][250/782]\tTime 0.165 (0.169)\tLoss 0.2473 (0.2702)\tPrec@1 93.750 (90.806)\n",
            "Epoch: [25][260/782]\tTime 0.169 (0.169)\tLoss 0.2339 (0.2707)\tPrec@1 90.625 (90.697)\n",
            "Epoch: [25][270/782]\tTime 0.168 (0.169)\tLoss 0.2596 (0.2704)\tPrec@1 92.188 (90.769)\n",
            "Epoch: [25][280/782]\tTime 0.168 (0.169)\tLoss 0.3727 (0.2713)\tPrec@1 85.938 (90.742)\n",
            "Epoch: [25][290/782]\tTime 0.169 (0.169)\tLoss 0.1805 (0.2708)\tPrec@1 93.750 (90.759)\n",
            "Epoch: [25][300/782]\tTime 0.167 (0.169)\tLoss 0.3108 (0.2704)\tPrec@1 93.750 (90.781)\n",
            "Epoch: [25][310/782]\tTime 0.168 (0.169)\tLoss 0.4923 (0.2708)\tPrec@1 87.500 (90.776)\n",
            "Epoch: [25][320/782]\tTime 0.168 (0.169)\tLoss 0.5320 (0.2720)\tPrec@1 82.812 (90.756)\n",
            "Epoch: [25][330/782]\tTime 0.167 (0.169)\tLoss 0.2462 (0.2721)\tPrec@1 93.750 (90.781)\n",
            "Epoch: [25][340/782]\tTime 0.168 (0.169)\tLoss 0.2339 (0.2729)\tPrec@1 92.188 (90.735)\n",
            "Epoch: [25][350/782]\tTime 0.166 (0.169)\tLoss 0.1580 (0.2720)\tPrec@1 92.188 (90.754)\n",
            "Epoch: [25][360/782]\tTime 0.167 (0.169)\tLoss 0.1663 (0.2722)\tPrec@1 93.750 (90.772)\n",
            "Epoch: [25][370/782]\tTime 0.166 (0.169)\tLoss 0.3458 (0.2722)\tPrec@1 90.625 (90.756)\n",
            "Epoch: [25][380/782]\tTime 0.167 (0.169)\tLoss 0.3266 (0.2719)\tPrec@1 89.062 (90.756)\n",
            "Epoch: [25][390/782]\tTime 0.172 (0.169)\tLoss 0.1756 (0.2713)\tPrec@1 93.750 (90.777)\n",
            "Epoch: [25][400/782]\tTime 0.168 (0.169)\tLoss 0.2553 (0.2705)\tPrec@1 90.625 (90.789)\n",
            "Epoch: [25][410/782]\tTime 0.167 (0.169)\tLoss 0.3988 (0.2708)\tPrec@1 85.938 (90.758)\n",
            "Epoch: [25][420/782]\tTime 0.168 (0.169)\tLoss 0.1621 (0.2719)\tPrec@1 98.438 (90.714)\n",
            "Epoch: [25][430/782]\tTime 0.167 (0.169)\tLoss 0.3344 (0.2728)\tPrec@1 87.500 (90.694)\n",
            "Epoch: [25][440/782]\tTime 0.167 (0.169)\tLoss 0.4255 (0.2730)\tPrec@1 76.562 (90.664)\n",
            "Epoch: [25][450/782]\tTime 0.167 (0.169)\tLoss 0.3270 (0.2727)\tPrec@1 85.938 (90.680)\n",
            "Epoch: [25][460/782]\tTime 0.168 (0.169)\tLoss 0.2591 (0.2730)\tPrec@1 89.062 (90.672)\n",
            "Epoch: [25][470/782]\tTime 0.167 (0.169)\tLoss 0.1437 (0.2722)\tPrec@1 96.875 (90.695)\n",
            "Epoch: [25][480/782]\tTime 0.166 (0.169)\tLoss 0.2386 (0.2718)\tPrec@1 90.625 (90.696)\n",
            "Epoch: [25][490/782]\tTime 0.169 (0.168)\tLoss 0.1930 (0.2716)\tPrec@1 92.188 (90.689)\n",
            "Epoch: [25][500/782]\tTime 0.168 (0.168)\tLoss 0.2937 (0.2714)\tPrec@1 87.500 (90.684)\n",
            "Epoch: [25][510/782]\tTime 0.168 (0.168)\tLoss 0.1922 (0.2720)\tPrec@1 92.188 (90.665)\n",
            "Epoch: [25][520/782]\tTime 0.167 (0.168)\tLoss 0.4576 (0.2730)\tPrec@1 89.062 (90.652)\n",
            "Epoch: [25][530/782]\tTime 0.168 (0.168)\tLoss 0.1959 (0.2724)\tPrec@1 93.750 (90.672)\n",
            "Epoch: [25][540/782]\tTime 0.167 (0.168)\tLoss 0.2318 (0.2717)\tPrec@1 90.625 (90.683)\n",
            "Epoch: [25][550/782]\tTime 0.167 (0.168)\tLoss 0.4480 (0.2720)\tPrec@1 84.375 (90.670)\n",
            "Epoch: [25][560/782]\tTime 0.168 (0.168)\tLoss 0.1792 (0.2722)\tPrec@1 92.188 (90.672)\n",
            "Epoch: [25][570/782]\tTime 0.167 (0.168)\tLoss 0.3201 (0.2724)\tPrec@1 93.750 (90.674)\n",
            "Epoch: [25][580/782]\tTime 0.168 (0.168)\tLoss 0.2528 (0.2723)\tPrec@1 90.625 (90.655)\n",
            "Epoch: [25][590/782]\tTime 0.167 (0.168)\tLoss 0.3887 (0.2726)\tPrec@1 84.375 (90.630)\n",
            "Epoch: [25][600/782]\tTime 0.167 (0.168)\tLoss 0.2820 (0.2735)\tPrec@1 90.625 (90.615)\n",
            "Epoch: [25][610/782]\tTime 0.167 (0.168)\tLoss 0.2326 (0.2732)\tPrec@1 90.625 (90.615)\n",
            "Epoch: [25][620/782]\tTime 0.167 (0.168)\tLoss 0.3162 (0.2730)\tPrec@1 84.375 (90.610)\n",
            "Epoch: [25][630/782]\tTime 0.166 (0.168)\tLoss 0.1147 (0.2729)\tPrec@1 98.438 (90.613)\n",
            "Epoch: [25][640/782]\tTime 0.167 (0.168)\tLoss 0.2701 (0.2732)\tPrec@1 90.625 (90.610)\n",
            "Epoch: [25][650/782]\tTime 0.167 (0.168)\tLoss 0.2275 (0.2726)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [25][660/782]\tTime 0.167 (0.168)\tLoss 0.2776 (0.2729)\tPrec@1 90.625 (90.627)\n",
            "Epoch: [25][670/782]\tTime 0.165 (0.168)\tLoss 0.3929 (0.2728)\tPrec@1 89.062 (90.623)\n",
            "Epoch: [25][680/782]\tTime 0.167 (0.168)\tLoss 0.2785 (0.2730)\tPrec@1 92.188 (90.625)\n",
            "Epoch: [25][690/782]\tTime 0.165 (0.168)\tLoss 0.3379 (0.2732)\tPrec@1 89.062 (90.607)\n",
            "Epoch: [25][700/782]\tTime 0.167 (0.168)\tLoss 0.2407 (0.2733)\tPrec@1 92.188 (90.605)\n",
            "Epoch: [25][710/782]\tTime 0.167 (0.168)\tLoss 0.1994 (0.2733)\tPrec@1 89.062 (90.592)\n",
            "Epoch: [25][720/782]\tTime 0.172 (0.168)\tLoss 0.3367 (0.2735)\tPrec@1 87.500 (90.592)\n",
            "Epoch: [25][730/782]\tTime 0.166 (0.168)\tLoss 0.3251 (0.2733)\tPrec@1 92.188 (90.593)\n",
            "Epoch: [25][740/782]\tTime 0.167 (0.168)\tLoss 0.1926 (0.2729)\tPrec@1 92.188 (90.604)\n",
            "Epoch: [25][750/782]\tTime 0.167 (0.168)\tLoss 0.3044 (0.2728)\tPrec@1 92.188 (90.613)\n",
            "Epoch: [25][760/782]\tTime 0.167 (0.168)\tLoss 0.1909 (0.2735)\tPrec@1 90.625 (90.584)\n",
            "Epoch: [25][770/782]\tTime 0.168 (0.168)\tLoss 0.2210 (0.2743)\tPrec@1 92.188 (90.556)\n",
            "Epoch: [25][780/782]\tTime 0.163 (0.168)\tLoss 0.1417 (0.2741)\tPrec@1 95.312 (90.551)\n",
            "Training accuracy:  tensor(90.5480, device='cuda:0')\n",
            "Best accuraacy:  tensor(90.5480, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.118 (0.118)\tLoss 0.3229 (0.3229)\tPrec@1 93.750 (93.750)\n",
            "Test: [10/157]\tTime 0.042 (0.048)\tLoss 0.4050 (0.3703)\tPrec@1 85.938 (88.210)\n",
            "Test: [20/157]\tTime 0.052 (0.046)\tLoss 0.3895 (0.3590)\tPrec@1 82.812 (87.500)\n",
            "Test: [30/157]\tTime 0.043 (0.046)\tLoss 0.2294 (0.3896)\tPrec@1 93.750 (86.946)\n",
            "Test: [40/157]\tTime 0.050 (0.046)\tLoss 0.3384 (0.4103)\tPrec@1 85.938 (86.585)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.3060 (0.4125)\tPrec@1 89.062 (86.612)\n",
            "Test: [60/157]\tTime 0.043 (0.045)\tLoss 0.2740 (0.4131)\tPrec@1 92.188 (86.527)\n",
            "Test: [70/157]\tTime 0.044 (0.045)\tLoss 0.4403 (0.4203)\tPrec@1 89.062 (86.444)\n",
            "Test: [80/157]\tTime 0.043 (0.045)\tLoss 0.2095 (0.4198)\tPrec@1 95.312 (86.497)\n",
            "Test: [90/157]\tTime 0.044 (0.045)\tLoss 0.3884 (0.4178)\tPrec@1 89.062 (86.281)\n",
            "Test: [100/157]\tTime 0.043 (0.044)\tLoss 0.6779 (0.4204)\tPrec@1 81.250 (86.309)\n",
            "Test: [110/157]\tTime 0.040 (0.044)\tLoss 0.1748 (0.4206)\tPrec@1 90.625 (86.261)\n",
            "Test: [120/157]\tTime 0.045 (0.044)\tLoss 0.4396 (0.4222)\tPrec@1 84.375 (86.131)\n",
            "Test: [130/157]\tTime 0.043 (0.044)\tLoss 0.3522 (0.4206)\tPrec@1 90.625 (86.248)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.4536 (0.4191)\tPrec@1 84.375 (86.259)\n",
            "Test: [150/157]\tTime 0.044 (0.044)\tLoss 0.3461 (0.4161)\tPrec@1 89.062 (86.372)\n",
            " * Prec@1 86.380\n",
            "Best accuracy:  tensor(87.5700, device='cuda:0')\n",
            "Epoch: [26][0/782]\tTime 0.270 (0.270)\tLoss 0.1575 (0.1575)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [26][10/782]\tTime 0.165 (0.176)\tLoss 0.3838 (0.2913)\tPrec@1 87.500 (90.341)\n",
            "Epoch: [26][20/782]\tTime 0.167 (0.172)\tLoss 0.3411 (0.2908)\tPrec@1 84.375 (89.955)\n",
            "Epoch: [26][30/782]\tTime 0.167 (0.171)\tLoss 0.3854 (0.2799)\tPrec@1 89.062 (90.373)\n",
            "Epoch: [26][40/782]\tTime 0.168 (0.170)\tLoss 0.3533 (0.2794)\tPrec@1 85.938 (90.053)\n",
            "Epoch: [26][50/782]\tTime 0.167 (0.170)\tLoss 0.3311 (0.2803)\tPrec@1 84.375 (89.920)\n",
            "Epoch: [26][60/782]\tTime 0.165 (0.169)\tLoss 0.2598 (0.2746)\tPrec@1 92.188 (90.215)\n",
            "Epoch: [26][70/782]\tTime 0.168 (0.169)\tLoss 0.2897 (0.2742)\tPrec@1 90.625 (90.163)\n",
            "Epoch: [26][80/782]\tTime 0.166 (0.169)\tLoss 0.0871 (0.2682)\tPrec@1 100.000 (90.509)\n",
            "Epoch: [26][90/782]\tTime 0.166 (0.169)\tLoss 0.2556 (0.2675)\tPrec@1 92.188 (90.591)\n",
            "Epoch: [26][100/782]\tTime 0.165 (0.168)\tLoss 0.4375 (0.2709)\tPrec@1 87.500 (90.594)\n",
            "Epoch: [26][110/782]\tTime 0.167 (0.168)\tLoss 0.3390 (0.2741)\tPrec@1 87.500 (90.400)\n",
            "Epoch: [26][120/782]\tTime 0.166 (0.168)\tLoss 0.3057 (0.2752)\tPrec@1 87.500 (90.315)\n",
            "Epoch: [26][130/782]\tTime 0.166 (0.168)\tLoss 0.2326 (0.2743)\tPrec@1 93.750 (90.303)\n",
            "Epoch: [26][140/782]\tTime 0.167 (0.168)\tLoss 0.3936 (0.2778)\tPrec@1 85.938 (90.259)\n",
            "Epoch: [26][150/782]\tTime 0.170 (0.168)\tLoss 0.3284 (0.2778)\tPrec@1 85.938 (90.211)\n",
            "Epoch: [26][160/782]\tTime 0.166 (0.168)\tLoss 0.2969 (0.2819)\tPrec@1 87.500 (90.072)\n",
            "Epoch: [26][170/782]\tTime 0.166 (0.168)\tLoss 0.2349 (0.2820)\tPrec@1 90.625 (90.104)\n",
            "Epoch: [26][180/782]\tTime 0.170 (0.168)\tLoss 0.2388 (0.2800)\tPrec@1 92.188 (90.193)\n",
            "Epoch: [26][190/782]\tTime 0.165 (0.168)\tLoss 0.2999 (0.2823)\tPrec@1 89.062 (90.118)\n",
            "Epoch: [26][200/782]\tTime 0.166 (0.168)\tLoss 0.2192 (0.2833)\tPrec@1 92.188 (90.034)\n",
            "Epoch: [26][210/782]\tTime 0.169 (0.168)\tLoss 0.2209 (0.2807)\tPrec@1 92.188 (90.092)\n",
            "Epoch: [26][220/782]\tTime 0.167 (0.168)\tLoss 0.2294 (0.2787)\tPrec@1 92.188 (90.158)\n",
            "Epoch: [26][230/782]\tTime 0.168 (0.168)\tLoss 0.2009 (0.2774)\tPrec@1 93.750 (90.206)\n",
            "Epoch: [26][240/782]\tTime 0.168 (0.168)\tLoss 0.1730 (0.2747)\tPrec@1 93.750 (90.268)\n",
            "Epoch: [26][250/782]\tTime 0.168 (0.168)\tLoss 0.3940 (0.2754)\tPrec@1 87.500 (90.239)\n",
            "Epoch: [26][260/782]\tTime 0.165 (0.168)\tLoss 0.3773 (0.2747)\tPrec@1 87.500 (90.230)\n",
            "Epoch: [26][270/782]\tTime 0.169 (0.168)\tLoss 0.1487 (0.2739)\tPrec@1 95.312 (90.268)\n",
            "Epoch: [26][280/782]\tTime 0.167 (0.168)\tLoss 0.1949 (0.2716)\tPrec@1 95.312 (90.375)\n",
            "Epoch: [26][290/782]\tTime 0.167 (0.168)\tLoss 0.4560 (0.2715)\tPrec@1 84.375 (90.394)\n",
            "Epoch: [26][300/782]\tTime 0.167 (0.168)\tLoss 0.1400 (0.2710)\tPrec@1 98.438 (90.423)\n",
            "Epoch: [26][310/782]\tTime 0.167 (0.168)\tLoss 0.3471 (0.2692)\tPrec@1 89.062 (90.494)\n",
            "Epoch: [26][320/782]\tTime 0.166 (0.168)\tLoss 0.1493 (0.2701)\tPrec@1 93.750 (90.489)\n",
            "Epoch: [26][330/782]\tTime 0.167 (0.168)\tLoss 0.2061 (0.2688)\tPrec@1 90.625 (90.526)\n",
            "Epoch: [26][340/782]\tTime 0.168 (0.168)\tLoss 0.2375 (0.2702)\tPrec@1 90.625 (90.520)\n",
            "Epoch: [26][350/782]\tTime 0.166 (0.168)\tLoss 0.3090 (0.2707)\tPrec@1 89.062 (90.491)\n",
            "Epoch: [26][360/782]\tTime 0.170 (0.168)\tLoss 0.2241 (0.2720)\tPrec@1 92.188 (90.474)\n",
            "Epoch: [26][370/782]\tTime 0.166 (0.168)\tLoss 0.2921 (0.2726)\tPrec@1 89.062 (90.469)\n",
            "Epoch: [26][380/782]\tTime 0.167 (0.168)\tLoss 0.3616 (0.2738)\tPrec@1 85.938 (90.424)\n",
            "Epoch: [26][390/782]\tTime 0.168 (0.168)\tLoss 0.2346 (0.2737)\tPrec@1 90.625 (90.441)\n",
            "Epoch: [26][400/782]\tTime 0.167 (0.168)\tLoss 0.4955 (0.2744)\tPrec@1 81.250 (90.380)\n",
            "Epoch: [26][410/782]\tTime 0.168 (0.168)\tLoss 0.1669 (0.2735)\tPrec@1 93.750 (90.382)\n",
            "Epoch: [26][420/782]\tTime 0.167 (0.168)\tLoss 0.4159 (0.2735)\tPrec@1 89.062 (90.402)\n",
            "Epoch: [26][430/782]\tTime 0.168 (0.168)\tLoss 0.2863 (0.2738)\tPrec@1 84.375 (90.360)\n",
            "Epoch: [26][440/782]\tTime 0.168 (0.168)\tLoss 0.4572 (0.2745)\tPrec@1 82.812 (90.352)\n",
            "Epoch: [26][450/782]\tTime 0.166 (0.168)\tLoss 0.2841 (0.2743)\tPrec@1 92.188 (90.376)\n",
            "Epoch: [26][460/782]\tTime 0.167 (0.168)\tLoss 0.4274 (0.2749)\tPrec@1 85.938 (90.374)\n",
            "Epoch: [26][470/782]\tTime 0.169 (0.168)\tLoss 0.3635 (0.2751)\tPrec@1 87.500 (90.383)\n",
            "Epoch: [26][480/782]\tTime 0.168 (0.168)\tLoss 0.1521 (0.2747)\tPrec@1 96.875 (90.401)\n",
            "Epoch: [26][490/782]\tTime 0.166 (0.168)\tLoss 0.1764 (0.2743)\tPrec@1 93.750 (90.386)\n",
            "Epoch: [26][500/782]\tTime 0.170 (0.168)\tLoss 0.2511 (0.2753)\tPrec@1 90.625 (90.354)\n",
            "Epoch: [26][510/782]\tTime 0.168 (0.168)\tLoss 0.3681 (0.2755)\tPrec@1 85.938 (90.350)\n",
            "Epoch: [26][520/782]\tTime 0.169 (0.168)\tLoss 0.2906 (0.2754)\tPrec@1 92.188 (90.352)\n",
            "Epoch: [26][530/782]\tTime 0.171 (0.168)\tLoss 0.1974 (0.2742)\tPrec@1 93.750 (90.390)\n",
            "Epoch: [26][540/782]\tTime 0.167 (0.168)\tLoss 0.3979 (0.2743)\tPrec@1 84.375 (90.365)\n",
            "Epoch: [26][550/782]\tTime 0.165 (0.168)\tLoss 0.2535 (0.2740)\tPrec@1 90.625 (90.378)\n",
            "Epoch: [26][560/782]\tTime 0.168 (0.168)\tLoss 0.5233 (0.2754)\tPrec@1 78.125 (90.327)\n",
            "Epoch: [26][570/782]\tTime 0.166 (0.168)\tLoss 0.3297 (0.2763)\tPrec@1 90.625 (90.294)\n",
            "Epoch: [26][580/782]\tTime 0.167 (0.168)\tLoss 0.1245 (0.2761)\tPrec@1 96.875 (90.308)\n",
            "Epoch: [26][590/782]\tTime 0.166 (0.168)\tLoss 0.1729 (0.2756)\tPrec@1 92.188 (90.326)\n",
            "Epoch: [26][600/782]\tTime 0.167 (0.168)\tLoss 0.2481 (0.2755)\tPrec@1 90.625 (90.326)\n",
            "Epoch: [26][610/782]\tTime 0.166 (0.168)\tLoss 0.1438 (0.2758)\tPrec@1 96.875 (90.310)\n",
            "Epoch: [26][620/782]\tTime 0.169 (0.168)\tLoss 0.2833 (0.2765)\tPrec@1 93.750 (90.298)\n",
            "Epoch: [26][630/782]\tTime 0.166 (0.168)\tLoss 0.3069 (0.2764)\tPrec@1 89.062 (90.311)\n",
            "Epoch: [26][640/782]\tTime 0.168 (0.168)\tLoss 0.1235 (0.2765)\tPrec@1 96.875 (90.320)\n",
            "Epoch: [26][650/782]\tTime 0.167 (0.168)\tLoss 0.2707 (0.2758)\tPrec@1 89.062 (90.351)\n",
            "Epoch: [26][660/782]\tTime 0.167 (0.168)\tLoss 0.4655 (0.2759)\tPrec@1 85.938 (90.341)\n",
            "Epoch: [26][670/782]\tTime 0.168 (0.168)\tLoss 0.1236 (0.2759)\tPrec@1 98.438 (90.336)\n",
            "Epoch: [26][680/782]\tTime 0.168 (0.168)\tLoss 0.2755 (0.2751)\tPrec@1 90.625 (90.354)\n",
            "Epoch: [26][690/782]\tTime 0.166 (0.168)\tLoss 0.2576 (0.2743)\tPrec@1 95.312 (90.379)\n",
            "Epoch: [26][700/782]\tTime 0.167 (0.168)\tLoss 0.2496 (0.2747)\tPrec@1 92.188 (90.362)\n",
            "Epoch: [26][710/782]\tTime 0.168 (0.168)\tLoss 0.3620 (0.2742)\tPrec@1 87.500 (90.383)\n",
            "Epoch: [26][720/782]\tTime 0.166 (0.168)\tLoss 0.2229 (0.2736)\tPrec@1 92.188 (90.415)\n",
            "Epoch: [26][730/782]\tTime 0.172 (0.168)\tLoss 0.1237 (0.2733)\tPrec@1 96.875 (90.424)\n",
            "Epoch: [26][740/782]\tTime 0.168 (0.168)\tLoss 0.1424 (0.2730)\tPrec@1 93.750 (90.439)\n",
            "Epoch: [26][750/782]\tTime 0.169 (0.168)\tLoss 0.3212 (0.2730)\tPrec@1 85.938 (90.427)\n",
            "Epoch: [26][760/782]\tTime 0.170 (0.168)\tLoss 0.3165 (0.2726)\tPrec@1 87.500 (90.442)\n",
            "Epoch: [26][770/782]\tTime 0.168 (0.168)\tLoss 0.2869 (0.2731)\tPrec@1 90.625 (90.426)\n",
            "Epoch: [26][780/782]\tTime 0.163 (0.168)\tLoss 0.2206 (0.2727)\tPrec@1 92.188 (90.441)\n",
            "Training accuracy:  tensor(90.4380, device='cuda:0')\n",
            "Best accuraacy:  tensor(90.5480, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.118 (0.118)\tLoss 0.4117 (0.4117)\tPrec@1 84.375 (84.375)\n",
            "Test: [10/157]\tTime 0.041 (0.048)\tLoss 0.4131 (0.5033)\tPrec@1 85.938 (83.381)\n",
            "Test: [20/157]\tTime 0.051 (0.046)\tLoss 0.4338 (0.4607)\tPrec@1 87.500 (85.119)\n",
            "Test: [30/157]\tTime 0.043 (0.046)\tLoss 0.3171 (0.4617)\tPrec@1 92.188 (85.685)\n",
            "Test: [40/157]\tTime 0.041 (0.045)\tLoss 0.2467 (0.4460)\tPrec@1 90.625 (86.319)\n",
            "Test: [50/157]\tTime 0.044 (0.045)\tLoss 0.4297 (0.4402)\tPrec@1 90.625 (86.366)\n",
            "Test: [60/157]\tTime 0.042 (0.045)\tLoss 0.4061 (0.4440)\tPrec@1 89.062 (86.117)\n",
            "Test: [70/157]\tTime 0.044 (0.045)\tLoss 0.8847 (0.4639)\tPrec@1 73.438 (85.827)\n",
            "Test: [80/157]\tTime 0.039 (0.045)\tLoss 0.6164 (0.4692)\tPrec@1 81.250 (85.706)\n",
            "Test: [90/157]\tTime 0.043 (0.045)\tLoss 0.3806 (0.4616)\tPrec@1 87.500 (85.852)\n",
            "Test: [100/157]\tTime 0.044 (0.045)\tLoss 0.4725 (0.4522)\tPrec@1 85.938 (86.185)\n",
            "Test: [110/157]\tTime 0.043 (0.044)\tLoss 0.6038 (0.4543)\tPrec@1 84.375 (86.177)\n",
            "Test: [120/157]\tTime 0.044 (0.044)\tLoss 0.4035 (0.4558)\tPrec@1 85.938 (86.105)\n",
            "Test: [130/157]\tTime 0.044 (0.044)\tLoss 0.3982 (0.4587)\tPrec@1 89.062 (85.985)\n",
            "Test: [140/157]\tTime 0.043 (0.044)\tLoss 0.6332 (0.4588)\tPrec@1 79.688 (85.949)\n",
            "Test: [150/157]\tTime 0.041 (0.044)\tLoss 0.2917 (0.4554)\tPrec@1 92.188 (85.969)\n",
            " * Prec@1 86.000\n",
            "Best accuracy:  tensor(87.5700, device='cuda:0')\n",
            "Epoch: [27][0/782]\tTime 0.270 (0.270)\tLoss 0.1050 (0.1050)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [27][10/782]\tTime 0.169 (0.178)\tLoss 0.1931 (0.2315)\tPrec@1 92.188 (91.903)\n",
            "Epoch: [27][20/782]\tTime 0.166 (0.173)\tLoss 0.1816 (0.2801)\tPrec@1 95.312 (90.476)\n",
            "Epoch: [27][30/782]\tTime 0.167 (0.171)\tLoss 0.3700 (0.2762)\tPrec@1 82.812 (90.323)\n",
            "Epoch: [27][40/782]\tTime 0.167 (0.170)\tLoss 0.1431 (0.2766)\tPrec@1 95.312 (90.244)\n",
            "Epoch: [27][50/782]\tTime 0.169 (0.170)\tLoss 0.3881 (0.2740)\tPrec@1 90.625 (90.380)\n",
            "Epoch: [27][60/782]\tTime 0.167 (0.169)\tLoss 0.3856 (0.2736)\tPrec@1 89.062 (90.548)\n",
            "Epoch: [27][70/782]\tTime 0.168 (0.169)\tLoss 0.2423 (0.2693)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [27][80/782]\tTime 0.171 (0.169)\tLoss 0.2558 (0.2647)\tPrec@1 90.625 (90.837)\n",
            "Epoch: [27][90/782]\tTime 0.167 (0.169)\tLoss 0.1306 (0.2656)\tPrec@1 98.438 (90.831)\n",
            "Epoch: [27][100/782]\tTime 0.167 (0.169)\tLoss 0.2911 (0.2694)\tPrec@1 87.500 (90.671)\n",
            "Epoch: [27][110/782]\tTime 0.166 (0.169)\tLoss 0.3221 (0.2703)\tPrec@1 92.188 (90.752)\n",
            "Epoch: [27][120/782]\tTime 0.167 (0.169)\tLoss 0.3316 (0.2680)\tPrec@1 85.938 (90.754)\n",
            "Epoch: [27][130/782]\tTime 0.167 (0.169)\tLoss 0.4099 (0.2673)\tPrec@1 89.062 (90.780)\n",
            "Epoch: [27][140/782]\tTime 0.168 (0.169)\tLoss 0.3529 (0.2653)\tPrec@1 85.938 (90.791)\n",
            "Epoch: [27][150/782]\tTime 0.167 (0.169)\tLoss 0.1956 (0.2645)\tPrec@1 93.750 (90.832)\n",
            "Epoch: [27][160/782]\tTime 0.168 (0.169)\tLoss 0.1824 (0.2654)\tPrec@1 92.188 (90.732)\n",
            "Epoch: [27][170/782]\tTime 0.168 (0.169)\tLoss 0.3982 (0.2661)\tPrec@1 89.062 (90.707)\n",
            "Epoch: [27][180/782]\tTime 0.167 (0.169)\tLoss 0.1788 (0.2680)\tPrec@1 95.312 (90.642)\n",
            "Epoch: [27][190/782]\tTime 0.168 (0.169)\tLoss 0.2457 (0.2673)\tPrec@1 87.500 (90.690)\n",
            "Epoch: [27][200/782]\tTime 0.166 (0.168)\tLoss 0.4035 (0.2685)\tPrec@1 84.375 (90.602)\n",
            "Epoch: [27][210/782]\tTime 0.167 (0.168)\tLoss 0.4721 (0.2679)\tPrec@1 85.938 (90.610)\n",
            "Epoch: [27][220/782]\tTime 0.167 (0.168)\tLoss 0.1907 (0.2661)\tPrec@1 90.625 (90.696)\n",
            "Epoch: [27][230/782]\tTime 0.168 (0.168)\tLoss 0.3954 (0.2661)\tPrec@1 82.812 (90.652)\n",
            "Epoch: [27][240/782]\tTime 0.167 (0.168)\tLoss 0.2754 (0.2662)\tPrec@1 90.625 (90.619)\n",
            "Epoch: [27][250/782]\tTime 0.177 (0.168)\tLoss 0.2046 (0.2664)\tPrec@1 93.750 (90.637)\n",
            "Epoch: [27][260/782]\tTime 0.167 (0.168)\tLoss 0.2650 (0.2659)\tPrec@1 93.750 (90.679)\n",
            "Epoch: [27][270/782]\tTime 0.170 (0.168)\tLoss 0.2355 (0.2645)\tPrec@1 92.188 (90.735)\n",
            "Epoch: [27][280/782]\tTime 0.176 (0.168)\tLoss 0.3459 (0.2657)\tPrec@1 89.062 (90.714)\n",
            "Epoch: [27][290/782]\tTime 0.167 (0.168)\tLoss 0.2009 (0.2653)\tPrec@1 93.750 (90.732)\n",
            "Epoch: [27][300/782]\tTime 0.167 (0.168)\tLoss 0.3682 (0.2655)\tPrec@1 89.062 (90.729)\n",
            "Epoch: [27][310/782]\tTime 0.171 (0.168)\tLoss 0.2470 (0.2665)\tPrec@1 89.062 (90.710)\n",
            "Epoch: [27][320/782]\tTime 0.167 (0.168)\tLoss 0.3156 (0.2660)\tPrec@1 89.062 (90.732)\n",
            "Epoch: [27][330/782]\tTime 0.165 (0.168)\tLoss 0.2103 (0.2663)\tPrec@1 92.188 (90.724)\n",
            "Epoch: [27][340/782]\tTime 0.167 (0.168)\tLoss 0.2914 (0.2665)\tPrec@1 87.500 (90.689)\n",
            "Epoch: [27][350/782]\tTime 0.166 (0.168)\tLoss 0.1271 (0.2663)\tPrec@1 98.438 (90.723)\n",
            "Epoch: [27][360/782]\tTime 0.166 (0.168)\tLoss 0.2854 (0.2668)\tPrec@1 89.062 (90.729)\n",
            "Epoch: [27][370/782]\tTime 0.168 (0.168)\tLoss 0.2736 (0.2681)\tPrec@1 89.062 (90.701)\n",
            "Epoch: [27][380/782]\tTime 0.167 (0.168)\tLoss 0.3365 (0.2670)\tPrec@1 89.062 (90.732)\n",
            "Epoch: [27][390/782]\tTime 0.166 (0.168)\tLoss 0.2189 (0.2660)\tPrec@1 93.750 (90.777)\n",
            "Epoch: [27][400/782]\tTime 0.169 (0.168)\tLoss 0.2957 (0.2669)\tPrec@1 90.625 (90.761)\n",
            "Epoch: [27][410/782]\tTime 0.167 (0.168)\tLoss 0.3567 (0.2678)\tPrec@1 90.625 (90.743)\n",
            "Epoch: [27][420/782]\tTime 0.174 (0.168)\tLoss 0.2749 (0.2673)\tPrec@1 92.188 (90.766)\n",
            "Epoch: [27][430/782]\tTime 0.173 (0.168)\tLoss 0.1643 (0.2670)\tPrec@1 96.875 (90.774)\n",
            "Epoch: [27][440/782]\tTime 0.168 (0.168)\tLoss 0.3812 (0.2673)\tPrec@1 85.938 (90.767)\n",
            "Epoch: [27][450/782]\tTime 0.167 (0.168)\tLoss 0.1617 (0.2665)\tPrec@1 95.312 (90.784)\n",
            "Epoch: [27][460/782]\tTime 0.168 (0.168)\tLoss 0.3960 (0.2666)\tPrec@1 87.500 (90.771)\n",
            "Epoch: [27][470/782]\tTime 0.171 (0.168)\tLoss 0.2306 (0.2668)\tPrec@1 95.312 (90.771)\n",
            "Epoch: [27][480/782]\tTime 0.168 (0.168)\tLoss 0.3127 (0.2666)\tPrec@1 90.625 (90.768)\n",
            "Epoch: [27][490/782]\tTime 0.168 (0.168)\tLoss 0.1344 (0.2661)\tPrec@1 96.875 (90.797)\n",
            "Epoch: [27][500/782]\tTime 0.167 (0.168)\tLoss 0.3085 (0.2667)\tPrec@1 92.188 (90.765)\n",
            "Epoch: [27][510/782]\tTime 0.167 (0.168)\tLoss 0.3394 (0.2667)\tPrec@1 85.938 (90.772)\n",
            "Epoch: [27][520/782]\tTime 0.169 (0.168)\tLoss 0.3160 (0.2672)\tPrec@1 89.062 (90.736)\n",
            "Epoch: [27][530/782]\tTime 0.167 (0.168)\tLoss 0.4704 (0.2677)\tPrec@1 82.812 (90.716)\n",
            "Epoch: [27][540/782]\tTime 0.167 (0.168)\tLoss 0.3634 (0.2697)\tPrec@1 87.500 (90.689)\n",
            "Epoch: [27][550/782]\tTime 0.168 (0.168)\tLoss 0.3030 (0.2698)\tPrec@1 89.062 (90.679)\n",
            "Epoch: [27][560/782]\tTime 0.165 (0.168)\tLoss 0.2807 (0.2698)\tPrec@1 87.500 (90.672)\n",
            "Epoch: [27][570/782]\tTime 0.168 (0.168)\tLoss 0.2133 (0.2697)\tPrec@1 92.188 (90.685)\n",
            "Epoch: [27][580/782]\tTime 0.166 (0.168)\tLoss 0.2394 (0.2697)\tPrec@1 92.188 (90.668)\n",
            "Epoch: [27][590/782]\tTime 0.166 (0.168)\tLoss 0.5049 (0.2706)\tPrec@1 81.250 (90.633)\n",
            "Epoch: [27][600/782]\tTime 0.171 (0.168)\tLoss 0.2448 (0.2706)\tPrec@1 90.625 (90.635)\n",
            "Epoch: [27][610/782]\tTime 0.166 (0.168)\tLoss 0.3802 (0.2713)\tPrec@1 84.375 (90.599)\n",
            "Epoch: [27][620/782]\tTime 0.167 (0.168)\tLoss 0.3023 (0.2719)\tPrec@1 89.062 (90.577)\n",
            "Epoch: [27][630/782]\tTime 0.166 (0.168)\tLoss 0.1181 (0.2715)\tPrec@1 98.438 (90.593)\n",
            "Epoch: [27][640/782]\tTime 0.168 (0.168)\tLoss 0.3349 (0.2725)\tPrec@1 87.500 (90.547)\n",
            "Epoch: [27][650/782]\tTime 0.166 (0.168)\tLoss 0.1303 (0.2729)\tPrec@1 95.312 (90.531)\n",
            "Epoch: [27][660/782]\tTime 0.167 (0.168)\tLoss 0.3263 (0.2722)\tPrec@1 89.062 (90.552)\n",
            "Epoch: [27][670/782]\tTime 0.168 (0.168)\tLoss 0.2731 (0.2722)\tPrec@1 92.188 (90.544)\n",
            "Epoch: [27][680/782]\tTime 0.167 (0.168)\tLoss 0.4793 (0.2724)\tPrec@1 85.938 (90.529)\n",
            "Epoch: [27][690/782]\tTime 0.168 (0.168)\tLoss 0.1890 (0.2723)\tPrec@1 92.188 (90.523)\n",
            "Epoch: [27][700/782]\tTime 0.167 (0.168)\tLoss 0.2390 (0.2727)\tPrec@1 95.312 (90.511)\n",
            "Epoch: [27][710/782]\tTime 0.167 (0.168)\tLoss 0.2639 (0.2731)\tPrec@1 89.062 (90.513)\n",
            "Epoch: [27][720/782]\tTime 0.168 (0.168)\tLoss 0.1892 (0.2738)\tPrec@1 93.750 (90.495)\n",
            "Epoch: [27][730/782]\tTime 0.167 (0.168)\tLoss 0.3155 (0.2743)\tPrec@1 90.625 (90.482)\n",
            "Epoch: [27][740/782]\tTime 0.168 (0.168)\tLoss 0.1837 (0.2741)\tPrec@1 90.625 (90.486)\n",
            "Epoch: [27][750/782]\tTime 0.167 (0.168)\tLoss 0.2920 (0.2742)\tPrec@1 85.938 (90.473)\n",
            "Epoch: [27][760/782]\tTime 0.167 (0.168)\tLoss 0.2628 (0.2742)\tPrec@1 87.500 (90.481)\n",
            "Epoch: [27][770/782]\tTime 0.167 (0.168)\tLoss 0.1824 (0.2742)\tPrec@1 95.312 (90.469)\n",
            "Epoch: [27][780/782]\tTime 0.164 (0.168)\tLoss 0.3048 (0.2741)\tPrec@1 93.750 (90.477)\n",
            "Training accuracy:  tensor(90.4760, device='cuda:0')\n",
            "Best accuraacy:  tensor(90.5480, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.121 (0.121)\tLoss 0.3008 (0.3008)\tPrec@1 89.062 (89.062)\n",
            "Test: [10/157]\tTime 0.041 (0.048)\tLoss 0.3947 (0.3267)\tPrec@1 90.625 (89.489)\n",
            "Test: [20/157]\tTime 0.055 (0.046)\tLoss 0.2998 (0.3578)\tPrec@1 90.625 (88.542)\n",
            "Test: [30/157]\tTime 0.044 (0.046)\tLoss 0.4597 (0.3435)\tPrec@1 90.625 (88.962)\n",
            "Test: [40/157]\tTime 0.041 (0.045)\tLoss 0.4244 (0.3526)\tPrec@1 87.500 (88.796)\n",
            "Test: [50/157]\tTime 0.042 (0.045)\tLoss 0.3335 (0.3597)\tPrec@1 92.188 (88.756)\n",
            "Test: [60/157]\tTime 0.044 (0.045)\tLoss 0.2923 (0.3519)\tPrec@1 93.750 (88.986)\n",
            "Test: [70/157]\tTime 0.043 (0.045)\tLoss 0.2046 (0.3546)\tPrec@1 90.625 (88.996)\n",
            "Test: [80/157]\tTime 0.044 (0.045)\tLoss 0.1615 (0.3559)\tPrec@1 92.188 (88.696)\n",
            "Test: [90/157]\tTime 0.040 (0.045)\tLoss 0.2374 (0.3540)\tPrec@1 87.500 (88.702)\n",
            "Test: [100/157]\tTime 0.044 (0.045)\tLoss 0.3823 (0.3588)\tPrec@1 89.062 (88.629)\n",
            "Test: [110/157]\tTime 0.044 (0.045)\tLoss 0.6217 (0.3671)\tPrec@1 90.625 (88.556)\n",
            "Test: [120/157]\tTime 0.044 (0.045)\tLoss 0.4115 (0.3728)\tPrec@1 87.500 (88.494)\n",
            "Test: [130/157]\tTime 0.043 (0.044)\tLoss 0.4076 (0.3743)\tPrec@1 89.062 (88.538)\n",
            "Test: [140/157]\tTime 0.043 (0.044)\tLoss 0.3749 (0.3788)\tPrec@1 89.062 (88.375)\n",
            "Test: [150/157]\tTime 0.046 (0.044)\tLoss 0.5846 (0.3758)\tPrec@1 81.250 (88.380)\n",
            " * Prec@1 88.290\n",
            "Best accuracy:  tensor(88.2900, device='cuda:0')\n",
            "Epoch: [28][0/782]\tTime 0.270 (0.270)\tLoss 0.2552 (0.2552)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [28][10/782]\tTime 0.168 (0.177)\tLoss 0.2160 (0.2393)\tPrec@1 93.750 (91.335)\n",
            "Epoch: [28][20/782]\tTime 0.166 (0.172)\tLoss 0.1606 (0.2354)\tPrec@1 96.875 (91.815)\n",
            "Epoch: [28][30/782]\tTime 0.167 (0.171)\tLoss 0.1115 (0.2317)\tPrec@1 95.312 (91.935)\n",
            "Epoch: [28][40/782]\tTime 0.167 (0.170)\tLoss 0.1777 (0.2349)\tPrec@1 95.312 (91.921)\n",
            "Epoch: [28][50/782]\tTime 0.167 (0.170)\tLoss 0.1689 (0.2398)\tPrec@1 93.750 (91.728)\n",
            "Epoch: [28][60/782]\tTime 0.166 (0.169)\tLoss 0.3117 (0.2410)\tPrec@1 89.062 (91.675)\n",
            "Epoch: [28][70/782]\tTime 0.167 (0.169)\tLoss 0.1695 (0.2401)\tPrec@1 93.750 (91.835)\n",
            "Epoch: [28][80/782]\tTime 0.168 (0.169)\tLoss 0.1528 (0.2344)\tPrec@1 98.438 (92.130)\n",
            "Epoch: [28][90/782]\tTime 0.166 (0.169)\tLoss 0.0945 (0.2319)\tPrec@1 98.438 (92.188)\n",
            "Epoch: [28][100/782]\tTime 0.168 (0.169)\tLoss 0.1744 (0.2307)\tPrec@1 93.750 (92.203)\n",
            "Epoch: [28][110/782]\tTime 0.171 (0.169)\tLoss 0.3399 (0.2336)\tPrec@1 89.062 (92.188)\n",
            "Epoch: [28][120/782]\tTime 0.171 (0.169)\tLoss 0.2164 (0.2343)\tPrec@1 93.750 (92.213)\n",
            "Epoch: [28][130/782]\tTime 0.168 (0.169)\tLoss 0.4340 (0.2368)\tPrec@1 84.375 (92.056)\n",
            "Epoch: [28][140/782]\tTime 0.167 (0.169)\tLoss 0.1217 (0.2387)\tPrec@1 98.438 (92.021)\n",
            "Epoch: [28][150/782]\tTime 0.171 (0.169)\tLoss 0.2370 (0.2417)\tPrec@1 92.188 (91.898)\n",
            "Epoch: [28][160/782]\tTime 0.170 (0.169)\tLoss 0.3414 (0.2441)\tPrec@1 92.188 (91.790)\n",
            "Epoch: [28][170/782]\tTime 0.167 (0.169)\tLoss 0.2549 (0.2441)\tPrec@1 90.625 (91.822)\n",
            "Epoch: [28][180/782]\tTime 0.173 (0.169)\tLoss 0.2046 (0.2457)\tPrec@1 92.188 (91.747)\n",
            "Epoch: [28][190/782]\tTime 0.168 (0.169)\tLoss 0.1179 (0.2472)\tPrec@1 96.875 (91.729)\n",
            "Epoch: [28][200/782]\tTime 0.166 (0.169)\tLoss 0.3048 (0.2498)\tPrec@1 89.062 (91.604)\n",
            "Epoch: [28][210/782]\tTime 0.171 (0.169)\tLoss 0.2440 (0.2495)\tPrec@1 90.625 (91.551)\n",
            "Epoch: [28][220/782]\tTime 0.166 (0.169)\tLoss 0.3526 (0.2495)\tPrec@1 89.062 (91.558)\n",
            "Epoch: [28][230/782]\tTime 0.168 (0.169)\tLoss 0.2342 (0.2493)\tPrec@1 90.625 (91.538)\n",
            "Epoch: [28][240/782]\tTime 0.168 (0.168)\tLoss 0.1454 (0.2509)\tPrec@1 95.312 (91.481)\n",
            "Epoch: [28][250/782]\tTime 0.167 (0.168)\tLoss 0.1952 (0.2519)\tPrec@1 96.875 (91.484)\n",
            "Epoch: [28][260/782]\tTime 0.167 (0.168)\tLoss 0.3117 (0.2536)\tPrec@1 87.500 (91.391)\n",
            "Epoch: [28][270/782]\tTime 0.167 (0.168)\tLoss 0.1996 (0.2548)\tPrec@1 93.750 (91.357)\n",
            "Epoch: [28][280/782]\tTime 0.167 (0.168)\tLoss 0.1856 (0.2554)\tPrec@1 95.312 (91.342)\n",
            "Epoch: [28][290/782]\tTime 0.166 (0.168)\tLoss 0.2574 (0.2558)\tPrec@1 93.750 (91.302)\n",
            "Epoch: [28][300/782]\tTime 0.168 (0.168)\tLoss 0.1889 (0.2569)\tPrec@1 96.875 (91.284)\n",
            "Epoch: [28][310/782]\tTime 0.166 (0.168)\tLoss 0.2692 (0.2563)\tPrec@1 87.500 (91.293)\n",
            "Epoch: [28][320/782]\tTime 0.167 (0.168)\tLoss 0.1752 (0.2580)\tPrec@1 95.312 (91.224)\n",
            "Epoch: [28][330/782]\tTime 0.168 (0.168)\tLoss 0.3568 (0.2582)\tPrec@1 89.062 (91.220)\n",
            "Epoch: [28][340/782]\tTime 0.166 (0.168)\tLoss 0.3778 (0.2580)\tPrec@1 90.625 (91.239)\n",
            "Epoch: [28][350/782]\tTime 0.169 (0.168)\tLoss 0.2344 (0.2566)\tPrec@1 90.625 (91.270)\n",
            "Epoch: [28][360/782]\tTime 0.172 (0.168)\tLoss 0.3888 (0.2564)\tPrec@1 87.500 (91.270)\n",
            "Epoch: [28][370/782]\tTime 0.167 (0.168)\tLoss 0.3958 (0.2563)\tPrec@1 89.062 (91.299)\n",
            "Epoch: [28][380/782]\tTime 0.167 (0.168)\tLoss 0.0883 (0.2575)\tPrec@1 96.875 (91.265)\n",
            "Epoch: [28][390/782]\tTime 0.167 (0.168)\tLoss 0.2952 (0.2581)\tPrec@1 85.938 (91.240)\n",
            "Epoch: [28][400/782]\tTime 0.166 (0.168)\tLoss 0.2729 (0.2585)\tPrec@1 90.625 (91.248)\n",
            "Epoch: [28][410/782]\tTime 0.167 (0.168)\tLoss 0.2449 (0.2594)\tPrec@1 90.625 (91.207)\n",
            "Epoch: [28][420/782]\tTime 0.168 (0.168)\tLoss 0.2702 (0.2591)\tPrec@1 85.938 (91.219)\n",
            "Epoch: [28][430/782]\tTime 0.166 (0.168)\tLoss 0.1653 (0.2581)\tPrec@1 95.312 (91.230)\n",
            "Epoch: [28][440/782]\tTime 0.169 (0.168)\tLoss 0.2661 (0.2577)\tPrec@1 87.500 (91.245)\n",
            "Epoch: [28][450/782]\tTime 0.169 (0.168)\tLoss 0.2636 (0.2577)\tPrec@1 89.062 (91.249)\n",
            "Epoch: [28][460/782]\tTime 0.167 (0.168)\tLoss 0.2565 (0.2574)\tPrec@1 89.062 (91.249)\n",
            "Epoch: [28][470/782]\tTime 0.166 (0.168)\tLoss 0.5370 (0.2581)\tPrec@1 85.938 (91.242)\n",
            "Epoch: [28][480/782]\tTime 0.169 (0.168)\tLoss 0.4052 (0.2583)\tPrec@1 85.938 (91.229)\n",
            "Epoch: [28][490/782]\tTime 0.167 (0.168)\tLoss 0.3983 (0.2589)\tPrec@1 85.938 (91.214)\n",
            "Epoch: [28][500/782]\tTime 0.167 (0.168)\tLoss 0.1222 (0.2584)\tPrec@1 96.875 (91.224)\n",
            "Epoch: [28][510/782]\tTime 0.168 (0.168)\tLoss 0.1438 (0.2588)\tPrec@1 95.312 (91.178)\n",
            "Epoch: [28][520/782]\tTime 0.170 (0.168)\tLoss 0.2189 (0.2587)\tPrec@1 92.188 (91.177)\n",
            "Epoch: [28][530/782]\tTime 0.167 (0.168)\tLoss 0.4497 (0.2590)\tPrec@1 84.375 (91.166)\n",
            "Epoch: [28][540/782]\tTime 0.168 (0.168)\tLoss 0.2038 (0.2593)\tPrec@1 93.750 (91.177)\n",
            "Epoch: [28][550/782]\tTime 0.167 (0.168)\tLoss 0.1664 (0.2598)\tPrec@1 95.312 (91.169)\n",
            "Epoch: [28][560/782]\tTime 0.167 (0.168)\tLoss 0.1983 (0.2589)\tPrec@1 93.750 (91.202)\n",
            "Epoch: [28][570/782]\tTime 0.169 (0.168)\tLoss 0.2805 (0.2584)\tPrec@1 89.062 (91.200)\n",
            "Epoch: [28][580/782]\tTime 0.167 (0.168)\tLoss 0.2031 (0.2589)\tPrec@1 95.312 (91.174)\n",
            "Epoch: [28][590/782]\tTime 0.168 (0.168)\tLoss 0.1772 (0.2586)\tPrec@1 93.750 (91.167)\n",
            "Epoch: [28][600/782]\tTime 0.167 (0.168)\tLoss 0.1672 (0.2584)\tPrec@1 93.750 (91.187)\n",
            "Epoch: [28][610/782]\tTime 0.167 (0.168)\tLoss 0.4452 (0.2585)\tPrec@1 85.938 (91.157)\n",
            "Epoch: [28][620/782]\tTime 0.171 (0.168)\tLoss 0.2079 (0.2586)\tPrec@1 90.625 (91.146)\n",
            "Epoch: [28][630/782]\tTime 0.168 (0.168)\tLoss 0.2735 (0.2593)\tPrec@1 87.500 (91.125)\n",
            "Epoch: [28][640/782]\tTime 0.166 (0.168)\tLoss 0.2368 (0.2586)\tPrec@1 90.625 (91.139)\n",
            "Epoch: [28][650/782]\tTime 0.167 (0.168)\tLoss 0.2209 (0.2582)\tPrec@1 95.312 (91.158)\n",
            "Epoch: [28][660/782]\tTime 0.167 (0.168)\tLoss 0.2906 (0.2586)\tPrec@1 89.062 (91.152)\n",
            "Epoch: [28][670/782]\tTime 0.168 (0.168)\tLoss 0.4963 (0.2598)\tPrec@1 84.375 (91.095)\n",
            "Epoch: [28][680/782]\tTime 0.168 (0.168)\tLoss 0.4227 (0.2601)\tPrec@1 78.125 (91.077)\n",
            "Epoch: [28][690/782]\tTime 0.167 (0.168)\tLoss 0.2701 (0.2599)\tPrec@1 89.062 (91.068)\n",
            "Epoch: [28][700/782]\tTime 0.167 (0.168)\tLoss 0.4527 (0.2602)\tPrec@1 90.625 (91.055)\n",
            "Epoch: [28][710/782]\tTime 0.169 (0.168)\tLoss 0.3951 (0.2608)\tPrec@1 85.938 (91.049)\n",
            "Epoch: [28][720/782]\tTime 0.168 (0.168)\tLoss 0.2423 (0.2605)\tPrec@1 93.750 (91.058)\n",
            "Epoch: [28][730/782]\tTime 0.168 (0.168)\tLoss 0.4047 (0.2618)\tPrec@1 81.250 (91.016)\n",
            "Epoch: [28][740/782]\tTime 0.168 (0.168)\tLoss 0.2547 (0.2625)\tPrec@1 87.500 (90.988)\n",
            "Epoch: [28][750/782]\tTime 0.167 (0.168)\tLoss 0.3776 (0.2629)\tPrec@1 85.938 (90.977)\n",
            "Epoch: [28][760/782]\tTime 0.166 (0.168)\tLoss 0.2455 (0.2634)\tPrec@1 89.062 (90.954)\n",
            "Epoch: [28][770/782]\tTime 0.167 (0.168)\tLoss 0.3370 (0.2632)\tPrec@1 90.625 (90.959)\n",
            "Epoch: [28][780/782]\tTime 0.162 (0.168)\tLoss 0.2586 (0.2633)\tPrec@1 89.062 (90.951)\n",
            "Training accuracy:  tensor(90.9520, device='cuda:0')\n",
            "Best accuraacy:  tensor(90.9520, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.116 (0.116)\tLoss 0.4211 (0.4211)\tPrec@1 89.062 (89.062)\n",
            "Test: [10/157]\tTime 0.041 (0.048)\tLoss 0.3663 (0.4250)\tPrec@1 89.062 (86.648)\n",
            "Test: [20/157]\tTime 0.052 (0.046)\tLoss 0.3446 (0.4068)\tPrec@1 89.062 (87.723)\n",
            "Test: [30/157]\tTime 0.040 (0.046)\tLoss 0.2646 (0.4035)\tPrec@1 90.625 (87.349)\n",
            "Test: [40/157]\tTime 0.042 (0.045)\tLoss 0.1915 (0.3928)\tPrec@1 95.312 (87.538)\n",
            "Test: [50/157]\tTime 0.041 (0.045)\tLoss 0.6109 (0.3941)\tPrec@1 82.812 (87.806)\n",
            "Test: [60/157]\tTime 0.041 (0.045)\tLoss 0.7484 (0.3962)\tPrec@1 81.250 (87.859)\n",
            "Test: [70/157]\tTime 0.043 (0.045)\tLoss 0.3724 (0.3899)\tPrec@1 87.500 (87.786)\n",
            "Test: [80/157]\tTime 0.043 (0.045)\tLoss 0.3203 (0.3850)\tPrec@1 92.188 (87.944)\n",
            "Test: [90/157]\tTime 0.045 (0.045)\tLoss 0.2104 (0.3809)\tPrec@1 93.750 (88.084)\n",
            "Test: [100/157]\tTime 0.040 (0.045)\tLoss 0.4679 (0.3785)\tPrec@1 84.375 (88.072)\n",
            "Test: [110/157]\tTime 0.044 (0.044)\tLoss 0.3472 (0.3801)\tPrec@1 92.188 (88.035)\n",
            "Test: [120/157]\tTime 0.050 (0.044)\tLoss 0.3237 (0.3863)\tPrec@1 90.625 (87.939)\n",
            "Test: [130/157]\tTime 0.043 (0.044)\tLoss 0.4117 (0.3878)\tPrec@1 89.062 (87.989)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.3529 (0.3918)\tPrec@1 89.062 (87.921)\n",
            "Test: [150/157]\tTime 0.045 (0.044)\tLoss 0.5378 (0.3885)\tPrec@1 79.688 (87.883)\n",
            " * Prec@1 87.910\n",
            "Best accuracy:  tensor(88.2900, device='cuda:0')\n",
            "Epoch: [29][0/782]\tTime 0.273 (0.273)\tLoss 0.3013 (0.3013)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [29][10/782]\tTime 0.167 (0.177)\tLoss 0.1048 (0.1928)\tPrec@1 96.875 (94.176)\n",
            "Epoch: [29][20/782]\tTime 0.167 (0.172)\tLoss 0.2441 (0.2138)\tPrec@1 93.750 (92.932)\n",
            "Epoch: [29][30/782]\tTime 0.167 (0.171)\tLoss 0.2777 (0.2449)\tPrec@1 89.062 (91.683)\n",
            "Epoch: [29][40/782]\tTime 0.167 (0.170)\tLoss 0.2025 (0.2457)\tPrec@1 90.625 (91.463)\n",
            "Epoch: [29][50/782]\tTime 0.170 (0.170)\tLoss 0.4119 (0.2447)\tPrec@1 90.625 (91.452)\n",
            "Epoch: [29][60/782]\tTime 0.167 (0.169)\tLoss 0.2877 (0.2492)\tPrec@1 85.938 (91.317)\n",
            "Epoch: [29][70/782]\tTime 0.166 (0.169)\tLoss 0.2541 (0.2535)\tPrec@1 92.188 (91.241)\n",
            "Epoch: [29][80/782]\tTime 0.174 (0.169)\tLoss 0.2200 (0.2497)\tPrec@1 92.188 (91.493)\n",
            "Epoch: [29][90/782]\tTime 0.168 (0.169)\tLoss 0.1327 (0.2453)\tPrec@1 95.312 (91.655)\n",
            "Epoch: [29][100/782]\tTime 0.166 (0.169)\tLoss 0.2568 (0.2429)\tPrec@1 84.375 (91.662)\n",
            "Epoch: [29][110/782]\tTime 0.171 (0.169)\tLoss 0.1794 (0.2460)\tPrec@1 93.750 (91.639)\n",
            "Epoch: [29][120/782]\tTime 0.166 (0.169)\tLoss 0.1959 (0.2459)\tPrec@1 92.188 (91.606)\n",
            "Epoch: [29][130/782]\tTime 0.166 (0.169)\tLoss 0.2521 (0.2479)\tPrec@1 89.062 (91.531)\n",
            "Epoch: [29][140/782]\tTime 0.166 (0.169)\tLoss 0.2839 (0.2485)\tPrec@1 89.062 (91.512)\n",
            "Epoch: [29][150/782]\tTime 0.167 (0.169)\tLoss 0.1867 (0.2498)\tPrec@1 95.312 (91.422)\n",
            "Epoch: [29][160/782]\tTime 0.166 (0.168)\tLoss 0.1651 (0.2491)\tPrec@1 93.750 (91.372)\n",
            "Epoch: [29][170/782]\tTime 0.169 (0.168)\tLoss 0.2120 (0.2496)\tPrec@1 95.312 (91.292)\n",
            "Epoch: [29][180/782]\tTime 0.167 (0.168)\tLoss 0.2309 (0.2498)\tPrec@1 90.625 (91.272)\n",
            "Epoch: [29][190/782]\tTime 0.167 (0.168)\tLoss 0.2141 (0.2519)\tPrec@1 92.188 (91.255)\n",
            "Epoch: [29][200/782]\tTime 0.172 (0.168)\tLoss 0.3132 (0.2508)\tPrec@1 93.750 (91.270)\n",
            "Epoch: [29][210/782]\tTime 0.167 (0.168)\tLoss 0.2786 (0.2513)\tPrec@1 89.062 (91.217)\n",
            "Epoch: [29][220/782]\tTime 0.165 (0.168)\tLoss 0.1390 (0.2527)\tPrec@1 95.312 (91.155)\n",
            "Epoch: [29][230/782]\tTime 0.168 (0.168)\tLoss 0.2753 (0.2555)\tPrec@1 87.500 (91.044)\n",
            "Epoch: [29][240/782]\tTime 0.167 (0.168)\tLoss 0.2153 (0.2566)\tPrec@1 90.625 (90.982)\n",
            "Epoch: [29][250/782]\tTime 0.167 (0.168)\tLoss 0.2611 (0.2580)\tPrec@1 89.062 (90.924)\n",
            "Epoch: [29][260/782]\tTime 0.168 (0.168)\tLoss 0.2812 (0.2577)\tPrec@1 89.062 (90.918)\n",
            "Epoch: [29][270/782]\tTime 0.166 (0.168)\tLoss 0.4375 (0.2582)\tPrec@1 81.250 (90.925)\n",
            "Epoch: [29][280/782]\tTime 0.168 (0.168)\tLoss 0.3321 (0.2606)\tPrec@1 89.062 (90.881)\n",
            "Epoch: [29][290/782]\tTime 0.166 (0.168)\tLoss 0.1760 (0.2612)\tPrec@1 90.625 (90.791)\n",
            "Epoch: [29][300/782]\tTime 0.167 (0.168)\tLoss 0.3926 (0.2612)\tPrec@1 85.938 (90.776)\n",
            "Epoch: [29][310/782]\tTime 0.168 (0.168)\tLoss 0.3005 (0.2623)\tPrec@1 89.062 (90.756)\n",
            "Epoch: [29][320/782]\tTime 0.166 (0.168)\tLoss 0.3564 (0.2622)\tPrec@1 84.375 (90.752)\n",
            "Epoch: [29][330/782]\tTime 0.166 (0.168)\tLoss 0.3268 (0.2628)\tPrec@1 93.750 (90.767)\n",
            "Epoch: [29][340/782]\tTime 0.167 (0.168)\tLoss 0.3176 (0.2626)\tPrec@1 89.062 (90.767)\n",
            "Epoch: [29][350/782]\tTime 0.166 (0.168)\tLoss 0.3672 (0.2625)\tPrec@1 85.938 (90.759)\n",
            "Epoch: [29][360/782]\tTime 0.166 (0.168)\tLoss 0.3100 (0.2635)\tPrec@1 89.062 (90.768)\n",
            "Epoch: [29][370/782]\tTime 0.174 (0.168)\tLoss 0.2860 (0.2633)\tPrec@1 90.625 (90.815)\n",
            "Epoch: [29][380/782]\tTime 0.167 (0.168)\tLoss 0.1774 (0.2627)\tPrec@1 95.312 (90.842)\n",
            "Epoch: [29][390/782]\tTime 0.165 (0.168)\tLoss 0.2797 (0.2616)\tPrec@1 87.500 (90.869)\n",
            "Epoch: [29][400/782]\tTime 0.172 (0.168)\tLoss 0.0977 (0.2615)\tPrec@1 96.875 (90.867)\n",
            "Epoch: [29][410/782]\tTime 0.167 (0.168)\tLoss 0.1911 (0.2615)\tPrec@1 96.875 (90.895)\n",
            "Epoch: [29][420/782]\tTime 0.165 (0.168)\tLoss 0.2903 (0.2616)\tPrec@1 87.500 (90.889)\n",
            "Epoch: [29][430/782]\tTime 0.166 (0.168)\tLoss 0.2629 (0.2617)\tPrec@1 92.188 (90.875)\n",
            "Epoch: [29][440/782]\tTime 0.165 (0.168)\tLoss 0.2511 (0.2618)\tPrec@1 87.500 (90.873)\n",
            "Epoch: [29][450/782]\tTime 0.167 (0.168)\tLoss 0.3172 (0.2613)\tPrec@1 89.062 (90.881)\n",
            "Epoch: [29][460/782]\tTime 0.168 (0.168)\tLoss 0.3647 (0.2611)\tPrec@1 90.625 (90.903)\n",
            "Epoch: [29][470/782]\tTime 0.165 (0.168)\tLoss 0.2520 (0.2613)\tPrec@1 93.750 (90.920)\n",
            "Epoch: [29][480/782]\tTime 0.167 (0.168)\tLoss 0.1957 (0.2610)\tPrec@1 90.625 (90.901)\n",
            "Epoch: [29][490/782]\tTime 0.170 (0.168)\tLoss 0.2327 (0.2619)\tPrec@1 93.750 (90.860)\n",
            "Epoch: [29][500/782]\tTime 0.167 (0.168)\tLoss 0.1880 (0.2613)\tPrec@1 93.750 (90.878)\n",
            "Epoch: [29][510/782]\tTime 0.166 (0.168)\tLoss 0.2025 (0.2605)\tPrec@1 92.188 (90.903)\n",
            "Epoch: [29][520/782]\tTime 0.168 (0.168)\tLoss 0.1877 (0.2601)\tPrec@1 93.750 (90.931)\n",
            "Epoch: [29][530/782]\tTime 0.166 (0.168)\tLoss 0.2308 (0.2594)\tPrec@1 92.188 (90.946)\n",
            "Epoch: [29][540/782]\tTime 0.167 (0.168)\tLoss 0.3375 (0.2592)\tPrec@1 90.625 (90.943)\n",
            "Epoch: [29][550/782]\tTime 0.167 (0.168)\tLoss 0.1906 (0.2590)\tPrec@1 93.750 (90.962)\n",
            "Epoch: [29][560/782]\tTime 0.166 (0.168)\tLoss 0.3793 (0.2590)\tPrec@1 89.062 (90.959)\n",
            "Epoch: [29][570/782]\tTime 0.167 (0.168)\tLoss 0.1695 (0.2592)\tPrec@1 93.750 (90.942)\n",
            "Epoch: [29][580/782]\tTime 0.168 (0.168)\tLoss 0.3232 (0.2594)\tPrec@1 85.938 (90.953)\n",
            "Epoch: [29][590/782]\tTime 0.167 (0.168)\tLoss 0.1758 (0.2593)\tPrec@1 93.750 (90.961)\n",
            "Epoch: [29][600/782]\tTime 0.166 (0.168)\tLoss 0.3170 (0.2590)\tPrec@1 90.625 (90.992)\n",
            "Epoch: [29][610/782]\tTime 0.166 (0.168)\tLoss 0.3267 (0.2596)\tPrec@1 87.500 (90.980)\n",
            "Epoch: [29][620/782]\tTime 0.166 (0.168)\tLoss 0.2781 (0.2594)\tPrec@1 95.312 (90.982)\n",
            "Epoch: [29][630/782]\tTime 0.170 (0.168)\tLoss 0.2882 (0.2599)\tPrec@1 93.750 (90.967)\n",
            "Epoch: [29][640/782]\tTime 0.166 (0.168)\tLoss 0.2472 (0.2603)\tPrec@1 90.625 (90.952)\n",
            "Epoch: [29][650/782]\tTime 0.167 (0.168)\tLoss 0.2217 (0.2603)\tPrec@1 90.625 (90.951)\n",
            "Epoch: [29][660/782]\tTime 0.171 (0.168)\tLoss 0.4148 (0.2603)\tPrec@1 85.938 (90.949)\n",
            "Epoch: [29][670/782]\tTime 0.167 (0.168)\tLoss 0.2305 (0.2607)\tPrec@1 92.188 (90.942)\n",
            "Epoch: [29][680/782]\tTime 0.167 (0.168)\tLoss 0.2193 (0.2607)\tPrec@1 92.188 (90.935)\n",
            "Epoch: [29][690/782]\tTime 0.167 (0.168)\tLoss 0.4997 (0.2612)\tPrec@1 85.938 (90.935)\n",
            "Epoch: [29][700/782]\tTime 0.168 (0.168)\tLoss 0.4457 (0.2615)\tPrec@1 84.375 (90.924)\n",
            "Epoch: [29][710/782]\tTime 0.166 (0.168)\tLoss 0.2632 (0.2614)\tPrec@1 90.625 (90.944)\n",
            "Epoch: [29][720/782]\tTime 0.167 (0.168)\tLoss 0.1596 (0.2612)\tPrec@1 89.062 (90.941)\n",
            "Epoch: [29][730/782]\tTime 0.167 (0.168)\tLoss 0.2358 (0.2609)\tPrec@1 89.062 (90.954)\n",
            "Epoch: [29][740/782]\tTime 0.166 (0.168)\tLoss 0.2276 (0.2610)\tPrec@1 89.062 (90.937)\n",
            "Epoch: [29][750/782]\tTime 0.170 (0.168)\tLoss 0.2301 (0.2609)\tPrec@1 92.188 (90.939)\n",
            "Epoch: [29][760/782]\tTime 0.167 (0.168)\tLoss 0.5896 (0.2615)\tPrec@1 78.125 (90.910)\n",
            "Epoch: [29][770/782]\tTime 0.167 (0.168)\tLoss 0.5317 (0.2624)\tPrec@1 81.250 (90.868)\n",
            "Epoch: [29][780/782]\tTime 0.164 (0.168)\tLoss 0.2469 (0.2622)\tPrec@1 92.188 (90.879)\n",
            "Training accuracy:  tensor(90.8760, device='cuda:0')\n",
            "Best accuraacy:  tensor(90.9520, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.133 (0.133)\tLoss 0.5443 (0.5443)\tPrec@1 78.125 (78.125)\n",
            "Test: [10/157]\tTime 0.043 (0.049)\tLoss 0.7591 (0.6266)\tPrec@1 82.812 (80.966)\n",
            "Test: [20/157]\tTime 0.041 (0.047)\tLoss 0.5945 (0.6700)\tPrec@1 82.812 (80.283)\n",
            "Test: [30/157]\tTime 0.043 (0.046)\tLoss 0.8356 (0.6545)\tPrec@1 76.562 (81.149)\n",
            "Test: [40/157]\tTime 0.043 (0.045)\tLoss 0.5947 (0.6490)\tPrec@1 87.500 (81.593)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.6944 (0.6368)\tPrec@1 78.125 (81.618)\n",
            "Test: [60/157]\tTime 0.043 (0.045)\tLoss 0.6801 (0.6364)\tPrec@1 81.250 (81.557)\n",
            "Test: [70/157]\tTime 0.045 (0.045)\tLoss 1.0299 (0.6438)\tPrec@1 70.312 (81.118)\n",
            "Test: [80/157]\tTime 0.044 (0.045)\tLoss 0.6483 (0.6362)\tPrec@1 79.688 (81.154)\n",
            "Test: [90/157]\tTime 0.041 (0.045)\tLoss 1.1454 (0.6469)\tPrec@1 75.000 (81.044)\n",
            "Test: [100/157]\tTime 0.043 (0.045)\tLoss 0.6305 (0.6444)\tPrec@1 73.438 (81.049)\n",
            "Test: [110/157]\tTime 0.044 (0.044)\tLoss 0.4151 (0.6395)\tPrec@1 85.938 (81.137)\n",
            "Test: [120/157]\tTime 0.044 (0.044)\tLoss 0.6998 (0.6441)\tPrec@1 82.812 (81.211)\n",
            "Test: [130/157]\tTime 0.044 (0.044)\tLoss 0.4480 (0.6452)\tPrec@1 87.500 (81.202)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.5940 (0.6422)\tPrec@1 82.812 (81.195)\n",
            "Test: [150/157]\tTime 0.044 (0.044)\tLoss 0.5034 (0.6376)\tPrec@1 87.500 (81.364)\n",
            " * Prec@1 81.460\n",
            "Best accuracy:  tensor(88.2900, device='cuda:0')\n",
            "Epoch: [30][0/782]\tTime 0.271 (0.271)\tLoss 0.2790 (0.2790)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [30][10/782]\tTime 0.168 (0.177)\tLoss 0.2139 (0.3096)\tPrec@1 95.312 (89.347)\n",
            "Epoch: [30][20/782]\tTime 0.166 (0.172)\tLoss 0.3783 (0.3067)\tPrec@1 89.062 (89.881)\n",
            "Epoch: [30][30/782]\tTime 0.168 (0.171)\tLoss 0.2761 (0.2860)\tPrec@1 90.625 (90.726)\n",
            "Epoch: [30][40/782]\tTime 0.166 (0.170)\tLoss 0.3817 (0.2719)\tPrec@1 85.938 (90.930)\n",
            "Epoch: [30][50/782]\tTime 0.167 (0.169)\tLoss 0.1271 (0.2688)\tPrec@1 96.875 (90.901)\n",
            "Epoch: [30][60/782]\tTime 0.166 (0.169)\tLoss 0.3201 (0.2622)\tPrec@1 90.625 (91.163)\n",
            "Epoch: [30][70/782]\tTime 0.166 (0.169)\tLoss 0.3309 (0.2604)\tPrec@1 90.625 (91.351)\n",
            "Epoch: [30][80/782]\tTime 0.166 (0.168)\tLoss 0.1279 (0.2590)\tPrec@1 95.312 (91.377)\n",
            "Epoch: [30][90/782]\tTime 0.171 (0.168)\tLoss 0.2228 (0.2613)\tPrec@1 90.625 (91.329)\n",
            "Epoch: [30][100/782]\tTime 0.167 (0.168)\tLoss 0.4381 (0.2657)\tPrec@1 85.938 (91.105)\n",
            "Epoch: [30][110/782]\tTime 0.167 (0.168)\tLoss 0.3317 (0.2697)\tPrec@1 87.500 (90.921)\n",
            "Epoch: [30][120/782]\tTime 0.169 (0.168)\tLoss 0.1873 (0.2663)\tPrec@1 92.188 (91.025)\n",
            "Epoch: [30][130/782]\tTime 0.168 (0.168)\tLoss 0.2602 (0.2613)\tPrec@1 92.188 (91.138)\n",
            "Epoch: [30][140/782]\tTime 0.166 (0.168)\tLoss 0.3038 (0.2608)\tPrec@1 89.062 (91.146)\n",
            "Epoch: [30][150/782]\tTime 0.166 (0.168)\tLoss 0.2154 (0.2648)\tPrec@1 92.188 (90.987)\n",
            "Epoch: [30][160/782]\tTime 0.166 (0.168)\tLoss 0.2539 (0.2647)\tPrec@1 89.062 (90.974)\n",
            "Epoch: [30][170/782]\tTime 0.168 (0.168)\tLoss 0.1884 (0.2622)\tPrec@1 90.625 (91.054)\n",
            "Epoch: [30][180/782]\tTime 0.167 (0.168)\tLoss 0.2037 (0.2623)\tPrec@1 92.188 (91.048)\n",
            "Epoch: [30][190/782]\tTime 0.165 (0.168)\tLoss 0.2133 (0.2622)\tPrec@1 92.188 (91.091)\n",
            "Epoch: [30][200/782]\tTime 0.168 (0.168)\tLoss 0.3137 (0.2613)\tPrec@1 85.938 (91.076)\n",
            "Epoch: [30][210/782]\tTime 0.168 (0.168)\tLoss 0.2119 (0.2623)\tPrec@1 92.188 (91.047)\n",
            "Epoch: [30][220/782]\tTime 0.167 (0.168)\tLoss 0.1586 (0.2613)\tPrec@1 95.312 (91.120)\n",
            "Epoch: [30][230/782]\tTime 0.166 (0.168)\tLoss 0.1880 (0.2602)\tPrec@1 95.312 (91.207)\n",
            "Epoch: [30][240/782]\tTime 0.167 (0.168)\tLoss 0.2366 (0.2609)\tPrec@1 92.188 (91.150)\n",
            "Epoch: [30][250/782]\tTime 0.165 (0.168)\tLoss 0.3054 (0.2601)\tPrec@1 92.188 (91.179)\n",
            "Epoch: [30][260/782]\tTime 0.165 (0.168)\tLoss 0.1690 (0.2586)\tPrec@1 95.312 (91.218)\n",
            "Epoch: [30][270/782]\tTime 0.166 (0.168)\tLoss 0.2084 (0.2573)\tPrec@1 93.750 (91.277)\n",
            "Epoch: [30][280/782]\tTime 0.168 (0.168)\tLoss 0.1429 (0.2573)\tPrec@1 95.312 (91.248)\n",
            "Epoch: [30][290/782]\tTime 0.166 (0.168)\tLoss 0.2524 (0.2564)\tPrec@1 93.750 (91.296)\n",
            "Epoch: [30][300/782]\tTime 0.167 (0.168)\tLoss 0.2900 (0.2566)\tPrec@1 90.625 (91.279)\n",
            "Epoch: [30][310/782]\tTime 0.166 (0.168)\tLoss 0.3271 (0.2564)\tPrec@1 87.500 (91.248)\n",
            "Epoch: [30][320/782]\tTime 0.175 (0.168)\tLoss 0.3735 (0.2559)\tPrec@1 87.500 (91.263)\n",
            "Epoch: [30][330/782]\tTime 0.167 (0.168)\tLoss 0.1991 (0.2568)\tPrec@1 92.188 (91.229)\n",
            "Epoch: [30][340/782]\tTime 0.167 (0.168)\tLoss 0.1730 (0.2588)\tPrec@1 93.750 (91.134)\n",
            "Epoch: [30][350/782]\tTime 0.171 (0.168)\tLoss 0.1679 (0.2582)\tPrec@1 96.875 (91.177)\n",
            "Epoch: [30][360/782]\tTime 0.166 (0.168)\tLoss 0.2226 (0.2577)\tPrec@1 90.625 (91.201)\n",
            "Epoch: [30][370/782]\tTime 0.168 (0.168)\tLoss 0.3435 (0.2570)\tPrec@1 89.062 (91.231)\n",
            "Epoch: [30][380/782]\tTime 0.167 (0.168)\tLoss 0.1600 (0.2578)\tPrec@1 92.188 (91.216)\n",
            "Epoch: [30][390/782]\tTime 0.167 (0.168)\tLoss 0.1610 (0.2576)\tPrec@1 95.312 (91.228)\n",
            "Epoch: [30][400/782]\tTime 0.166 (0.168)\tLoss 0.3253 (0.2591)\tPrec@1 89.062 (91.209)\n",
            "Epoch: [30][410/782]\tTime 0.165 (0.168)\tLoss 0.3948 (0.2595)\tPrec@1 85.938 (91.188)\n",
            "Epoch: [30][420/782]\tTime 0.165 (0.168)\tLoss 0.1171 (0.2597)\tPrec@1 98.438 (91.178)\n",
            "Epoch: [30][430/782]\tTime 0.167 (0.168)\tLoss 0.1352 (0.2594)\tPrec@1 96.875 (91.176)\n",
            "Epoch: [30][440/782]\tTime 0.168 (0.168)\tLoss 0.3064 (0.2597)\tPrec@1 89.062 (91.178)\n",
            "Epoch: [30][450/782]\tTime 0.168 (0.168)\tLoss 0.1790 (0.2587)\tPrec@1 90.625 (91.186)\n",
            "Epoch: [30][460/782]\tTime 0.167 (0.168)\tLoss 0.3085 (0.2589)\tPrec@1 89.062 (91.164)\n",
            "Epoch: [30][470/782]\tTime 0.168 (0.168)\tLoss 0.3136 (0.2597)\tPrec@1 90.625 (91.109)\n",
            "Epoch: [30][480/782]\tTime 0.168 (0.168)\tLoss 0.3972 (0.2597)\tPrec@1 89.062 (91.093)\n",
            "Epoch: [30][490/782]\tTime 0.166 (0.168)\tLoss 0.2374 (0.2593)\tPrec@1 89.062 (91.093)\n",
            "Epoch: [30][500/782]\tTime 0.167 (0.168)\tLoss 0.3399 (0.2594)\tPrec@1 89.062 (91.071)\n",
            "Epoch: [30][510/782]\tTime 0.167 (0.168)\tLoss 0.2984 (0.2600)\tPrec@1 87.500 (91.035)\n",
            "Epoch: [30][520/782]\tTime 0.167 (0.168)\tLoss 0.2609 (0.2602)\tPrec@1 89.062 (91.045)\n",
            "Epoch: [30][530/782]\tTime 0.166 (0.168)\tLoss 0.2660 (0.2602)\tPrec@1 92.188 (91.028)\n",
            "Epoch: [30][540/782]\tTime 0.167 (0.168)\tLoss 0.2213 (0.2603)\tPrec@1 85.938 (90.992)\n",
            "Epoch: [30][550/782]\tTime 0.171 (0.168)\tLoss 0.2186 (0.2598)\tPrec@1 93.750 (91.013)\n",
            "Epoch: [30][560/782]\tTime 0.166 (0.168)\tLoss 0.2680 (0.2606)\tPrec@1 90.625 (90.973)\n",
            "Epoch: [30][570/782]\tTime 0.167 (0.168)\tLoss 0.1775 (0.2600)\tPrec@1 96.875 (91.005)\n",
            "Epoch: [30][580/782]\tTime 0.171 (0.168)\tLoss 0.2534 (0.2607)\tPrec@1 90.625 (90.972)\n",
            "Epoch: [30][590/782]\tTime 0.168 (0.168)\tLoss 0.2373 (0.2609)\tPrec@1 89.062 (90.953)\n",
            "Epoch: [30][600/782]\tTime 0.167 (0.168)\tLoss 0.3120 (0.2602)\tPrec@1 89.062 (90.992)\n",
            "Epoch: [30][610/782]\tTime 0.167 (0.168)\tLoss 0.3082 (0.2605)\tPrec@1 90.625 (90.980)\n",
            "Epoch: [30][620/782]\tTime 0.168 (0.168)\tLoss 0.2246 (0.2608)\tPrec@1 89.062 (90.970)\n",
            "Epoch: [30][630/782]\tTime 0.168 (0.168)\tLoss 0.1769 (0.2604)\tPrec@1 92.188 (90.984)\n",
            "Epoch: [30][640/782]\tTime 0.169 (0.168)\tLoss 0.4664 (0.2612)\tPrec@1 89.062 (90.991)\n",
            "Epoch: [30][650/782]\tTime 0.168 (0.168)\tLoss 0.5633 (0.2618)\tPrec@1 81.250 (90.966)\n",
            "Epoch: [30][660/782]\tTime 0.168 (0.168)\tLoss 0.2749 (0.2624)\tPrec@1 93.750 (90.937)\n",
            "Epoch: [30][670/782]\tTime 0.168 (0.168)\tLoss 0.2317 (0.2625)\tPrec@1 90.625 (90.914)\n",
            "Epoch: [30][680/782]\tTime 0.166 (0.168)\tLoss 0.1402 (0.2632)\tPrec@1 93.750 (90.889)\n",
            "Epoch: [30][690/782]\tTime 0.168 (0.168)\tLoss 0.2832 (0.2634)\tPrec@1 90.625 (90.883)\n",
            "Epoch: [30][700/782]\tTime 0.171 (0.168)\tLoss 0.2254 (0.2632)\tPrec@1 92.188 (90.872)\n",
            "Epoch: [30][710/782]\tTime 0.168 (0.168)\tLoss 0.4214 (0.2635)\tPrec@1 82.812 (90.867)\n",
            "Epoch: [30][720/782]\tTime 0.166 (0.168)\tLoss 0.2114 (0.2639)\tPrec@1 92.188 (90.842)\n",
            "Epoch: [30][730/782]\tTime 0.166 (0.168)\tLoss 0.3584 (0.2638)\tPrec@1 85.938 (90.830)\n",
            "Epoch: [30][740/782]\tTime 0.166 (0.168)\tLoss 0.2126 (0.2636)\tPrec@1 92.188 (90.838)\n",
            "Epoch: [30][750/782]\tTime 0.167 (0.168)\tLoss 0.6462 (0.2648)\tPrec@1 81.250 (90.789)\n",
            "Epoch: [30][760/782]\tTime 0.169 (0.168)\tLoss 0.2513 (0.2650)\tPrec@1 90.625 (90.785)\n",
            "Epoch: [30][770/782]\tTime 0.166 (0.168)\tLoss 0.4202 (0.2659)\tPrec@1 84.375 (90.751)\n",
            "Epoch: [30][780/782]\tTime 0.163 (0.168)\tLoss 0.3874 (0.2662)\tPrec@1 89.062 (90.739)\n",
            "Training accuracy:  tensor(90.7400, device='cuda:0')\n",
            "Best accuraacy:  tensor(90.9520, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.132 (0.132)\tLoss 0.4537 (0.4537)\tPrec@1 84.375 (84.375)\n",
            "Test: [10/157]\tTime 0.042 (0.049)\tLoss 0.3623 (0.4044)\tPrec@1 85.938 (86.222)\n",
            "Test: [20/157]\tTime 0.044 (0.047)\tLoss 0.4881 (0.4152)\tPrec@1 84.375 (86.161)\n",
            "Test: [30/157]\tTime 0.043 (0.046)\tLoss 0.4606 (0.4051)\tPrec@1 87.500 (86.845)\n",
            "Test: [40/157]\tTime 0.045 (0.046)\tLoss 0.3035 (0.3932)\tPrec@1 90.625 (87.233)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.3526 (0.3943)\tPrec@1 87.500 (87.316)\n",
            "Test: [60/157]\tTime 0.040 (0.045)\tLoss 0.3940 (0.3935)\tPrec@1 87.500 (87.449)\n",
            "Test: [70/157]\tTime 0.043 (0.045)\tLoss 0.3113 (0.3966)\tPrec@1 90.625 (87.500)\n",
            "Test: [80/157]\tTime 0.043 (0.045)\tLoss 0.5986 (0.4003)\tPrec@1 82.812 (87.481)\n",
            "Test: [90/157]\tTime 0.044 (0.045)\tLoss 0.3067 (0.3909)\tPrec@1 92.188 (87.758)\n",
            "Test: [100/157]\tTime 0.043 (0.045)\tLoss 0.1534 (0.3937)\tPrec@1 96.875 (87.670)\n",
            "Test: [110/157]\tTime 0.044 (0.045)\tLoss 0.3217 (0.3880)\tPrec@1 85.938 (87.796)\n",
            "Test: [120/157]\tTime 0.044 (0.044)\tLoss 0.1684 (0.3901)\tPrec@1 93.750 (87.629)\n",
            "Test: [130/157]\tTime 0.041 (0.044)\tLoss 0.2334 (0.3972)\tPrec@1 90.625 (87.381)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.4316 (0.3948)\tPrec@1 82.812 (87.389)\n",
            "Test: [150/157]\tTime 0.044 (0.044)\tLoss 0.6272 (0.3993)\tPrec@1 75.000 (87.148)\n",
            " * Prec@1 87.180\n",
            "Best accuracy:  tensor(88.2900, device='cuda:0')\n",
            "Epoch: [31][0/782]\tTime 0.269 (0.269)\tLoss 0.2550 (0.2550)\tPrec@1 87.500 (87.500)\n",
            "Epoch: [31][10/782]\tTime 0.166 (0.177)\tLoss 0.2278 (0.2291)\tPrec@1 92.188 (91.335)\n",
            "Epoch: [31][20/782]\tTime 0.167 (0.172)\tLoss 0.3290 (0.2650)\tPrec@1 87.500 (90.699)\n",
            "Epoch: [31][30/782]\tTime 0.167 (0.171)\tLoss 0.1387 (0.2489)\tPrec@1 96.875 (91.633)\n",
            "Epoch: [31][40/782]\tTime 0.167 (0.170)\tLoss 0.2968 (0.2479)\tPrec@1 90.625 (91.806)\n",
            "Epoch: [31][50/782]\tTime 0.167 (0.170)\tLoss 0.1381 (0.2407)\tPrec@1 95.312 (91.881)\n",
            "Epoch: [31][60/782]\tTime 0.167 (0.170)\tLoss 0.1805 (0.2411)\tPrec@1 95.312 (91.957)\n",
            "Epoch: [31][70/782]\tTime 0.168 (0.170)\tLoss 0.2704 (0.2399)\tPrec@1 90.625 (91.901)\n",
            "Epoch: [31][80/782]\tTime 0.167 (0.169)\tLoss 0.1537 (0.2385)\tPrec@1 93.750 (91.995)\n",
            "Epoch: [31][90/782]\tTime 0.168 (0.169)\tLoss 0.2030 (0.2391)\tPrec@1 95.312 (91.930)\n",
            "Epoch: [31][100/782]\tTime 0.170 (0.169)\tLoss 0.1537 (0.2361)\tPrec@1 95.312 (92.017)\n",
            "Epoch: [31][110/782]\tTime 0.166 (0.169)\tLoss 0.1643 (0.2309)\tPrec@1 93.750 (92.145)\n",
            "Epoch: [31][120/782]\tTime 0.167 (0.169)\tLoss 0.3112 (0.2334)\tPrec@1 92.188 (92.033)\n",
            "Epoch: [31][130/782]\tTime 0.167 (0.169)\tLoss 0.3899 (0.2341)\tPrec@1 87.500 (92.009)\n",
            "Epoch: [31][140/782]\tTime 0.167 (0.169)\tLoss 0.1307 (0.2373)\tPrec@1 93.750 (91.888)\n",
            "Epoch: [31][150/782]\tTime 0.166 (0.169)\tLoss 0.2653 (0.2411)\tPrec@1 90.625 (91.743)\n",
            "Epoch: [31][160/782]\tTime 0.169 (0.168)\tLoss 0.2483 (0.2371)\tPrec@1 89.062 (91.887)\n",
            "Epoch: [31][170/782]\tTime 0.167 (0.168)\tLoss 0.4237 (0.2390)\tPrec@1 84.375 (91.758)\n",
            "Epoch: [31][180/782]\tTime 0.167 (0.168)\tLoss 0.2087 (0.2363)\tPrec@1 90.625 (91.790)\n",
            "Epoch: [31][190/782]\tTime 0.167 (0.168)\tLoss 0.2337 (0.2373)\tPrec@1 93.750 (91.811)\n",
            "Epoch: [31][200/782]\tTime 0.168 (0.168)\tLoss 0.2718 (0.2355)\tPrec@1 90.625 (91.845)\n",
            "Epoch: [31][210/782]\tTime 0.165 (0.168)\tLoss 0.1558 (0.2363)\tPrec@1 95.312 (91.780)\n",
            "Epoch: [31][220/782]\tTime 0.166 (0.168)\tLoss 0.2114 (0.2371)\tPrec@1 90.625 (91.693)\n",
            "Epoch: [31][230/782]\tTime 0.167 (0.168)\tLoss 0.2546 (0.2386)\tPrec@1 92.188 (91.585)\n",
            "Epoch: [31][240/782]\tTime 0.169 (0.168)\tLoss 0.2016 (0.2382)\tPrec@1 90.625 (91.565)\n",
            "Epoch: [31][250/782]\tTime 0.167 (0.168)\tLoss 0.2495 (0.2418)\tPrec@1 87.500 (91.465)\n",
            "Epoch: [31][260/782]\tTime 0.165 (0.168)\tLoss 0.2144 (0.2421)\tPrec@1 92.188 (91.475)\n",
            "Epoch: [31][270/782]\tTime 0.168 (0.168)\tLoss 0.2337 (0.2435)\tPrec@1 93.750 (91.444)\n",
            "Epoch: [31][280/782]\tTime 0.166 (0.168)\tLoss 0.1910 (0.2459)\tPrec@1 95.312 (91.376)\n",
            "Epoch: [31][290/782]\tTime 0.167 (0.168)\tLoss 0.2492 (0.2462)\tPrec@1 93.750 (91.371)\n",
            "Epoch: [31][300/782]\tTime 0.171 (0.168)\tLoss 0.1538 (0.2462)\tPrec@1 96.875 (91.352)\n",
            "Epoch: [31][310/782]\tTime 0.168 (0.168)\tLoss 0.1465 (0.2473)\tPrec@1 96.875 (91.293)\n",
            "Epoch: [31][320/782]\tTime 0.168 (0.168)\tLoss 0.3026 (0.2482)\tPrec@1 90.625 (91.268)\n",
            "Epoch: [31][330/782]\tTime 0.170 (0.168)\tLoss 0.2440 (0.2495)\tPrec@1 90.625 (91.201)\n",
            "Epoch: [31][340/782]\tTime 0.167 (0.168)\tLoss 0.1859 (0.2492)\tPrec@1 92.188 (91.198)\n",
            "Epoch: [31][350/782]\tTime 0.167 (0.168)\tLoss 0.1779 (0.2495)\tPrec@1 92.188 (91.164)\n",
            "Epoch: [31][360/782]\tTime 0.166 (0.168)\tLoss 0.2218 (0.2509)\tPrec@1 93.750 (91.153)\n",
            "Epoch: [31][370/782]\tTime 0.167 (0.168)\tLoss 0.2301 (0.2512)\tPrec@1 90.625 (91.135)\n",
            "Epoch: [31][380/782]\tTime 0.166 (0.168)\tLoss 0.2841 (0.2510)\tPrec@1 93.750 (91.142)\n",
            "Epoch: [31][390/782]\tTime 0.166 (0.168)\tLoss 0.2939 (0.2516)\tPrec@1 85.938 (91.117)\n",
            "Epoch: [31][400/782]\tTime 0.167 (0.168)\tLoss 0.3259 (0.2522)\tPrec@1 90.625 (91.108)\n",
            "Epoch: [31][410/782]\tTime 0.166 (0.168)\tLoss 0.2702 (0.2517)\tPrec@1 89.062 (91.131)\n",
            "Epoch: [31][420/782]\tTime 0.168 (0.168)\tLoss 0.2023 (0.2525)\tPrec@1 90.625 (91.082)\n",
            "Epoch: [31][430/782]\tTime 0.166 (0.168)\tLoss 0.3287 (0.2526)\tPrec@1 85.938 (91.071)\n",
            "Epoch: [31][440/782]\tTime 0.168 (0.168)\tLoss 0.4278 (0.2532)\tPrec@1 87.500 (91.054)\n",
            "Epoch: [31][450/782]\tTime 0.168 (0.168)\tLoss 0.4619 (0.2542)\tPrec@1 85.938 (91.048)\n",
            "Epoch: [31][460/782]\tTime 0.166 (0.168)\tLoss 0.4437 (0.2557)\tPrec@1 84.375 (91.001)\n",
            "Epoch: [31][470/782]\tTime 0.165 (0.168)\tLoss 0.3235 (0.2557)\tPrec@1 90.625 (91.013)\n",
            "Epoch: [31][480/782]\tTime 0.167 (0.168)\tLoss 0.3496 (0.2556)\tPrec@1 84.375 (91.005)\n",
            "Epoch: [31][490/782]\tTime 0.167 (0.168)\tLoss 0.3576 (0.2559)\tPrec@1 85.938 (90.978)\n",
            "Epoch: [31][500/782]\tTime 0.167 (0.168)\tLoss 0.1716 (0.2564)\tPrec@1 93.750 (90.952)\n",
            "Epoch: [31][510/782]\tTime 0.168 (0.168)\tLoss 0.3132 (0.2557)\tPrec@1 90.625 (90.977)\n",
            "Epoch: [31][520/782]\tTime 0.167 (0.168)\tLoss 0.3791 (0.2560)\tPrec@1 89.062 (90.967)\n",
            "Epoch: [31][530/782]\tTime 0.165 (0.168)\tLoss 0.2119 (0.2561)\tPrec@1 93.750 (90.963)\n",
            "Epoch: [31][540/782]\tTime 0.168 (0.168)\tLoss 0.2469 (0.2556)\tPrec@1 90.625 (90.977)\n",
            "Epoch: [31][550/782]\tTime 0.167 (0.168)\tLoss 0.3266 (0.2557)\tPrec@1 89.062 (90.982)\n",
            "Epoch: [31][560/782]\tTime 0.166 (0.168)\tLoss 0.2692 (0.2557)\tPrec@1 90.625 (90.990)\n",
            "Epoch: [31][570/782]\tTime 0.167 (0.168)\tLoss 0.3029 (0.2564)\tPrec@1 89.062 (90.956)\n",
            "Epoch: [31][580/782]\tTime 0.168 (0.168)\tLoss 0.1790 (0.2575)\tPrec@1 93.750 (90.921)\n",
            "Epoch: [31][590/782]\tTime 0.172 (0.168)\tLoss 0.2859 (0.2578)\tPrec@1 92.188 (90.921)\n",
            "Epoch: [31][600/782]\tTime 0.167 (0.168)\tLoss 0.1093 (0.2583)\tPrec@1 98.438 (90.927)\n",
            "Epoch: [31][610/782]\tTime 0.165 (0.168)\tLoss 0.1496 (0.2584)\tPrec@1 90.625 (90.911)\n",
            "Epoch: [31][620/782]\tTime 0.166 (0.168)\tLoss 0.3311 (0.2588)\tPrec@1 87.500 (90.869)\n",
            "Epoch: [31][630/782]\tTime 0.168 (0.168)\tLoss 0.3837 (0.2594)\tPrec@1 87.500 (90.853)\n",
            "Epoch: [31][640/782]\tTime 0.166 (0.168)\tLoss 0.1252 (0.2593)\tPrec@1 98.438 (90.869)\n",
            "Epoch: [31][650/782]\tTime 0.166 (0.168)\tLoss 0.1790 (0.2594)\tPrec@1 92.188 (90.875)\n",
            "Epoch: [31][660/782]\tTime 0.169 (0.168)\tLoss 0.2411 (0.2591)\tPrec@1 89.062 (90.878)\n",
            "Epoch: [31][670/782]\tTime 0.167 (0.168)\tLoss 0.2471 (0.2585)\tPrec@1 95.312 (90.916)\n",
            "Epoch: [31][680/782]\tTime 0.166 (0.168)\tLoss 0.2024 (0.2590)\tPrec@1 92.188 (90.898)\n",
            "Epoch: [31][690/782]\tTime 0.166 (0.168)\tLoss 0.2701 (0.2594)\tPrec@1 89.062 (90.881)\n",
            "Epoch: [31][700/782]\tTime 0.166 (0.168)\tLoss 0.2912 (0.2599)\tPrec@1 93.750 (90.857)\n",
            "Epoch: [31][710/782]\tTime 0.168 (0.168)\tLoss 0.1499 (0.2591)\tPrec@1 95.312 (90.893)\n",
            "Epoch: [31][720/782]\tTime 0.166 (0.168)\tLoss 0.2016 (0.2598)\tPrec@1 92.188 (90.870)\n",
            "Epoch: [31][730/782]\tTime 0.167 (0.168)\tLoss 0.1929 (0.2594)\tPrec@1 93.750 (90.888)\n",
            "Epoch: [31][740/782]\tTime 0.166 (0.168)\tLoss 0.1890 (0.2596)\tPrec@1 92.188 (90.880)\n",
            "Epoch: [31][750/782]\tTime 0.166 (0.168)\tLoss 0.2507 (0.2605)\tPrec@1 89.062 (90.843)\n",
            "Epoch: [31][760/782]\tTime 0.167 (0.168)\tLoss 0.4005 (0.2604)\tPrec@1 85.938 (90.845)\n",
            "Epoch: [31][770/782]\tTime 0.168 (0.168)\tLoss 0.2607 (0.2608)\tPrec@1 90.625 (90.840)\n",
            "Epoch: [31][780/782]\tTime 0.162 (0.168)\tLoss 0.3355 (0.2611)\tPrec@1 87.500 (90.847)\n",
            "Training accuracy:  tensor(90.8460, device='cuda:0')\n",
            "Best accuraacy:  tensor(90.9520, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.119 (0.119)\tLoss 0.4924 (0.4924)\tPrec@1 81.250 (81.250)\n",
            "Test: [10/157]\tTime 0.040 (0.048)\tLoss 0.4138 (0.4999)\tPrec@1 87.500 (82.670)\n",
            "Test: [20/157]\tTime 0.051 (0.046)\tLoss 0.4382 (0.5092)\tPrec@1 81.250 (83.036)\n",
            "Test: [30/157]\tTime 0.039 (0.046)\tLoss 0.4038 (0.4996)\tPrec@1 82.812 (83.821)\n",
            "Test: [40/157]\tTime 0.043 (0.045)\tLoss 0.3291 (0.4823)\tPrec@1 87.500 (83.689)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.6353 (0.5030)\tPrec@1 82.812 (83.303)\n",
            "Test: [60/157]\tTime 0.044 (0.045)\tLoss 0.5521 (0.5024)\tPrec@1 79.688 (83.607)\n",
            "Test: [70/157]\tTime 0.047 (0.045)\tLoss 0.6342 (0.4934)\tPrec@1 85.938 (84.111)\n",
            "Test: [80/157]\tTime 0.043 (0.045)\tLoss 0.6246 (0.4905)\tPrec@1 82.812 (84.201)\n",
            "Test: [90/157]\tTime 0.045 (0.045)\tLoss 0.6514 (0.4895)\tPrec@1 79.688 (84.409)\n",
            "Test: [100/157]\tTime 0.042 (0.045)\tLoss 0.3253 (0.5026)\tPrec@1 85.938 (84.050)\n",
            "Test: [110/157]\tTime 0.044 (0.045)\tLoss 0.5750 (0.5041)\tPrec@1 84.375 (84.108)\n",
            "Test: [120/157]\tTime 0.044 (0.044)\tLoss 0.7397 (0.5076)\tPrec@1 78.125 (83.949)\n",
            "Test: [130/157]\tTime 0.042 (0.044)\tLoss 0.4664 (0.5085)\tPrec@1 85.938 (83.981)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.7034 (0.5094)\tPrec@1 78.125 (83.777)\n",
            "Test: [150/157]\tTime 0.043 (0.044)\tLoss 0.6021 (0.5115)\tPrec@1 84.375 (83.744)\n",
            " * Prec@1 83.770\n",
            "Best accuracy:  tensor(88.2900, device='cuda:0')\n",
            "Epoch: [32][0/782]\tTime 0.272 (0.272)\tLoss 0.2196 (0.2196)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [32][10/782]\tTime 0.166 (0.177)\tLoss 0.3414 (0.2704)\tPrec@1 84.375 (90.909)\n",
            "Epoch: [32][20/782]\tTime 0.165 (0.172)\tLoss 0.3385 (0.2923)\tPrec@1 89.062 (89.732)\n",
            "Epoch: [32][30/782]\tTime 0.167 (0.171)\tLoss 0.2806 (0.2798)\tPrec@1 89.062 (89.970)\n",
            "Epoch: [32][40/782]\tTime 0.167 (0.170)\tLoss 0.2578 (0.2837)\tPrec@1 87.500 (89.787)\n",
            "Epoch: [32][50/782]\tTime 0.171 (0.170)\tLoss 0.2388 (0.2721)\tPrec@1 90.625 (90.135)\n",
            "Epoch: [32][60/782]\tTime 0.168 (0.169)\tLoss 0.2046 (0.2693)\tPrec@1 90.625 (90.318)\n",
            "Epoch: [32][70/782]\tTime 0.166 (0.169)\tLoss 0.1322 (0.2614)\tPrec@1 95.312 (90.581)\n",
            "Epoch: [32][80/782]\tTime 0.168 (0.169)\tLoss 0.1086 (0.2560)\tPrec@1 95.312 (90.818)\n",
            "Epoch: [32][90/782]\tTime 0.166 (0.169)\tLoss 0.2035 (0.2531)\tPrec@1 92.188 (90.934)\n",
            "Epoch: [32][100/782]\tTime 0.167 (0.168)\tLoss 0.3181 (0.2498)\tPrec@1 85.938 (91.074)\n",
            "Epoch: [32][110/782]\tTime 0.167 (0.168)\tLoss 0.2153 (0.2476)\tPrec@1 90.625 (91.118)\n",
            "Epoch: [32][120/782]\tTime 0.167 (0.168)\tLoss 0.3758 (0.2451)\tPrec@1 87.500 (91.206)\n",
            "Epoch: [32][130/782]\tTime 0.168 (0.168)\tLoss 0.2131 (0.2395)\tPrec@1 93.750 (91.484)\n",
            "Epoch: [32][140/782]\tTime 0.172 (0.168)\tLoss 0.1708 (0.2378)\tPrec@1 92.188 (91.534)\n",
            "Epoch: [32][150/782]\tTime 0.166 (0.168)\tLoss 0.1173 (0.2366)\tPrec@1 96.875 (91.639)\n",
            "Epoch: [32][160/782]\tTime 0.166 (0.168)\tLoss 0.2898 (0.2351)\tPrec@1 90.625 (91.790)\n",
            "Epoch: [32][170/782]\tTime 0.167 (0.168)\tLoss 0.2536 (0.2358)\tPrec@1 89.062 (91.740)\n",
            "Epoch: [32][180/782]\tTime 0.166 (0.168)\tLoss 0.2159 (0.2391)\tPrec@1 95.312 (91.644)\n",
            "Epoch: [32][190/782]\tTime 0.165 (0.168)\tLoss 0.3072 (0.2407)\tPrec@1 87.500 (91.549)\n",
            "Epoch: [32][200/782]\tTime 0.168 (0.168)\tLoss 0.2727 (0.2425)\tPrec@1 92.188 (91.465)\n",
            "Epoch: [32][210/782]\tTime 0.167 (0.168)\tLoss 0.2011 (0.2451)\tPrec@1 92.188 (91.358)\n",
            "Epoch: [32][220/782]\tTime 0.167 (0.168)\tLoss 0.3016 (0.2468)\tPrec@1 92.188 (91.311)\n",
            "Epoch: [32][230/782]\tTime 0.168 (0.168)\tLoss 0.1464 (0.2464)\tPrec@1 95.312 (91.362)\n",
            "Epoch: [32][240/782]\tTime 0.174 (0.168)\tLoss 0.2513 (0.2467)\tPrec@1 90.625 (91.338)\n",
            "Epoch: [32][250/782]\tTime 0.166 (0.168)\tLoss 0.1614 (0.2459)\tPrec@1 93.750 (91.335)\n",
            "Epoch: [32][260/782]\tTime 0.168 (0.168)\tLoss 0.2485 (0.2475)\tPrec@1 90.625 (91.272)\n",
            "Epoch: [32][270/782]\tTime 0.167 (0.168)\tLoss 0.2562 (0.2460)\tPrec@1 89.062 (91.300)\n",
            "Epoch: [32][280/782]\tTime 0.170 (0.168)\tLoss 0.1776 (0.2452)\tPrec@1 93.750 (91.353)\n",
            "Epoch: [32][290/782]\tTime 0.167 (0.168)\tLoss 0.1536 (0.2442)\tPrec@1 95.312 (91.382)\n",
            "Epoch: [32][300/782]\tTime 0.169 (0.168)\tLoss 0.2423 (0.2466)\tPrec@1 89.062 (91.289)\n",
            "Epoch: [32][310/782]\tTime 0.171 (0.168)\tLoss 0.2722 (0.2469)\tPrec@1 93.750 (91.313)\n",
            "Epoch: [32][320/782]\tTime 0.166 (0.168)\tLoss 0.4595 (0.2487)\tPrec@1 87.500 (91.282)\n",
            "Epoch: [32][330/782]\tTime 0.166 (0.168)\tLoss 0.3455 (0.2493)\tPrec@1 89.062 (91.267)\n",
            "Epoch: [32][340/782]\tTime 0.167 (0.168)\tLoss 0.2652 (0.2494)\tPrec@1 92.188 (91.244)\n",
            "Epoch: [32][350/782]\tTime 0.167 (0.168)\tLoss 0.2706 (0.2500)\tPrec@1 89.062 (91.248)\n",
            "Epoch: [32][360/782]\tTime 0.167 (0.168)\tLoss 0.2260 (0.2507)\tPrec@1 95.312 (91.192)\n",
            "Epoch: [32][370/782]\tTime 0.166 (0.168)\tLoss 0.2934 (0.2509)\tPrec@1 93.750 (91.215)\n",
            "Epoch: [32][380/782]\tTime 0.168 (0.168)\tLoss 0.1919 (0.2501)\tPrec@1 89.062 (91.244)\n",
            "Epoch: [32][390/782]\tTime 0.167 (0.168)\tLoss 0.2356 (0.2503)\tPrec@1 92.188 (91.264)\n",
            "Epoch: [32][400/782]\tTime 0.167 (0.168)\tLoss 0.1852 (0.2508)\tPrec@1 93.750 (91.268)\n",
            "Epoch: [32][410/782]\tTime 0.166 (0.168)\tLoss 0.2423 (0.2503)\tPrec@1 92.188 (91.294)\n",
            "Epoch: [32][420/782]\tTime 0.168 (0.168)\tLoss 0.2008 (0.2500)\tPrec@1 95.312 (91.300)\n",
            "Epoch: [32][430/782]\tTime 0.167 (0.168)\tLoss 0.2218 (0.2501)\tPrec@1 96.875 (91.270)\n",
            "Epoch: [32][440/782]\tTime 0.167 (0.168)\tLoss 0.2155 (0.2495)\tPrec@1 92.188 (91.280)\n",
            "Epoch: [32][450/782]\tTime 0.167 (0.168)\tLoss 0.2314 (0.2494)\tPrec@1 89.062 (91.269)\n",
            "Epoch: [32][460/782]\tTime 0.168 (0.168)\tLoss 0.2289 (0.2489)\tPrec@1 92.188 (91.296)\n",
            "Epoch: [32][470/782]\tTime 0.166 (0.168)\tLoss 0.2276 (0.2480)\tPrec@1 92.188 (91.328)\n",
            "Epoch: [32][480/782]\tTime 0.167 (0.168)\tLoss 0.3250 (0.2483)\tPrec@1 85.938 (91.314)\n",
            "Epoch: [32][490/782]\tTime 0.166 (0.168)\tLoss 0.3969 (0.2481)\tPrec@1 89.062 (91.328)\n",
            "Epoch: [32][500/782]\tTime 0.166 (0.168)\tLoss 0.1994 (0.2483)\tPrec@1 95.312 (91.314)\n",
            "Epoch: [32][510/782]\tTime 0.168 (0.168)\tLoss 0.2961 (0.2481)\tPrec@1 89.062 (91.301)\n",
            "Epoch: [32][520/782]\tTime 0.167 (0.168)\tLoss 0.1750 (0.2477)\tPrec@1 93.750 (91.333)\n",
            "Epoch: [32][530/782]\tTime 0.167 (0.168)\tLoss 0.3023 (0.2480)\tPrec@1 85.938 (91.334)\n",
            "Epoch: [32][540/782]\tTime 0.168 (0.168)\tLoss 0.2386 (0.2485)\tPrec@1 89.062 (91.307)\n",
            "Epoch: [32][550/782]\tTime 0.167 (0.168)\tLoss 0.2074 (0.2485)\tPrec@1 96.875 (91.308)\n",
            "Epoch: [32][560/782]\tTime 0.167 (0.168)\tLoss 0.2727 (0.2495)\tPrec@1 89.062 (91.268)\n",
            "Epoch: [32][570/782]\tTime 0.168 (0.168)\tLoss 0.3236 (0.2504)\tPrec@1 87.500 (91.230)\n",
            "Epoch: [32][580/782]\tTime 0.168 (0.168)\tLoss 0.2937 (0.2507)\tPrec@1 90.625 (91.217)\n",
            "Epoch: [32][590/782]\tTime 0.167 (0.168)\tLoss 0.2857 (0.2518)\tPrec@1 90.625 (91.180)\n",
            "Epoch: [32][600/782]\tTime 0.169 (0.168)\tLoss 0.2804 (0.2526)\tPrec@1 87.500 (91.153)\n",
            "Epoch: [32][610/782]\tTime 0.166 (0.168)\tLoss 0.3490 (0.2531)\tPrec@1 90.625 (91.124)\n",
            "Epoch: [32][620/782]\tTime 0.166 (0.168)\tLoss 0.1733 (0.2533)\tPrec@1 93.750 (91.116)\n",
            "Epoch: [32][630/782]\tTime 0.168 (0.168)\tLoss 0.2278 (0.2535)\tPrec@1 90.625 (91.095)\n",
            "Epoch: [32][640/782]\tTime 0.167 (0.168)\tLoss 0.2261 (0.2533)\tPrec@1 92.188 (91.110)\n",
            "Epoch: [32][650/782]\tTime 0.167 (0.168)\tLoss 0.2182 (0.2539)\tPrec@1 93.750 (91.083)\n",
            "Epoch: [32][660/782]\tTime 0.168 (0.168)\tLoss 0.2580 (0.2539)\tPrec@1 89.062 (91.095)\n",
            "Epoch: [32][670/782]\tTime 0.167 (0.168)\tLoss 0.3644 (0.2541)\tPrec@1 87.500 (91.088)\n",
            "Epoch: [32][680/782]\tTime 0.166 (0.168)\tLoss 0.1714 (0.2544)\tPrec@1 93.750 (91.077)\n",
            "Epoch: [32][690/782]\tTime 0.165 (0.168)\tLoss 0.1981 (0.2543)\tPrec@1 92.188 (91.091)\n",
            "Epoch: [32][700/782]\tTime 0.166 (0.168)\tLoss 0.2424 (0.2546)\tPrec@1 92.188 (91.073)\n",
            "Epoch: [32][710/782]\tTime 0.170 (0.168)\tLoss 0.2230 (0.2551)\tPrec@1 89.062 (91.038)\n",
            "Epoch: [32][720/782]\tTime 0.167 (0.168)\tLoss 0.2530 (0.2551)\tPrec@1 90.625 (91.041)\n",
            "Epoch: [32][730/782]\tTime 0.166 (0.168)\tLoss 0.2785 (0.2556)\tPrec@1 89.062 (91.025)\n",
            "Epoch: [32][740/782]\tTime 0.169 (0.168)\tLoss 0.1706 (0.2553)\tPrec@1 98.438 (91.045)\n",
            "Epoch: [32][750/782]\tTime 0.167 (0.168)\tLoss 0.3510 (0.2556)\tPrec@1 90.625 (91.031)\n",
            "Epoch: [32][760/782]\tTime 0.167 (0.168)\tLoss 0.3004 (0.2553)\tPrec@1 89.062 (91.038)\n",
            "Epoch: [32][770/782]\tTime 0.167 (0.168)\tLoss 0.2972 (0.2549)\tPrec@1 84.375 (91.045)\n",
            "Epoch: [32][780/782]\tTime 0.162 (0.168)\tLoss 0.1250 (0.2543)\tPrec@1 96.875 (91.059)\n",
            "Training accuracy:  tensor(91.0580, device='cuda:0')\n",
            "Best accuraacy:  tensor(91.0580, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.129 (0.129)\tLoss 0.3491 (0.3491)\tPrec@1 84.375 (84.375)\n",
            "Test: [10/157]\tTime 0.043 (0.049)\tLoss 0.4844 (0.3612)\tPrec@1 85.938 (87.216)\n",
            "Test: [20/157]\tTime 0.050 (0.047)\tLoss 0.3777 (0.3677)\tPrec@1 89.062 (87.723)\n",
            "Test: [30/157]\tTime 0.042 (0.046)\tLoss 0.5082 (0.3616)\tPrec@1 87.500 (87.954)\n",
            "Test: [40/157]\tTime 0.040 (0.046)\tLoss 0.2175 (0.3486)\tPrec@1 96.875 (88.529)\n",
            "Test: [50/157]\tTime 0.042 (0.045)\tLoss 0.3867 (0.3556)\tPrec@1 89.062 (88.082)\n",
            "Test: [60/157]\tTime 0.042 (0.045)\tLoss 0.3932 (0.3586)\tPrec@1 87.500 (88.115)\n",
            "Test: [70/157]\tTime 0.049 (0.045)\tLoss 0.5617 (0.3524)\tPrec@1 82.812 (88.248)\n",
            "Test: [80/157]\tTime 0.043 (0.045)\tLoss 0.4435 (0.3561)\tPrec@1 87.500 (88.272)\n",
            "Test: [90/157]\tTime 0.045 (0.045)\tLoss 0.5229 (0.3631)\tPrec@1 81.250 (88.118)\n",
            "Test: [100/157]\tTime 0.044 (0.045)\tLoss 0.3962 (0.3599)\tPrec@1 92.188 (88.320)\n",
            "Test: [110/157]\tTime 0.042 (0.045)\tLoss 0.5456 (0.3555)\tPrec@1 81.250 (88.471)\n",
            "Test: [120/157]\tTime 0.044 (0.044)\tLoss 0.0865 (0.3492)\tPrec@1 98.438 (88.611)\n",
            "Test: [130/157]\tTime 0.044 (0.044)\tLoss 0.2985 (0.3486)\tPrec@1 90.625 (88.621)\n",
            "Test: [140/157]\tTime 0.042 (0.044)\tLoss 0.4185 (0.3472)\tPrec@1 89.062 (88.686)\n",
            "Test: [150/157]\tTime 0.043 (0.044)\tLoss 0.5267 (0.3458)\tPrec@1 82.812 (88.659)\n",
            " * Prec@1 88.580\n",
            "Best accuracy:  tensor(88.5800, device='cuda:0')\n",
            "Epoch: [33][0/782]\tTime 0.276 (0.276)\tLoss 0.1960 (0.1960)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [33][10/782]\tTime 0.169 (0.178)\tLoss 0.2362 (0.2506)\tPrec@1 92.188 (91.477)\n",
            "Epoch: [33][20/782]\tTime 0.167 (0.173)\tLoss 0.1585 (0.2571)\tPrec@1 93.750 (90.625)\n",
            "Epoch: [33][30/782]\tTime 0.169 (0.172)\tLoss 0.0837 (0.2436)\tPrec@1 100.000 (91.028)\n",
            "Epoch: [33][40/782]\tTime 0.169 (0.171)\tLoss 0.2364 (0.2422)\tPrec@1 93.750 (91.159)\n",
            "Epoch: [33][50/782]\tTime 0.169 (0.170)\tLoss 0.1785 (0.2341)\tPrec@1 92.188 (91.299)\n",
            "Epoch: [33][60/782]\tTime 0.167 (0.170)\tLoss 0.2424 (0.2294)\tPrec@1 90.625 (91.445)\n",
            "Epoch: [33][70/782]\tTime 0.168 (0.170)\tLoss 0.2107 (0.2257)\tPrec@1 93.750 (91.483)\n",
            "Epoch: [33][80/782]\tTime 0.166 (0.169)\tLoss 0.2348 (0.2242)\tPrec@1 93.750 (91.686)\n",
            "Epoch: [33][90/782]\tTime 0.172 (0.169)\tLoss 0.1994 (0.2258)\tPrec@1 93.750 (91.758)\n",
            "Epoch: [33][100/782]\tTime 0.165 (0.169)\tLoss 0.2375 (0.2297)\tPrec@1 90.625 (91.569)\n",
            "Epoch: [33][110/782]\tTime 0.165 (0.169)\tLoss 0.1730 (0.2304)\tPrec@1 93.750 (91.653)\n",
            "Epoch: [33][120/782]\tTime 0.168 (0.169)\tLoss 0.1028 (0.2293)\tPrec@1 98.438 (91.684)\n",
            "Epoch: [33][130/782]\tTime 0.167 (0.169)\tLoss 0.3502 (0.2289)\tPrec@1 90.625 (91.698)\n",
            "Epoch: [33][140/782]\tTime 0.166 (0.169)\tLoss 0.2198 (0.2320)\tPrec@1 93.750 (91.667)\n",
            "Epoch: [33][150/782]\tTime 0.167 (0.168)\tLoss 0.1194 (0.2341)\tPrec@1 95.312 (91.567)\n",
            "Epoch: [33][160/782]\tTime 0.167 (0.168)\tLoss 0.2995 (0.2346)\tPrec@1 93.750 (91.586)\n",
            "Epoch: [33][170/782]\tTime 0.167 (0.168)\tLoss 0.4321 (0.2363)\tPrec@1 82.812 (91.484)\n",
            "Epoch: [33][180/782]\tTime 0.166 (0.168)\tLoss 0.1628 (0.2399)\tPrec@1 95.312 (91.428)\n",
            "Epoch: [33][190/782]\tTime 0.167 (0.168)\tLoss 0.2459 (0.2419)\tPrec@1 89.062 (91.320)\n",
            "Epoch: [33][200/782]\tTime 0.166 (0.168)\tLoss 0.1950 (0.2421)\tPrec@1 95.312 (91.317)\n",
            "Epoch: [33][210/782]\tTime 0.167 (0.168)\tLoss 0.2447 (0.2428)\tPrec@1 90.625 (91.328)\n",
            "Epoch: [33][220/782]\tTime 0.167 (0.168)\tLoss 0.1636 (0.2456)\tPrec@1 96.875 (91.268)\n",
            "Epoch: [33][230/782]\tTime 0.169 (0.168)\tLoss 0.2608 (0.2463)\tPrec@1 92.188 (91.241)\n",
            "Epoch: [33][240/782]\tTime 0.169 (0.168)\tLoss 0.1542 (0.2459)\tPrec@1 92.188 (91.254)\n",
            "Epoch: [33][250/782]\tTime 0.167 (0.168)\tLoss 0.3419 (0.2464)\tPrec@1 87.500 (91.297)\n",
            "Epoch: [33][260/782]\tTime 0.168 (0.168)\tLoss 0.2080 (0.2453)\tPrec@1 93.750 (91.337)\n",
            "Epoch: [33][270/782]\tTime 0.167 (0.168)\tLoss 0.1855 (0.2449)\tPrec@1 93.750 (91.351)\n",
            "Epoch: [33][280/782]\tTime 0.167 (0.168)\tLoss 0.2967 (0.2448)\tPrec@1 84.375 (91.326)\n",
            "Epoch: [33][290/782]\tTime 0.167 (0.168)\tLoss 0.1596 (0.2454)\tPrec@1 93.750 (91.280)\n",
            "Epoch: [33][300/782]\tTime 0.166 (0.168)\tLoss 0.1545 (0.2454)\tPrec@1 98.438 (91.321)\n",
            "Epoch: [33][310/782]\tTime 0.167 (0.168)\tLoss 0.1135 (0.2451)\tPrec@1 95.312 (91.323)\n",
            "Epoch: [33][320/782]\tTime 0.170 (0.168)\tLoss 0.2134 (0.2449)\tPrec@1 90.625 (91.345)\n",
            "Epoch: [33][330/782]\tTime 0.167 (0.168)\tLoss 0.3321 (0.2463)\tPrec@1 87.500 (91.295)\n",
            "Epoch: [33][340/782]\tTime 0.173 (0.168)\tLoss 0.3887 (0.2454)\tPrec@1 85.938 (91.326)\n",
            "Epoch: [33][350/782]\tTime 0.167 (0.168)\tLoss 0.2200 (0.2445)\tPrec@1 93.750 (91.364)\n",
            "Epoch: [33][360/782]\tTime 0.170 (0.168)\tLoss 0.4121 (0.2452)\tPrec@1 89.062 (91.339)\n",
            "Epoch: [33][370/782]\tTime 0.166 (0.168)\tLoss 0.3512 (0.2463)\tPrec@1 87.500 (91.303)\n",
            "Epoch: [33][380/782]\tTime 0.168 (0.168)\tLoss 0.2778 (0.2463)\tPrec@1 89.062 (91.306)\n",
            "Epoch: [33][390/782]\tTime 0.166 (0.168)\tLoss 0.2557 (0.2473)\tPrec@1 90.625 (91.288)\n",
            "Epoch: [33][400/782]\tTime 0.167 (0.168)\tLoss 0.3222 (0.2476)\tPrec@1 87.500 (91.268)\n",
            "Epoch: [33][410/782]\tTime 0.167 (0.168)\tLoss 0.2368 (0.2481)\tPrec@1 92.188 (91.237)\n",
            "Epoch: [33][420/782]\tTime 0.167 (0.168)\tLoss 0.1366 (0.2482)\tPrec@1 93.750 (91.215)\n",
            "Epoch: [33][430/782]\tTime 0.168 (0.168)\tLoss 0.1054 (0.2489)\tPrec@1 95.312 (91.191)\n",
            "Epoch: [33][440/782]\tTime 0.168 (0.168)\tLoss 0.1488 (0.2496)\tPrec@1 93.750 (91.185)\n",
            "Epoch: [33][450/782]\tTime 0.167 (0.168)\tLoss 0.2983 (0.2493)\tPrec@1 90.625 (91.176)\n",
            "Epoch: [33][460/782]\tTime 0.169 (0.168)\tLoss 0.1655 (0.2494)\tPrec@1 93.750 (91.161)\n",
            "Epoch: [33][470/782]\tTime 0.166 (0.168)\tLoss 0.2397 (0.2500)\tPrec@1 95.312 (91.119)\n",
            "Epoch: [33][480/782]\tTime 0.166 (0.168)\tLoss 0.2709 (0.2508)\tPrec@1 90.625 (91.109)\n",
            "Epoch: [33][490/782]\tTime 0.169 (0.168)\tLoss 0.4107 (0.2513)\tPrec@1 87.500 (91.115)\n",
            "Epoch: [33][500/782]\tTime 0.165 (0.168)\tLoss 0.2086 (0.2511)\tPrec@1 87.500 (91.105)\n",
            "Epoch: [33][510/782]\tTime 0.166 (0.168)\tLoss 0.1806 (0.2514)\tPrec@1 92.188 (91.096)\n",
            "Epoch: [33][520/782]\tTime 0.167 (0.168)\tLoss 0.4362 (0.2516)\tPrec@1 84.375 (91.090)\n",
            "Epoch: [33][530/782]\tTime 0.167 (0.168)\tLoss 0.2084 (0.2511)\tPrec@1 89.062 (91.081)\n",
            "Epoch: [33][540/782]\tTime 0.167 (0.168)\tLoss 0.2383 (0.2503)\tPrec@1 90.625 (91.110)\n",
            "Epoch: [33][550/782]\tTime 0.167 (0.168)\tLoss 0.3511 (0.2501)\tPrec@1 87.500 (91.101)\n",
            "Epoch: [33][560/782]\tTime 0.167 (0.168)\tLoss 0.1601 (0.2500)\tPrec@1 95.312 (91.132)\n",
            "Epoch: [33][570/782]\tTime 0.168 (0.168)\tLoss 0.1201 (0.2499)\tPrec@1 96.875 (91.148)\n",
            "Epoch: [33][580/782]\tTime 0.168 (0.168)\tLoss 0.2820 (0.2503)\tPrec@1 89.062 (91.141)\n",
            "Epoch: [33][590/782]\tTime 0.166 (0.168)\tLoss 0.1641 (0.2507)\tPrec@1 93.750 (91.146)\n",
            "Epoch: [33][600/782]\tTime 0.167 (0.168)\tLoss 0.1923 (0.2511)\tPrec@1 90.625 (91.116)\n",
            "Epoch: [33][610/782]\tTime 0.168 (0.168)\tLoss 0.1237 (0.2502)\tPrec@1 95.312 (91.162)\n",
            "Epoch: [33][620/782]\tTime 0.165 (0.168)\tLoss 0.2587 (0.2503)\tPrec@1 90.625 (91.168)\n",
            "Epoch: [33][630/782]\tTime 0.166 (0.168)\tLoss 0.2132 (0.2505)\tPrec@1 89.062 (91.162)\n",
            "Epoch: [33][640/782]\tTime 0.167 (0.168)\tLoss 0.1372 (0.2506)\tPrec@1 95.312 (91.159)\n",
            "Epoch: [33][650/782]\tTime 0.168 (0.168)\tLoss 0.4076 (0.2511)\tPrec@1 89.062 (91.153)\n",
            "Epoch: [33][660/782]\tTime 0.167 (0.168)\tLoss 0.1931 (0.2510)\tPrec@1 96.875 (91.173)\n",
            "Epoch: [33][670/782]\tTime 0.166 (0.168)\tLoss 0.2600 (0.2510)\tPrec@1 92.188 (91.172)\n",
            "Epoch: [33][680/782]\tTime 0.167 (0.168)\tLoss 0.2255 (0.2514)\tPrec@1 90.625 (91.153)\n",
            "Epoch: [33][690/782]\tTime 0.166 (0.168)\tLoss 0.3251 (0.2528)\tPrec@1 87.500 (91.111)\n",
            "Epoch: [33][700/782]\tTime 0.166 (0.168)\tLoss 0.3113 (0.2532)\tPrec@1 89.062 (91.102)\n",
            "Epoch: [33][710/782]\tTime 0.165 (0.168)\tLoss 0.5045 (0.2526)\tPrec@1 85.938 (91.139)\n",
            "Epoch: [33][720/782]\tTime 0.171 (0.168)\tLoss 0.3741 (0.2534)\tPrec@1 87.500 (91.126)\n",
            "Epoch: [33][730/782]\tTime 0.166 (0.168)\tLoss 0.1768 (0.2531)\tPrec@1 93.750 (91.125)\n",
            "Epoch: [33][740/782]\tTime 0.166 (0.168)\tLoss 0.2715 (0.2535)\tPrec@1 90.625 (91.114)\n",
            "Epoch: [33][750/782]\tTime 0.170 (0.168)\tLoss 0.2275 (0.2543)\tPrec@1 90.625 (91.097)\n",
            "Epoch: [33][760/782]\tTime 0.167 (0.168)\tLoss 0.2060 (0.2545)\tPrec@1 90.625 (91.083)\n",
            "Epoch: [33][770/782]\tTime 0.168 (0.168)\tLoss 0.2797 (0.2551)\tPrec@1 90.625 (91.063)\n",
            "Epoch: [33][780/782]\tTime 0.162 (0.168)\tLoss 0.2693 (0.2552)\tPrec@1 85.938 (91.043)\n",
            "Training accuracy:  tensor(91.0440, device='cuda:0')\n",
            "Best accuraacy:  tensor(91.0580, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.118 (0.118)\tLoss 0.5380 (0.5380)\tPrec@1 79.688 (79.688)\n",
            "Test: [10/157]\tTime 0.042 (0.048)\tLoss 0.5674 (0.4802)\tPrec@1 78.125 (85.085)\n",
            "Test: [20/157]\tTime 0.049 (0.046)\tLoss 0.5529 (0.5017)\tPrec@1 82.812 (84.449)\n",
            "Test: [30/157]\tTime 0.042 (0.046)\tLoss 0.5128 (0.4865)\tPrec@1 85.938 (84.627)\n",
            "Test: [40/157]\tTime 0.040 (0.045)\tLoss 0.4186 (0.4771)\tPrec@1 81.250 (84.718)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.6272 (0.4746)\tPrec@1 79.688 (84.406)\n",
            "Test: [60/157]\tTime 0.041 (0.045)\tLoss 0.5325 (0.4691)\tPrec@1 82.812 (84.939)\n",
            "Test: [70/157]\tTime 0.045 (0.045)\tLoss 0.5037 (0.4881)\tPrec@1 84.375 (84.397)\n",
            "Test: [80/157]\tTime 0.040 (0.045)\tLoss 0.5230 (0.4803)\tPrec@1 82.812 (84.491)\n",
            "Test: [90/157]\tTime 0.044 (0.045)\tLoss 0.4326 (0.4815)\tPrec@1 89.062 (84.701)\n",
            "Test: [100/157]\tTime 0.044 (0.045)\tLoss 0.6708 (0.4925)\tPrec@1 85.938 (84.298)\n",
            "Test: [110/157]\tTime 0.038 (0.045)\tLoss 0.8499 (0.4884)\tPrec@1 68.750 (84.276)\n",
            "Test: [120/157]\tTime 0.043 (0.044)\tLoss 0.3350 (0.4863)\tPrec@1 87.500 (84.323)\n",
            "Test: [130/157]\tTime 0.045 (0.044)\tLoss 0.3593 (0.4846)\tPrec@1 89.062 (84.423)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.4248 (0.4850)\tPrec@1 81.250 (84.386)\n",
            "Test: [150/157]\tTime 0.045 (0.044)\tLoss 0.5798 (0.4866)\tPrec@1 78.125 (84.272)\n",
            " * Prec@1 84.210\n",
            "Best accuracy:  tensor(88.5800, device='cuda:0')\n",
            "Epoch: [34][0/782]\tTime 0.274 (0.274)\tLoss 0.3677 (0.3677)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [34][10/782]\tTime 0.167 (0.177)\tLoss 0.3012 (0.2636)\tPrec@1 87.500 (90.625)\n",
            "Epoch: [34][20/782]\tTime 0.166 (0.172)\tLoss 0.2521 (0.2529)\tPrec@1 90.625 (91.369)\n",
            "Epoch: [34][30/782]\tTime 0.167 (0.171)\tLoss 0.3332 (0.2497)\tPrec@1 90.625 (91.532)\n",
            "Epoch: [34][40/782]\tTime 0.167 (0.170)\tLoss 0.1142 (0.2419)\tPrec@1 93.750 (91.540)\n",
            "Epoch: [34][50/782]\tTime 0.166 (0.170)\tLoss 0.4093 (0.2384)\tPrec@1 84.375 (91.820)\n",
            "Epoch: [34][60/782]\tTime 0.166 (0.169)\tLoss 0.2214 (0.2341)\tPrec@1 93.750 (92.008)\n",
            "Epoch: [34][70/782]\tTime 0.167 (0.169)\tLoss 0.2455 (0.2322)\tPrec@1 90.625 (92.033)\n",
            "Epoch: [34][80/782]\tTime 0.166 (0.169)\tLoss 0.2910 (0.2343)\tPrec@1 93.750 (92.033)\n",
            "Epoch: [34][90/782]\tTime 0.166 (0.169)\tLoss 0.1578 (0.2259)\tPrec@1 96.875 (92.308)\n",
            "Epoch: [34][100/782]\tTime 0.168 (0.169)\tLoss 0.1253 (0.2268)\tPrec@1 95.312 (92.265)\n",
            "Epoch: [34][110/782]\tTime 0.167 (0.169)\tLoss 0.2838 (0.2320)\tPrec@1 90.625 (92.089)\n",
            "Epoch: [34][120/782]\tTime 0.167 (0.169)\tLoss 0.1437 (0.2301)\tPrec@1 93.750 (92.162)\n",
            "Epoch: [34][130/782]\tTime 0.167 (0.169)\tLoss 0.1533 (0.2293)\tPrec@1 95.312 (92.116)\n",
            "Epoch: [34][140/782]\tTime 0.166 (0.169)\tLoss 0.2380 (0.2307)\tPrec@1 89.062 (92.021)\n",
            "Epoch: [34][150/782]\tTime 0.167 (0.169)\tLoss 0.1506 (0.2325)\tPrec@1 95.312 (91.908)\n",
            "Epoch: [34][160/782]\tTime 0.167 (0.168)\tLoss 0.1975 (0.2350)\tPrec@1 90.625 (91.751)\n",
            "Epoch: [34][170/782]\tTime 0.168 (0.168)\tLoss 0.3188 (0.2337)\tPrec@1 89.062 (91.795)\n",
            "Epoch: [34][180/782]\tTime 0.167 (0.168)\tLoss 0.1541 (0.2319)\tPrec@1 93.750 (91.842)\n",
            "Epoch: [34][190/782]\tTime 0.167 (0.168)\tLoss 0.1649 (0.2327)\tPrec@1 92.188 (91.787)\n",
            "Epoch: [34][200/782]\tTime 0.167 (0.168)\tLoss 0.1884 (0.2338)\tPrec@1 93.750 (91.791)\n",
            "Epoch: [34][210/782]\tTime 0.170 (0.168)\tLoss 0.2628 (0.2347)\tPrec@1 96.875 (91.758)\n",
            "Epoch: [34][220/782]\tTime 0.167 (0.168)\tLoss 0.2069 (0.2357)\tPrec@1 90.625 (91.707)\n",
            "Epoch: [34][230/782]\tTime 0.168 (0.168)\tLoss 0.1300 (0.2346)\tPrec@1 95.312 (91.734)\n",
            "Epoch: [34][240/782]\tTime 0.172 (0.168)\tLoss 0.2902 (0.2339)\tPrec@1 92.188 (91.773)\n",
            "Epoch: [34][250/782]\tTime 0.167 (0.168)\tLoss 0.4028 (0.2345)\tPrec@1 87.500 (91.752)\n",
            "Epoch: [34][260/782]\tTime 0.168 (0.168)\tLoss 0.1486 (0.2336)\tPrec@1 95.312 (91.798)\n",
            "Epoch: [34][270/782]\tTime 0.166 (0.168)\tLoss 0.3499 (0.2330)\tPrec@1 84.375 (91.813)\n",
            "Epoch: [34][280/782]\tTime 0.168 (0.168)\tLoss 0.2813 (0.2339)\tPrec@1 89.062 (91.770)\n",
            "Epoch: [34][290/782]\tTime 0.166 (0.168)\tLoss 0.3071 (0.2343)\tPrec@1 87.500 (91.715)\n",
            "Epoch: [34][300/782]\tTime 0.167 (0.168)\tLoss 0.2847 (0.2349)\tPrec@1 89.062 (91.674)\n",
            "Epoch: [34][310/782]\tTime 0.167 (0.168)\tLoss 0.3262 (0.2362)\tPrec@1 90.625 (91.660)\n",
            "Epoch: [34][320/782]\tTime 0.167 (0.168)\tLoss 0.3353 (0.2367)\tPrec@1 87.500 (91.623)\n",
            "Epoch: [34][330/782]\tTime 0.168 (0.168)\tLoss 0.1730 (0.2375)\tPrec@1 95.312 (91.597)\n",
            "Epoch: [34][340/782]\tTime 0.167 (0.168)\tLoss 0.1883 (0.2366)\tPrec@1 95.312 (91.596)\n",
            "Epoch: [34][350/782]\tTime 0.167 (0.168)\tLoss 0.2866 (0.2384)\tPrec@1 89.062 (91.546)\n",
            "Epoch: [34][360/782]\tTime 0.166 (0.168)\tLoss 0.1436 (0.2381)\tPrec@1 95.312 (91.573)\n",
            "Epoch: [34][370/782]\tTime 0.169 (0.168)\tLoss 0.1381 (0.2379)\tPrec@1 96.875 (91.611)\n",
            "Epoch: [34][380/782]\tTime 0.168 (0.168)\tLoss 0.2689 (0.2395)\tPrec@1 89.062 (91.523)\n",
            "Epoch: [34][390/782]\tTime 0.167 (0.168)\tLoss 0.2094 (0.2407)\tPrec@1 92.188 (91.452)\n",
            "Epoch: [34][400/782]\tTime 0.168 (0.168)\tLoss 0.2277 (0.2404)\tPrec@1 95.312 (91.474)\n",
            "Epoch: [34][410/782]\tTime 0.168 (0.168)\tLoss 0.2637 (0.2411)\tPrec@1 93.750 (91.477)\n",
            "Epoch: [34][420/782]\tTime 0.168 (0.168)\tLoss 0.3080 (0.2416)\tPrec@1 90.625 (91.479)\n",
            "Epoch: [34][430/782]\tTime 0.167 (0.168)\tLoss 0.3124 (0.2409)\tPrec@1 92.188 (91.513)\n",
            "Epoch: [34][440/782]\tTime 0.167 (0.168)\tLoss 0.3395 (0.2406)\tPrec@1 85.938 (91.543)\n",
            "Epoch: [34][450/782]\tTime 0.167 (0.168)\tLoss 0.2163 (0.2394)\tPrec@1 95.312 (91.599)\n",
            "Epoch: [34][460/782]\tTime 0.166 (0.168)\tLoss 0.2005 (0.2394)\tPrec@1 92.188 (91.608)\n",
            "Epoch: [34][470/782]\tTime 0.172 (0.168)\tLoss 0.1922 (0.2392)\tPrec@1 90.625 (91.610)\n",
            "Epoch: [34][480/782]\tTime 0.169 (0.168)\tLoss 0.1901 (0.2394)\tPrec@1 96.875 (91.609)\n",
            "Epoch: [34][490/782]\tTime 0.168 (0.168)\tLoss 0.2716 (0.2398)\tPrec@1 89.062 (91.586)\n",
            "Epoch: [34][500/782]\tTime 0.169 (0.168)\tLoss 0.2435 (0.2409)\tPrec@1 92.188 (91.561)\n",
            "Epoch: [34][510/782]\tTime 0.167 (0.168)\tLoss 0.1359 (0.2419)\tPrec@1 93.750 (91.512)\n",
            "Epoch: [34][520/782]\tTime 0.168 (0.168)\tLoss 0.4516 (0.2426)\tPrec@1 81.250 (91.504)\n",
            "Epoch: [34][530/782]\tTime 0.170 (0.168)\tLoss 0.2802 (0.2431)\tPrec@1 90.625 (91.484)\n",
            "Epoch: [34][540/782]\tTime 0.166 (0.168)\tLoss 0.1481 (0.2423)\tPrec@1 96.875 (91.517)\n",
            "Epoch: [34][550/782]\tTime 0.169 (0.168)\tLoss 0.3814 (0.2432)\tPrec@1 85.938 (91.487)\n",
            "Epoch: [34][560/782]\tTime 0.168 (0.168)\tLoss 0.2064 (0.2430)\tPrec@1 92.188 (91.502)\n",
            "Epoch: [34][570/782]\tTime 0.168 (0.168)\tLoss 0.1842 (0.2434)\tPrec@1 96.875 (91.506)\n",
            "Epoch: [34][580/782]\tTime 0.166 (0.168)\tLoss 0.2955 (0.2432)\tPrec@1 90.625 (91.529)\n",
            "Epoch: [34][590/782]\tTime 0.171 (0.168)\tLoss 0.3024 (0.2434)\tPrec@1 89.062 (91.521)\n",
            "Epoch: [34][600/782]\tTime 0.166 (0.168)\tLoss 0.3473 (0.2438)\tPrec@1 89.062 (91.509)\n",
            "Epoch: [34][610/782]\tTime 0.166 (0.168)\tLoss 0.3317 (0.2440)\tPrec@1 89.062 (91.505)\n",
            "Epoch: [34][620/782]\tTime 0.168 (0.168)\tLoss 0.1342 (0.2439)\tPrec@1 96.875 (91.498)\n",
            "Epoch: [34][630/782]\tTime 0.165 (0.168)\tLoss 0.2572 (0.2449)\tPrec@1 90.625 (91.474)\n",
            "Epoch: [34][640/782]\tTime 0.168 (0.168)\tLoss 0.2079 (0.2448)\tPrec@1 92.188 (91.488)\n",
            "Epoch: [34][650/782]\tTime 0.167 (0.168)\tLoss 0.2588 (0.2448)\tPrec@1 92.188 (91.499)\n",
            "Epoch: [34][660/782]\tTime 0.170 (0.168)\tLoss 0.1909 (0.2452)\tPrec@1 96.875 (91.488)\n",
            "Epoch: [34][670/782]\tTime 0.165 (0.168)\tLoss 0.2512 (0.2454)\tPrec@1 90.625 (91.494)\n",
            "Epoch: [34][680/782]\tTime 0.168 (0.168)\tLoss 0.1385 (0.2457)\tPrec@1 95.312 (91.469)\n",
            "Epoch: [34][690/782]\tTime 0.167 (0.168)\tLoss 0.3091 (0.2470)\tPrec@1 87.500 (91.425)\n",
            "Epoch: [34][700/782]\tTime 0.167 (0.168)\tLoss 0.2601 (0.2469)\tPrec@1 93.750 (91.441)\n",
            "Epoch: [34][710/782]\tTime 0.167 (0.168)\tLoss 0.1474 (0.2472)\tPrec@1 95.312 (91.414)\n",
            "Epoch: [34][720/782]\tTime 0.167 (0.168)\tLoss 0.4724 (0.2475)\tPrec@1 87.500 (91.401)\n",
            "Epoch: [34][730/782]\tTime 0.171 (0.168)\tLoss 0.3002 (0.2474)\tPrec@1 89.062 (91.399)\n",
            "Epoch: [34][740/782]\tTime 0.168 (0.168)\tLoss 0.3239 (0.2473)\tPrec@1 87.500 (91.386)\n",
            "Epoch: [34][750/782]\tTime 0.165 (0.168)\tLoss 0.3563 (0.2474)\tPrec@1 85.938 (91.378)\n",
            "Epoch: [34][760/782]\tTime 0.170 (0.168)\tLoss 0.1822 (0.2472)\tPrec@1 98.438 (91.387)\n",
            "Epoch: [34][770/782]\tTime 0.167 (0.168)\tLoss 0.1714 (0.2470)\tPrec@1 95.312 (91.389)\n",
            "Epoch: [34][780/782]\tTime 0.162 (0.168)\tLoss 0.1970 (0.2471)\tPrec@1 95.312 (91.391)\n",
            "Training accuracy:  tensor(91.3900, device='cuda:0')\n",
            "Best accuraacy:  tensor(91.3900, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.118 (0.118)\tLoss 0.3958 (0.3958)\tPrec@1 87.500 (87.500)\n",
            "Test: [10/157]\tTime 0.041 (0.048)\tLoss 0.6605 (0.3175)\tPrec@1 84.375 (89.915)\n",
            "Test: [20/157]\tTime 0.041 (0.046)\tLoss 0.5770 (0.3145)\tPrec@1 87.500 (89.955)\n",
            "Test: [30/157]\tTime 0.043 (0.046)\tLoss 0.1980 (0.3224)\tPrec@1 93.750 (89.869)\n",
            "Test: [40/157]\tTime 0.043 (0.045)\tLoss 0.6546 (0.3554)\tPrec@1 81.250 (89.177)\n",
            "Test: [50/157]\tTime 0.042 (0.045)\tLoss 0.3337 (0.3531)\tPrec@1 90.625 (88.817)\n",
            "Test: [60/157]\tTime 0.042 (0.045)\tLoss 0.3809 (0.3523)\tPrec@1 89.062 (88.960)\n",
            "Test: [70/157]\tTime 0.044 (0.045)\tLoss 0.2797 (0.3535)\tPrec@1 89.062 (88.886)\n",
            "Test: [80/157]\tTime 0.042 (0.045)\tLoss 0.5077 (0.3580)\tPrec@1 79.688 (88.677)\n",
            "Test: [90/157]\tTime 0.044 (0.045)\tLoss 0.2845 (0.3499)\tPrec@1 89.062 (88.736)\n",
            "Test: [100/157]\tTime 0.046 (0.044)\tLoss 0.2388 (0.3465)\tPrec@1 89.062 (88.753)\n",
            "Test: [110/157]\tTime 0.045 (0.044)\tLoss 0.4745 (0.3511)\tPrec@1 85.938 (88.542)\n",
            "Test: [120/157]\tTime 0.044 (0.044)\tLoss 0.2392 (0.3467)\tPrec@1 92.188 (88.675)\n",
            "Test: [130/157]\tTime 0.043 (0.044)\tLoss 0.5526 (0.3413)\tPrec@1 84.375 (88.824)\n",
            "Test: [140/157]\tTime 0.041 (0.044)\tLoss 0.4310 (0.3431)\tPrec@1 85.938 (88.763)\n",
            "Test: [150/157]\tTime 0.042 (0.044)\tLoss 0.4851 (0.3432)\tPrec@1 90.625 (88.845)\n",
            " * Prec@1 88.880\n",
            "Best accuracy:  tensor(88.8800, device='cuda:0')\n",
            "Epoch: [35][0/782]\tTime 0.271 (0.271)\tLoss 0.3213 (0.3213)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [35][10/782]\tTime 0.166 (0.177)\tLoss 0.2012 (0.2223)\tPrec@1 93.750 (91.761)\n",
            "Epoch: [35][20/782]\tTime 0.167 (0.172)\tLoss 0.1767 (0.2282)\tPrec@1 95.312 (91.295)\n",
            "Epoch: [35][30/782]\tTime 0.166 (0.171)\tLoss 0.1536 (0.2283)\tPrec@1 95.312 (91.683)\n",
            "Epoch: [35][40/782]\tTime 0.166 (0.170)\tLoss 0.1732 (0.2366)\tPrec@1 95.312 (91.578)\n",
            "Epoch: [35][50/782]\tTime 0.171 (0.169)\tLoss 0.2669 (0.2394)\tPrec@1 89.062 (91.728)\n",
            "Epoch: [35][60/782]\tTime 0.166 (0.169)\tLoss 0.1597 (0.2321)\tPrec@1 93.750 (91.931)\n",
            "Epoch: [35][70/782]\tTime 0.167 (0.169)\tLoss 0.2098 (0.2323)\tPrec@1 93.750 (91.945)\n",
            "Epoch: [35][80/782]\tTime 0.167 (0.169)\tLoss 0.3359 (0.2332)\tPrec@1 87.500 (92.033)\n",
            "Epoch: [35][90/782]\tTime 0.168 (0.169)\tLoss 0.2358 (0.2332)\tPrec@1 90.625 (91.930)\n",
            "Epoch: [35][100/782]\tTime 0.167 (0.169)\tLoss 0.3722 (0.2335)\tPrec@1 84.375 (92.002)\n",
            "Epoch: [35][110/782]\tTime 0.169 (0.169)\tLoss 0.3244 (0.2357)\tPrec@1 90.625 (91.850)\n",
            "Epoch: [35][120/782]\tTime 0.165 (0.169)\tLoss 0.2309 (0.2338)\tPrec@1 92.188 (91.865)\n",
            "Epoch: [35][130/782]\tTime 0.167 (0.169)\tLoss 0.1359 (0.2349)\tPrec@1 92.188 (91.770)\n",
            "Epoch: [35][140/782]\tTime 0.166 (0.169)\tLoss 0.2435 (0.2332)\tPrec@1 89.062 (91.766)\n",
            "Epoch: [35][150/782]\tTime 0.167 (0.169)\tLoss 0.2277 (0.2317)\tPrec@1 93.750 (91.856)\n",
            "Epoch: [35][160/782]\tTime 0.168 (0.169)\tLoss 0.1095 (0.2298)\tPrec@1 93.750 (91.896)\n",
            "Epoch: [35][170/782]\tTime 0.166 (0.168)\tLoss 0.1715 (0.2286)\tPrec@1 93.750 (91.986)\n",
            "Epoch: [35][180/782]\tTime 0.167 (0.168)\tLoss 0.1090 (0.2279)\tPrec@1 98.438 (91.989)\n",
            "Epoch: [35][190/782]\tTime 0.165 (0.168)\tLoss 0.2626 (0.2282)\tPrec@1 93.750 (91.967)\n",
            "Epoch: [35][200/782]\tTime 0.166 (0.168)\tLoss 0.1706 (0.2316)\tPrec@1 90.625 (91.783)\n",
            "Epoch: [35][210/782]\tTime 0.166 (0.168)\tLoss 0.1073 (0.2324)\tPrec@1 96.875 (91.743)\n",
            "Epoch: [35][220/782]\tTime 0.170 (0.168)\tLoss 0.3358 (0.2325)\tPrec@1 89.062 (91.785)\n",
            "Epoch: [35][230/782]\tTime 0.167 (0.168)\tLoss 0.3592 (0.2331)\tPrec@1 87.500 (91.761)\n",
            "Epoch: [35][240/782]\tTime 0.167 (0.168)\tLoss 0.2073 (0.2337)\tPrec@1 95.312 (91.740)\n",
            "Epoch: [35][250/782]\tTime 0.171 (0.168)\tLoss 0.0991 (0.2326)\tPrec@1 96.875 (91.770)\n",
            "Epoch: [35][260/782]\tTime 0.167 (0.168)\tLoss 0.2569 (0.2337)\tPrec@1 92.188 (91.768)\n",
            "Epoch: [35][270/782]\tTime 0.167 (0.168)\tLoss 0.1640 (0.2345)\tPrec@1 93.750 (91.732)\n",
            "Epoch: [35][280/782]\tTime 0.170 (0.168)\tLoss 0.2229 (0.2369)\tPrec@1 89.062 (91.681)\n",
            "Epoch: [35][290/782]\tTime 0.167 (0.168)\tLoss 0.0724 (0.2367)\tPrec@1 98.438 (91.694)\n",
            "Epoch: [35][300/782]\tTime 0.167 (0.168)\tLoss 0.1688 (0.2368)\tPrec@1 95.312 (91.679)\n",
            "Epoch: [35][310/782]\tTime 0.167 (0.168)\tLoss 0.3358 (0.2379)\tPrec@1 90.625 (91.635)\n",
            "Epoch: [35][320/782]\tTime 0.167 (0.168)\tLoss 0.1402 (0.2374)\tPrec@1 93.750 (91.637)\n",
            "Epoch: [35][330/782]\tTime 0.168 (0.168)\tLoss 0.2005 (0.2393)\tPrec@1 96.875 (91.593)\n",
            "Epoch: [35][340/782]\tTime 0.166 (0.168)\tLoss 0.3466 (0.2394)\tPrec@1 89.062 (91.606)\n",
            "Epoch: [35][350/782]\tTime 0.169 (0.168)\tLoss 0.2235 (0.2404)\tPrec@1 90.625 (91.555)\n",
            "Epoch: [35][360/782]\tTime 0.168 (0.168)\tLoss 0.1724 (0.2406)\tPrec@1 95.312 (91.538)\n",
            "Epoch: [35][370/782]\tTime 0.166 (0.168)\tLoss 0.3260 (0.2411)\tPrec@1 92.188 (91.535)\n",
            "Epoch: [35][380/782]\tTime 0.167 (0.168)\tLoss 0.1003 (0.2415)\tPrec@1 98.438 (91.535)\n",
            "Epoch: [35][390/782]\tTime 0.167 (0.168)\tLoss 0.2316 (0.2405)\tPrec@1 90.625 (91.544)\n",
            "Epoch: [35][400/782]\tTime 0.168 (0.168)\tLoss 0.2183 (0.2398)\tPrec@1 93.750 (91.568)\n",
            "Epoch: [35][410/782]\tTime 0.166 (0.168)\tLoss 0.3506 (0.2396)\tPrec@1 85.938 (91.549)\n",
            "Epoch: [35][420/782]\tTime 0.166 (0.168)\tLoss 0.2736 (0.2394)\tPrec@1 92.188 (91.583)\n",
            "Epoch: [35][430/782]\tTime 0.166 (0.168)\tLoss 0.3458 (0.2410)\tPrec@1 85.938 (91.513)\n",
            "Epoch: [35][440/782]\tTime 0.167 (0.168)\tLoss 0.2276 (0.2416)\tPrec@1 92.188 (91.490)\n",
            "Epoch: [35][450/782]\tTime 0.168 (0.168)\tLoss 0.3295 (0.2421)\tPrec@1 92.188 (91.484)\n",
            "Epoch: [35][460/782]\tTime 0.165 (0.168)\tLoss 0.1493 (0.2425)\tPrec@1 93.750 (91.472)\n",
            "Epoch: [35][470/782]\tTime 0.167 (0.168)\tLoss 0.1105 (0.2420)\tPrec@1 95.312 (91.478)\n",
            "Epoch: [35][480/782]\tTime 0.167 (0.168)\tLoss 0.2314 (0.2421)\tPrec@1 93.750 (91.473)\n",
            "Epoch: [35][490/782]\tTime 0.166 (0.168)\tLoss 0.2483 (0.2423)\tPrec@1 92.188 (91.462)\n",
            "Epoch: [35][500/782]\tTime 0.166 (0.168)\tLoss 0.3046 (0.2429)\tPrec@1 90.625 (91.458)\n",
            "Epoch: [35][510/782]\tTime 0.174 (0.168)\tLoss 0.3289 (0.2434)\tPrec@1 92.188 (91.435)\n",
            "Epoch: [35][520/782]\tTime 0.167 (0.168)\tLoss 0.4014 (0.2437)\tPrec@1 85.938 (91.429)\n",
            "Epoch: [35][530/782]\tTime 0.166 (0.168)\tLoss 0.1990 (0.2438)\tPrec@1 92.188 (91.434)\n",
            "Epoch: [35][540/782]\tTime 0.176 (0.168)\tLoss 0.2967 (0.2440)\tPrec@1 93.750 (91.439)\n",
            "Epoch: [35][550/782]\tTime 0.166 (0.168)\tLoss 0.3413 (0.2440)\tPrec@1 85.938 (91.433)\n",
            "Epoch: [35][560/782]\tTime 0.167 (0.168)\tLoss 0.3530 (0.2440)\tPrec@1 90.625 (91.441)\n",
            "Epoch: [35][570/782]\tTime 0.167 (0.168)\tLoss 0.1549 (0.2439)\tPrec@1 96.875 (91.443)\n",
            "Epoch: [35][580/782]\tTime 0.167 (0.168)\tLoss 0.1738 (0.2445)\tPrec@1 93.750 (91.413)\n",
            "Epoch: [35][590/782]\tTime 0.167 (0.168)\tLoss 0.1965 (0.2444)\tPrec@1 92.188 (91.421)\n",
            "Epoch: [35][600/782]\tTime 0.169 (0.168)\tLoss 0.2776 (0.2442)\tPrec@1 90.625 (91.439)\n",
            "Epoch: [35][610/782]\tTime 0.166 (0.168)\tLoss 0.3791 (0.2441)\tPrec@1 87.500 (91.443)\n",
            "Epoch: [35][620/782]\tTime 0.166 (0.168)\tLoss 0.2646 (0.2447)\tPrec@1 89.062 (91.413)\n",
            "Epoch: [35][630/782]\tTime 0.168 (0.168)\tLoss 0.2475 (0.2464)\tPrec@1 89.062 (91.365)\n",
            "Epoch: [35][640/782]\tTime 0.166 (0.168)\tLoss 0.1486 (0.2460)\tPrec@1 93.750 (91.368)\n",
            "Epoch: [35][650/782]\tTime 0.166 (0.168)\tLoss 0.1978 (0.2466)\tPrec@1 95.312 (91.345)\n",
            "Epoch: [35][660/782]\tTime 0.168 (0.168)\tLoss 0.3506 (0.2473)\tPrec@1 90.625 (91.325)\n",
            "Epoch: [35][670/782]\tTime 0.167 (0.168)\tLoss 0.2477 (0.2473)\tPrec@1 93.750 (91.314)\n",
            "Epoch: [35][680/782]\tTime 0.166 (0.168)\tLoss 0.3482 (0.2482)\tPrec@1 84.375 (91.277)\n",
            "Epoch: [35][690/782]\tTime 0.164 (0.168)\tLoss 0.1846 (0.2480)\tPrec@1 92.188 (91.278)\n",
            "Epoch: [35][700/782]\tTime 0.168 (0.168)\tLoss 0.1468 (0.2484)\tPrec@1 95.312 (91.269)\n",
            "Epoch: [35][710/782]\tTime 0.167 (0.168)\tLoss 0.1900 (0.2481)\tPrec@1 95.312 (91.275)\n",
            "Epoch: [35][720/782]\tTime 0.167 (0.168)\tLoss 0.1506 (0.2482)\tPrec@1 92.188 (91.273)\n",
            "Epoch: [35][730/782]\tTime 0.167 (0.168)\tLoss 0.0698 (0.2483)\tPrec@1 100.000 (91.283)\n",
            "Epoch: [35][740/782]\tTime 0.171 (0.168)\tLoss 0.1999 (0.2477)\tPrec@1 92.188 (91.310)\n",
            "Epoch: [35][750/782]\tTime 0.165 (0.168)\tLoss 0.2029 (0.2473)\tPrec@1 93.750 (91.330)\n",
            "Epoch: [35][760/782]\tTime 0.165 (0.168)\tLoss 0.2047 (0.2478)\tPrec@1 93.750 (91.317)\n",
            "Epoch: [35][770/782]\tTime 0.167 (0.168)\tLoss 0.1764 (0.2477)\tPrec@1 92.188 (91.324)\n",
            "Epoch: [35][780/782]\tTime 0.162 (0.168)\tLoss 0.2629 (0.2478)\tPrec@1 92.188 (91.327)\n",
            "Training accuracy:  tensor(91.3280, device='cuda:0')\n",
            "Best accuraacy:  tensor(91.3900, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.117 (0.117)\tLoss 0.6044 (0.6044)\tPrec@1 82.812 (82.812)\n",
            "Test: [10/157]\tTime 0.040 (0.048)\tLoss 0.4161 (0.3833)\tPrec@1 87.500 (87.926)\n",
            "Test: [20/157]\tTime 0.054 (0.046)\tLoss 0.3139 (0.3585)\tPrec@1 87.500 (88.170)\n",
            "Test: [30/157]\tTime 0.042 (0.046)\tLoss 0.4702 (0.3687)\tPrec@1 85.938 (87.601)\n",
            "Test: [40/157]\tTime 0.042 (0.045)\tLoss 0.4238 (0.3758)\tPrec@1 87.500 (87.424)\n",
            "Test: [50/157]\tTime 0.040 (0.045)\tLoss 0.3172 (0.3853)\tPrec@1 92.188 (87.347)\n",
            "Test: [60/157]\tTime 0.042 (0.045)\tLoss 0.5502 (0.3936)\tPrec@1 76.562 (86.988)\n",
            "Test: [70/157]\tTime 0.049 (0.045)\tLoss 0.2191 (0.3887)\tPrec@1 92.188 (87.192)\n",
            "Test: [80/157]\tTime 0.044 (0.045)\tLoss 0.3292 (0.3848)\tPrec@1 89.062 (87.230)\n",
            "Test: [90/157]\tTime 0.046 (0.045)\tLoss 0.3729 (0.3826)\tPrec@1 84.375 (87.225)\n",
            "Test: [100/157]\tTime 0.042 (0.045)\tLoss 0.5481 (0.3812)\tPrec@1 84.375 (87.392)\n",
            "Test: [110/157]\tTime 0.044 (0.044)\tLoss 0.5626 (0.3907)\tPrec@1 82.812 (87.218)\n",
            "Test: [120/157]\tTime 0.042 (0.044)\tLoss 0.3897 (0.3897)\tPrec@1 81.250 (87.229)\n",
            "Test: [130/157]\tTime 0.050 (0.044)\tLoss 0.2972 (0.3873)\tPrec@1 89.062 (87.297)\n",
            "Test: [140/157]\tTime 0.050 (0.044)\tLoss 0.3995 (0.3903)\tPrec@1 89.062 (87.245)\n",
            "Test: [150/157]\tTime 0.046 (0.044)\tLoss 0.5438 (0.3956)\tPrec@1 79.688 (87.200)\n",
            " * Prec@1 87.180\n",
            "Best accuracy:  tensor(88.8800, device='cuda:0')\n",
            "Epoch: [36][0/782]\tTime 0.274 (0.274)\tLoss 0.2275 (0.2275)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [36][10/782]\tTime 0.167 (0.177)\tLoss 0.1991 (0.2561)\tPrec@1 95.312 (91.619)\n",
            "Epoch: [36][20/782]\tTime 0.166 (0.172)\tLoss 0.1827 (0.2368)\tPrec@1 93.750 (92.039)\n",
            "Epoch: [36][30/782]\tTime 0.168 (0.171)\tLoss 0.2734 (0.2407)\tPrec@1 92.188 (91.583)\n",
            "Epoch: [36][40/782]\tTime 0.166 (0.170)\tLoss 0.1658 (0.2377)\tPrec@1 96.875 (91.616)\n",
            "Epoch: [36][50/782]\tTime 0.167 (0.169)\tLoss 0.1787 (0.2311)\tPrec@1 95.312 (91.850)\n",
            "Epoch: [36][60/782]\tTime 0.167 (0.169)\tLoss 0.1614 (0.2265)\tPrec@1 95.312 (92.136)\n",
            "Epoch: [36][70/782]\tTime 0.168 (0.169)\tLoss 0.5154 (0.2327)\tPrec@1 82.812 (91.945)\n",
            "Epoch: [36][80/782]\tTime 0.167 (0.169)\tLoss 0.2086 (0.2349)\tPrec@1 95.312 (91.782)\n",
            "Epoch: [36][90/782]\tTime 0.168 (0.169)\tLoss 0.1818 (0.2388)\tPrec@1 92.188 (91.638)\n",
            "Epoch: [36][100/782]\tTime 0.166 (0.169)\tLoss 0.2730 (0.2435)\tPrec@1 87.500 (91.460)\n",
            "Epoch: [36][110/782]\tTime 0.167 (0.168)\tLoss 0.1981 (0.2421)\tPrec@1 93.750 (91.470)\n",
            "Epoch: [36][120/782]\tTime 0.165 (0.168)\tLoss 0.1954 (0.2423)\tPrec@1 92.188 (91.426)\n",
            "Epoch: [36][130/782]\tTime 0.165 (0.168)\tLoss 0.1681 (0.2398)\tPrec@1 92.188 (91.508)\n",
            "Epoch: [36][140/782]\tTime 0.170 (0.168)\tLoss 0.2043 (0.2377)\tPrec@1 92.188 (91.578)\n",
            "Epoch: [36][150/782]\tTime 0.170 (0.168)\tLoss 0.1040 (0.2367)\tPrec@1 95.312 (91.629)\n",
            "Epoch: [36][160/782]\tTime 0.166 (0.168)\tLoss 0.3035 (0.2380)\tPrec@1 89.062 (91.566)\n",
            "Epoch: [36][170/782]\tTime 0.172 (0.168)\tLoss 0.3628 (0.2394)\tPrec@1 87.500 (91.520)\n",
            "Epoch: [36][180/782]\tTime 0.172 (0.168)\tLoss 0.2896 (0.2376)\tPrec@1 89.062 (91.609)\n",
            "Epoch: [36][190/782]\tTime 0.167 (0.168)\tLoss 0.2281 (0.2368)\tPrec@1 93.750 (91.639)\n",
            "Epoch: [36][200/782]\tTime 0.169 (0.168)\tLoss 0.2704 (0.2376)\tPrec@1 89.062 (91.628)\n",
            "Epoch: [36][210/782]\tTime 0.166 (0.168)\tLoss 0.1206 (0.2380)\tPrec@1 96.875 (91.669)\n",
            "Epoch: [36][220/782]\tTime 0.166 (0.168)\tLoss 0.2516 (0.2414)\tPrec@1 87.500 (91.601)\n",
            "Epoch: [36][230/782]\tTime 0.166 (0.168)\tLoss 0.2187 (0.2419)\tPrec@1 92.188 (91.585)\n",
            "Epoch: [36][240/782]\tTime 0.167 (0.168)\tLoss 0.2634 (0.2451)\tPrec@1 90.625 (91.442)\n",
            "Epoch: [36][250/782]\tTime 0.167 (0.168)\tLoss 0.1110 (0.2459)\tPrec@1 95.312 (91.409)\n",
            "Epoch: [36][260/782]\tTime 0.166 (0.168)\tLoss 0.1980 (0.2461)\tPrec@1 93.750 (91.409)\n",
            "Epoch: [36][270/782]\tTime 0.164 (0.168)\tLoss 0.2404 (0.2461)\tPrec@1 93.750 (91.426)\n",
            "Epoch: [36][280/782]\tTime 0.166 (0.168)\tLoss 0.3249 (0.2459)\tPrec@1 89.062 (91.431)\n",
            "Epoch: [36][290/782]\tTime 0.168 (0.168)\tLoss 0.1492 (0.2465)\tPrec@1 93.750 (91.377)\n",
            "Epoch: [36][300/782]\tTime 0.166 (0.168)\tLoss 0.2469 (0.2471)\tPrec@1 92.188 (91.362)\n",
            "Epoch: [36][310/782]\tTime 0.167 (0.168)\tLoss 0.1344 (0.2464)\tPrec@1 95.312 (91.414)\n",
            "Epoch: [36][320/782]\tTime 0.167 (0.168)\tLoss 0.2296 (0.2465)\tPrec@1 90.625 (91.404)\n",
            "Epoch: [36][330/782]\tTime 0.167 (0.168)\tLoss 0.2403 (0.2462)\tPrec@1 87.500 (91.413)\n",
            "Epoch: [36][340/782]\tTime 0.168 (0.168)\tLoss 0.2481 (0.2467)\tPrec@1 85.938 (91.399)\n",
            "Epoch: [36][350/782]\tTime 0.166 (0.168)\tLoss 0.2096 (0.2473)\tPrec@1 92.188 (91.368)\n",
            "Epoch: [36][360/782]\tTime 0.167 (0.168)\tLoss 0.3055 (0.2462)\tPrec@1 89.062 (91.391)\n",
            "Epoch: [36][370/782]\tTime 0.166 (0.168)\tLoss 0.2735 (0.2470)\tPrec@1 87.500 (91.354)\n",
            "Epoch: [36][380/782]\tTime 0.166 (0.168)\tLoss 0.2207 (0.2482)\tPrec@1 92.188 (91.318)\n",
            "Epoch: [36][390/782]\tTime 0.167 (0.168)\tLoss 0.1727 (0.2490)\tPrec@1 95.312 (91.308)\n",
            "Epoch: [36][400/782]\tTime 0.169 (0.168)\tLoss 0.4509 (0.2500)\tPrec@1 87.500 (91.287)\n",
            "Epoch: [36][410/782]\tTime 0.166 (0.168)\tLoss 0.2148 (0.2500)\tPrec@1 95.312 (91.286)\n",
            "Epoch: [36][420/782]\tTime 0.167 (0.168)\tLoss 0.3201 (0.2494)\tPrec@1 87.500 (91.289)\n",
            "Epoch: [36][430/782]\tTime 0.167 (0.168)\tLoss 0.2488 (0.2500)\tPrec@1 87.500 (91.267)\n",
            "Epoch: [36][440/782]\tTime 0.167 (0.168)\tLoss 0.1724 (0.2497)\tPrec@1 92.188 (91.288)\n",
            "Epoch: [36][450/782]\tTime 0.167 (0.168)\tLoss 0.1748 (0.2497)\tPrec@1 96.875 (91.308)\n",
            "Epoch: [36][460/782]\tTime 0.167 (0.168)\tLoss 0.1950 (0.2492)\tPrec@1 93.750 (91.316)\n",
            "Epoch: [36][470/782]\tTime 0.165 (0.168)\tLoss 0.2687 (0.2481)\tPrec@1 92.188 (91.368)\n",
            "Epoch: [36][480/782]\tTime 0.167 (0.168)\tLoss 0.2077 (0.2482)\tPrec@1 93.750 (91.372)\n",
            "Epoch: [36][490/782]\tTime 0.171 (0.168)\tLoss 0.1760 (0.2477)\tPrec@1 92.188 (91.395)\n",
            "Epoch: [36][500/782]\tTime 0.168 (0.168)\tLoss 0.2262 (0.2477)\tPrec@1 90.625 (91.383)\n",
            "Epoch: [36][510/782]\tTime 0.167 (0.168)\tLoss 0.1779 (0.2475)\tPrec@1 93.750 (91.377)\n",
            "Epoch: [36][520/782]\tTime 0.167 (0.168)\tLoss 0.3271 (0.2474)\tPrec@1 87.500 (91.396)\n",
            "Epoch: [36][530/782]\tTime 0.167 (0.168)\tLoss 0.2143 (0.2469)\tPrec@1 90.625 (91.408)\n",
            "Epoch: [36][540/782]\tTime 0.167 (0.168)\tLoss 0.3680 (0.2475)\tPrec@1 85.938 (91.370)\n",
            "Epoch: [36][550/782]\tTime 0.167 (0.168)\tLoss 0.3197 (0.2481)\tPrec@1 90.625 (91.368)\n",
            "Epoch: [36][560/782]\tTime 0.166 (0.168)\tLoss 0.1253 (0.2488)\tPrec@1 95.312 (91.349)\n",
            "Epoch: [36][570/782]\tTime 0.167 (0.168)\tLoss 0.3317 (0.2492)\tPrec@1 90.625 (91.350)\n",
            "Epoch: [36][580/782]\tTime 0.169 (0.168)\tLoss 0.1475 (0.2500)\tPrec@1 95.312 (91.332)\n",
            "Epoch: [36][590/782]\tTime 0.166 (0.168)\tLoss 0.1653 (0.2499)\tPrec@1 93.750 (91.341)\n",
            "Epoch: [36][600/782]\tTime 0.169 (0.168)\tLoss 0.1672 (0.2498)\tPrec@1 92.188 (91.340)\n",
            "Epoch: [36][610/782]\tTime 0.167 (0.168)\tLoss 0.2242 (0.2501)\tPrec@1 93.750 (91.315)\n",
            "Epoch: [36][620/782]\tTime 0.168 (0.168)\tLoss 0.3289 (0.2499)\tPrec@1 89.062 (91.322)\n",
            "Epoch: [36][630/782]\tTime 0.167 (0.168)\tLoss 0.1895 (0.2495)\tPrec@1 93.750 (91.346)\n",
            "Epoch: [36][640/782]\tTime 0.166 (0.168)\tLoss 0.3774 (0.2496)\tPrec@1 87.500 (91.342)\n",
            "Epoch: [36][650/782]\tTime 0.166 (0.168)\tLoss 0.3635 (0.2496)\tPrec@1 90.625 (91.347)\n",
            "Epoch: [36][660/782]\tTime 0.170 (0.168)\tLoss 0.2130 (0.2492)\tPrec@1 92.188 (91.355)\n",
            "Epoch: [36][670/782]\tTime 0.166 (0.168)\tLoss 0.2390 (0.2487)\tPrec@1 92.188 (91.368)\n",
            "Epoch: [36][680/782]\tTime 0.166 (0.168)\tLoss 0.2093 (0.2481)\tPrec@1 90.625 (91.389)\n",
            "Epoch: [36][690/782]\tTime 0.170 (0.168)\tLoss 0.1265 (0.2484)\tPrec@1 96.875 (91.367)\n",
            "Epoch: [36][700/782]\tTime 0.167 (0.168)\tLoss 0.2495 (0.2488)\tPrec@1 90.625 (91.361)\n",
            "Epoch: [36][710/782]\tTime 0.166 (0.168)\tLoss 0.1971 (0.2487)\tPrec@1 95.312 (91.361)\n",
            "Epoch: [36][720/782]\tTime 0.166 (0.168)\tLoss 0.3963 (0.2494)\tPrec@1 85.938 (91.327)\n",
            "Epoch: [36][730/782]\tTime 0.168 (0.168)\tLoss 0.5071 (0.2502)\tPrec@1 79.688 (91.294)\n",
            "Epoch: [36][740/782]\tTime 0.167 (0.168)\tLoss 0.0883 (0.2504)\tPrec@1 98.438 (91.293)\n",
            "Epoch: [36][750/782]\tTime 0.167 (0.168)\tLoss 0.1939 (0.2503)\tPrec@1 92.188 (91.285)\n",
            "Epoch: [36][760/782]\tTime 0.167 (0.168)\tLoss 0.2370 (0.2506)\tPrec@1 90.625 (91.268)\n",
            "Epoch: [36][770/782]\tTime 0.165 (0.168)\tLoss 0.2360 (0.2498)\tPrec@1 92.188 (91.308)\n",
            "Epoch: [36][780/782]\tTime 0.163 (0.168)\tLoss 0.1697 (0.2503)\tPrec@1 93.750 (91.301)\n",
            "Training accuracy:  tensor(91.2980, device='cuda:0')\n",
            "Best accuraacy:  tensor(91.3900, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.118 (0.118)\tLoss 0.6660 (0.6660)\tPrec@1 81.250 (81.250)\n",
            "Test: [10/157]\tTime 0.043 (0.048)\tLoss 0.2896 (0.4605)\tPrec@1 89.062 (85.085)\n",
            "Test: [20/157]\tTime 0.048 (0.046)\tLoss 0.3380 (0.4647)\tPrec@1 89.062 (85.193)\n",
            "Test: [30/157]\tTime 0.043 (0.046)\tLoss 0.3081 (0.4381)\tPrec@1 89.062 (85.887)\n",
            "Test: [40/157]\tTime 0.043 (0.045)\tLoss 0.5676 (0.4517)\tPrec@1 84.375 (85.671)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.3015 (0.4472)\tPrec@1 90.625 (85.938)\n",
            "Test: [60/157]\tTime 0.043 (0.045)\tLoss 0.2993 (0.4398)\tPrec@1 92.188 (86.347)\n",
            "Test: [70/157]\tTime 0.044 (0.045)\tLoss 0.3968 (0.4409)\tPrec@1 87.500 (86.334)\n",
            "Test: [80/157]\tTime 0.043 (0.045)\tLoss 0.2627 (0.4277)\tPrec@1 89.062 (86.651)\n",
            "Test: [90/157]\tTime 0.044 (0.045)\tLoss 0.4432 (0.4185)\tPrec@1 87.500 (86.933)\n",
            "Test: [100/157]\tTime 0.043 (0.045)\tLoss 0.4756 (0.4173)\tPrec@1 84.375 (87.036)\n",
            "Test: [110/157]\tTime 0.050 (0.044)\tLoss 0.5025 (0.4167)\tPrec@1 81.250 (86.923)\n",
            "Test: [120/157]\tTime 0.044 (0.044)\tLoss 0.4331 (0.4194)\tPrec@1 85.938 (86.945)\n",
            "Test: [130/157]\tTime 0.044 (0.044)\tLoss 0.2565 (0.4284)\tPrec@1 89.062 (86.629)\n",
            "Test: [140/157]\tTime 0.046 (0.044)\tLoss 0.3533 (0.4258)\tPrec@1 89.062 (86.625)\n",
            "Test: [150/157]\tTime 0.041 (0.044)\tLoss 0.4344 (0.4263)\tPrec@1 87.500 (86.548)\n",
            " * Prec@1 86.560\n",
            "Best accuracy:  tensor(88.8800, device='cuda:0')\n",
            "Epoch: [37][0/782]\tTime 0.274 (0.274)\tLoss 0.2092 (0.2092)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [37][10/782]\tTime 0.166 (0.176)\tLoss 0.2676 (0.2750)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [37][20/782]\tTime 0.165 (0.172)\tLoss 0.1868 (0.2639)\tPrec@1 90.625 (90.699)\n",
            "Epoch: [37][30/782]\tTime 0.165 (0.171)\tLoss 0.1608 (0.2504)\tPrec@1 98.438 (90.927)\n",
            "Epoch: [37][40/782]\tTime 0.168 (0.170)\tLoss 0.3832 (0.2501)\tPrec@1 87.500 (90.930)\n",
            "Epoch: [37][50/782]\tTime 0.167 (0.169)\tLoss 0.2362 (0.2448)\tPrec@1 92.188 (91.207)\n",
            "Epoch: [37][60/782]\tTime 0.167 (0.169)\tLoss 0.1829 (0.2410)\tPrec@1 95.312 (91.317)\n",
            "Epoch: [37][70/782]\tTime 0.167 (0.169)\tLoss 0.3716 (0.2459)\tPrec@1 87.500 (91.131)\n",
            "Epoch: [37][80/782]\tTime 0.168 (0.169)\tLoss 0.2711 (0.2408)\tPrec@1 92.188 (91.435)\n",
            "Epoch: [37][90/782]\tTime 0.167 (0.168)\tLoss 0.2347 (0.2369)\tPrec@1 92.188 (91.690)\n",
            "Epoch: [37][100/782]\tTime 0.167 (0.168)\tLoss 0.1974 (0.2347)\tPrec@1 89.062 (91.723)\n",
            "Epoch: [37][110/782]\tTime 0.167 (0.168)\tLoss 0.1120 (0.2319)\tPrec@1 98.438 (91.807)\n",
            "Epoch: [37][120/782]\tTime 0.168 (0.168)\tLoss 0.2498 (0.2297)\tPrec@1 87.500 (91.942)\n",
            "Epoch: [37][130/782]\tTime 0.165 (0.168)\tLoss 0.2980 (0.2278)\tPrec@1 87.500 (92.056)\n",
            "Epoch: [37][140/782]\tTime 0.166 (0.168)\tLoss 0.4026 (0.2297)\tPrec@1 85.938 (91.944)\n",
            "Epoch: [37][150/782]\tTime 0.168 (0.168)\tLoss 0.1874 (0.2321)\tPrec@1 93.750 (91.784)\n",
            "Epoch: [37][160/782]\tTime 0.166 (0.168)\tLoss 0.2387 (0.2327)\tPrec@1 93.750 (91.809)\n",
            "Epoch: [37][170/782]\tTime 0.169 (0.168)\tLoss 0.2220 (0.2317)\tPrec@1 92.188 (91.849)\n",
            "Epoch: [37][180/782]\tTime 0.166 (0.168)\tLoss 0.2168 (0.2302)\tPrec@1 93.750 (91.937)\n",
            "Epoch: [37][190/782]\tTime 0.164 (0.168)\tLoss 0.2597 (0.2324)\tPrec@1 89.062 (91.918)\n",
            "Epoch: [37][200/782]\tTime 0.167 (0.168)\tLoss 0.1244 (0.2309)\tPrec@1 98.438 (91.970)\n",
            "Epoch: [37][210/782]\tTime 0.172 (0.168)\tLoss 0.2994 (0.2317)\tPrec@1 92.188 (91.958)\n",
            "Epoch: [37][220/782]\tTime 0.166 (0.168)\tLoss 0.2566 (0.2319)\tPrec@1 95.312 (91.990)\n",
            "Epoch: [37][230/782]\tTime 0.166 (0.168)\tLoss 0.4061 (0.2341)\tPrec@1 84.375 (91.897)\n",
            "Epoch: [37][240/782]\tTime 0.168 (0.168)\tLoss 0.3840 (0.2336)\tPrec@1 85.938 (91.870)\n",
            "Epoch: [37][250/782]\tTime 0.168 (0.168)\tLoss 0.1984 (0.2347)\tPrec@1 93.750 (91.814)\n",
            "Epoch: [37][260/782]\tTime 0.166 (0.168)\tLoss 0.2212 (0.2359)\tPrec@1 92.188 (91.816)\n",
            "Epoch: [37][270/782]\tTime 0.167 (0.168)\tLoss 0.2928 (0.2359)\tPrec@1 92.188 (91.853)\n",
            "Epoch: [37][280/782]\tTime 0.165 (0.168)\tLoss 0.3276 (0.2362)\tPrec@1 89.062 (91.865)\n",
            "Epoch: [37][290/782]\tTime 0.166 (0.168)\tLoss 0.2282 (0.2360)\tPrec@1 90.625 (91.849)\n",
            "Epoch: [37][300/782]\tTime 0.167 (0.168)\tLoss 0.2830 (0.2357)\tPrec@1 90.625 (91.902)\n",
            "Epoch: [37][310/782]\tTime 0.167 (0.168)\tLoss 0.2047 (0.2348)\tPrec@1 92.188 (91.926)\n",
            "Epoch: [37][320/782]\tTime 0.166 (0.168)\tLoss 0.1434 (0.2361)\tPrec@1 92.188 (91.861)\n",
            "Epoch: [37][330/782]\tTime 0.166 (0.168)\tLoss 0.2705 (0.2367)\tPrec@1 90.625 (91.815)\n",
            "Epoch: [37][340/782]\tTime 0.167 (0.168)\tLoss 0.4033 (0.2383)\tPrec@1 87.500 (91.761)\n",
            "Epoch: [37][350/782]\tTime 0.168 (0.168)\tLoss 0.2890 (0.2385)\tPrec@1 90.625 (91.778)\n",
            "Epoch: [37][360/782]\tTime 0.168 (0.168)\tLoss 0.1212 (0.2384)\tPrec@1 95.312 (91.789)\n",
            "Epoch: [37][370/782]\tTime 0.167 (0.168)\tLoss 0.3777 (0.2391)\tPrec@1 89.062 (91.792)\n",
            "Epoch: [37][380/782]\tTime 0.168 (0.168)\tLoss 0.1806 (0.2390)\tPrec@1 95.312 (91.794)\n",
            "Epoch: [37][390/782]\tTime 0.166 (0.168)\tLoss 0.3306 (0.2401)\tPrec@1 87.500 (91.756)\n",
            "Epoch: [37][400/782]\tTime 0.168 (0.168)\tLoss 0.2160 (0.2395)\tPrec@1 92.188 (91.786)\n",
            "Epoch: [37][410/782]\tTime 0.168 (0.168)\tLoss 0.1795 (0.2404)\tPrec@1 92.188 (91.766)\n",
            "Epoch: [37][420/782]\tTime 0.170 (0.168)\tLoss 0.1573 (0.2409)\tPrec@1 93.750 (91.750)\n",
            "Epoch: [37][430/782]\tTime 0.167 (0.168)\tLoss 0.2086 (0.2414)\tPrec@1 90.625 (91.698)\n",
            "Epoch: [37][440/782]\tTime 0.167 (0.168)\tLoss 0.2316 (0.2413)\tPrec@1 92.188 (91.709)\n",
            "Epoch: [37][450/782]\tTime 0.169 (0.168)\tLoss 0.1699 (0.2419)\tPrec@1 92.188 (91.682)\n",
            "Epoch: [37][460/782]\tTime 0.167 (0.168)\tLoss 0.1983 (0.2416)\tPrec@1 93.750 (91.679)\n",
            "Epoch: [37][470/782]\tTime 0.169 (0.168)\tLoss 0.2049 (0.2402)\tPrec@1 92.188 (91.736)\n",
            "Epoch: [37][480/782]\tTime 0.168 (0.168)\tLoss 0.3848 (0.2405)\tPrec@1 82.812 (91.726)\n",
            "Epoch: [37][490/782]\tTime 0.166 (0.168)\tLoss 0.4433 (0.2404)\tPrec@1 82.812 (91.707)\n",
            "Epoch: [37][500/782]\tTime 0.167 (0.168)\tLoss 0.1649 (0.2394)\tPrec@1 93.750 (91.742)\n",
            "Epoch: [37][510/782]\tTime 0.167 (0.168)\tLoss 0.1770 (0.2397)\tPrec@1 93.750 (91.717)\n",
            "Epoch: [37][520/782]\tTime 0.167 (0.168)\tLoss 0.2938 (0.2399)\tPrec@1 92.188 (91.699)\n",
            "Epoch: [37][530/782]\tTime 0.168 (0.168)\tLoss 0.2495 (0.2393)\tPrec@1 92.188 (91.723)\n",
            "Epoch: [37][540/782]\tTime 0.166 (0.168)\tLoss 0.2837 (0.2387)\tPrec@1 89.062 (91.737)\n",
            "Epoch: [37][550/782]\tTime 0.168 (0.168)\tLoss 0.1672 (0.2383)\tPrec@1 92.188 (91.739)\n",
            "Epoch: [37][560/782]\tTime 0.169 (0.168)\tLoss 0.2751 (0.2387)\tPrec@1 90.625 (91.739)\n",
            "Epoch: [37][570/782]\tTime 0.166 (0.168)\tLoss 0.2755 (0.2386)\tPrec@1 89.062 (91.744)\n",
            "Epoch: [37][580/782]\tTime 0.167 (0.168)\tLoss 0.1370 (0.2385)\tPrec@1 92.188 (91.733)\n",
            "Epoch: [37][590/782]\tTime 0.166 (0.168)\tLoss 0.2031 (0.2387)\tPrec@1 93.750 (91.746)\n",
            "Epoch: [37][600/782]\tTime 0.167 (0.168)\tLoss 0.3108 (0.2383)\tPrec@1 90.625 (91.753)\n",
            "Epoch: [37][610/782]\tTime 0.167 (0.168)\tLoss 0.1707 (0.2375)\tPrec@1 93.750 (91.783)\n",
            "Epoch: [37][620/782]\tTime 0.165 (0.168)\tLoss 0.0985 (0.2378)\tPrec@1 98.438 (91.775)\n",
            "Epoch: [37][630/782]\tTime 0.166 (0.168)\tLoss 0.3100 (0.2379)\tPrec@1 87.500 (91.754)\n",
            "Epoch: [37][640/782]\tTime 0.170 (0.168)\tLoss 0.2613 (0.2376)\tPrec@1 85.938 (91.771)\n",
            "Epoch: [37][650/782]\tTime 0.167 (0.168)\tLoss 0.1599 (0.2382)\tPrec@1 90.625 (91.731)\n",
            "Epoch: [37][660/782]\tTime 0.169 (0.168)\tLoss 0.3557 (0.2381)\tPrec@1 87.500 (91.745)\n",
            "Epoch: [37][670/782]\tTime 0.167 (0.168)\tLoss 0.2097 (0.2381)\tPrec@1 90.625 (91.750)\n",
            "Epoch: [37][680/782]\tTime 0.171 (0.168)\tLoss 0.4175 (0.2383)\tPrec@1 85.938 (91.742)\n",
            "Epoch: [37][690/782]\tTime 0.166 (0.168)\tLoss 0.3110 (0.2388)\tPrec@1 90.625 (91.722)\n",
            "Epoch: [37][700/782]\tTime 0.167 (0.168)\tLoss 0.2878 (0.2388)\tPrec@1 90.625 (91.717)\n",
            "Epoch: [37][710/782]\tTime 0.166 (0.168)\tLoss 0.2366 (0.2391)\tPrec@1 92.188 (91.715)\n",
            "Epoch: [37][720/782]\tTime 0.166 (0.168)\tLoss 0.2512 (0.2396)\tPrec@1 92.188 (91.706)\n",
            "Epoch: [37][730/782]\tTime 0.173 (0.168)\tLoss 0.2865 (0.2395)\tPrec@1 87.500 (91.707)\n",
            "Epoch: [37][740/782]\tTime 0.166 (0.168)\tLoss 0.3021 (0.2401)\tPrec@1 85.938 (91.673)\n",
            "Epoch: [37][750/782]\tTime 0.165 (0.168)\tLoss 0.1376 (0.2401)\tPrec@1 96.875 (91.672)\n",
            "Epoch: [37][760/782]\tTime 0.168 (0.168)\tLoss 0.2466 (0.2407)\tPrec@1 90.625 (91.647)\n",
            "Epoch: [37][770/782]\tTime 0.168 (0.168)\tLoss 0.3203 (0.2410)\tPrec@1 87.500 (91.642)\n",
            "Epoch: [37][780/782]\tTime 0.162 (0.168)\tLoss 0.2197 (0.2413)\tPrec@1 90.625 (91.629)\n",
            "Training accuracy:  tensor(91.6260, device='cuda:0')\n",
            "Best accuraacy:  tensor(91.6260, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.127 (0.127)\tLoss 0.3542 (0.3542)\tPrec@1 87.500 (87.500)\n",
            "Test: [10/157]\tTime 0.042 (0.049)\tLoss 0.4875 (0.5149)\tPrec@1 87.500 (84.375)\n",
            "Test: [20/157]\tTime 0.051 (0.047)\tLoss 0.5326 (0.4964)\tPrec@1 84.375 (85.565)\n",
            "Test: [30/157]\tTime 0.043 (0.046)\tLoss 0.5160 (0.4814)\tPrec@1 81.250 (85.383)\n",
            "Test: [40/157]\tTime 0.043 (0.045)\tLoss 0.3299 (0.4649)\tPrec@1 87.500 (85.938)\n",
            "Test: [50/157]\tTime 0.044 (0.045)\tLoss 0.9435 (0.4588)\tPrec@1 79.688 (86.213)\n",
            "Test: [60/157]\tTime 0.040 (0.045)\tLoss 0.4022 (0.4654)\tPrec@1 85.938 (86.245)\n",
            "Test: [70/157]\tTime 0.044 (0.045)\tLoss 0.2582 (0.4445)\tPrec@1 90.625 (86.620)\n",
            "Test: [80/157]\tTime 0.044 (0.045)\tLoss 0.6753 (0.4518)\tPrec@1 79.688 (86.439)\n",
            "Test: [90/157]\tTime 0.045 (0.045)\tLoss 0.5030 (0.4499)\tPrec@1 81.250 (86.229)\n",
            "Test: [100/157]\tTime 0.043 (0.045)\tLoss 0.2526 (0.4479)\tPrec@1 92.188 (86.324)\n",
            "Test: [110/157]\tTime 0.043 (0.045)\tLoss 0.6562 (0.4651)\tPrec@1 81.250 (85.966)\n",
            "Test: [120/157]\tTime 0.043 (0.044)\tLoss 0.4946 (0.4704)\tPrec@1 84.375 (85.821)\n",
            "Test: [130/157]\tTime 0.043 (0.044)\tLoss 0.3634 (0.4668)\tPrec@1 85.938 (85.902)\n",
            "Test: [140/157]\tTime 0.042 (0.044)\tLoss 0.4373 (0.4683)\tPrec@1 85.938 (85.882)\n",
            "Test: [150/157]\tTime 0.052 (0.044)\tLoss 0.4166 (0.4637)\tPrec@1 92.188 (86.010)\n",
            " * Prec@1 86.030\n",
            "Best accuracy:  tensor(88.8800, device='cuda:0')\n",
            "Epoch: [38][0/782]\tTime 0.272 (0.272)\tLoss 0.2299 (0.2299)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [38][10/782]\tTime 0.166 (0.178)\tLoss 0.2951 (0.2798)\tPrec@1 90.625 (90.909)\n",
            "Epoch: [38][20/782]\tTime 0.168 (0.173)\tLoss 0.1787 (0.2416)\tPrec@1 93.750 (91.592)\n",
            "Epoch: [38][30/782]\tTime 0.168 (0.171)\tLoss 0.2520 (0.2355)\tPrec@1 92.188 (91.935)\n",
            "Epoch: [38][40/782]\tTime 0.167 (0.170)\tLoss 0.3195 (0.2374)\tPrec@1 90.625 (92.111)\n",
            "Epoch: [38][50/782]\tTime 0.168 (0.170)\tLoss 0.3624 (0.2368)\tPrec@1 89.062 (92.065)\n",
            "Epoch: [38][60/782]\tTime 0.167 (0.170)\tLoss 0.4595 (0.2349)\tPrec@1 82.812 (91.983)\n",
            "Epoch: [38][70/782]\tTime 0.166 (0.169)\tLoss 0.0971 (0.2322)\tPrec@1 96.875 (92.188)\n",
            "Epoch: [38][80/782]\tTime 0.169 (0.169)\tLoss 0.2663 (0.2354)\tPrec@1 89.062 (91.975)\n",
            "Epoch: [38][90/782]\tTime 0.167 (0.169)\tLoss 0.2397 (0.2354)\tPrec@1 90.625 (91.947)\n",
            "Epoch: [38][100/782]\tTime 0.166 (0.169)\tLoss 0.3705 (0.2394)\tPrec@1 87.500 (91.677)\n",
            "Epoch: [38][110/782]\tTime 0.169 (0.169)\tLoss 0.0736 (0.2416)\tPrec@1 98.438 (91.554)\n",
            "Epoch: [38][120/782]\tTime 0.167 (0.169)\tLoss 0.1724 (0.2400)\tPrec@1 93.750 (91.593)\n",
            "Epoch: [38][130/782]\tTime 0.172 (0.169)\tLoss 0.3624 (0.2424)\tPrec@1 84.375 (91.424)\n",
            "Epoch: [38][140/782]\tTime 0.166 (0.169)\tLoss 0.0625 (0.2418)\tPrec@1 98.438 (91.434)\n",
            "Epoch: [38][150/782]\tTime 0.167 (0.169)\tLoss 0.0862 (0.2388)\tPrec@1 95.312 (91.567)\n",
            "Epoch: [38][160/782]\tTime 0.171 (0.169)\tLoss 0.2307 (0.2360)\tPrec@1 92.188 (91.673)\n",
            "Epoch: [38][170/782]\tTime 0.166 (0.168)\tLoss 0.1454 (0.2319)\tPrec@1 93.750 (91.776)\n",
            "Epoch: [38][180/782]\tTime 0.165 (0.168)\tLoss 0.5892 (0.2333)\tPrec@1 85.938 (91.773)\n",
            "Epoch: [38][190/782]\tTime 0.167 (0.168)\tLoss 0.1993 (0.2349)\tPrec@1 90.625 (91.713)\n",
            "Epoch: [38][200/782]\tTime 0.166 (0.168)\tLoss 0.1692 (0.2325)\tPrec@1 90.625 (91.799)\n",
            "Epoch: [38][210/782]\tTime 0.169 (0.168)\tLoss 0.3033 (0.2320)\tPrec@1 92.188 (91.802)\n",
            "Epoch: [38][220/782]\tTime 0.166 (0.168)\tLoss 0.2554 (0.2320)\tPrec@1 89.062 (91.770)\n",
            "Epoch: [38][230/782]\tTime 0.166 (0.168)\tLoss 0.2603 (0.2321)\tPrec@1 92.188 (91.761)\n",
            "Epoch: [38][240/782]\tTime 0.166 (0.168)\tLoss 0.2354 (0.2317)\tPrec@1 90.625 (91.773)\n",
            "Epoch: [38][250/782]\tTime 0.171 (0.168)\tLoss 0.2794 (0.2314)\tPrec@1 92.188 (91.783)\n",
            "Epoch: [38][260/782]\tTime 0.167 (0.168)\tLoss 0.1700 (0.2324)\tPrec@1 93.750 (91.756)\n",
            "Epoch: [38][270/782]\tTime 0.167 (0.168)\tLoss 0.4376 (0.2372)\tPrec@1 89.062 (91.657)\n",
            "Epoch: [38][280/782]\tTime 0.167 (0.168)\tLoss 0.2954 (0.2360)\tPrec@1 90.625 (91.709)\n",
            "Epoch: [38][290/782]\tTime 0.165 (0.168)\tLoss 0.1387 (0.2351)\tPrec@1 93.750 (91.704)\n",
            "Epoch: [38][300/782]\tTime 0.168 (0.168)\tLoss 0.2515 (0.2356)\tPrec@1 89.062 (91.648)\n",
            "Epoch: [38][310/782]\tTime 0.168 (0.168)\tLoss 0.1938 (0.2346)\tPrec@1 92.188 (91.665)\n",
            "Epoch: [38][320/782]\tTime 0.166 (0.168)\tLoss 0.1663 (0.2368)\tPrec@1 93.750 (91.613)\n",
            "Epoch: [38][330/782]\tTime 0.166 (0.168)\tLoss 0.1005 (0.2369)\tPrec@1 98.438 (91.654)\n",
            "Epoch: [38][340/782]\tTime 0.167 (0.168)\tLoss 0.0922 (0.2356)\tPrec@1 98.438 (91.688)\n",
            "Epoch: [38][350/782]\tTime 0.167 (0.168)\tLoss 0.1975 (0.2349)\tPrec@1 92.188 (91.684)\n",
            "Epoch: [38][360/782]\tTime 0.167 (0.168)\tLoss 0.1332 (0.2355)\tPrec@1 98.438 (91.685)\n",
            "Epoch: [38][370/782]\tTime 0.168 (0.168)\tLoss 0.2633 (0.2381)\tPrec@1 90.625 (91.594)\n",
            "Epoch: [38][380/782]\tTime 0.166 (0.168)\tLoss 0.2662 (0.2388)\tPrec@1 93.750 (91.572)\n",
            "Epoch: [38][390/782]\tTime 0.172 (0.168)\tLoss 0.3869 (0.2388)\tPrec@1 85.938 (91.560)\n",
            "Epoch: [38][400/782]\tTime 0.167 (0.168)\tLoss 0.3473 (0.2408)\tPrec@1 93.750 (91.510)\n",
            "Epoch: [38][410/782]\tTime 0.166 (0.168)\tLoss 0.1590 (0.2408)\tPrec@1 96.875 (91.503)\n",
            "Epoch: [38][420/782]\tTime 0.172 (0.168)\tLoss 0.2790 (0.2412)\tPrec@1 89.062 (91.486)\n",
            "Epoch: [38][430/782]\tTime 0.167 (0.168)\tLoss 0.1444 (0.2410)\tPrec@1 95.312 (91.510)\n",
            "Epoch: [38][440/782]\tTime 0.167 (0.168)\tLoss 0.2381 (0.2409)\tPrec@1 89.062 (91.504)\n",
            "Epoch: [38][450/782]\tTime 0.166 (0.168)\tLoss 0.3030 (0.2406)\tPrec@1 89.062 (91.522)\n",
            "Epoch: [38][460/782]\tTime 0.167 (0.168)\tLoss 0.4668 (0.2405)\tPrec@1 81.250 (91.537)\n",
            "Epoch: [38][470/782]\tTime 0.167 (0.168)\tLoss 0.1441 (0.2399)\tPrec@1 96.875 (91.554)\n",
            "Epoch: [38][480/782]\tTime 0.168 (0.168)\tLoss 0.2042 (0.2396)\tPrec@1 90.625 (91.567)\n",
            "Epoch: [38][490/782]\tTime 0.168 (0.168)\tLoss 0.0982 (0.2398)\tPrec@1 96.875 (91.542)\n",
            "Epoch: [38][500/782]\tTime 0.167 (0.168)\tLoss 0.3382 (0.2400)\tPrec@1 85.938 (91.533)\n",
            "Epoch: [38][510/782]\tTime 0.167 (0.168)\tLoss 0.2105 (0.2399)\tPrec@1 93.750 (91.555)\n",
            "Epoch: [38][520/782]\tTime 0.167 (0.168)\tLoss 0.2402 (0.2402)\tPrec@1 92.188 (91.552)\n",
            "Epoch: [38][530/782]\tTime 0.167 (0.168)\tLoss 0.3094 (0.2406)\tPrec@1 89.062 (91.525)\n",
            "Epoch: [38][540/782]\tTime 0.171 (0.168)\tLoss 0.1551 (0.2405)\tPrec@1 96.875 (91.549)\n",
            "Epoch: [38][550/782]\tTime 0.166 (0.168)\tLoss 0.2739 (0.2405)\tPrec@1 92.188 (91.561)\n",
            "Epoch: [38][560/782]\tTime 0.168 (0.168)\tLoss 0.2822 (0.2402)\tPrec@1 89.062 (91.569)\n",
            "Epoch: [38][570/782]\tTime 0.167 (0.168)\tLoss 0.4378 (0.2416)\tPrec@1 89.062 (91.528)\n",
            "Epoch: [38][580/782]\tTime 0.167 (0.168)\tLoss 0.1847 (0.2412)\tPrec@1 95.312 (91.539)\n",
            "Epoch: [38][590/782]\tTime 0.168 (0.168)\tLoss 0.3584 (0.2421)\tPrec@1 89.062 (91.482)\n",
            "Epoch: [38][600/782]\tTime 0.167 (0.168)\tLoss 0.1957 (0.2429)\tPrec@1 93.750 (91.457)\n",
            "Epoch: [38][610/782]\tTime 0.167 (0.168)\tLoss 0.1822 (0.2435)\tPrec@1 90.625 (91.433)\n",
            "Epoch: [38][620/782]\tTime 0.167 (0.168)\tLoss 0.1772 (0.2436)\tPrec@1 95.312 (91.438)\n",
            "Epoch: [38][630/782]\tTime 0.168 (0.168)\tLoss 0.1835 (0.2433)\tPrec@1 93.750 (91.459)\n",
            "Epoch: [38][640/782]\tTime 0.166 (0.168)\tLoss 0.2693 (0.2433)\tPrec@1 92.188 (91.471)\n",
            "Epoch: [38][650/782]\tTime 0.167 (0.168)\tLoss 0.3725 (0.2432)\tPrec@1 87.500 (91.479)\n",
            "Epoch: [38][660/782]\tTime 0.168 (0.168)\tLoss 0.2594 (0.2433)\tPrec@1 90.625 (91.464)\n",
            "Epoch: [38][670/782]\tTime 0.167 (0.168)\tLoss 0.1445 (0.2434)\tPrec@1 93.750 (91.473)\n",
            "Epoch: [38][680/782]\tTime 0.172 (0.168)\tLoss 0.1726 (0.2434)\tPrec@1 92.188 (91.476)\n",
            "Epoch: [38][690/782]\tTime 0.165 (0.168)\tLoss 0.1763 (0.2430)\tPrec@1 92.188 (91.496)\n",
            "Epoch: [38][700/782]\tTime 0.167 (0.168)\tLoss 0.2598 (0.2434)\tPrec@1 89.062 (91.488)\n",
            "Epoch: [38][710/782]\tTime 0.171 (0.168)\tLoss 0.2442 (0.2438)\tPrec@1 90.625 (91.480)\n",
            "Epoch: [38][720/782]\tTime 0.166 (0.168)\tLoss 0.1713 (0.2436)\tPrec@1 95.312 (91.483)\n",
            "Epoch: [38][730/782]\tTime 0.167 (0.168)\tLoss 0.2252 (0.2438)\tPrec@1 95.312 (91.480)\n",
            "Epoch: [38][740/782]\tTime 0.166 (0.168)\tLoss 0.3886 (0.2440)\tPrec@1 90.625 (91.471)\n",
            "Epoch: [38][750/782]\tTime 0.168 (0.168)\tLoss 0.2494 (0.2435)\tPrec@1 92.188 (91.495)\n",
            "Epoch: [38][760/782]\tTime 0.165 (0.168)\tLoss 0.3000 (0.2433)\tPrec@1 89.062 (91.500)\n",
            "Epoch: [38][770/782]\tTime 0.166 (0.168)\tLoss 0.2511 (0.2432)\tPrec@1 92.188 (91.505)\n",
            "Epoch: [38][780/782]\tTime 0.162 (0.168)\tLoss 0.1496 (0.2429)\tPrec@1 93.750 (91.519)\n",
            "Training accuracy:  tensor(91.5160, device='cuda:0')\n",
            "Best accuraacy:  tensor(91.6260, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.126 (0.126)\tLoss 0.4839 (0.4839)\tPrec@1 87.500 (87.500)\n",
            "Test: [10/157]\tTime 0.042 (0.049)\tLoss 0.3381 (0.4073)\tPrec@1 85.938 (88.352)\n",
            "Test: [20/157]\tTime 0.047 (0.047)\tLoss 0.3675 (0.4047)\tPrec@1 82.812 (87.649)\n",
            "Test: [30/157]\tTime 0.046 (0.046)\tLoss 0.3540 (0.3998)\tPrec@1 84.375 (86.946)\n",
            "Test: [40/157]\tTime 0.041 (0.046)\tLoss 0.3718 (0.4031)\tPrec@1 84.375 (86.852)\n",
            "Test: [50/157]\tTime 0.041 (0.045)\tLoss 0.2301 (0.4073)\tPrec@1 92.188 (86.795)\n",
            "Test: [60/157]\tTime 0.040 (0.045)\tLoss 0.6035 (0.4160)\tPrec@1 81.250 (86.808)\n",
            "Test: [70/157]\tTime 0.044 (0.045)\tLoss 0.2682 (0.4151)\tPrec@1 89.062 (86.906)\n",
            "Test: [80/157]\tTime 0.043 (0.045)\tLoss 0.1930 (0.4110)\tPrec@1 92.188 (87.018)\n",
            "Test: [90/157]\tTime 0.045 (0.045)\tLoss 0.3191 (0.4086)\tPrec@1 85.938 (87.002)\n",
            "Test: [100/157]\tTime 0.042 (0.045)\tLoss 0.5702 (0.4143)\tPrec@1 84.375 (86.897)\n",
            "Test: [110/157]\tTime 0.042 (0.045)\tLoss 0.2003 (0.4081)\tPrec@1 90.625 (86.979)\n",
            "Test: [120/157]\tTime 0.041 (0.045)\tLoss 0.3242 (0.3999)\tPrec@1 87.500 (87.164)\n",
            "Test: [130/157]\tTime 0.043 (0.044)\tLoss 0.2113 (0.4025)\tPrec@1 90.625 (87.166)\n",
            "Test: [140/157]\tTime 0.050 (0.044)\tLoss 0.5567 (0.4041)\tPrec@1 84.375 (87.134)\n",
            "Test: [150/157]\tTime 0.043 (0.044)\tLoss 0.3534 (0.3994)\tPrec@1 85.938 (87.262)\n",
            " * Prec@1 87.280\n",
            "Best accuracy:  tensor(88.8800, device='cuda:0')\n",
            "Epoch: [39][0/782]\tTime 0.274 (0.274)\tLoss 0.2203 (0.2203)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [39][10/782]\tTime 0.168 (0.178)\tLoss 0.4612 (0.2954)\tPrec@1 84.375 (89.915)\n",
            "Epoch: [39][20/782]\tTime 0.166 (0.173)\tLoss 0.3208 (0.2710)\tPrec@1 85.938 (90.104)\n",
            "Epoch: [39][30/782]\tTime 0.171 (0.172)\tLoss 0.1381 (0.2662)\tPrec@1 96.875 (90.373)\n",
            "Epoch: [39][40/782]\tTime 0.171 (0.171)\tLoss 0.3056 (0.2532)\tPrec@1 89.062 (90.930)\n",
            "Epoch: [39][50/782]\tTime 0.165 (0.170)\tLoss 0.2079 (0.2503)\tPrec@1 92.188 (90.901)\n",
            "Epoch: [39][60/782]\tTime 0.168 (0.170)\tLoss 0.3422 (0.2484)\tPrec@1 87.500 (90.856)\n",
            "Epoch: [39][70/782]\tTime 0.168 (0.170)\tLoss 0.2939 (0.2463)\tPrec@1 92.188 (90.911)\n",
            "Epoch: [39][80/782]\tTime 0.166 (0.169)\tLoss 0.2295 (0.2407)\tPrec@1 90.625 (91.088)\n",
            "Epoch: [39][90/782]\tTime 0.170 (0.169)\tLoss 0.1499 (0.2444)\tPrec@1 93.750 (91.106)\n",
            "Epoch: [39][100/782]\tTime 0.168 (0.169)\tLoss 0.1419 (0.2390)\tPrec@1 95.312 (91.383)\n",
            "Epoch: [39][110/782]\tTime 0.170 (0.169)\tLoss 0.1933 (0.2406)\tPrec@1 93.750 (91.385)\n",
            "Epoch: [39][120/782]\tTime 0.168 (0.169)\tLoss 0.2811 (0.2390)\tPrec@1 89.062 (91.477)\n",
            "Epoch: [39][130/782]\tTime 0.166 (0.169)\tLoss 0.2322 (0.2394)\tPrec@1 92.188 (91.484)\n",
            "Epoch: [39][140/782]\tTime 0.168 (0.169)\tLoss 0.3487 (0.2410)\tPrec@1 87.500 (91.423)\n",
            "Epoch: [39][150/782]\tTime 0.167 (0.169)\tLoss 0.3149 (0.2412)\tPrec@1 89.062 (91.453)\n",
            "Epoch: [39][160/782]\tTime 0.167 (0.169)\tLoss 0.2130 (0.2416)\tPrec@1 95.312 (91.411)\n",
            "Epoch: [39][170/782]\tTime 0.169 (0.169)\tLoss 0.3483 (0.2417)\tPrec@1 87.500 (91.411)\n",
            "Epoch: [39][180/782]\tTime 0.165 (0.169)\tLoss 0.3268 (0.2406)\tPrec@1 89.062 (91.471)\n",
            "Epoch: [39][190/782]\tTime 0.169 (0.169)\tLoss 0.1180 (0.2403)\tPrec@1 95.312 (91.509)\n",
            "Epoch: [39][200/782]\tTime 0.167 (0.169)\tLoss 0.1722 (0.2385)\tPrec@1 93.750 (91.581)\n",
            "Epoch: [39][210/782]\tTime 0.167 (0.169)\tLoss 0.1714 (0.2387)\tPrec@1 93.750 (91.647)\n",
            "Epoch: [39][220/782]\tTime 0.166 (0.169)\tLoss 0.2470 (0.2383)\tPrec@1 93.750 (91.664)\n",
            "Epoch: [39][230/782]\tTime 0.167 (0.169)\tLoss 0.1958 (0.2389)\tPrec@1 96.875 (91.687)\n",
            "Epoch: [39][240/782]\tTime 0.167 (0.169)\tLoss 0.3443 (0.2385)\tPrec@1 87.500 (91.669)\n",
            "Epoch: [39][250/782]\tTime 0.165 (0.168)\tLoss 0.3736 (0.2372)\tPrec@1 90.625 (91.727)\n",
            "Epoch: [39][260/782]\tTime 0.172 (0.168)\tLoss 0.2403 (0.2365)\tPrec@1 85.938 (91.721)\n",
            "Epoch: [39][270/782]\tTime 0.167 (0.168)\tLoss 0.2442 (0.2376)\tPrec@1 92.188 (91.663)\n",
            "Epoch: [39][280/782]\tTime 0.167 (0.168)\tLoss 0.2059 (0.2380)\tPrec@1 93.750 (91.637)\n",
            "Epoch: [39][290/782]\tTime 0.166 (0.168)\tLoss 0.1892 (0.2373)\tPrec@1 89.062 (91.661)\n",
            "Epoch: [39][300/782]\tTime 0.167 (0.168)\tLoss 0.3648 (0.2395)\tPrec@1 89.062 (91.606)\n",
            "Epoch: [39][310/782]\tTime 0.167 (0.168)\tLoss 0.2524 (0.2396)\tPrec@1 92.188 (91.605)\n",
            "Epoch: [39][320/782]\tTime 0.166 (0.168)\tLoss 0.3448 (0.2391)\tPrec@1 93.750 (91.676)\n",
            "Epoch: [39][330/782]\tTime 0.169 (0.168)\tLoss 0.2717 (0.2405)\tPrec@1 89.062 (91.635)\n",
            "Epoch: [39][340/782]\tTime 0.168 (0.168)\tLoss 0.2942 (0.2399)\tPrec@1 89.062 (91.628)\n",
            "Epoch: [39][350/782]\tTime 0.167 (0.168)\tLoss 0.1207 (0.2390)\tPrec@1 98.438 (91.649)\n",
            "Epoch: [39][360/782]\tTime 0.166 (0.168)\tLoss 0.3035 (0.2392)\tPrec@1 90.625 (91.642)\n",
            "Epoch: [39][370/782]\tTime 0.167 (0.168)\tLoss 0.1817 (0.2387)\tPrec@1 95.312 (91.686)\n",
            "Epoch: [39][380/782]\tTime 0.166 (0.168)\tLoss 0.2970 (0.2384)\tPrec@1 89.062 (91.658)\n",
            "Epoch: [39][390/782]\tTime 0.167 (0.168)\tLoss 0.3283 (0.2383)\tPrec@1 84.375 (91.644)\n",
            "Epoch: [39][400/782]\tTime 0.167 (0.168)\tLoss 0.2002 (0.2382)\tPrec@1 95.312 (91.661)\n",
            "Epoch: [39][410/782]\tTime 0.167 (0.168)\tLoss 0.1989 (0.2379)\tPrec@1 95.312 (91.686)\n",
            "Epoch: [39][420/782]\tTime 0.168 (0.168)\tLoss 0.3091 (0.2385)\tPrec@1 90.625 (91.660)\n",
            "Epoch: [39][430/782]\tTime 0.166 (0.168)\tLoss 0.1975 (0.2382)\tPrec@1 93.750 (91.676)\n",
            "Epoch: [39][440/782]\tTime 0.168 (0.168)\tLoss 0.2472 (0.2386)\tPrec@1 89.062 (91.663)\n",
            "Epoch: [39][450/782]\tTime 0.167 (0.168)\tLoss 0.2672 (0.2381)\tPrec@1 90.625 (91.678)\n",
            "Epoch: [39][460/782]\tTime 0.168 (0.168)\tLoss 0.2202 (0.2378)\tPrec@1 92.188 (91.693)\n",
            "Epoch: [39][470/782]\tTime 0.166 (0.168)\tLoss 0.3785 (0.2377)\tPrec@1 85.938 (91.700)\n",
            "Epoch: [39][480/782]\tTime 0.167 (0.168)\tLoss 0.1552 (0.2377)\tPrec@1 95.312 (91.687)\n",
            "Epoch: [39][490/782]\tTime 0.166 (0.168)\tLoss 0.1221 (0.2376)\tPrec@1 95.312 (91.704)\n",
            "Epoch: [39][500/782]\tTime 0.167 (0.168)\tLoss 0.1421 (0.2375)\tPrec@1 93.750 (91.704)\n",
            "Epoch: [39][510/782]\tTime 0.166 (0.168)\tLoss 0.1563 (0.2364)\tPrec@1 95.312 (91.747)\n",
            "Epoch: [39][520/782]\tTime 0.173 (0.168)\tLoss 0.2720 (0.2360)\tPrec@1 90.625 (91.777)\n",
            "Epoch: [39][530/782]\tTime 0.167 (0.168)\tLoss 0.2988 (0.2368)\tPrec@1 90.625 (91.776)\n",
            "Epoch: [39][540/782]\tTime 0.166 (0.168)\tLoss 0.2230 (0.2370)\tPrec@1 92.188 (91.757)\n",
            "Epoch: [39][550/782]\tTime 0.172 (0.168)\tLoss 0.3190 (0.2379)\tPrec@1 85.938 (91.711)\n",
            "Epoch: [39][560/782]\tTime 0.167 (0.168)\tLoss 0.3324 (0.2386)\tPrec@1 89.062 (91.708)\n",
            "Epoch: [39][570/782]\tTime 0.168 (0.168)\tLoss 0.1859 (0.2386)\tPrec@1 92.188 (91.700)\n",
            "Epoch: [39][580/782]\tTime 0.166 (0.168)\tLoss 0.3670 (0.2386)\tPrec@1 84.375 (91.690)\n",
            "Epoch: [39][590/782]\tTime 0.166 (0.168)\tLoss 0.1131 (0.2381)\tPrec@1 96.875 (91.701)\n",
            "Epoch: [39][600/782]\tTime 0.168 (0.168)\tLoss 0.2193 (0.2389)\tPrec@1 90.625 (91.678)\n",
            "Epoch: [39][610/782]\tTime 0.168 (0.168)\tLoss 0.1837 (0.2387)\tPrec@1 92.188 (91.673)\n",
            "Epoch: [39][620/782]\tTime 0.170 (0.168)\tLoss 0.2136 (0.2385)\tPrec@1 92.188 (91.694)\n",
            "Epoch: [39][630/782]\tTime 0.166 (0.168)\tLoss 0.2086 (0.2387)\tPrec@1 90.625 (91.685)\n",
            "Epoch: [39][640/782]\tTime 0.171 (0.168)\tLoss 0.1982 (0.2386)\tPrec@1 95.312 (91.671)\n",
            "Epoch: [39][650/782]\tTime 0.167 (0.168)\tLoss 0.3447 (0.2389)\tPrec@1 89.062 (91.659)\n",
            "Epoch: [39][660/782]\tTime 0.168 (0.168)\tLoss 0.2387 (0.2391)\tPrec@1 92.188 (91.641)\n",
            "Epoch: [39][670/782]\tTime 0.173 (0.168)\tLoss 0.6220 (0.2397)\tPrec@1 87.500 (91.652)\n",
            "Epoch: [39][680/782]\tTime 0.167 (0.168)\tLoss 0.1412 (0.2388)\tPrec@1 95.312 (91.692)\n",
            "Epoch: [39][690/782]\tTime 0.164 (0.168)\tLoss 0.3095 (0.2396)\tPrec@1 92.188 (91.672)\n",
            "Epoch: [39][700/782]\tTime 0.168 (0.168)\tLoss 0.3522 (0.2400)\tPrec@1 87.500 (91.661)\n",
            "Epoch: [39][710/782]\tTime 0.166 (0.168)\tLoss 0.1772 (0.2403)\tPrec@1 95.312 (91.656)\n",
            "Epoch: [39][720/782]\tTime 0.168 (0.168)\tLoss 0.0963 (0.2404)\tPrec@1 96.875 (91.644)\n",
            "Epoch: [39][730/782]\tTime 0.167 (0.168)\tLoss 0.2366 (0.2407)\tPrec@1 90.625 (91.634)\n",
            "Epoch: [39][740/782]\tTime 0.168 (0.168)\tLoss 0.1788 (0.2412)\tPrec@1 93.750 (91.618)\n",
            "Epoch: [39][750/782]\tTime 0.167 (0.168)\tLoss 0.1391 (0.2412)\tPrec@1 98.438 (91.617)\n",
            "Epoch: [39][760/782]\tTime 0.167 (0.168)\tLoss 0.3204 (0.2418)\tPrec@1 92.188 (91.606)\n",
            "Epoch: [39][770/782]\tTime 0.167 (0.168)\tLoss 0.1150 (0.2415)\tPrec@1 93.750 (91.618)\n",
            "Epoch: [39][780/782]\tTime 0.162 (0.168)\tLoss 0.3187 (0.2425)\tPrec@1 90.625 (91.589)\n",
            "Training accuracy:  tensor(91.5900, device='cuda:0')\n",
            "Best accuraacy:  tensor(91.6260, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.114 (0.114)\tLoss 0.4948 (0.4948)\tPrec@1 87.500 (87.500)\n",
            "Test: [10/157]\tTime 0.044 (0.048)\tLoss 0.5207 (0.4801)\tPrec@1 85.938 (86.080)\n",
            "Test: [20/157]\tTime 0.050 (0.046)\tLoss 0.5978 (0.4562)\tPrec@1 78.125 (85.789)\n",
            "Test: [30/157]\tTime 0.041 (0.046)\tLoss 0.5590 (0.4445)\tPrec@1 90.625 (86.442)\n",
            "Test: [40/157]\tTime 0.042 (0.045)\tLoss 0.3704 (0.4356)\tPrec@1 84.375 (86.662)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.3822 (0.4280)\tPrec@1 85.938 (86.642)\n",
            "Test: [60/157]\tTime 0.049 (0.045)\tLoss 0.4177 (0.4266)\tPrec@1 82.812 (86.475)\n",
            "Test: [70/157]\tTime 0.043 (0.045)\tLoss 0.5357 (0.4234)\tPrec@1 84.375 (86.576)\n",
            "Test: [80/157]\tTime 0.043 (0.045)\tLoss 0.5796 (0.4348)\tPrec@1 79.688 (86.400)\n",
            "Test: [90/157]\tTime 0.043 (0.045)\tLoss 0.3622 (0.4306)\tPrec@1 90.625 (86.590)\n",
            "Test: [100/157]\tTime 0.043 (0.044)\tLoss 0.4716 (0.4345)\tPrec@1 84.375 (86.510)\n",
            "Test: [110/157]\tTime 0.044 (0.044)\tLoss 0.5968 (0.4403)\tPrec@1 87.500 (86.599)\n",
            "Test: [120/157]\tTime 0.044 (0.044)\tLoss 0.3004 (0.4408)\tPrec@1 87.500 (86.583)\n",
            "Test: [130/157]\tTime 0.040 (0.044)\tLoss 0.3630 (0.4363)\tPrec@1 87.500 (86.725)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.1576 (0.4337)\tPrec@1 90.625 (86.780)\n",
            "Test: [150/157]\tTime 0.044 (0.044)\tLoss 0.4687 (0.4356)\tPrec@1 87.500 (86.807)\n",
            " * Prec@1 86.820\n",
            "Best accuracy:  tensor(88.8800, device='cuda:0')\n",
            "Epoch: [40][0/782]\tTime 0.267 (0.267)\tLoss 0.1607 (0.1607)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [40][10/782]\tTime 0.172 (0.176)\tLoss 0.4384 (0.2523)\tPrec@1 84.375 (90.625)\n",
            "Epoch: [40][20/782]\tTime 0.167 (0.172)\tLoss 0.2109 (0.2258)\tPrec@1 93.750 (91.890)\n",
            "Epoch: [40][30/782]\tTime 0.166 (0.171)\tLoss 0.2820 (0.2228)\tPrec@1 90.625 (91.935)\n",
            "Epoch: [40][40/782]\tTime 0.167 (0.170)\tLoss 0.2586 (0.2286)\tPrec@1 92.188 (91.845)\n",
            "Epoch: [40][50/782]\tTime 0.166 (0.169)\tLoss 0.3433 (0.2315)\tPrec@1 85.938 (91.820)\n",
            "Epoch: [40][60/782]\tTime 0.167 (0.169)\tLoss 0.2048 (0.2294)\tPrec@1 92.188 (91.829)\n",
            "Epoch: [40][70/782]\tTime 0.167 (0.169)\tLoss 0.2320 (0.2264)\tPrec@1 89.062 (91.945)\n",
            "Epoch: [40][80/782]\tTime 0.168 (0.169)\tLoss 0.2851 (0.2246)\tPrec@1 87.500 (92.014)\n",
            "Epoch: [40][90/782]\tTime 0.166 (0.168)\tLoss 0.3497 (0.2290)\tPrec@1 90.625 (91.964)\n",
            "Epoch: [40][100/782]\tTime 0.172 (0.168)\tLoss 0.2233 (0.2301)\tPrec@1 93.750 (92.033)\n",
            "Epoch: [40][110/782]\tTime 0.166 (0.168)\tLoss 0.2175 (0.2289)\tPrec@1 93.750 (91.934)\n",
            "Epoch: [40][120/782]\tTime 0.168 (0.168)\tLoss 0.2776 (0.2271)\tPrec@1 93.750 (92.007)\n",
            "Epoch: [40][130/782]\tTime 0.168 (0.168)\tLoss 0.2304 (0.2242)\tPrec@1 95.312 (92.128)\n",
            "Epoch: [40][140/782]\tTime 0.165 (0.168)\tLoss 0.1859 (0.2244)\tPrec@1 95.312 (92.099)\n",
            "Epoch: [40][150/782]\tTime 0.166 (0.168)\tLoss 0.2142 (0.2272)\tPrec@1 93.750 (92.043)\n",
            "Epoch: [40][160/782]\tTime 0.167 (0.168)\tLoss 0.2037 (0.2268)\tPrec@1 95.312 (92.061)\n",
            "Epoch: [40][170/782]\tTime 0.166 (0.168)\tLoss 0.2451 (0.2244)\tPrec@1 87.500 (92.114)\n",
            "Epoch: [40][180/782]\tTime 0.167 (0.168)\tLoss 0.2139 (0.2243)\tPrec@1 92.188 (92.118)\n",
            "Epoch: [40][190/782]\tTime 0.167 (0.168)\tLoss 0.1763 (0.2231)\tPrec@1 96.875 (92.220)\n",
            "Epoch: [40][200/782]\tTime 0.168 (0.168)\tLoss 0.1575 (0.2239)\tPrec@1 95.312 (92.211)\n",
            "Epoch: [40][210/782]\tTime 0.165 (0.168)\tLoss 0.1932 (0.2226)\tPrec@1 93.750 (92.306)\n",
            "Epoch: [40][220/782]\tTime 0.167 (0.168)\tLoss 0.2993 (0.2222)\tPrec@1 90.625 (92.308)\n",
            "Epoch: [40][230/782]\tTime 0.167 (0.168)\tLoss 0.2246 (0.2241)\tPrec@1 93.750 (92.275)\n",
            "Epoch: [40][240/782]\tTime 0.167 (0.168)\tLoss 0.3194 (0.2247)\tPrec@1 90.625 (92.298)\n",
            "Epoch: [40][250/782]\tTime 0.168 (0.168)\tLoss 0.2384 (0.2241)\tPrec@1 90.625 (92.312)\n",
            "Epoch: [40][260/782]\tTime 0.166 (0.168)\tLoss 0.1814 (0.2224)\tPrec@1 92.188 (92.361)\n",
            "Epoch: [40][270/782]\tTime 0.172 (0.168)\tLoss 0.1534 (0.2233)\tPrec@1 93.750 (92.343)\n",
            "Epoch: [40][280/782]\tTime 0.168 (0.168)\tLoss 0.2036 (0.2232)\tPrec@1 92.188 (92.354)\n",
            "Epoch: [40][290/782]\tTime 0.166 (0.168)\tLoss 0.4035 (0.2248)\tPrec@1 92.188 (92.316)\n",
            "Epoch: [40][300/782]\tTime 0.168 (0.168)\tLoss 0.2025 (0.2254)\tPrec@1 89.062 (92.260)\n",
            "Epoch: [40][310/782]\tTime 0.168 (0.168)\tLoss 0.1971 (0.2271)\tPrec@1 92.188 (92.193)\n",
            "Epoch: [40][320/782]\tTime 0.165 (0.168)\tLoss 0.5198 (0.2290)\tPrec@1 79.688 (92.139)\n",
            "Epoch: [40][330/782]\tTime 0.170 (0.168)\tLoss 0.2163 (0.2279)\tPrec@1 93.750 (92.197)\n",
            "Epoch: [40][340/782]\tTime 0.167 (0.168)\tLoss 0.3023 (0.2285)\tPrec@1 85.938 (92.178)\n",
            "Epoch: [40][350/782]\tTime 0.166 (0.168)\tLoss 0.2643 (0.2288)\tPrec@1 90.625 (92.130)\n",
            "Epoch: [40][360/782]\tTime 0.167 (0.168)\tLoss 0.2431 (0.2300)\tPrec@1 90.625 (92.079)\n",
            "Epoch: [40][370/782]\tTime 0.168 (0.168)\tLoss 0.2548 (0.2306)\tPrec@1 92.188 (92.057)\n",
            "Epoch: [40][380/782]\tTime 0.166 (0.168)\tLoss 0.2095 (0.2305)\tPrec@1 92.188 (92.044)\n",
            "Epoch: [40][390/782]\tTime 0.167 (0.168)\tLoss 0.2345 (0.2308)\tPrec@1 93.750 (92.020)\n",
            "Epoch: [40][400/782]\tTime 0.168 (0.168)\tLoss 0.1786 (0.2302)\tPrec@1 90.625 (92.039)\n",
            "Epoch: [40][410/782]\tTime 0.166 (0.168)\tLoss 0.1836 (0.2309)\tPrec@1 92.188 (92.013)\n",
            "Epoch: [40][420/782]\tTime 0.168 (0.168)\tLoss 0.4066 (0.2314)\tPrec@1 85.938 (91.980)\n",
            "Epoch: [40][430/782]\tTime 0.166 (0.168)\tLoss 0.2722 (0.2322)\tPrec@1 89.062 (91.941)\n",
            "Epoch: [40][440/782]\tTime 0.168 (0.168)\tLoss 0.2385 (0.2323)\tPrec@1 93.750 (91.947)\n",
            "Epoch: [40][450/782]\tTime 0.167 (0.168)\tLoss 0.2146 (0.2324)\tPrec@1 95.312 (91.962)\n",
            "Epoch: [40][460/782]\tTime 0.167 (0.168)\tLoss 0.3572 (0.2331)\tPrec@1 85.938 (91.943)\n",
            "Epoch: [40][470/782]\tTime 0.166 (0.168)\tLoss 0.2156 (0.2334)\tPrec@1 89.062 (91.925)\n",
            "Epoch: [40][480/782]\tTime 0.168 (0.168)\tLoss 0.1728 (0.2327)\tPrec@1 92.188 (91.931)\n",
            "Epoch: [40][490/782]\tTime 0.167 (0.168)\tLoss 0.2633 (0.2337)\tPrec@1 92.188 (91.901)\n",
            "Epoch: [40][500/782]\tTime 0.167 (0.168)\tLoss 0.2132 (0.2339)\tPrec@1 89.062 (91.901)\n",
            "Epoch: [40][510/782]\tTime 0.167 (0.168)\tLoss 0.3039 (0.2332)\tPrec@1 87.500 (91.918)\n",
            "Epoch: [40][520/782]\tTime 0.165 (0.168)\tLoss 0.3015 (0.2334)\tPrec@1 89.062 (91.900)\n",
            "Epoch: [40][530/782]\tTime 0.166 (0.168)\tLoss 0.3125 (0.2336)\tPrec@1 87.500 (91.879)\n",
            "Epoch: [40][540/782]\tTime 0.168 (0.168)\tLoss 0.1848 (0.2341)\tPrec@1 95.312 (91.878)\n",
            "Epoch: [40][550/782]\tTime 0.167 (0.168)\tLoss 0.2619 (0.2348)\tPrec@1 92.188 (91.859)\n",
            "Epoch: [40][560/782]\tTime 0.172 (0.168)\tLoss 0.1535 (0.2347)\tPrec@1 96.875 (91.850)\n",
            "Epoch: [40][570/782]\tTime 0.167 (0.168)\tLoss 0.1633 (0.2349)\tPrec@1 95.312 (91.834)\n",
            "Epoch: [40][580/782]\tTime 0.168 (0.168)\tLoss 0.1550 (0.2352)\tPrec@1 95.312 (91.822)\n",
            "Epoch: [40][590/782]\tTime 0.170 (0.168)\tLoss 0.2386 (0.2349)\tPrec@1 92.188 (91.809)\n",
            "Epoch: [40][600/782]\tTime 0.167 (0.168)\tLoss 0.3529 (0.2344)\tPrec@1 90.625 (91.821)\n",
            "Epoch: [40][610/782]\tTime 0.168 (0.168)\tLoss 0.2839 (0.2343)\tPrec@1 87.500 (91.814)\n",
            "Epoch: [40][620/782]\tTime 0.166 (0.168)\tLoss 0.2370 (0.2344)\tPrec@1 90.625 (91.810)\n",
            "Epoch: [40][630/782]\tTime 0.167 (0.168)\tLoss 0.2480 (0.2344)\tPrec@1 89.062 (91.794)\n",
            "Epoch: [40][640/782]\tTime 0.167 (0.168)\tLoss 0.3983 (0.2347)\tPrec@1 82.812 (91.754)\n",
            "Epoch: [40][650/782]\tTime 0.167 (0.168)\tLoss 0.2690 (0.2352)\tPrec@1 89.062 (91.729)\n",
            "Epoch: [40][660/782]\tTime 0.167 (0.168)\tLoss 0.1866 (0.2356)\tPrec@1 93.750 (91.731)\n",
            "Epoch: [40][670/782]\tTime 0.166 (0.168)\tLoss 0.2753 (0.2360)\tPrec@1 92.188 (91.726)\n",
            "Epoch: [40][680/782]\tTime 0.170 (0.168)\tLoss 0.1930 (0.2359)\tPrec@1 95.312 (91.722)\n",
            "Epoch: [40][690/782]\tTime 0.167 (0.168)\tLoss 0.2343 (0.2366)\tPrec@1 95.312 (91.708)\n",
            "Epoch: [40][700/782]\tTime 0.167 (0.168)\tLoss 0.2548 (0.2370)\tPrec@1 89.062 (91.690)\n",
            "Epoch: [40][710/782]\tTime 0.168 (0.168)\tLoss 0.2800 (0.2374)\tPrec@1 87.500 (91.682)\n",
            "Epoch: [40][720/782]\tTime 0.166 (0.168)\tLoss 0.1306 (0.2373)\tPrec@1 95.312 (91.680)\n",
            "Epoch: [40][730/782]\tTime 0.167 (0.168)\tLoss 0.2060 (0.2370)\tPrec@1 93.750 (91.689)\n",
            "Epoch: [40][740/782]\tTime 0.167 (0.168)\tLoss 0.2316 (0.2369)\tPrec@1 92.188 (91.703)\n",
            "Epoch: [40][750/782]\tTime 0.177 (0.168)\tLoss 0.1648 (0.2372)\tPrec@1 93.750 (91.696)\n",
            "Epoch: [40][760/782]\tTime 0.167 (0.168)\tLoss 0.2809 (0.2379)\tPrec@1 89.062 (91.678)\n",
            "Epoch: [40][770/782]\tTime 0.167 (0.168)\tLoss 0.3058 (0.2381)\tPrec@1 90.625 (91.663)\n",
            "Epoch: [40][780/782]\tTime 0.163 (0.168)\tLoss 0.2965 (0.2387)\tPrec@1 89.062 (91.637)\n",
            "Training accuracy:  tensor(91.6360, device='cuda:0')\n",
            "Best accuraacy:  tensor(91.6360, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.118 (0.118)\tLoss 0.4410 (0.4410)\tPrec@1 82.812 (82.812)\n",
            "Test: [10/157]\tTime 0.041 (0.048)\tLoss 0.2815 (0.4659)\tPrec@1 89.062 (83.807)\n",
            "Test: [20/157]\tTime 0.050 (0.046)\tLoss 0.3524 (0.4456)\tPrec@1 92.188 (84.673)\n",
            "Test: [30/157]\tTime 0.041 (0.046)\tLoss 0.4990 (0.4313)\tPrec@1 79.688 (84.980)\n",
            "Test: [40/157]\tTime 0.042 (0.045)\tLoss 0.3452 (0.4407)\tPrec@1 89.062 (84.947)\n",
            "Test: [50/157]\tTime 0.042 (0.045)\tLoss 0.5569 (0.4453)\tPrec@1 84.375 (85.172)\n",
            "Test: [60/157]\tTime 0.041 (0.045)\tLoss 0.3016 (0.4411)\tPrec@1 90.625 (85.425)\n",
            "Test: [70/157]\tTime 0.041 (0.045)\tLoss 0.3818 (0.4346)\tPrec@1 87.500 (85.695)\n",
            "Test: [80/157]\tTime 0.043 (0.045)\tLoss 0.5495 (0.4429)\tPrec@1 84.375 (85.417)\n",
            "Test: [90/157]\tTime 0.044 (0.045)\tLoss 0.6751 (0.4497)\tPrec@1 81.250 (85.251)\n",
            "Test: [100/157]\tTime 0.040 (0.045)\tLoss 0.5282 (0.4501)\tPrec@1 82.812 (85.381)\n",
            "Test: [110/157]\tTime 0.045 (0.045)\tLoss 0.5351 (0.4529)\tPrec@1 76.562 (85.374)\n",
            "Test: [120/157]\tTime 0.043 (0.044)\tLoss 0.5015 (0.4561)\tPrec@1 79.688 (85.227)\n",
            "Test: [130/157]\tTime 0.039 (0.044)\tLoss 0.3782 (0.4626)\tPrec@1 84.375 (85.126)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.5837 (0.4672)\tPrec@1 81.250 (84.973)\n",
            "Test: [150/157]\tTime 0.043 (0.044)\tLoss 0.6167 (0.4660)\tPrec@1 82.812 (85.006)\n",
            " * Prec@1 85.060\n",
            "Best accuracy:  tensor(88.8800, device='cuda:0')\n",
            "Epoch: [41][0/782]\tTime 0.269 (0.269)\tLoss 0.2485 (0.2485)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [41][10/782]\tTime 0.166 (0.177)\tLoss 0.3580 (0.2579)\tPrec@1 84.375 (90.199)\n",
            "Epoch: [41][20/782]\tTime 0.167 (0.173)\tLoss 0.2840 (0.2413)\tPrec@1 87.500 (91.220)\n",
            "Epoch: [41][30/782]\tTime 0.166 (0.171)\tLoss 0.4027 (0.2518)\tPrec@1 87.500 (91.331)\n",
            "Epoch: [41][40/782]\tTime 0.166 (0.170)\tLoss 0.2956 (0.2449)\tPrec@1 93.750 (91.349)\n",
            "Epoch: [41][50/782]\tTime 0.171 (0.170)\tLoss 0.1312 (0.2376)\tPrec@1 96.875 (91.667)\n",
            "Epoch: [41][60/782]\tTime 0.165 (0.170)\tLoss 0.1661 (0.2410)\tPrec@1 96.875 (91.650)\n",
            "Epoch: [41][70/782]\tTime 0.167 (0.169)\tLoss 0.1299 (0.2383)\tPrec@1 96.875 (91.835)\n",
            "Epoch: [41][80/782]\tTime 0.170 (0.169)\tLoss 0.3159 (0.2383)\tPrec@1 93.750 (91.840)\n",
            "Epoch: [41][90/782]\tTime 0.168 (0.169)\tLoss 0.2088 (0.2352)\tPrec@1 90.625 (92.016)\n",
            "Epoch: [41][100/782]\tTime 0.166 (0.169)\tLoss 0.2721 (0.2366)\tPrec@1 90.625 (91.847)\n",
            "Epoch: [41][110/782]\tTime 0.168 (0.169)\tLoss 0.3934 (0.2380)\tPrec@1 84.375 (91.807)\n",
            "Epoch: [41][120/782]\tTime 0.167 (0.169)\tLoss 0.3380 (0.2402)\tPrec@1 89.062 (91.736)\n",
            "Epoch: [41][130/782]\tTime 0.167 (0.169)\tLoss 0.0884 (0.2413)\tPrec@1 98.438 (91.782)\n",
            "Epoch: [41][140/782]\tTime 0.167 (0.169)\tLoss 0.2908 (0.2390)\tPrec@1 90.625 (91.800)\n",
            "Epoch: [41][150/782]\tTime 0.166 (0.169)\tLoss 0.2709 (0.2396)\tPrec@1 92.188 (91.763)\n",
            "Epoch: [41][160/782]\tTime 0.166 (0.169)\tLoss 0.1785 (0.2374)\tPrec@1 93.750 (91.896)\n",
            "Epoch: [41][170/782]\tTime 0.166 (0.168)\tLoss 0.1856 (0.2358)\tPrec@1 95.312 (91.923)\n",
            "Epoch: [41][180/782]\tTime 0.166 (0.168)\tLoss 0.4097 (0.2342)\tPrec@1 87.500 (91.980)\n",
            "Epoch: [41][190/782]\tTime 0.168 (0.168)\tLoss 0.1660 (0.2332)\tPrec@1 90.625 (91.991)\n",
            "Epoch: [41][200/782]\tTime 0.167 (0.168)\tLoss 0.2117 (0.2343)\tPrec@1 93.750 (91.970)\n",
            "Epoch: [41][210/782]\tTime 0.166 (0.168)\tLoss 0.1826 (0.2336)\tPrec@1 96.875 (92.076)\n",
            "Epoch: [41][220/782]\tTime 0.166 (0.168)\tLoss 0.1698 (0.2351)\tPrec@1 95.312 (92.046)\n",
            "Epoch: [41][230/782]\tTime 0.168 (0.168)\tLoss 0.1982 (0.2352)\tPrec@1 92.188 (92.032)\n",
            "Epoch: [41][240/782]\tTime 0.167 (0.168)\tLoss 0.2523 (0.2352)\tPrec@1 92.188 (92.032)\n",
            "Epoch: [41][250/782]\tTime 0.168 (0.168)\tLoss 0.2680 (0.2364)\tPrec@1 90.625 (91.988)\n",
            "Epoch: [41][260/782]\tTime 0.166 (0.168)\tLoss 0.2210 (0.2367)\tPrec@1 92.188 (91.978)\n",
            "Epoch: [41][270/782]\tTime 0.168 (0.168)\tLoss 0.3864 (0.2384)\tPrec@1 89.062 (91.928)\n",
            "Epoch: [41][280/782]\tTime 0.166 (0.168)\tLoss 0.3903 (0.2386)\tPrec@1 85.938 (91.909)\n",
            "Epoch: [41][290/782]\tTime 0.165 (0.168)\tLoss 0.3535 (0.2383)\tPrec@1 89.062 (91.924)\n",
            "Epoch: [41][300/782]\tTime 0.165 (0.168)\tLoss 0.3283 (0.2389)\tPrec@1 92.188 (91.897)\n",
            "Epoch: [41][310/782]\tTime 0.166 (0.168)\tLoss 0.0774 (0.2379)\tPrec@1 98.438 (91.946)\n",
            "Epoch: [41][320/782]\tTime 0.166 (0.168)\tLoss 0.5075 (0.2395)\tPrec@1 89.062 (91.895)\n",
            "Epoch: [41][330/782]\tTime 0.167 (0.168)\tLoss 0.1884 (0.2397)\tPrec@1 92.188 (91.923)\n",
            "Epoch: [41][340/782]\tTime 0.166 (0.168)\tLoss 0.2420 (0.2385)\tPrec@1 92.188 (91.949)\n",
            "Epoch: [41][350/782]\tTime 0.166 (0.168)\tLoss 0.2886 (0.2383)\tPrec@1 87.500 (91.956)\n",
            "Epoch: [41][360/782]\tTime 0.165 (0.168)\tLoss 0.3481 (0.2385)\tPrec@1 85.938 (91.932)\n",
            "Epoch: [41][370/782]\tTime 0.168 (0.168)\tLoss 0.3225 (0.2388)\tPrec@1 89.062 (91.914)\n",
            "Epoch: [41][380/782]\tTime 0.165 (0.168)\tLoss 0.2339 (0.2397)\tPrec@1 92.188 (91.880)\n",
            "Epoch: [41][390/782]\tTime 0.165 (0.168)\tLoss 0.2103 (0.2397)\tPrec@1 96.875 (91.900)\n",
            "Epoch: [41][400/782]\tTime 0.166 (0.168)\tLoss 0.2212 (0.2382)\tPrec@1 92.188 (91.958)\n",
            "Epoch: [41][410/782]\tTime 0.167 (0.168)\tLoss 0.1775 (0.2378)\tPrec@1 93.750 (91.971)\n",
            "Epoch: [41][420/782]\tTime 0.168 (0.168)\tLoss 0.2301 (0.2374)\tPrec@1 90.625 (91.980)\n",
            "Epoch: [41][430/782]\tTime 0.166 (0.168)\tLoss 0.3112 (0.2388)\tPrec@1 87.500 (91.916)\n",
            "Epoch: [41][440/782]\tTime 0.165 (0.168)\tLoss 0.3017 (0.2400)\tPrec@1 89.062 (91.893)\n",
            "Epoch: [41][450/782]\tTime 0.167 (0.168)\tLoss 0.2898 (0.2408)\tPrec@1 87.500 (91.862)\n",
            "Epoch: [41][460/782]\tTime 0.165 (0.168)\tLoss 0.1551 (0.2410)\tPrec@1 96.875 (91.842)\n",
            "Epoch: [41][470/782]\tTime 0.164 (0.167)\tLoss 0.2544 (0.2403)\tPrec@1 90.625 (91.872)\n",
            "Epoch: [41][480/782]\tTime 0.165 (0.167)\tLoss 0.1889 (0.2404)\tPrec@1 92.188 (91.846)\n",
            "Epoch: [41][490/782]\tTime 0.166 (0.167)\tLoss 0.3060 (0.2405)\tPrec@1 87.500 (91.837)\n",
            "Epoch: [41][500/782]\tTime 0.164 (0.167)\tLoss 0.2252 (0.2392)\tPrec@1 89.062 (91.841)\n",
            "Epoch: [41][510/782]\tTime 0.168 (0.167)\tLoss 0.3273 (0.2395)\tPrec@1 89.062 (91.848)\n",
            "Epoch: [41][520/782]\tTime 0.166 (0.167)\tLoss 0.2432 (0.2395)\tPrec@1 92.188 (91.867)\n",
            "Epoch: [41][530/782]\tTime 0.168 (0.167)\tLoss 0.1999 (0.2389)\tPrec@1 93.750 (91.876)\n",
            "Epoch: [41][540/782]\tTime 0.165 (0.167)\tLoss 0.2093 (0.2392)\tPrec@1 92.188 (91.884)\n",
            "Epoch: [41][550/782]\tTime 0.167 (0.167)\tLoss 0.2684 (0.2390)\tPrec@1 90.625 (91.884)\n",
            "Epoch: [41][560/782]\tTime 0.165 (0.167)\tLoss 0.2060 (0.2385)\tPrec@1 92.188 (91.881)\n",
            "Epoch: [41][570/782]\tTime 0.166 (0.167)\tLoss 0.1784 (0.2379)\tPrec@1 92.188 (91.900)\n",
            "Epoch: [41][580/782]\tTime 0.165 (0.167)\tLoss 0.2235 (0.2383)\tPrec@1 92.188 (91.857)\n",
            "Epoch: [41][590/782]\tTime 0.166 (0.167)\tLoss 0.2239 (0.2383)\tPrec@1 90.625 (91.868)\n",
            "Epoch: [41][600/782]\tTime 0.166 (0.167)\tLoss 0.0597 (0.2375)\tPrec@1 98.438 (91.899)\n",
            "Epoch: [41][610/782]\tTime 0.167 (0.167)\tLoss 0.2105 (0.2374)\tPrec@1 92.188 (91.888)\n",
            "Epoch: [41][620/782]\tTime 0.166 (0.167)\tLoss 0.1959 (0.2378)\tPrec@1 89.062 (91.888)\n",
            "Epoch: [41][630/782]\tTime 0.166 (0.167)\tLoss 0.2646 (0.2380)\tPrec@1 85.938 (91.873)\n",
            "Epoch: [41][640/782]\tTime 0.164 (0.167)\tLoss 0.3708 (0.2378)\tPrec@1 89.062 (91.875)\n",
            "Epoch: [41][650/782]\tTime 0.167 (0.167)\tLoss 0.1641 (0.2388)\tPrec@1 96.875 (91.851)\n",
            "Epoch: [41][660/782]\tTime 0.165 (0.167)\tLoss 0.1991 (0.2390)\tPrec@1 90.625 (91.823)\n",
            "Epoch: [41][670/782]\tTime 0.166 (0.167)\tLoss 0.3259 (0.2395)\tPrec@1 89.062 (91.808)\n",
            "Epoch: [41][680/782]\tTime 0.166 (0.167)\tLoss 0.2789 (0.2396)\tPrec@1 92.188 (91.807)\n",
            "Epoch: [41][690/782]\tTime 0.167 (0.167)\tLoss 0.2694 (0.2396)\tPrec@1 90.625 (91.808)\n",
            "Epoch: [41][700/782]\tTime 0.169 (0.167)\tLoss 0.2683 (0.2397)\tPrec@1 93.750 (91.793)\n",
            "Epoch: [41][710/782]\tTime 0.165 (0.167)\tLoss 0.1410 (0.2401)\tPrec@1 95.312 (91.785)\n",
            "Epoch: [41][720/782]\tTime 0.165 (0.167)\tLoss 0.1177 (0.2400)\tPrec@1 96.875 (91.784)\n",
            "Epoch: [41][730/782]\tTime 0.166 (0.167)\tLoss 0.1587 (0.2397)\tPrec@1 95.312 (91.788)\n",
            "Epoch: [41][740/782]\tTime 0.165 (0.167)\tLoss 0.3299 (0.2396)\tPrec@1 87.500 (91.797)\n",
            "Epoch: [41][750/782]\tTime 0.163 (0.167)\tLoss 0.2707 (0.2398)\tPrec@1 89.062 (91.782)\n",
            "Epoch: [41][760/782]\tTime 0.165 (0.167)\tLoss 0.2663 (0.2400)\tPrec@1 90.625 (91.758)\n",
            "Epoch: [41][770/782]\tTime 0.165 (0.167)\tLoss 0.2575 (0.2402)\tPrec@1 93.750 (91.754)\n",
            "Epoch: [41][780/782]\tTime 0.163 (0.167)\tLoss 0.1773 (0.2409)\tPrec@1 95.312 (91.733)\n",
            "Training accuracy:  tensor(91.7320, device='cuda:0')\n",
            "Best accuraacy:  tensor(91.7320, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.112 (0.112)\tLoss 0.8250 (0.8250)\tPrec@1 81.250 (81.250)\n",
            "Test: [10/157]\tTime 0.043 (0.047)\tLoss 0.3542 (0.4924)\tPrec@1 85.938 (85.369)\n",
            "Test: [20/157]\tTime 0.048 (0.046)\tLoss 0.7373 (0.5020)\tPrec@1 78.125 (84.970)\n",
            "Test: [30/157]\tTime 0.043 (0.046)\tLoss 0.2316 (0.4696)\tPrec@1 92.188 (85.081)\n",
            "Test: [40/157]\tTime 0.043 (0.045)\tLoss 0.3134 (0.4603)\tPrec@1 87.500 (85.290)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.2176 (0.4742)\tPrec@1 93.750 (85.233)\n",
            "Test: [60/157]\tTime 0.043 (0.045)\tLoss 0.5550 (0.4717)\tPrec@1 87.500 (85.656)\n",
            "Test: [70/157]\tTime 0.044 (0.045)\tLoss 0.2600 (0.4743)\tPrec@1 96.875 (85.717)\n",
            "Test: [80/157]\tTime 0.043 (0.044)\tLoss 0.4925 (0.4811)\tPrec@1 87.500 (85.513)\n",
            "Test: [90/157]\tTime 0.044 (0.044)\tLoss 0.4408 (0.4779)\tPrec@1 90.625 (85.628)\n",
            "Test: [100/157]\tTime 0.044 (0.044)\tLoss 0.5797 (0.4725)\tPrec@1 79.688 (85.628)\n",
            "Test: [110/157]\tTime 0.044 (0.044)\tLoss 0.4914 (0.4666)\tPrec@1 89.062 (85.825)\n",
            "Test: [120/157]\tTime 0.043 (0.044)\tLoss 0.4496 (0.4660)\tPrec@1 82.812 (85.989)\n",
            "Test: [130/157]\tTime 0.043 (0.044)\tLoss 0.3818 (0.4665)\tPrec@1 84.375 (85.914)\n",
            "Test: [140/157]\tTime 0.043 (0.044)\tLoss 0.6525 (0.4718)\tPrec@1 81.250 (85.860)\n",
            "Test: [150/157]\tTime 0.042 (0.044)\tLoss 0.4911 (0.4692)\tPrec@1 81.250 (85.803)\n",
            " * Prec@1 85.800\n",
            "Best accuracy:  tensor(88.8800, device='cuda:0')\n",
            "Epoch: [42][0/782]\tTime 0.270 (0.270)\tLoss 0.2629 (0.2629)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [42][10/782]\tTime 0.166 (0.177)\tLoss 0.1325 (0.2815)\tPrec@1 96.875 (90.057)\n",
            "Epoch: [42][20/782]\tTime 0.165 (0.172)\tLoss 0.1820 (0.2599)\tPrec@1 92.188 (90.774)\n",
            "Epoch: [42][30/782]\tTime 0.166 (0.170)\tLoss 0.2296 (0.2523)\tPrec@1 90.625 (91.179)\n",
            "Epoch: [42][40/782]\tTime 0.169 (0.170)\tLoss 0.2605 (0.2379)\tPrec@1 90.625 (91.806)\n",
            "Epoch: [42][50/782]\tTime 0.166 (0.169)\tLoss 0.2276 (0.2421)\tPrec@1 92.188 (91.759)\n",
            "Epoch: [42][60/782]\tTime 0.166 (0.169)\tLoss 0.2339 (0.2368)\tPrec@1 90.625 (91.906)\n",
            "Epoch: [42][70/782]\tTime 0.172 (0.169)\tLoss 0.2732 (0.2304)\tPrec@1 89.062 (92.099)\n",
            "Epoch: [42][80/782]\tTime 0.167 (0.169)\tLoss 0.2206 (0.2241)\tPrec@1 89.062 (92.188)\n",
            "Epoch: [42][90/782]\tTime 0.166 (0.169)\tLoss 0.2965 (0.2226)\tPrec@1 93.750 (92.308)\n",
            "Epoch: [42][100/782]\tTime 0.165 (0.169)\tLoss 0.2143 (0.2221)\tPrec@1 93.750 (92.342)\n",
            "Epoch: [42][110/782]\tTime 0.165 (0.168)\tLoss 0.3096 (0.2239)\tPrec@1 87.500 (92.272)\n",
            "Epoch: [42][120/782]\tTime 0.164 (0.168)\tLoss 0.0792 (0.2230)\tPrec@1 98.438 (92.368)\n",
            "Epoch: [42][130/782]\tTime 0.165 (0.168)\tLoss 0.1740 (0.2267)\tPrec@1 93.750 (92.283)\n",
            "Epoch: [42][140/782]\tTime 0.165 (0.168)\tLoss 0.2062 (0.2245)\tPrec@1 92.188 (92.332)\n",
            "Epoch: [42][150/782]\tTime 0.166 (0.168)\tLoss 0.2596 (0.2248)\tPrec@1 90.625 (92.343)\n",
            "Epoch: [42][160/782]\tTime 0.163 (0.168)\tLoss 0.1954 (0.2264)\tPrec@1 95.312 (92.459)\n",
            "Epoch: [42][170/782]\tTime 0.164 (0.167)\tLoss 0.1403 (0.2246)\tPrec@1 93.750 (92.489)\n",
            "Epoch: [42][180/782]\tTime 0.165 (0.167)\tLoss 0.3227 (0.2231)\tPrec@1 85.938 (92.550)\n",
            "Epoch: [42][190/782]\tTime 0.165 (0.167)\tLoss 0.2048 (0.2242)\tPrec@1 90.625 (92.466)\n",
            "Epoch: [42][200/782]\tTime 0.166 (0.167)\tLoss 0.1595 (0.2230)\tPrec@1 93.750 (92.530)\n",
            "Epoch: [42][210/782]\tTime 0.167 (0.167)\tLoss 0.1199 (0.2253)\tPrec@1 96.875 (92.476)\n",
            "Epoch: [42][220/782]\tTime 0.167 (0.167)\tLoss 0.1691 (0.2235)\tPrec@1 93.750 (92.534)\n",
            "Epoch: [42][230/782]\tTime 0.166 (0.167)\tLoss 0.2665 (0.2225)\tPrec@1 89.062 (92.539)\n",
            "Epoch: [42][240/782]\tTime 0.166 (0.167)\tLoss 0.2490 (0.2241)\tPrec@1 89.062 (92.479)\n",
            "Epoch: [42][250/782]\tTime 0.165 (0.167)\tLoss 0.2153 (0.2245)\tPrec@1 92.188 (92.474)\n",
            "Epoch: [42][260/782]\tTime 0.166 (0.167)\tLoss 0.3403 (0.2257)\tPrec@1 85.938 (92.433)\n",
            "Epoch: [42][270/782]\tTime 0.166 (0.167)\tLoss 0.3146 (0.2266)\tPrec@1 93.750 (92.418)\n",
            "Epoch: [42][280/782]\tTime 0.165 (0.167)\tLoss 0.2898 (0.2270)\tPrec@1 90.625 (92.365)\n",
            "Epoch: [42][290/782]\tTime 0.166 (0.167)\tLoss 0.4128 (0.2293)\tPrec@1 85.938 (92.284)\n",
            "Epoch: [42][300/782]\tTime 0.166 (0.167)\tLoss 0.1014 (0.2301)\tPrec@1 95.312 (92.250)\n",
            "Epoch: [42][310/782]\tTime 0.165 (0.167)\tLoss 0.2788 (0.2305)\tPrec@1 92.188 (92.273)\n",
            "Epoch: [42][320/782]\tTime 0.165 (0.167)\tLoss 0.2395 (0.2309)\tPrec@1 92.188 (92.280)\n",
            "Epoch: [42][330/782]\tTime 0.165 (0.167)\tLoss 0.1758 (0.2309)\tPrec@1 92.188 (92.291)\n",
            "Epoch: [42][340/782]\tTime 0.166 (0.167)\tLoss 0.3503 (0.2327)\tPrec@1 85.938 (92.238)\n",
            "Epoch: [42][350/782]\tTime 0.165 (0.167)\tLoss 0.1972 (0.2325)\tPrec@1 93.750 (92.223)\n",
            "Epoch: [42][360/782]\tTime 0.170 (0.167)\tLoss 0.1970 (0.2337)\tPrec@1 92.188 (92.144)\n",
            "Epoch: [42][370/782]\tTime 0.168 (0.167)\tLoss 0.1174 (0.2337)\tPrec@1 96.875 (92.107)\n",
            "Epoch: [42][380/782]\tTime 0.167 (0.167)\tLoss 0.1339 (0.2332)\tPrec@1 95.312 (92.130)\n",
            "Epoch: [42][390/782]\tTime 0.168 (0.167)\tLoss 0.2016 (0.2337)\tPrec@1 92.188 (92.100)\n",
            "Epoch: [42][400/782]\tTime 0.167 (0.167)\tLoss 0.1908 (0.2326)\tPrec@1 92.188 (92.121)\n",
            "Epoch: [42][410/782]\tTime 0.166 (0.167)\tLoss 0.3032 (0.2332)\tPrec@1 90.625 (92.115)\n",
            "Epoch: [42][420/782]\tTime 0.166 (0.167)\tLoss 0.2487 (0.2338)\tPrec@1 92.188 (92.110)\n",
            "Epoch: [42][430/782]\tTime 0.166 (0.167)\tLoss 0.2478 (0.2336)\tPrec@1 89.062 (92.100)\n",
            "Epoch: [42][440/782]\tTime 0.165 (0.167)\tLoss 0.3601 (0.2344)\tPrec@1 87.500 (92.056)\n",
            "Epoch: [42][450/782]\tTime 0.167 (0.167)\tLoss 0.1963 (0.2343)\tPrec@1 90.625 (92.039)\n",
            "Epoch: [42][460/782]\tTime 0.166 (0.167)\tLoss 0.2709 (0.2351)\tPrec@1 87.500 (91.998)\n",
            "Epoch: [42][470/782]\tTime 0.165 (0.167)\tLoss 0.3086 (0.2360)\tPrec@1 87.500 (91.962)\n",
            "Epoch: [42][480/782]\tTime 0.166 (0.167)\tLoss 0.2341 (0.2360)\tPrec@1 92.188 (91.944)\n",
            "Epoch: [42][490/782]\tTime 0.169 (0.167)\tLoss 0.2796 (0.2359)\tPrec@1 90.625 (91.933)\n",
            "Epoch: [42][500/782]\tTime 0.167 (0.167)\tLoss 0.3109 (0.2359)\tPrec@1 90.625 (91.938)\n",
            "Epoch: [42][510/782]\tTime 0.166 (0.167)\tLoss 0.5037 (0.2369)\tPrec@1 82.812 (91.906)\n",
            "Epoch: [42][520/782]\tTime 0.165 (0.167)\tLoss 0.2882 (0.2366)\tPrec@1 89.062 (91.906)\n",
            "Epoch: [42][530/782]\tTime 0.166 (0.167)\tLoss 0.2838 (0.2363)\tPrec@1 89.062 (91.914)\n",
            "Epoch: [42][540/782]\tTime 0.165 (0.167)\tLoss 0.2658 (0.2373)\tPrec@1 90.625 (91.881)\n",
            "Epoch: [42][550/782]\tTime 0.166 (0.167)\tLoss 0.1323 (0.2369)\tPrec@1 93.750 (91.898)\n",
            "Epoch: [42][560/782]\tTime 0.165 (0.167)\tLoss 0.1777 (0.2369)\tPrec@1 90.625 (91.870)\n",
            "Epoch: [42][570/782]\tTime 0.165 (0.167)\tLoss 0.1095 (0.2365)\tPrec@1 96.875 (91.903)\n",
            "Epoch: [42][580/782]\tTime 0.167 (0.167)\tLoss 0.2547 (0.2370)\tPrec@1 90.625 (91.865)\n",
            "Epoch: [42][590/782]\tTime 0.166 (0.167)\tLoss 0.2299 (0.2368)\tPrec@1 87.500 (91.860)\n",
            "Epoch: [42][600/782]\tTime 0.167 (0.167)\tLoss 0.1510 (0.2369)\tPrec@1 93.750 (91.837)\n",
            "Epoch: [42][610/782]\tTime 0.171 (0.167)\tLoss 0.1801 (0.2370)\tPrec@1 93.750 (91.829)\n",
            "Epoch: [42][620/782]\tTime 0.167 (0.167)\tLoss 0.1294 (0.2371)\tPrec@1 93.750 (91.818)\n",
            "Epoch: [42][630/782]\tTime 0.167 (0.167)\tLoss 0.1709 (0.2364)\tPrec@1 95.312 (91.841)\n",
            "Epoch: [42][640/782]\tTime 0.165 (0.167)\tLoss 0.2202 (0.2369)\tPrec@1 89.062 (91.817)\n",
            "Epoch: [42][650/782]\tTime 0.163 (0.167)\tLoss 0.3530 (0.2362)\tPrec@1 87.500 (91.837)\n",
            "Epoch: [42][660/782]\tTime 0.168 (0.167)\tLoss 0.2799 (0.2365)\tPrec@1 89.062 (91.835)\n",
            "Epoch: [42][670/782]\tTime 0.165 (0.167)\tLoss 0.1674 (0.2370)\tPrec@1 93.750 (91.817)\n",
            "Epoch: [42][680/782]\tTime 0.165 (0.167)\tLoss 0.1769 (0.2369)\tPrec@1 92.188 (91.811)\n",
            "Epoch: [42][690/782]\tTime 0.166 (0.167)\tLoss 0.3543 (0.2368)\tPrec@1 89.062 (91.814)\n",
            "Epoch: [42][700/782]\tTime 0.165 (0.167)\tLoss 0.1392 (0.2363)\tPrec@1 93.750 (91.835)\n",
            "Epoch: [42][710/782]\tTime 0.165 (0.167)\tLoss 0.1834 (0.2359)\tPrec@1 93.750 (91.851)\n",
            "Epoch: [42][720/782]\tTime 0.166 (0.167)\tLoss 0.2056 (0.2361)\tPrec@1 93.750 (91.856)\n",
            "Epoch: [42][730/782]\tTime 0.167 (0.167)\tLoss 0.0968 (0.2359)\tPrec@1 98.438 (91.865)\n",
            "Epoch: [42][740/782]\tTime 0.169 (0.167)\tLoss 0.0695 (0.2355)\tPrec@1 96.875 (91.871)\n",
            "Epoch: [42][750/782]\tTime 0.165 (0.167)\tLoss 0.2564 (0.2356)\tPrec@1 92.188 (91.859)\n",
            "Epoch: [42][760/782]\tTime 0.165 (0.167)\tLoss 0.2075 (0.2354)\tPrec@1 90.625 (91.861)\n",
            "Epoch: [42][770/782]\tTime 0.165 (0.167)\tLoss 0.2286 (0.2356)\tPrec@1 90.625 (91.849)\n",
            "Epoch: [42][780/782]\tTime 0.163 (0.167)\tLoss 0.2423 (0.2360)\tPrec@1 90.625 (91.825)\n",
            "Training accuracy:  tensor(91.8260, device='cuda:0')\n",
            "Best accuraacy:  tensor(91.8260, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.113 (0.113)\tLoss 0.3402 (0.3402)\tPrec@1 85.938 (85.938)\n",
            "Test: [10/157]\tTime 0.044 (0.047)\tLoss 0.1998 (0.3647)\tPrec@1 93.750 (87.500)\n",
            "Test: [20/157]\tTime 0.051 (0.046)\tLoss 0.4208 (0.3521)\tPrec@1 84.375 (87.798)\n",
            "Test: [30/157]\tTime 0.044 (0.046)\tLoss 0.1764 (0.3447)\tPrec@1 90.625 (88.508)\n",
            "Test: [40/157]\tTime 0.043 (0.045)\tLoss 0.5378 (0.3508)\tPrec@1 90.625 (88.491)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.3056 (0.3554)\tPrec@1 92.188 (88.756)\n",
            "Test: [60/157]\tTime 0.043 (0.045)\tLoss 0.5352 (0.3572)\tPrec@1 81.250 (88.601)\n",
            "Test: [70/157]\tTime 0.044 (0.045)\tLoss 0.4089 (0.3503)\tPrec@1 85.938 (88.732)\n",
            "Test: [80/157]\tTime 0.041 (0.045)\tLoss 0.3125 (0.3570)\tPrec@1 87.500 (88.542)\n",
            "Test: [90/157]\tTime 0.044 (0.045)\tLoss 0.5286 (0.3658)\tPrec@1 84.375 (88.496)\n",
            "Test: [100/157]\tTime 0.044 (0.045)\tLoss 0.3545 (0.3708)\tPrec@1 89.062 (88.397)\n",
            "Test: [110/157]\tTime 0.046 (0.044)\tLoss 0.5954 (0.3753)\tPrec@1 84.375 (88.288)\n",
            "Test: [120/157]\tTime 0.046 (0.044)\tLoss 0.4035 (0.3739)\tPrec@1 89.062 (88.301)\n",
            "Test: [130/157]\tTime 0.045 (0.044)\tLoss 0.4370 (0.3719)\tPrec@1 85.938 (88.371)\n",
            "Test: [140/157]\tTime 0.048 (0.044)\tLoss 0.4723 (0.3678)\tPrec@1 87.500 (88.486)\n",
            "Test: [150/157]\tTime 0.043 (0.044)\tLoss 0.2423 (0.3638)\tPrec@1 92.188 (88.680)\n",
            " * Prec@1 88.610\n",
            "Best accuracy:  tensor(88.8800, device='cuda:0')\n",
            "Epoch: [43][0/782]\tTime 0.267 (0.267)\tLoss 0.1777 (0.1777)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [43][10/782]\tTime 0.167 (0.175)\tLoss 0.2598 (0.2479)\tPrec@1 87.500 (91.051)\n",
            "Epoch: [43][20/782]\tTime 0.165 (0.171)\tLoss 0.1660 (0.2454)\tPrec@1 95.312 (91.592)\n",
            "Epoch: [43][30/782]\tTime 0.167 (0.170)\tLoss 0.1420 (0.2319)\tPrec@1 93.750 (92.238)\n",
            "Epoch: [43][40/782]\tTime 0.165 (0.169)\tLoss 0.2988 (0.2278)\tPrec@1 89.062 (92.340)\n",
            "Epoch: [43][50/782]\tTime 0.163 (0.168)\tLoss 0.2110 (0.2261)\tPrec@1 96.875 (92.647)\n",
            "Epoch: [43][60/782]\tTime 0.165 (0.168)\tLoss 0.1534 (0.2139)\tPrec@1 93.750 (92.982)\n",
            "Epoch: [43][70/782]\tTime 0.165 (0.168)\tLoss 0.1822 (0.2130)\tPrec@1 93.750 (92.980)\n",
            "Epoch: [43][80/782]\tTime 0.170 (0.167)\tLoss 0.3281 (0.2172)\tPrec@1 85.938 (92.650)\n",
            "Epoch: [43][90/782]\tTime 0.166 (0.167)\tLoss 0.1969 (0.2149)\tPrec@1 92.188 (92.771)\n",
            "Epoch: [43][100/782]\tTime 0.164 (0.167)\tLoss 0.1907 (0.2163)\tPrec@1 95.312 (92.683)\n",
            "Epoch: [43][110/782]\tTime 0.166 (0.167)\tLoss 0.2489 (0.2215)\tPrec@1 92.188 (92.370)\n",
            "Epoch: [43][120/782]\tTime 0.168 (0.167)\tLoss 0.0816 (0.2184)\tPrec@1 96.875 (92.523)\n",
            "Epoch: [43][130/782]\tTime 0.164 (0.167)\tLoss 0.1432 (0.2220)\tPrec@1 95.312 (92.438)\n",
            "Epoch: [43][140/782]\tTime 0.166 (0.167)\tLoss 0.1785 (0.2202)\tPrec@1 95.312 (92.564)\n",
            "Epoch: [43][150/782]\tTime 0.167 (0.167)\tLoss 0.2760 (0.2211)\tPrec@1 87.500 (92.446)\n",
            "Epoch: [43][160/782]\tTime 0.166 (0.167)\tLoss 0.1762 (0.2181)\tPrec@1 92.188 (92.537)\n",
            "Epoch: [43][170/782]\tTime 0.165 (0.167)\tLoss 0.2142 (0.2182)\tPrec@1 93.750 (92.553)\n",
            "Epoch: [43][180/782]\tTime 0.166 (0.167)\tLoss 0.1063 (0.2204)\tPrec@1 96.875 (92.421)\n",
            "Epoch: [43][190/782]\tTime 0.165 (0.167)\tLoss 0.2486 (0.2214)\tPrec@1 89.062 (92.384)\n",
            "Epoch: [43][200/782]\tTime 0.166 (0.167)\tLoss 0.2718 (0.2232)\tPrec@1 93.750 (92.296)\n",
            "Epoch: [43][210/782]\tTime 0.167 (0.167)\tLoss 0.2736 (0.2246)\tPrec@1 92.188 (92.202)\n",
            "Epoch: [43][220/782]\tTime 0.171 (0.167)\tLoss 0.1427 (0.2255)\tPrec@1 95.312 (92.131)\n",
            "Epoch: [43][230/782]\tTime 0.165 (0.167)\tLoss 0.1719 (0.2266)\tPrec@1 96.875 (92.120)\n",
            "Epoch: [43][240/782]\tTime 0.165 (0.167)\tLoss 0.1110 (0.2255)\tPrec@1 98.438 (92.194)\n",
            "Epoch: [43][250/782]\tTime 0.165 (0.167)\tLoss 0.2648 (0.2249)\tPrec@1 89.062 (92.181)\n",
            "Epoch: [43][260/782]\tTime 0.166 (0.167)\tLoss 0.1776 (0.2243)\tPrec@1 93.750 (92.217)\n",
            "Epoch: [43][270/782]\tTime 0.166 (0.167)\tLoss 0.2717 (0.2243)\tPrec@1 90.625 (92.245)\n",
            "Epoch: [43][280/782]\tTime 0.165 (0.167)\tLoss 0.2151 (0.2241)\tPrec@1 93.750 (92.238)\n",
            "Epoch: [43][290/782]\tTime 0.166 (0.167)\tLoss 0.2099 (0.2243)\tPrec@1 89.062 (92.225)\n",
            "Epoch: [43][300/782]\tTime 0.166 (0.167)\tLoss 0.2211 (0.2238)\tPrec@1 92.188 (92.255)\n",
            "Epoch: [43][310/782]\tTime 0.165 (0.167)\tLoss 0.2537 (0.2244)\tPrec@1 85.938 (92.228)\n",
            "Epoch: [43][320/782]\tTime 0.165 (0.167)\tLoss 0.2550 (0.2242)\tPrec@1 90.625 (92.231)\n",
            "Epoch: [43][330/782]\tTime 0.165 (0.167)\tLoss 0.2830 (0.2247)\tPrec@1 92.188 (92.211)\n",
            "Epoch: [43][340/782]\tTime 0.166 (0.167)\tLoss 0.2084 (0.2253)\tPrec@1 90.625 (92.206)\n",
            "Epoch: [43][350/782]\tTime 0.164 (0.167)\tLoss 0.1910 (0.2249)\tPrec@1 89.062 (92.201)\n",
            "Epoch: [43][360/782]\tTime 0.166 (0.167)\tLoss 0.3961 (0.2261)\tPrec@1 84.375 (92.153)\n",
            "Epoch: [43][370/782]\tTime 0.164 (0.167)\tLoss 0.2667 (0.2261)\tPrec@1 93.750 (92.158)\n",
            "Epoch: [43][380/782]\tTime 0.165 (0.167)\tLoss 0.2903 (0.2265)\tPrec@1 90.625 (92.134)\n",
            "Epoch: [43][390/782]\tTime 0.166 (0.167)\tLoss 0.2137 (0.2267)\tPrec@1 95.312 (92.148)\n",
            "Epoch: [43][400/782]\tTime 0.167 (0.167)\tLoss 0.3089 (0.2266)\tPrec@1 89.062 (92.156)\n",
            "Epoch: [43][410/782]\tTime 0.167 (0.167)\tLoss 0.3041 (0.2275)\tPrec@1 85.938 (92.130)\n",
            "Epoch: [43][420/782]\tTime 0.166 (0.167)\tLoss 0.2458 (0.2271)\tPrec@1 93.750 (92.154)\n",
            "Epoch: [43][430/782]\tTime 0.166 (0.167)\tLoss 0.3744 (0.2282)\tPrec@1 89.062 (92.129)\n",
            "Epoch: [43][440/782]\tTime 0.165 (0.167)\tLoss 0.2004 (0.2294)\tPrec@1 93.750 (92.102)\n",
            "Epoch: [43][450/782]\tTime 0.166 (0.167)\tLoss 0.1800 (0.2288)\tPrec@1 93.750 (92.139)\n",
            "Epoch: [43][460/782]\tTime 0.166 (0.167)\tLoss 0.3024 (0.2294)\tPrec@1 93.750 (92.116)\n",
            "Epoch: [43][470/782]\tTime 0.171 (0.167)\tLoss 0.2249 (0.2287)\tPrec@1 92.188 (92.141)\n",
            "Epoch: [43][480/782]\tTime 0.166 (0.167)\tLoss 0.2502 (0.2289)\tPrec@1 90.625 (92.136)\n",
            "Epoch: [43][490/782]\tTime 0.163 (0.167)\tLoss 0.3156 (0.2298)\tPrec@1 89.062 (92.117)\n",
            "Epoch: [43][500/782]\tTime 0.167 (0.167)\tLoss 0.2556 (0.2301)\tPrec@1 92.188 (92.094)\n",
            "Epoch: [43][510/782]\tTime 0.166 (0.167)\tLoss 0.2842 (0.2303)\tPrec@1 90.625 (92.126)\n",
            "Epoch: [43][520/782]\tTime 0.166 (0.167)\tLoss 0.3745 (0.2304)\tPrec@1 85.938 (92.107)\n",
            "Epoch: [43][530/782]\tTime 0.168 (0.167)\tLoss 0.3507 (0.2302)\tPrec@1 87.500 (92.126)\n",
            "Epoch: [43][540/782]\tTime 0.165 (0.167)\tLoss 0.1746 (0.2296)\tPrec@1 93.750 (92.138)\n",
            "Epoch: [43][550/782]\tTime 0.165 (0.167)\tLoss 0.1869 (0.2293)\tPrec@1 92.188 (92.139)\n",
            "Epoch: [43][560/782]\tTime 0.165 (0.167)\tLoss 0.3965 (0.2302)\tPrec@1 92.188 (92.115)\n",
            "Epoch: [43][570/782]\tTime 0.166 (0.167)\tLoss 0.0543 (0.2294)\tPrec@1 100.000 (92.144)\n",
            "Epoch: [43][580/782]\tTime 0.165 (0.167)\tLoss 0.1504 (0.2291)\tPrec@1 92.188 (92.150)\n",
            "Epoch: [43][590/782]\tTime 0.166 (0.167)\tLoss 0.1908 (0.2284)\tPrec@1 96.875 (92.188)\n",
            "Epoch: [43][600/782]\tTime 0.164 (0.167)\tLoss 0.1910 (0.2279)\tPrec@1 93.750 (92.200)\n",
            "Epoch: [43][610/782]\tTime 0.164 (0.167)\tLoss 0.4369 (0.2281)\tPrec@1 84.375 (92.195)\n",
            "Epoch: [43][620/782]\tTime 0.164 (0.167)\tLoss 0.2726 (0.2284)\tPrec@1 92.188 (92.200)\n",
            "Epoch: [43][630/782]\tTime 0.166 (0.167)\tLoss 0.2371 (0.2289)\tPrec@1 92.188 (92.178)\n",
            "Epoch: [43][640/782]\tTime 0.168 (0.167)\tLoss 0.2474 (0.2291)\tPrec@1 89.062 (92.161)\n",
            "Epoch: [43][650/782]\tTime 0.166 (0.167)\tLoss 0.2024 (0.2290)\tPrec@1 95.312 (92.154)\n",
            "Epoch: [43][660/782]\tTime 0.165 (0.167)\tLoss 0.1833 (0.2291)\tPrec@1 90.625 (92.138)\n",
            "Epoch: [43][670/782]\tTime 0.167 (0.167)\tLoss 0.2758 (0.2296)\tPrec@1 92.188 (92.106)\n",
            "Epoch: [43][680/782]\tTime 0.165 (0.167)\tLoss 0.4513 (0.2309)\tPrec@1 87.500 (92.045)\n",
            "Epoch: [43][690/782]\tTime 0.164 (0.167)\tLoss 0.3746 (0.2319)\tPrec@1 92.188 (92.016)\n",
            "Epoch: [43][700/782]\tTime 0.165 (0.167)\tLoss 0.2176 (0.2321)\tPrec@1 92.188 (92.009)\n",
            "Epoch: [43][710/782]\tTime 0.166 (0.166)\tLoss 0.2887 (0.2322)\tPrec@1 90.625 (92.003)\n",
            "Epoch: [43][720/782]\tTime 0.171 (0.166)\tLoss 0.2155 (0.2326)\tPrec@1 93.750 (91.986)\n",
            "Epoch: [43][730/782]\tTime 0.165 (0.166)\tLoss 0.5670 (0.2334)\tPrec@1 84.375 (91.976)\n",
            "Epoch: [43][740/782]\tTime 0.165 (0.166)\tLoss 0.2856 (0.2337)\tPrec@1 89.062 (91.970)\n",
            "Epoch: [43][750/782]\tTime 0.166 (0.166)\tLoss 0.1915 (0.2342)\tPrec@1 93.750 (91.959)\n",
            "Epoch: [43][760/782]\tTime 0.164 (0.166)\tLoss 0.2978 (0.2337)\tPrec@1 85.938 (91.958)\n",
            "Epoch: [43][770/782]\tTime 0.166 (0.166)\tLoss 0.1816 (0.2335)\tPrec@1 96.875 (91.977)\n",
            "Epoch: [43][780/782]\tTime 0.163 (0.166)\tLoss 0.2681 (0.2338)\tPrec@1 87.500 (91.949)\n",
            "Training accuracy:  tensor(91.9520, device='cuda:0')\n",
            "Best accuraacy:  tensor(91.9520, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.117 (0.117)\tLoss 0.4665 (0.4665)\tPrec@1 85.938 (85.938)\n",
            "Test: [10/157]\tTime 0.043 (0.048)\tLoss 0.4410 (0.3815)\tPrec@1 85.938 (87.358)\n",
            "Test: [20/157]\tTime 0.049 (0.046)\tLoss 0.3225 (0.3489)\tPrec@1 92.188 (88.542)\n",
            "Test: [30/157]\tTime 0.043 (0.046)\tLoss 0.3011 (0.3483)\tPrec@1 87.500 (88.861)\n",
            "Test: [40/157]\tTime 0.043 (0.045)\tLoss 0.5262 (0.3655)\tPrec@1 90.625 (88.491)\n",
            "Test: [50/157]\tTime 0.044 (0.045)\tLoss 0.2818 (0.3658)\tPrec@1 89.062 (88.266)\n",
            "Test: [60/157]\tTime 0.044 (0.045)\tLoss 0.2727 (0.3689)\tPrec@1 90.625 (88.345)\n",
            "Test: [70/157]\tTime 0.043 (0.045)\tLoss 0.3549 (0.3718)\tPrec@1 89.062 (88.358)\n",
            "Test: [80/157]\tTime 0.044 (0.045)\tLoss 0.1821 (0.3780)\tPrec@1 92.188 (88.194)\n",
            "Test: [90/157]\tTime 0.041 (0.045)\tLoss 0.4329 (0.3749)\tPrec@1 84.375 (88.118)\n",
            "Test: [100/157]\tTime 0.044 (0.045)\tLoss 0.3575 (0.3732)\tPrec@1 87.500 (88.057)\n",
            "Test: [110/157]\tTime 0.045 (0.044)\tLoss 0.2458 (0.3683)\tPrec@1 90.625 (88.162)\n",
            "Test: [120/157]\tTime 0.045 (0.044)\tLoss 0.2519 (0.3664)\tPrec@1 85.938 (88.288)\n",
            "Test: [130/157]\tTime 0.044 (0.044)\tLoss 0.2289 (0.3730)\tPrec@1 92.188 (88.287)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.4240 (0.3669)\tPrec@1 85.938 (88.464)\n",
            "Test: [150/157]\tTime 0.044 (0.044)\tLoss 0.4429 (0.3710)\tPrec@1 85.938 (88.380)\n",
            " * Prec@1 88.320\n",
            "Best accuracy:  tensor(88.8800, device='cuda:0')\n",
            "Epoch: [44][0/782]\tTime 0.265 (0.265)\tLoss 0.2466 (0.2466)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [44][10/782]\tTime 0.166 (0.175)\tLoss 0.1739 (0.1935)\tPrec@1 96.875 (93.466)\n",
            "Epoch: [44][20/782]\tTime 0.166 (0.171)\tLoss 0.2527 (0.2034)\tPrec@1 90.625 (92.932)\n",
            "Epoch: [44][30/782]\tTime 0.167 (0.169)\tLoss 0.1442 (0.1990)\tPrec@1 93.750 (92.944)\n",
            "Epoch: [44][40/782]\tTime 0.166 (0.169)\tLoss 0.1919 (0.1967)\tPrec@1 95.312 (92.950)\n",
            "Epoch: [44][50/782]\tTime 0.165 (0.168)\tLoss 0.1808 (0.1971)\tPrec@1 93.750 (92.984)\n",
            "Epoch: [44][60/782]\tTime 0.169 (0.168)\tLoss 0.1200 (0.1935)\tPrec@1 95.312 (93.263)\n",
            "Epoch: [44][70/782]\tTime 0.166 (0.168)\tLoss 0.2576 (0.1987)\tPrec@1 90.625 (93.156)\n",
            "Epoch: [44][80/782]\tTime 0.167 (0.168)\tLoss 0.1809 (0.2002)\tPrec@1 93.750 (92.998)\n",
            "Epoch: [44][90/782]\tTime 0.167 (0.167)\tLoss 0.3703 (0.2073)\tPrec@1 90.625 (92.806)\n",
            "Epoch: [44][100/782]\tTime 0.168 (0.167)\tLoss 0.1907 (0.2096)\tPrec@1 90.625 (92.713)\n",
            "Epoch: [44][110/782]\tTime 0.165 (0.167)\tLoss 0.2336 (0.2101)\tPrec@1 90.625 (92.568)\n",
            "Epoch: [44][120/782]\tTime 0.166 (0.167)\tLoss 0.1864 (0.2121)\tPrec@1 93.750 (92.484)\n",
            "Epoch: [44][130/782]\tTime 0.165 (0.167)\tLoss 0.1822 (0.2153)\tPrec@1 92.188 (92.426)\n",
            "Epoch: [44][140/782]\tTime 0.165 (0.167)\tLoss 0.2372 (0.2148)\tPrec@1 92.188 (92.465)\n",
            "Epoch: [44][150/782]\tTime 0.165 (0.167)\tLoss 0.2153 (0.2138)\tPrec@1 95.312 (92.477)\n",
            "Epoch: [44][160/782]\tTime 0.165 (0.167)\tLoss 0.1692 (0.2152)\tPrec@1 92.188 (92.411)\n",
            "Epoch: [44][170/782]\tTime 0.165 (0.167)\tLoss 0.2102 (0.2152)\tPrec@1 93.750 (92.452)\n",
            "Epoch: [44][180/782]\tTime 0.165 (0.167)\tLoss 0.2153 (0.2161)\tPrec@1 90.625 (92.377)\n",
            "Epoch: [44][190/782]\tTime 0.166 (0.167)\tLoss 0.1256 (0.2149)\tPrec@1 96.875 (92.425)\n",
            "Epoch: [44][200/782]\tTime 0.168 (0.167)\tLoss 0.3411 (0.2146)\tPrec@1 84.375 (92.444)\n",
            "Epoch: [44][210/782]\tTime 0.165 (0.167)\tLoss 0.1674 (0.2148)\tPrec@1 92.188 (92.454)\n",
            "Epoch: [44][220/782]\tTime 0.167 (0.167)\tLoss 0.1475 (0.2139)\tPrec@1 95.312 (92.506)\n",
            "Epoch: [44][230/782]\tTime 0.166 (0.167)\tLoss 0.2360 (0.2140)\tPrec@1 89.062 (92.492)\n",
            "Epoch: [44][240/782]\tTime 0.167 (0.167)\tLoss 0.1300 (0.2134)\tPrec@1 96.875 (92.525)\n",
            "Epoch: [44][250/782]\tTime 0.166 (0.167)\tLoss 0.3096 (0.2142)\tPrec@1 87.500 (92.418)\n",
            "Epoch: [44][260/782]\tTime 0.173 (0.167)\tLoss 0.3641 (0.2151)\tPrec@1 92.188 (92.403)\n",
            "Epoch: [44][270/782]\tTime 0.166 (0.167)\tLoss 0.3493 (0.2166)\tPrec@1 87.500 (92.360)\n",
            "Epoch: [44][280/782]\tTime 0.166 (0.167)\tLoss 0.2185 (0.2189)\tPrec@1 89.062 (92.238)\n",
            "Epoch: [44][290/782]\tTime 0.166 (0.167)\tLoss 0.3325 (0.2204)\tPrec@1 87.500 (92.193)\n",
            "Epoch: [44][300/782]\tTime 0.166 (0.167)\tLoss 0.1138 (0.2195)\tPrec@1 98.438 (92.229)\n",
            "Epoch: [44][310/782]\tTime 0.166 (0.167)\tLoss 0.1059 (0.2186)\tPrec@1 96.875 (92.258)\n",
            "Epoch: [44][320/782]\tTime 0.165 (0.167)\tLoss 0.1622 (0.2198)\tPrec@1 95.312 (92.241)\n",
            "Epoch: [44][330/782]\tTime 0.166 (0.167)\tLoss 0.4508 (0.2199)\tPrec@1 84.375 (92.239)\n",
            "Epoch: [44][340/782]\tTime 0.169 (0.167)\tLoss 0.1516 (0.2201)\tPrec@1 96.875 (92.233)\n",
            "Epoch: [44][350/782]\tTime 0.166 (0.167)\tLoss 0.2560 (0.2206)\tPrec@1 90.625 (92.223)\n",
            "Epoch: [44][360/782]\tTime 0.164 (0.167)\tLoss 0.2847 (0.2204)\tPrec@1 93.750 (92.248)\n",
            "Epoch: [44][370/782]\tTime 0.167 (0.167)\tLoss 0.1100 (0.2206)\tPrec@1 98.438 (92.255)\n",
            "Epoch: [44][380/782]\tTime 0.169 (0.167)\tLoss 0.1734 (0.2198)\tPrec@1 93.750 (92.286)\n",
            "Epoch: [44][390/782]\tTime 0.164 (0.167)\tLoss 0.1458 (0.2206)\tPrec@1 93.750 (92.251)\n",
            "Epoch: [44][400/782]\tTime 0.166 (0.167)\tLoss 0.1052 (0.2207)\tPrec@1 98.438 (92.265)\n",
            "Epoch: [44][410/782]\tTime 0.167 (0.167)\tLoss 0.2359 (0.2210)\tPrec@1 93.750 (92.271)\n",
            "Epoch: [44][420/782]\tTime 0.166 (0.167)\tLoss 0.0624 (0.2220)\tPrec@1 100.000 (92.243)\n",
            "Epoch: [44][430/782]\tTime 0.167 (0.167)\tLoss 0.2607 (0.2226)\tPrec@1 93.750 (92.220)\n",
            "Epoch: [44][440/782]\tTime 0.167 (0.167)\tLoss 0.1322 (0.2217)\tPrec@1 92.188 (92.226)\n",
            "Epoch: [44][450/782]\tTime 0.167 (0.167)\tLoss 0.2677 (0.2220)\tPrec@1 93.750 (92.191)\n",
            "Epoch: [44][460/782]\tTime 0.165 (0.167)\tLoss 0.1120 (0.2220)\tPrec@1 95.312 (92.171)\n",
            "Epoch: [44][470/782]\tTime 0.166 (0.167)\tLoss 0.3186 (0.2226)\tPrec@1 85.938 (92.168)\n",
            "Epoch: [44][480/782]\tTime 0.168 (0.167)\tLoss 0.1959 (0.2233)\tPrec@1 93.750 (92.165)\n",
            "Epoch: [44][490/782]\tTime 0.166 (0.167)\tLoss 0.3982 (0.2243)\tPrec@1 85.938 (92.114)\n",
            "Epoch: [44][500/782]\tTime 0.163 (0.167)\tLoss 0.3127 (0.2252)\tPrec@1 90.625 (92.085)\n",
            "Epoch: [44][510/782]\tTime 0.165 (0.167)\tLoss 0.1886 (0.2257)\tPrec@1 92.188 (92.084)\n",
            "Epoch: [44][520/782]\tTime 0.166 (0.167)\tLoss 0.1617 (0.2260)\tPrec@1 92.188 (92.062)\n",
            "Epoch: [44][530/782]\tTime 0.167 (0.167)\tLoss 0.2675 (0.2276)\tPrec@1 89.062 (92.020)\n",
            "Epoch: [44][540/782]\tTime 0.167 (0.167)\tLoss 0.3535 (0.2283)\tPrec@1 89.062 (91.991)\n",
            "Epoch: [44][550/782]\tTime 0.170 (0.167)\tLoss 0.4077 (0.2287)\tPrec@1 85.938 (91.975)\n",
            "Epoch: [44][560/782]\tTime 0.168 (0.167)\tLoss 0.2395 (0.2291)\tPrec@1 92.188 (91.976)\n",
            "Epoch: [44][570/782]\tTime 0.166 (0.167)\tLoss 0.2469 (0.2302)\tPrec@1 90.625 (91.938)\n",
            "Epoch: [44][580/782]\tTime 0.166 (0.167)\tLoss 0.2565 (0.2301)\tPrec@1 93.750 (91.945)\n",
            "Epoch: [44][590/782]\tTime 0.169 (0.167)\tLoss 0.0986 (0.2301)\tPrec@1 96.875 (91.947)\n",
            "Epoch: [44][600/782]\tTime 0.164 (0.167)\tLoss 0.2233 (0.2303)\tPrec@1 92.188 (91.956)\n",
            "Epoch: [44][610/782]\tTime 0.166 (0.167)\tLoss 0.3275 (0.2307)\tPrec@1 90.625 (91.942)\n",
            "Epoch: [44][620/782]\tTime 0.165 (0.167)\tLoss 0.3583 (0.2314)\tPrec@1 85.938 (91.913)\n",
            "Epoch: [44][630/782]\tTime 0.165 (0.167)\tLoss 0.3839 (0.2316)\tPrec@1 87.500 (91.903)\n",
            "Epoch: [44][640/782]\tTime 0.166 (0.167)\tLoss 0.1713 (0.2314)\tPrec@1 92.188 (91.890)\n",
            "Epoch: [44][650/782]\tTime 0.163 (0.167)\tLoss 0.2350 (0.2313)\tPrec@1 93.750 (91.899)\n",
            "Epoch: [44][660/782]\tTime 0.164 (0.167)\tLoss 0.3076 (0.2314)\tPrec@1 87.500 (91.890)\n",
            "Epoch: [44][670/782]\tTime 0.165 (0.167)\tLoss 0.1152 (0.2314)\tPrec@1 96.875 (91.894)\n",
            "Epoch: [44][680/782]\tTime 0.167 (0.167)\tLoss 0.4347 (0.2319)\tPrec@1 84.375 (91.875)\n",
            "Epoch: [44][690/782]\tTime 0.166 (0.167)\tLoss 0.1529 (0.2320)\tPrec@1 96.875 (91.862)\n",
            "Epoch: [44][700/782]\tTime 0.165 (0.167)\tLoss 0.2230 (0.2322)\tPrec@1 89.062 (91.855)\n",
            "Epoch: [44][710/782]\tTime 0.165 (0.167)\tLoss 0.2612 (0.2318)\tPrec@1 90.625 (91.869)\n",
            "Epoch: [44][720/782]\tTime 0.166 (0.167)\tLoss 0.2177 (0.2319)\tPrec@1 92.188 (91.860)\n",
            "Epoch: [44][730/782]\tTime 0.164 (0.167)\tLoss 0.1884 (0.2319)\tPrec@1 95.312 (91.865)\n",
            "Epoch: [44][740/782]\tTime 0.167 (0.167)\tLoss 0.1662 (0.2320)\tPrec@1 95.312 (91.865)\n",
            "Epoch: [44][750/782]\tTime 0.165 (0.167)\tLoss 0.2060 (0.2314)\tPrec@1 95.312 (91.886)\n",
            "Epoch: [44][760/782]\tTime 0.166 (0.167)\tLoss 0.1957 (0.2314)\tPrec@1 92.188 (91.886)\n",
            "Epoch: [44][770/782]\tTime 0.165 (0.167)\tLoss 0.3296 (0.2317)\tPrec@1 89.062 (91.884)\n",
            "Epoch: [44][780/782]\tTime 0.163 (0.167)\tLoss 0.1608 (0.2316)\tPrec@1 96.875 (91.887)\n",
            "Training accuracy:  tensor(91.8900, device='cuda:0')\n",
            "Best accuraacy:  tensor(91.9520, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.113 (0.113)\tLoss 0.3866 (0.3866)\tPrec@1 81.250 (81.250)\n",
            "Test: [10/157]\tTime 0.047 (0.048)\tLoss 0.2885 (0.3287)\tPrec@1 92.188 (89.347)\n",
            "Test: [20/157]\tTime 0.049 (0.046)\tLoss 0.2776 (0.3316)\tPrec@1 95.312 (90.402)\n",
            "Test: [30/157]\tTime 0.042 (0.046)\tLoss 0.2446 (0.3137)\tPrec@1 92.188 (90.625)\n",
            "Test: [40/157]\tTime 0.041 (0.045)\tLoss 0.3822 (0.3272)\tPrec@1 82.812 (89.825)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.3781 (0.3299)\tPrec@1 89.062 (89.614)\n",
            "Test: [60/157]\tTime 0.042 (0.045)\tLoss 0.4098 (0.3377)\tPrec@1 89.062 (89.242)\n",
            "Test: [70/157]\tTime 0.045 (0.045)\tLoss 0.2574 (0.3384)\tPrec@1 95.312 (89.283)\n",
            "Test: [80/157]\tTime 0.044 (0.045)\tLoss 0.3779 (0.3442)\tPrec@1 89.062 (89.120)\n",
            "Test: [90/157]\tTime 0.044 (0.044)\tLoss 0.2726 (0.3463)\tPrec@1 90.625 (89.183)\n",
            "Test: [100/157]\tTime 0.044 (0.044)\tLoss 0.2510 (0.3402)\tPrec@1 89.062 (89.341)\n",
            "Test: [110/157]\tTime 0.044 (0.044)\tLoss 0.4484 (0.3402)\tPrec@1 87.500 (89.414)\n",
            "Test: [120/157]\tTime 0.043 (0.044)\tLoss 0.2873 (0.3438)\tPrec@1 89.062 (89.192)\n",
            "Test: [130/157]\tTime 0.046 (0.044)\tLoss 0.2319 (0.3457)\tPrec@1 89.062 (89.146)\n",
            "Test: [140/157]\tTime 0.047 (0.044)\tLoss 0.2555 (0.3420)\tPrec@1 90.625 (89.195)\n",
            "Test: [150/157]\tTime 0.041 (0.044)\tLoss 0.4489 (0.3478)\tPrec@1 84.375 (88.969)\n",
            " * Prec@1 88.870\n",
            "Best accuracy:  tensor(88.8800, device='cuda:0')\n",
            "Epoch: [45][0/782]\tTime 0.269 (0.269)\tLoss 0.2354 (0.2354)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [45][10/782]\tTime 0.165 (0.176)\tLoss 0.1724 (0.2264)\tPrec@1 90.625 (91.335)\n",
            "Epoch: [45][20/782]\tTime 0.167 (0.171)\tLoss 0.0989 (0.2113)\tPrec@1 95.312 (92.262)\n",
            "Epoch: [45][30/782]\tTime 0.165 (0.170)\tLoss 0.1812 (0.2268)\tPrec@1 92.188 (92.238)\n",
            "Epoch: [45][40/782]\tTime 0.167 (0.169)\tLoss 0.1533 (0.2265)\tPrec@1 95.312 (92.111)\n",
            "Epoch: [45][50/782]\tTime 0.165 (0.168)\tLoss 0.1213 (0.2274)\tPrec@1 96.875 (91.912)\n",
            "Epoch: [45][60/782]\tTime 0.165 (0.168)\tLoss 0.0689 (0.2219)\tPrec@1 100.000 (92.162)\n",
            "Epoch: [45][70/782]\tTime 0.164 (0.167)\tLoss 0.1949 (0.2178)\tPrec@1 92.188 (92.210)\n",
            "Epoch: [45][80/782]\tTime 0.166 (0.167)\tLoss 0.3121 (0.2160)\tPrec@1 92.188 (92.323)\n",
            "Epoch: [45][90/782]\tTime 0.165 (0.167)\tLoss 0.1420 (0.2187)\tPrec@1 95.312 (92.205)\n",
            "Epoch: [45][100/782]\tTime 0.167 (0.167)\tLoss 0.2041 (0.2174)\tPrec@1 93.750 (92.188)\n",
            "Epoch: [45][110/782]\tTime 0.164 (0.167)\tLoss 0.1496 (0.2191)\tPrec@1 95.312 (92.173)\n",
            "Epoch: [45][120/782]\tTime 0.166 (0.167)\tLoss 0.2082 (0.2189)\tPrec@1 92.188 (92.175)\n",
            "Epoch: [45][130/782]\tTime 0.167 (0.167)\tLoss 0.1477 (0.2184)\tPrec@1 96.875 (92.223)\n",
            "Epoch: [45][140/782]\tTime 0.163 (0.167)\tLoss 0.3726 (0.2212)\tPrec@1 90.625 (92.210)\n",
            "Epoch: [45][150/782]\tTime 0.168 (0.167)\tLoss 0.3206 (0.2229)\tPrec@1 90.625 (92.188)\n",
            "Epoch: [45][160/782]\tTime 0.166 (0.167)\tLoss 0.3523 (0.2230)\tPrec@1 90.625 (92.168)\n",
            "Epoch: [45][170/782]\tTime 0.166 (0.167)\tLoss 0.1962 (0.2246)\tPrec@1 93.750 (92.114)\n",
            "Epoch: [45][180/782]\tTime 0.165 (0.167)\tLoss 0.1847 (0.2257)\tPrec@1 95.312 (92.093)\n",
            "Epoch: [45][190/782]\tTime 0.164 (0.167)\tLoss 0.1481 (0.2245)\tPrec@1 93.750 (92.114)\n",
            "Epoch: [45][200/782]\tTime 0.163 (0.167)\tLoss 0.2731 (0.2245)\tPrec@1 89.062 (92.094)\n",
            "Epoch: [45][210/782]\tTime 0.166 (0.167)\tLoss 0.1760 (0.2240)\tPrec@1 93.750 (92.099)\n",
            "Epoch: [45][220/782]\tTime 0.165 (0.167)\tLoss 0.1456 (0.2239)\tPrec@1 93.750 (92.060)\n",
            "Epoch: [45][230/782]\tTime 0.165 (0.167)\tLoss 0.2262 (0.2229)\tPrec@1 92.188 (92.113)\n",
            "Epoch: [45][240/782]\tTime 0.165 (0.167)\tLoss 0.1761 (0.2225)\tPrec@1 93.750 (92.142)\n",
            "Epoch: [45][250/782]\tTime 0.167 (0.167)\tLoss 0.3116 (0.2243)\tPrec@1 87.500 (92.075)\n",
            "Epoch: [45][260/782]\tTime 0.167 (0.166)\tLoss 0.1069 (0.2232)\tPrec@1 96.875 (92.116)\n",
            "Epoch: [45][270/782]\tTime 0.165 (0.167)\tLoss 0.1292 (0.2224)\tPrec@1 95.312 (92.170)\n",
            "Epoch: [45][280/782]\tTime 0.167 (0.167)\tLoss 0.3757 (0.2216)\tPrec@1 89.062 (92.210)\n",
            "Epoch: [45][290/782]\tTime 0.166 (0.167)\tLoss 0.2504 (0.2212)\tPrec@1 93.750 (92.268)\n",
            "Epoch: [45][300/782]\tTime 0.165 (0.167)\tLoss 0.2841 (0.2223)\tPrec@1 89.062 (92.281)\n",
            "Epoch: [45][310/782]\tTime 0.167 (0.167)\tLoss 0.1538 (0.2209)\tPrec@1 96.875 (92.338)\n",
            "Epoch: [45][320/782]\tTime 0.168 (0.166)\tLoss 0.2660 (0.2229)\tPrec@1 92.188 (92.295)\n",
            "Epoch: [45][330/782]\tTime 0.166 (0.166)\tLoss 0.0981 (0.2228)\tPrec@1 98.438 (92.301)\n",
            "Epoch: [45][340/782]\tTime 0.166 (0.166)\tLoss 0.1170 (0.2231)\tPrec@1 95.312 (92.284)\n",
            "Epoch: [45][350/782]\tTime 0.165 (0.166)\tLoss 0.2371 (0.2234)\tPrec@1 90.625 (92.281)\n",
            "Epoch: [45][360/782]\tTime 0.165 (0.166)\tLoss 0.1828 (0.2236)\tPrec@1 93.750 (92.300)\n",
            "Epoch: [45][370/782]\tTime 0.166 (0.166)\tLoss 0.2535 (0.2240)\tPrec@1 90.625 (92.301)\n",
            "Epoch: [45][380/782]\tTime 0.166 (0.166)\tLoss 0.1787 (0.2248)\tPrec@1 96.875 (92.286)\n",
            "Epoch: [45][390/782]\tTime 0.165 (0.166)\tLoss 0.2502 (0.2254)\tPrec@1 92.188 (92.251)\n",
            "Epoch: [45][400/782]\tTime 0.165 (0.166)\tLoss 0.3292 (0.2264)\tPrec@1 90.625 (92.242)\n",
            "Epoch: [45][410/782]\tTime 0.166 (0.166)\tLoss 0.2871 (0.2281)\tPrec@1 90.625 (92.180)\n",
            "Epoch: [45][420/782]\tTime 0.166 (0.166)\tLoss 0.1161 (0.2277)\tPrec@1 96.875 (92.195)\n",
            "Epoch: [45][430/782]\tTime 0.169 (0.166)\tLoss 0.3283 (0.2278)\tPrec@1 87.500 (92.195)\n",
            "Epoch: [45][440/782]\tTime 0.165 (0.166)\tLoss 0.2416 (0.2276)\tPrec@1 92.188 (92.195)\n",
            "Epoch: [45][450/782]\tTime 0.166 (0.166)\tLoss 0.2291 (0.2283)\tPrec@1 92.188 (92.167)\n",
            "Epoch: [45][460/782]\tTime 0.166 (0.166)\tLoss 0.3029 (0.2295)\tPrec@1 93.750 (92.143)\n",
            "Epoch: [45][470/782]\tTime 0.165 (0.166)\tLoss 0.3156 (0.2291)\tPrec@1 84.375 (92.138)\n",
            "Epoch: [45][480/782]\tTime 0.163 (0.166)\tLoss 0.1774 (0.2290)\tPrec@1 90.625 (92.119)\n",
            "Epoch: [45][490/782]\tTime 0.166 (0.166)\tLoss 0.3401 (0.2296)\tPrec@1 85.938 (92.114)\n",
            "Epoch: [45][500/782]\tTime 0.164 (0.166)\tLoss 0.1635 (0.2303)\tPrec@1 93.750 (92.078)\n",
            "Epoch: [45][510/782]\tTime 0.169 (0.166)\tLoss 0.1911 (0.2297)\tPrec@1 93.750 (92.099)\n",
            "Epoch: [45][520/782]\tTime 0.166 (0.166)\tLoss 0.2051 (0.2292)\tPrec@1 92.188 (92.116)\n",
            "Epoch: [45][530/782]\tTime 0.165 (0.166)\tLoss 0.1703 (0.2293)\tPrec@1 93.750 (92.117)\n",
            "Epoch: [45][540/782]\tTime 0.164 (0.166)\tLoss 0.1621 (0.2282)\tPrec@1 92.188 (92.167)\n",
            "Epoch: [45][550/782]\tTime 0.165 (0.166)\tLoss 0.0684 (0.2270)\tPrec@1 98.438 (92.222)\n",
            "Epoch: [45][560/782]\tTime 0.163 (0.166)\tLoss 0.1963 (0.2270)\tPrec@1 90.625 (92.226)\n",
            "Epoch: [45][570/782]\tTime 0.167 (0.166)\tLoss 0.1211 (0.2278)\tPrec@1 96.875 (92.196)\n",
            "Epoch: [45][580/782]\tTime 0.167 (0.166)\tLoss 0.3053 (0.2274)\tPrec@1 89.062 (92.198)\n",
            "Epoch: [45][590/782]\tTime 0.165 (0.166)\tLoss 0.1346 (0.2271)\tPrec@1 93.750 (92.193)\n",
            "Epoch: [45][600/782]\tTime 0.165 (0.166)\tLoss 0.4272 (0.2273)\tPrec@1 87.500 (92.188)\n",
            "Epoch: [45][610/782]\tTime 0.164 (0.166)\tLoss 0.2457 (0.2279)\tPrec@1 93.750 (92.172)\n",
            "Epoch: [45][620/782]\tTime 0.166 (0.166)\tLoss 0.1018 (0.2279)\tPrec@1 98.438 (92.180)\n",
            "Epoch: [45][630/782]\tTime 0.167 (0.166)\tLoss 0.1948 (0.2272)\tPrec@1 93.750 (92.183)\n",
            "Epoch: [45][640/782]\tTime 0.163 (0.166)\tLoss 0.2387 (0.2270)\tPrec@1 90.625 (92.170)\n",
            "Epoch: [45][650/782]\tTime 0.163 (0.166)\tLoss 0.1682 (0.2281)\tPrec@1 95.312 (92.137)\n",
            "Epoch: [45][660/782]\tTime 0.166 (0.166)\tLoss 0.2300 (0.2285)\tPrec@1 90.625 (92.100)\n",
            "Epoch: [45][670/782]\tTime 0.166 (0.166)\tLoss 0.3174 (0.2292)\tPrec@1 89.062 (92.106)\n",
            "Epoch: [45][680/782]\tTime 0.166 (0.166)\tLoss 0.1662 (0.2288)\tPrec@1 95.312 (92.128)\n",
            "Epoch: [45][690/782]\tTime 0.165 (0.166)\tLoss 0.2363 (0.2295)\tPrec@1 95.312 (92.097)\n",
            "Epoch: [45][700/782]\tTime 0.169 (0.166)\tLoss 0.2845 (0.2301)\tPrec@1 92.188 (92.074)\n",
            "Epoch: [45][710/782]\tTime 0.165 (0.166)\tLoss 0.1785 (0.2308)\tPrec@1 90.625 (92.049)\n",
            "Epoch: [45][720/782]\tTime 0.166 (0.166)\tLoss 0.2580 (0.2312)\tPrec@1 89.062 (92.036)\n",
            "Epoch: [45][730/782]\tTime 0.164 (0.166)\tLoss 0.2243 (0.2309)\tPrec@1 95.312 (92.046)\n",
            "Epoch: [45][740/782]\tTime 0.163 (0.166)\tLoss 0.1663 (0.2306)\tPrec@1 96.875 (92.072)\n",
            "Epoch: [45][750/782]\tTime 0.167 (0.166)\tLoss 0.2080 (0.2307)\tPrec@1 93.750 (92.071)\n",
            "Epoch: [45][760/782]\tTime 0.163 (0.166)\tLoss 0.1152 (0.2302)\tPrec@1 95.312 (92.085)\n",
            "Epoch: [45][770/782]\tTime 0.165 (0.166)\tLoss 0.1357 (0.2304)\tPrec@1 95.312 (92.082)\n",
            "Epoch: [45][780/782]\tTime 0.161 (0.166)\tLoss 0.1572 (0.2296)\tPrec@1 93.750 (92.105)\n",
            "Training accuracy:  tensor(92.1060, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.1060, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.118 (0.118)\tLoss 0.6258 (0.6258)\tPrec@1 89.062 (89.062)\n",
            "Test: [10/157]\tTime 0.040 (0.048)\tLoss 0.4788 (0.4366)\tPrec@1 87.500 (88.210)\n",
            "Test: [20/157]\tTime 0.050 (0.046)\tLoss 0.3087 (0.4146)\tPrec@1 92.188 (87.872)\n",
            "Test: [30/157]\tTime 0.043 (0.046)\tLoss 0.4318 (0.4068)\tPrec@1 87.500 (87.954)\n",
            "Test: [40/157]\tTime 0.043 (0.045)\tLoss 0.4004 (0.3991)\tPrec@1 87.500 (88.072)\n",
            "Test: [50/157]\tTime 0.044 (0.045)\tLoss 0.4141 (0.3998)\tPrec@1 85.938 (88.082)\n",
            "Test: [60/157]\tTime 0.039 (0.045)\tLoss 0.3552 (0.3913)\tPrec@1 87.500 (88.166)\n",
            "Test: [70/157]\tTime 0.043 (0.045)\tLoss 0.4704 (0.3817)\tPrec@1 81.250 (88.490)\n",
            "Test: [80/157]\tTime 0.044 (0.045)\tLoss 0.5140 (0.3832)\tPrec@1 85.938 (88.484)\n",
            "Test: [90/157]\tTime 0.045 (0.044)\tLoss 0.3309 (0.3867)\tPrec@1 87.500 (88.290)\n",
            "Test: [100/157]\tTime 0.044 (0.044)\tLoss 0.4090 (0.3836)\tPrec@1 87.500 (88.320)\n",
            "Test: [110/157]\tTime 0.044 (0.044)\tLoss 0.3780 (0.3775)\tPrec@1 85.938 (88.401)\n",
            "Test: [120/157]\tTime 0.044 (0.044)\tLoss 0.2409 (0.3721)\tPrec@1 92.188 (88.481)\n",
            "Test: [130/157]\tTime 0.039 (0.044)\tLoss 0.3995 (0.3698)\tPrec@1 87.500 (88.454)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.5811 (0.3756)\tPrec@1 85.938 (88.309)\n",
            "Test: [150/157]\tTime 0.042 (0.044)\tLoss 0.3960 (0.3764)\tPrec@1 90.625 (88.400)\n",
            " * Prec@1 88.370\n",
            "Best accuracy:  tensor(88.8800, device='cuda:0')\n",
            "Epoch: [46][0/782]\tTime 0.263 (0.263)\tLoss 0.2784 (0.2784)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [46][10/782]\tTime 0.167 (0.175)\tLoss 0.0988 (0.2107)\tPrec@1 98.438 (92.898)\n",
            "Epoch: [46][20/782]\tTime 0.167 (0.171)\tLoss 0.1152 (0.2027)\tPrec@1 96.875 (92.783)\n",
            "Epoch: [46][30/782]\tTime 0.167 (0.170)\tLoss 0.2294 (0.2166)\tPrec@1 92.188 (92.339)\n",
            "Epoch: [46][40/782]\tTime 0.167 (0.169)\tLoss 0.1159 (0.2058)\tPrec@1 95.312 (92.721)\n",
            "Epoch: [46][50/782]\tTime 0.166 (0.168)\tLoss 0.3802 (0.2107)\tPrec@1 85.938 (92.708)\n",
            "Epoch: [46][60/782]\tTime 0.166 (0.168)\tLoss 0.1871 (0.2151)\tPrec@1 95.312 (92.649)\n",
            "Epoch: [46][70/782]\tTime 0.165 (0.167)\tLoss 0.1562 (0.2125)\tPrec@1 96.875 (92.694)\n",
            "Epoch: [46][80/782]\tTime 0.166 (0.167)\tLoss 0.1343 (0.2034)\tPrec@1 95.312 (92.978)\n",
            "Epoch: [46][90/782]\tTime 0.165 (0.167)\tLoss 0.1410 (0.2059)\tPrec@1 95.312 (92.874)\n",
            "Epoch: [46][100/782]\tTime 0.166 (0.167)\tLoss 0.1797 (0.2084)\tPrec@1 90.625 (92.729)\n",
            "Epoch: [46][110/782]\tTime 0.166 (0.167)\tLoss 0.1922 (0.2116)\tPrec@1 92.188 (92.652)\n",
            "Epoch: [46][120/782]\tTime 0.168 (0.167)\tLoss 0.1577 (0.2121)\tPrec@1 93.750 (92.575)\n",
            "Epoch: [46][130/782]\tTime 0.167 (0.167)\tLoss 0.2257 (0.2167)\tPrec@1 90.625 (92.510)\n",
            "Epoch: [46][140/782]\tTime 0.164 (0.167)\tLoss 0.2447 (0.2201)\tPrec@1 90.625 (92.309)\n",
            "Epoch: [46][150/782]\tTime 0.164 (0.167)\tLoss 0.3136 (0.2195)\tPrec@1 90.625 (92.343)\n",
            "Epoch: [46][160/782]\tTime 0.165 (0.166)\tLoss 0.2049 (0.2194)\tPrec@1 92.188 (92.323)\n",
            "Epoch: [46][170/782]\tTime 0.164 (0.166)\tLoss 0.3662 (0.2238)\tPrec@1 85.938 (92.197)\n",
            "Epoch: [46][180/782]\tTime 0.164 (0.166)\tLoss 0.3405 (0.2246)\tPrec@1 92.188 (92.179)\n",
            "Epoch: [46][190/782]\tTime 0.163 (0.166)\tLoss 0.1737 (0.2249)\tPrec@1 93.750 (92.171)\n",
            "Epoch: [46][200/782]\tTime 0.167 (0.166)\tLoss 0.2614 (0.2252)\tPrec@1 90.625 (92.149)\n",
            "Epoch: [46][210/782]\tTime 0.163 (0.166)\tLoss 0.2641 (0.2243)\tPrec@1 89.062 (92.143)\n",
            "Epoch: [46][220/782]\tTime 0.166 (0.166)\tLoss 0.4228 (0.2244)\tPrec@1 87.500 (92.166)\n",
            "Epoch: [46][230/782]\tTime 0.169 (0.166)\tLoss 0.1694 (0.2252)\tPrec@1 95.312 (92.100)\n",
            "Epoch: [46][240/782]\tTime 0.164 (0.166)\tLoss 0.2171 (0.2271)\tPrec@1 90.625 (92.006)\n",
            "Epoch: [46][250/782]\tTime 0.165 (0.166)\tLoss 0.1493 (0.2274)\tPrec@1 93.750 (92.013)\n",
            "Epoch: [46][260/782]\tTime 0.165 (0.166)\tLoss 0.1828 (0.2264)\tPrec@1 93.750 (92.080)\n",
            "Epoch: [46][270/782]\tTime 0.167 (0.166)\tLoss 0.0723 (0.2259)\tPrec@1 98.438 (92.107)\n",
            "Epoch: [46][280/782]\tTime 0.163 (0.166)\tLoss 0.1437 (0.2256)\tPrec@1 96.875 (92.121)\n",
            "Epoch: [46][290/782]\tTime 0.166 (0.166)\tLoss 0.0600 (0.2248)\tPrec@1 98.438 (92.161)\n",
            "Epoch: [46][300/782]\tTime 0.166 (0.166)\tLoss 0.2811 (0.2244)\tPrec@1 90.625 (92.172)\n",
            "Epoch: [46][310/782]\tTime 0.164 (0.166)\tLoss 0.2612 (0.2246)\tPrec@1 89.062 (92.152)\n",
            "Epoch: [46][320/782]\tTime 0.164 (0.166)\tLoss 0.2420 (0.2243)\tPrec@1 93.750 (92.149)\n",
            "Epoch: [46][330/782]\tTime 0.164 (0.166)\tLoss 0.2303 (0.2246)\tPrec@1 89.062 (92.107)\n",
            "Epoch: [46][340/782]\tTime 0.165 (0.166)\tLoss 0.5466 (0.2245)\tPrec@1 81.250 (92.110)\n",
            "Epoch: [46][350/782]\tTime 0.163 (0.166)\tLoss 0.2113 (0.2247)\tPrec@1 93.750 (92.094)\n",
            "Epoch: [46][360/782]\tTime 0.166 (0.166)\tLoss 0.2054 (0.2249)\tPrec@1 95.312 (92.084)\n",
            "Epoch: [46][370/782]\tTime 0.164 (0.166)\tLoss 0.1342 (0.2251)\tPrec@1 95.312 (92.070)\n",
            "Epoch: [46][380/782]\tTime 0.166 (0.166)\tLoss 0.1891 (0.2248)\tPrec@1 93.750 (92.064)\n",
            "Epoch: [46][390/782]\tTime 0.165 (0.166)\tLoss 0.3141 (0.2251)\tPrec@1 89.062 (92.044)\n",
            "Epoch: [46][400/782]\tTime 0.166 (0.166)\tLoss 0.1951 (0.2247)\tPrec@1 90.625 (92.020)\n",
            "Epoch: [46][410/782]\tTime 0.164 (0.166)\tLoss 0.1916 (0.2245)\tPrec@1 93.750 (92.058)\n",
            "Epoch: [46][420/782]\tTime 0.167 (0.166)\tLoss 0.3942 (0.2250)\tPrec@1 90.625 (92.050)\n",
            "Epoch: [46][430/782]\tTime 0.164 (0.166)\tLoss 0.2918 (0.2249)\tPrec@1 90.625 (92.064)\n",
            "Epoch: [46][440/782]\tTime 0.167 (0.166)\tLoss 0.2492 (0.2251)\tPrec@1 90.625 (92.071)\n",
            "Epoch: [46][450/782]\tTime 0.166 (0.166)\tLoss 0.3646 (0.2270)\tPrec@1 92.188 (92.018)\n",
            "Epoch: [46][460/782]\tTime 0.165 (0.166)\tLoss 0.2204 (0.2269)\tPrec@1 92.188 (92.018)\n",
            "Epoch: [46][470/782]\tTime 0.166 (0.166)\tLoss 0.3504 (0.2280)\tPrec@1 87.500 (91.959)\n",
            "Epoch: [46][480/782]\tTime 0.165 (0.166)\tLoss 0.3383 (0.2285)\tPrec@1 89.062 (91.957)\n",
            "Epoch: [46][490/782]\tTime 0.167 (0.166)\tLoss 0.2503 (0.2279)\tPrec@1 95.312 (91.990)\n",
            "Epoch: [46][500/782]\tTime 0.166 (0.166)\tLoss 0.2937 (0.2282)\tPrec@1 87.500 (91.985)\n",
            "Epoch: [46][510/782]\tTime 0.166 (0.166)\tLoss 0.1909 (0.2287)\tPrec@1 96.875 (91.967)\n",
            "Epoch: [46][520/782]\tTime 0.164 (0.166)\tLoss 0.1799 (0.2277)\tPrec@1 92.188 (91.996)\n",
            "Epoch: [46][530/782]\tTime 0.164 (0.166)\tLoss 0.2223 (0.2280)\tPrec@1 92.188 (91.990)\n",
            "Epoch: [46][540/782]\tTime 0.165 (0.166)\tLoss 0.2129 (0.2279)\tPrec@1 93.750 (92.008)\n",
            "Epoch: [46][550/782]\tTime 0.166 (0.166)\tLoss 0.2507 (0.2280)\tPrec@1 95.312 (92.012)\n",
            "Epoch: [46][560/782]\tTime 0.168 (0.166)\tLoss 0.1174 (0.2272)\tPrec@1 95.312 (92.032)\n",
            "Epoch: [46][570/782]\tTime 0.167 (0.166)\tLoss 0.1955 (0.2272)\tPrec@1 96.875 (92.034)\n",
            "Epoch: [46][580/782]\tTime 0.164 (0.166)\tLoss 0.3173 (0.2273)\tPrec@1 87.500 (92.029)\n",
            "Epoch: [46][590/782]\tTime 0.164 (0.166)\tLoss 0.2190 (0.2277)\tPrec@1 90.625 (92.021)\n",
            "Epoch: [46][600/782]\tTime 0.165 (0.166)\tLoss 0.2637 (0.2285)\tPrec@1 90.625 (92.000)\n",
            "Epoch: [46][610/782]\tTime 0.165 (0.166)\tLoss 0.1614 (0.2282)\tPrec@1 92.188 (91.998)\n",
            "Epoch: [46][620/782]\tTime 0.164 (0.166)\tLoss 0.2995 (0.2282)\tPrec@1 89.062 (91.999)\n",
            "Epoch: [46][630/782]\tTime 0.165 (0.166)\tLoss 0.2894 (0.2283)\tPrec@1 85.938 (91.992)\n",
            "Epoch: [46][640/782]\tTime 0.165 (0.166)\tLoss 0.2159 (0.2293)\tPrec@1 95.312 (91.966)\n",
            "Epoch: [46][650/782]\tTime 0.164 (0.166)\tLoss 0.1822 (0.2295)\tPrec@1 95.312 (91.959)\n",
            "Epoch: [46][660/782]\tTime 0.168 (0.166)\tLoss 0.2707 (0.2294)\tPrec@1 95.312 (91.972)\n",
            "Epoch: [46][670/782]\tTime 0.169 (0.166)\tLoss 0.2008 (0.2299)\tPrec@1 92.188 (91.943)\n",
            "Epoch: [46][680/782]\tTime 0.165 (0.166)\tLoss 0.2050 (0.2303)\tPrec@1 92.188 (91.937)\n",
            "Epoch: [46][690/782]\tTime 0.166 (0.166)\tLoss 0.0907 (0.2299)\tPrec@1 96.875 (91.957)\n",
            "Epoch: [46][700/782]\tTime 0.168 (0.166)\tLoss 0.1884 (0.2297)\tPrec@1 90.625 (91.958)\n",
            "Epoch: [46][710/782]\tTime 0.165 (0.166)\tLoss 0.2650 (0.2304)\tPrec@1 89.062 (91.937)\n",
            "Epoch: [46][720/782]\tTime 0.166 (0.166)\tLoss 0.3059 (0.2304)\tPrec@1 90.625 (91.932)\n",
            "Epoch: [46][730/782]\tTime 0.164 (0.166)\tLoss 0.3196 (0.2308)\tPrec@1 85.938 (91.922)\n",
            "Epoch: [46][740/782]\tTime 0.163 (0.166)\tLoss 0.2242 (0.2313)\tPrec@1 92.188 (91.922)\n",
            "Epoch: [46][750/782]\tTime 0.167 (0.166)\tLoss 0.2718 (0.2315)\tPrec@1 92.188 (91.921)\n",
            "Epoch: [46][760/782]\tTime 0.164 (0.166)\tLoss 0.2178 (0.2316)\tPrec@1 92.188 (91.906)\n",
            "Epoch: [46][770/782]\tTime 0.166 (0.166)\tLoss 0.2197 (0.2318)\tPrec@1 90.625 (91.894)\n",
            "Epoch: [46][780/782]\tTime 0.161 (0.166)\tLoss 0.3685 (0.2322)\tPrec@1 89.062 (91.863)\n",
            "Training accuracy:  tensor(91.8620, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.1060, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.114 (0.114)\tLoss 0.4499 (0.4499)\tPrec@1 81.250 (81.250)\n",
            "Test: [10/157]\tTime 0.044 (0.047)\tLoss 0.2484 (0.2791)\tPrec@1 90.625 (90.767)\n",
            "Test: [20/157]\tTime 0.053 (0.046)\tLoss 0.3369 (0.3219)\tPrec@1 89.062 (89.360)\n",
            "Test: [30/157]\tTime 0.044 (0.046)\tLoss 0.5767 (0.3318)\tPrec@1 84.375 (89.315)\n",
            "Test: [40/157]\tTime 0.039 (0.045)\tLoss 0.3053 (0.3312)\tPrec@1 92.188 (89.291)\n",
            "Test: [50/157]\tTime 0.038 (0.045)\tLoss 0.1906 (0.3501)\tPrec@1 89.062 (88.695)\n",
            "Test: [60/157]\tTime 0.043 (0.045)\tLoss 0.3295 (0.3568)\tPrec@1 92.188 (88.499)\n",
            "Test: [70/157]\tTime 0.043 (0.045)\tLoss 0.4813 (0.3642)\tPrec@1 81.250 (88.248)\n",
            "Test: [80/157]\tTime 0.044 (0.045)\tLoss 0.7701 (0.3709)\tPrec@1 79.688 (88.059)\n",
            "Test: [90/157]\tTime 0.043 (0.044)\tLoss 0.3243 (0.3729)\tPrec@1 89.062 (88.049)\n",
            "Test: [100/157]\tTime 0.044 (0.044)\tLoss 0.3161 (0.3666)\tPrec@1 85.938 (88.041)\n",
            "Test: [110/157]\tTime 0.045 (0.044)\tLoss 0.3734 (0.3624)\tPrec@1 87.500 (88.176)\n",
            "Test: [120/157]\tTime 0.045 (0.044)\tLoss 0.3147 (0.3688)\tPrec@1 90.625 (88.017)\n",
            "Test: [130/157]\tTime 0.047 (0.044)\tLoss 0.3592 (0.3699)\tPrec@1 89.062 (87.977)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.3921 (0.3697)\tPrec@1 84.375 (87.866)\n",
            "Test: [150/157]\tTime 0.043 (0.044)\tLoss 0.1816 (0.3646)\tPrec@1 93.750 (88.017)\n",
            " * Prec@1 87.870\n",
            "Best accuracy:  tensor(88.8800, device='cuda:0')\n",
            "Epoch: [47][0/782]\tTime 0.267 (0.267)\tLoss 0.2117 (0.2117)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [47][10/782]\tTime 0.169 (0.176)\tLoss 0.1815 (0.2297)\tPrec@1 92.188 (91.477)\n",
            "Epoch: [47][20/782]\tTime 0.166 (0.171)\tLoss 0.2394 (0.2206)\tPrec@1 90.625 (91.667)\n",
            "Epoch: [47][30/782]\tTime 0.167 (0.169)\tLoss 0.1716 (0.2229)\tPrec@1 93.750 (91.885)\n",
            "Epoch: [47][40/782]\tTime 0.165 (0.168)\tLoss 0.2449 (0.2376)\tPrec@1 89.062 (91.311)\n",
            "Epoch: [47][50/782]\tTime 0.164 (0.168)\tLoss 0.2479 (0.2244)\tPrec@1 92.188 (91.912)\n",
            "Epoch: [47][60/782]\tTime 0.165 (0.168)\tLoss 0.1354 (0.2182)\tPrec@1 96.875 (92.162)\n",
            "Epoch: [47][70/782]\tTime 0.166 (0.167)\tLoss 0.2698 (0.2215)\tPrec@1 90.625 (91.967)\n",
            "Epoch: [47][80/782]\tTime 0.163 (0.167)\tLoss 0.1123 (0.2197)\tPrec@1 96.875 (92.130)\n",
            "Epoch: [47][90/782]\tTime 0.166 (0.167)\tLoss 0.3013 (0.2220)\tPrec@1 92.188 (92.119)\n",
            "Epoch: [47][100/782]\tTime 0.165 (0.167)\tLoss 0.1722 (0.2215)\tPrec@1 95.312 (92.126)\n",
            "Epoch: [47][110/782]\tTime 0.166 (0.167)\tLoss 0.1374 (0.2222)\tPrec@1 95.312 (92.159)\n",
            "Epoch: [47][120/782]\tTime 0.165 (0.167)\tLoss 0.1175 (0.2229)\tPrec@1 98.438 (92.187)\n",
            "Epoch: [47][130/782]\tTime 0.164 (0.167)\tLoss 0.1462 (0.2249)\tPrec@1 95.312 (92.164)\n",
            "Epoch: [47][140/782]\tTime 0.166 (0.167)\tLoss 0.2294 (0.2253)\tPrec@1 92.188 (92.143)\n",
            "Epoch: [47][150/782]\tTime 0.169 (0.167)\tLoss 0.2464 (0.2245)\tPrec@1 93.750 (92.188)\n",
            "Epoch: [47][160/782]\tTime 0.165 (0.167)\tLoss 0.1662 (0.2224)\tPrec@1 93.750 (92.217)\n",
            "Epoch: [47][170/782]\tTime 0.169 (0.167)\tLoss 0.2409 (0.2231)\tPrec@1 87.500 (92.169)\n",
            "Epoch: [47][180/782]\tTime 0.166 (0.167)\tLoss 0.2490 (0.2243)\tPrec@1 92.188 (92.136)\n",
            "Epoch: [47][190/782]\tTime 0.164 (0.166)\tLoss 0.3525 (0.2251)\tPrec@1 87.500 (92.073)\n",
            "Epoch: [47][200/782]\tTime 0.165 (0.166)\tLoss 0.1465 (0.2251)\tPrec@1 96.875 (92.079)\n",
            "Epoch: [47][210/782]\tTime 0.165 (0.166)\tLoss 0.1562 (0.2258)\tPrec@1 95.312 (92.069)\n",
            "Epoch: [47][220/782]\tTime 0.166 (0.166)\tLoss 0.2274 (0.2258)\tPrec@1 90.625 (92.081)\n",
            "Epoch: [47][230/782]\tTime 0.165 (0.166)\tLoss 0.0913 (0.2245)\tPrec@1 96.875 (92.113)\n",
            "Epoch: [47][240/782]\tTime 0.168 (0.166)\tLoss 0.2248 (0.2265)\tPrec@1 90.625 (92.006)\n",
            "Epoch: [47][250/782]\tTime 0.165 (0.166)\tLoss 0.2368 (0.2264)\tPrec@1 89.062 (92.013)\n",
            "Epoch: [47][260/782]\tTime 0.170 (0.166)\tLoss 0.2012 (0.2260)\tPrec@1 93.750 (92.050)\n",
            "Epoch: [47][270/782]\tTime 0.167 (0.166)\tLoss 0.1643 (0.2262)\tPrec@1 96.875 (92.020)\n",
            "Epoch: [47][280/782]\tTime 0.165 (0.166)\tLoss 0.2156 (0.2268)\tPrec@1 92.188 (92.026)\n",
            "Epoch: [47][290/782]\tTime 0.166 (0.166)\tLoss 0.3020 (0.2262)\tPrec@1 89.062 (92.096)\n",
            "Epoch: [47][300/782]\tTime 0.163 (0.166)\tLoss 0.3190 (0.2260)\tPrec@1 92.188 (92.136)\n",
            "Epoch: [47][310/782]\tTime 0.169 (0.166)\tLoss 0.1628 (0.2260)\tPrec@1 93.750 (92.092)\n",
            "Epoch: [47][320/782]\tTime 0.163 (0.166)\tLoss 0.2182 (0.2248)\tPrec@1 90.625 (92.149)\n",
            "Epoch: [47][330/782]\tTime 0.164 (0.166)\tLoss 0.1704 (0.2251)\tPrec@1 93.750 (92.145)\n",
            "Epoch: [47][340/782]\tTime 0.170 (0.166)\tLoss 0.1201 (0.2256)\tPrec@1 98.438 (92.096)\n",
            "Epoch: [47][350/782]\tTime 0.167 (0.166)\tLoss 0.2430 (0.2250)\tPrec@1 92.188 (92.116)\n",
            "Epoch: [47][360/782]\tTime 0.165 (0.166)\tLoss 0.1532 (0.2256)\tPrec@1 96.875 (92.079)\n",
            "Epoch: [47][370/782]\tTime 0.164 (0.166)\tLoss 0.3280 (0.2254)\tPrec@1 87.500 (92.095)\n",
            "Epoch: [47][380/782]\tTime 0.163 (0.166)\tLoss 0.2234 (0.2241)\tPrec@1 90.625 (92.114)\n",
            "Epoch: [47][390/782]\tTime 0.163 (0.166)\tLoss 0.1154 (0.2239)\tPrec@1 96.875 (92.132)\n",
            "Epoch: [47][400/782]\tTime 0.167 (0.166)\tLoss 0.2569 (0.2244)\tPrec@1 90.625 (92.106)\n",
            "Epoch: [47][410/782]\tTime 0.166 (0.166)\tLoss 0.3097 (0.2249)\tPrec@1 89.062 (92.104)\n",
            "Epoch: [47][420/782]\tTime 0.170 (0.166)\tLoss 0.1981 (0.2250)\tPrec@1 95.312 (92.084)\n",
            "Epoch: [47][430/782]\tTime 0.164 (0.166)\tLoss 0.3547 (0.2260)\tPrec@1 85.938 (92.068)\n",
            "Epoch: [47][440/782]\tTime 0.164 (0.166)\tLoss 0.0602 (0.2252)\tPrec@1 100.000 (92.102)\n",
            "Epoch: [47][450/782]\tTime 0.167 (0.166)\tLoss 0.3292 (0.2252)\tPrec@1 84.375 (92.111)\n",
            "Epoch: [47][460/782]\tTime 0.164 (0.166)\tLoss 0.2250 (0.2255)\tPrec@1 90.625 (92.089)\n",
            "Epoch: [47][470/782]\tTime 0.168 (0.166)\tLoss 0.1387 (0.2253)\tPrec@1 95.312 (92.108)\n",
            "Epoch: [47][480/782]\tTime 0.166 (0.166)\tLoss 0.1565 (0.2266)\tPrec@1 93.750 (92.077)\n",
            "Epoch: [47][490/782]\tTime 0.164 (0.166)\tLoss 0.1310 (0.2270)\tPrec@1 95.312 (92.073)\n",
            "Epoch: [47][500/782]\tTime 0.164 (0.166)\tLoss 0.2881 (0.2268)\tPrec@1 84.375 (92.063)\n",
            "Epoch: [47][510/782]\tTime 0.166 (0.166)\tLoss 0.1393 (0.2260)\tPrec@1 93.750 (92.077)\n",
            "Epoch: [47][520/782]\tTime 0.164 (0.166)\tLoss 0.3063 (0.2258)\tPrec@1 85.938 (92.080)\n",
            "Epoch: [47][530/782]\tTime 0.169 (0.166)\tLoss 0.2471 (0.2258)\tPrec@1 90.625 (92.085)\n",
            "Epoch: [47][540/782]\tTime 0.165 (0.166)\tLoss 0.0961 (0.2258)\tPrec@1 98.438 (92.115)\n",
            "Epoch: [47][550/782]\tTime 0.165 (0.166)\tLoss 0.2067 (0.2256)\tPrec@1 90.625 (92.136)\n",
            "Epoch: [47][560/782]\tTime 0.167 (0.166)\tLoss 0.2566 (0.2252)\tPrec@1 89.062 (92.149)\n",
            "Epoch: [47][570/782]\tTime 0.166 (0.166)\tLoss 0.2664 (0.2253)\tPrec@1 90.625 (92.136)\n",
            "Epoch: [47][580/782]\tTime 0.165 (0.166)\tLoss 0.1965 (0.2260)\tPrec@1 90.625 (92.091)\n",
            "Epoch: [47][590/782]\tTime 0.165 (0.166)\tLoss 0.1468 (0.2260)\tPrec@1 96.875 (92.084)\n",
            "Epoch: [47][600/782]\tTime 0.165 (0.166)\tLoss 0.1481 (0.2259)\tPrec@1 93.750 (92.068)\n",
            "Epoch: [47][610/782]\tTime 0.165 (0.166)\tLoss 0.3432 (0.2263)\tPrec@1 90.625 (92.060)\n",
            "Epoch: [47][620/782]\tTime 0.163 (0.166)\tLoss 0.3085 (0.2263)\tPrec@1 90.625 (92.057)\n",
            "Epoch: [47][630/782]\tTime 0.164 (0.166)\tLoss 0.2735 (0.2265)\tPrec@1 89.062 (92.036)\n",
            "Epoch: [47][640/782]\tTime 0.168 (0.166)\tLoss 0.2114 (0.2269)\tPrec@1 92.188 (92.031)\n",
            "Epoch: [47][650/782]\tTime 0.166 (0.166)\tLoss 0.1000 (0.2264)\tPrec@1 96.875 (92.053)\n",
            "Epoch: [47][660/782]\tTime 0.164 (0.166)\tLoss 0.1265 (0.2265)\tPrec@1 96.875 (92.036)\n",
            "Epoch: [47][670/782]\tTime 0.163 (0.166)\tLoss 0.3128 (0.2273)\tPrec@1 90.625 (92.013)\n",
            "Epoch: [47][680/782]\tTime 0.167 (0.166)\tLoss 0.1696 (0.2278)\tPrec@1 92.188 (91.997)\n",
            "Epoch: [47][690/782]\tTime 0.165 (0.166)\tLoss 0.2505 (0.2279)\tPrec@1 90.625 (91.995)\n",
            "Epoch: [47][700/782]\tTime 0.166 (0.166)\tLoss 0.1722 (0.2280)\tPrec@1 95.312 (92.005)\n",
            "Epoch: [47][710/782]\tTime 0.166 (0.166)\tLoss 0.2355 (0.2291)\tPrec@1 87.500 (91.963)\n",
            "Epoch: [47][720/782]\tTime 0.164 (0.166)\tLoss 0.2587 (0.2294)\tPrec@1 95.312 (91.975)\n",
            "Epoch: [47][730/782]\tTime 0.165 (0.166)\tLoss 0.1191 (0.2293)\tPrec@1 96.875 (91.987)\n",
            "Epoch: [47][740/782]\tTime 0.168 (0.166)\tLoss 0.2269 (0.2298)\tPrec@1 90.625 (91.968)\n",
            "Epoch: [47][750/782]\tTime 0.167 (0.166)\tLoss 0.2110 (0.2303)\tPrec@1 89.062 (91.942)\n",
            "Epoch: [47][760/782]\tTime 0.166 (0.166)\tLoss 0.1891 (0.2312)\tPrec@1 93.750 (91.908)\n",
            "Epoch: [47][770/782]\tTime 0.165 (0.166)\tLoss 0.2924 (0.2318)\tPrec@1 90.625 (91.892)\n",
            "Epoch: [47][780/782]\tTime 0.162 (0.166)\tLoss 0.1287 (0.2320)\tPrec@1 96.875 (91.895)\n",
            "Training accuracy:  tensor(91.8900, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.1060, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.110 (0.110)\tLoss 0.3677 (0.3677)\tPrec@1 89.062 (89.062)\n",
            "Test: [10/157]\tTime 0.044 (0.047)\tLoss 0.4297 (0.3333)\tPrec@1 82.812 (88.920)\n",
            "Test: [20/157]\tTime 0.052 (0.046)\tLoss 0.3315 (0.3891)\tPrec@1 89.062 (87.202)\n",
            "Test: [30/157]\tTime 0.042 (0.046)\tLoss 0.2304 (0.3752)\tPrec@1 93.750 (87.651)\n",
            "Test: [40/157]\tTime 0.047 (0.045)\tLoss 0.3005 (0.3881)\tPrec@1 92.188 (87.348)\n",
            "Test: [50/157]\tTime 0.046 (0.045)\tLoss 0.3177 (0.3875)\tPrec@1 90.625 (87.132)\n",
            "Test: [60/157]\tTime 0.043 (0.045)\tLoss 0.4473 (0.3878)\tPrec@1 87.500 (87.295)\n",
            "Test: [70/157]\tTime 0.044 (0.045)\tLoss 0.4350 (0.3885)\tPrec@1 85.938 (87.566)\n",
            "Test: [80/157]\tTime 0.043 (0.045)\tLoss 0.3128 (0.3875)\tPrec@1 89.062 (87.731)\n",
            "Test: [90/157]\tTime 0.045 (0.045)\tLoss 0.3052 (0.3948)\tPrec@1 90.625 (87.603)\n",
            "Test: [100/157]\tTime 0.044 (0.044)\tLoss 0.5544 (0.3959)\tPrec@1 85.938 (87.392)\n",
            "Test: [110/157]\tTime 0.040 (0.044)\tLoss 0.3560 (0.3949)\tPrec@1 89.062 (87.528)\n",
            "Test: [120/157]\tTime 0.044 (0.044)\tLoss 0.3467 (0.3941)\tPrec@1 90.625 (87.552)\n",
            "Test: [130/157]\tTime 0.041 (0.044)\tLoss 0.4195 (0.3936)\tPrec@1 89.062 (87.643)\n",
            "Test: [140/157]\tTime 0.045 (0.044)\tLoss 0.4206 (0.3939)\tPrec@1 92.188 (87.655)\n",
            "Test: [150/157]\tTime 0.043 (0.044)\tLoss 0.2784 (0.3938)\tPrec@1 92.188 (87.666)\n",
            " * Prec@1 87.680\n",
            "Best accuracy:  tensor(88.8800, device='cuda:0')\n",
            "Epoch: [48][0/782]\tTime 0.265 (0.265)\tLoss 0.2902 (0.2902)\tPrec@1 90.625 (90.625)\n",
            "Epoch: [48][10/782]\tTime 0.165 (0.176)\tLoss 0.3311 (0.2489)\tPrec@1 90.625 (92.045)\n",
            "Epoch: [48][20/782]\tTime 0.164 (0.171)\tLoss 0.3934 (0.2638)\tPrec@1 89.062 (90.699)\n",
            "Epoch: [48][30/782]\tTime 0.166 (0.170)\tLoss 0.2333 (0.2594)\tPrec@1 95.312 (90.827)\n",
            "Epoch: [48][40/782]\tTime 0.166 (0.169)\tLoss 0.2105 (0.2541)\tPrec@1 95.312 (91.120)\n",
            "Epoch: [48][50/782]\tTime 0.163 (0.168)\tLoss 0.1962 (0.2433)\tPrec@1 89.062 (91.238)\n",
            "Epoch: [48][60/782]\tTime 0.167 (0.168)\tLoss 0.1813 (0.2358)\tPrec@1 93.750 (91.393)\n",
            "Epoch: [48][70/782]\tTime 0.168 (0.168)\tLoss 0.1972 (0.2333)\tPrec@1 92.188 (91.483)\n",
            "Epoch: [48][80/782]\tTime 0.165 (0.168)\tLoss 0.2458 (0.2292)\tPrec@1 92.188 (91.667)\n",
            "Epoch: [48][90/782]\tTime 0.169 (0.167)\tLoss 0.1607 (0.2303)\tPrec@1 92.188 (91.707)\n",
            "Epoch: [48][100/782]\tTime 0.167 (0.167)\tLoss 0.1395 (0.2337)\tPrec@1 95.312 (91.739)\n",
            "Epoch: [48][110/782]\tTime 0.164 (0.167)\tLoss 0.2930 (0.2320)\tPrec@1 87.500 (91.836)\n",
            "Epoch: [48][120/782]\tTime 0.166 (0.167)\tLoss 0.3815 (0.2305)\tPrec@1 84.375 (91.890)\n",
            "Epoch: [48][130/782]\tTime 0.167 (0.167)\tLoss 0.2398 (0.2277)\tPrec@1 90.625 (91.997)\n",
            "Epoch: [48][140/782]\tTime 0.166 (0.167)\tLoss 0.2163 (0.2240)\tPrec@1 96.875 (92.176)\n",
            "Epoch: [48][150/782]\tTime 0.165 (0.167)\tLoss 0.2421 (0.2265)\tPrec@1 92.188 (92.115)\n",
            "Epoch: [48][160/782]\tTime 0.165 (0.167)\tLoss 0.1656 (0.2262)\tPrec@1 92.188 (92.100)\n",
            "Epoch: [48][170/782]\tTime 0.166 (0.167)\tLoss 0.1664 (0.2289)\tPrec@1 95.312 (92.023)\n",
            "Epoch: [48][180/782]\tTime 0.166 (0.167)\tLoss 0.2796 (0.2293)\tPrec@1 92.188 (91.989)\n",
            "Epoch: [48][190/782]\tTime 0.165 (0.167)\tLoss 0.3530 (0.2298)\tPrec@1 85.938 (91.934)\n",
            "Epoch: [48][200/782]\tTime 0.167 (0.167)\tLoss 0.2983 (0.2295)\tPrec@1 90.625 (91.954)\n",
            "Epoch: [48][210/782]\tTime 0.166 (0.167)\tLoss 0.2631 (0.2279)\tPrec@1 90.625 (91.995)\n",
            "Epoch: [48][220/782]\tTime 0.164 (0.167)\tLoss 0.2976 (0.2291)\tPrec@1 90.625 (92.004)\n",
            "Epoch: [48][230/782]\tTime 0.165 (0.166)\tLoss 0.1812 (0.2310)\tPrec@1 93.750 (91.971)\n",
            "Epoch: [48][240/782]\tTime 0.164 (0.166)\tLoss 0.1219 (0.2297)\tPrec@1 93.750 (92.006)\n",
            "Epoch: [48][250/782]\tTime 0.164 (0.166)\tLoss 0.2174 (0.2304)\tPrec@1 90.625 (91.982)\n",
            "Epoch: [48][260/782]\tTime 0.167 (0.166)\tLoss 0.3194 (0.2311)\tPrec@1 90.625 (91.942)\n",
            "Epoch: [48][270/782]\tTime 0.166 (0.166)\tLoss 0.1517 (0.2314)\tPrec@1 95.312 (91.951)\n",
            "Epoch: [48][280/782]\tTime 0.166 (0.166)\tLoss 0.0666 (0.2303)\tPrec@1 96.875 (91.976)\n",
            "Epoch: [48][290/782]\tTime 0.167 (0.166)\tLoss 0.1823 (0.2314)\tPrec@1 92.188 (91.941)\n",
            "Epoch: [48][300/782]\tTime 0.167 (0.166)\tLoss 0.1261 (0.2293)\tPrec@1 96.875 (92.063)\n",
            "Epoch: [48][310/782]\tTime 0.167 (0.166)\tLoss 0.3758 (0.2292)\tPrec@1 85.938 (92.067)\n",
            "Epoch: [48][320/782]\tTime 0.163 (0.166)\tLoss 0.3330 (0.2292)\tPrec@1 87.500 (92.051)\n",
            "Epoch: [48][330/782]\tTime 0.165 (0.166)\tLoss 0.3023 (0.2305)\tPrec@1 90.625 (92.018)\n",
            "Epoch: [48][340/782]\tTime 0.166 (0.166)\tLoss 0.2335 (0.2310)\tPrec@1 93.750 (92.009)\n",
            "Epoch: [48][350/782]\tTime 0.163 (0.166)\tLoss 0.1272 (0.2307)\tPrec@1 95.312 (92.023)\n",
            "Epoch: [48][360/782]\tTime 0.164 (0.166)\tLoss 0.2249 (0.2304)\tPrec@1 90.625 (92.027)\n",
            "Epoch: [48][370/782]\tTime 0.166 (0.166)\tLoss 0.3849 (0.2316)\tPrec@1 89.062 (92.006)\n",
            "Epoch: [48][380/782]\tTime 0.164 (0.166)\tLoss 0.2627 (0.2316)\tPrec@1 92.188 (91.991)\n",
            "Epoch: [48][390/782]\tTime 0.166 (0.166)\tLoss 0.2128 (0.2310)\tPrec@1 93.750 (92.016)\n",
            "Epoch: [48][400/782]\tTime 0.167 (0.166)\tLoss 0.2989 (0.2308)\tPrec@1 90.625 (92.028)\n",
            "Epoch: [48][410/782]\tTime 0.165 (0.166)\tLoss 0.3237 (0.2305)\tPrec@1 87.500 (92.035)\n",
            "Epoch: [48][420/782]\tTime 0.168 (0.166)\tLoss 0.3845 (0.2313)\tPrec@1 90.625 (91.998)\n",
            "Epoch: [48][430/782]\tTime 0.165 (0.166)\tLoss 0.1206 (0.2311)\tPrec@1 92.188 (91.992)\n",
            "Epoch: [48][440/782]\tTime 0.163 (0.166)\tLoss 0.1038 (0.2305)\tPrec@1 96.875 (92.000)\n",
            "Epoch: [48][450/782]\tTime 0.169 (0.166)\tLoss 0.1857 (0.2309)\tPrec@1 90.625 (91.980)\n",
            "Epoch: [48][460/782]\tTime 0.165 (0.166)\tLoss 0.2209 (0.2310)\tPrec@1 95.312 (91.984)\n",
            "Epoch: [48][470/782]\tTime 0.164 (0.166)\tLoss 0.2280 (0.2308)\tPrec@1 92.188 (92.008)\n",
            "Epoch: [48][480/782]\tTime 0.168 (0.166)\tLoss 0.2136 (0.2307)\tPrec@1 93.750 (92.038)\n",
            "Epoch: [48][490/782]\tTime 0.164 (0.166)\tLoss 0.2241 (0.2302)\tPrec@1 90.625 (92.047)\n",
            "Epoch: [48][500/782]\tTime 0.166 (0.166)\tLoss 0.1793 (0.2295)\tPrec@1 90.625 (92.069)\n",
            "Epoch: [48][510/782]\tTime 0.164 (0.166)\tLoss 0.0983 (0.2294)\tPrec@1 96.875 (92.068)\n",
            "Epoch: [48][520/782]\tTime 0.166 (0.166)\tLoss 0.1368 (0.2288)\tPrec@1 96.875 (92.101)\n",
            "Epoch: [48][530/782]\tTime 0.171 (0.166)\tLoss 0.2110 (0.2281)\tPrec@1 90.625 (92.105)\n",
            "Epoch: [48][540/782]\tTime 0.165 (0.166)\tLoss 0.1511 (0.2271)\tPrec@1 95.312 (92.147)\n",
            "Epoch: [48][550/782]\tTime 0.165 (0.166)\tLoss 0.3332 (0.2280)\tPrec@1 89.062 (92.091)\n",
            "Epoch: [48][560/782]\tTime 0.165 (0.166)\tLoss 0.1391 (0.2283)\tPrec@1 95.312 (92.093)\n",
            "Epoch: [48][570/782]\tTime 0.163 (0.166)\tLoss 0.1827 (0.2289)\tPrec@1 96.875 (92.064)\n",
            "Epoch: [48][580/782]\tTime 0.165 (0.166)\tLoss 0.1653 (0.2283)\tPrec@1 95.312 (92.083)\n",
            "Epoch: [48][590/782]\tTime 0.165 (0.166)\tLoss 0.2733 (0.2285)\tPrec@1 89.062 (92.061)\n",
            "Epoch: [48][600/782]\tTime 0.164 (0.166)\tLoss 0.1757 (0.2291)\tPrec@1 93.750 (92.042)\n",
            "Epoch: [48][610/782]\tTime 0.164 (0.166)\tLoss 0.2243 (0.2295)\tPrec@1 95.312 (92.026)\n",
            "Epoch: [48][620/782]\tTime 0.166 (0.166)\tLoss 0.3773 (0.2297)\tPrec@1 89.062 (92.006)\n",
            "Epoch: [48][630/782]\tTime 0.164 (0.166)\tLoss 0.2349 (0.2303)\tPrec@1 92.188 (91.984)\n",
            "Epoch: [48][640/782]\tTime 0.164 (0.166)\tLoss 0.1191 (0.2297)\tPrec@1 95.312 (91.995)\n",
            "Epoch: [48][650/782]\tTime 0.166 (0.166)\tLoss 0.1737 (0.2299)\tPrec@1 92.188 (91.988)\n",
            "Epoch: [48][660/782]\tTime 0.166 (0.166)\tLoss 0.1812 (0.2298)\tPrec@1 95.312 (91.998)\n",
            "Epoch: [48][670/782]\tTime 0.164 (0.166)\tLoss 0.2690 (0.2300)\tPrec@1 92.188 (92.011)\n",
            "Epoch: [48][680/782]\tTime 0.167 (0.166)\tLoss 0.2902 (0.2298)\tPrec@1 89.062 (92.020)\n",
            "Epoch: [48][690/782]\tTime 0.166 (0.166)\tLoss 0.3774 (0.2305)\tPrec@1 87.500 (92.002)\n",
            "Epoch: [48][700/782]\tTime 0.165 (0.166)\tLoss 0.3381 (0.2313)\tPrec@1 90.625 (91.978)\n",
            "Epoch: [48][710/782]\tTime 0.167 (0.166)\tLoss 0.2366 (0.2312)\tPrec@1 90.625 (91.990)\n",
            "Epoch: [48][720/782]\tTime 0.166 (0.166)\tLoss 0.1893 (0.2315)\tPrec@1 95.312 (91.992)\n",
            "Epoch: [48][730/782]\tTime 0.166 (0.166)\tLoss 0.1532 (0.2319)\tPrec@1 95.312 (91.982)\n",
            "Epoch: [48][740/782]\tTime 0.167 (0.166)\tLoss 0.2340 (0.2322)\tPrec@1 93.750 (91.966)\n",
            "Epoch: [48][750/782]\tTime 0.169 (0.166)\tLoss 0.2792 (0.2326)\tPrec@1 87.500 (91.938)\n",
            "Epoch: [48][760/782]\tTime 0.163 (0.166)\tLoss 0.2674 (0.2326)\tPrec@1 92.188 (91.955)\n",
            "Epoch: [48][770/782]\tTime 0.167 (0.166)\tLoss 0.2639 (0.2327)\tPrec@1 84.375 (91.940)\n",
            "Epoch: [48][780/782]\tTime 0.163 (0.166)\tLoss 0.1779 (0.2325)\tPrec@1 92.188 (91.947)\n",
            "Training accuracy:  tensor(91.9440, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.1060, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.114 (0.114)\tLoss 0.4256 (0.4256)\tPrec@1 85.938 (85.938)\n",
            "Test: [10/157]\tTime 0.048 (0.048)\tLoss 0.9081 (0.4236)\tPrec@1 78.125 (87.358)\n",
            "Test: [20/157]\tTime 0.049 (0.046)\tLoss 0.4591 (0.4442)\tPrec@1 87.500 (86.756)\n",
            "Test: [30/157]\tTime 0.044 (0.046)\tLoss 0.3066 (0.4333)\tPrec@1 90.625 (86.744)\n",
            "Test: [40/157]\tTime 0.048 (0.045)\tLoss 0.3745 (0.4263)\tPrec@1 92.188 (86.966)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.4154 (0.4311)\tPrec@1 85.938 (86.765)\n",
            "Test: [60/157]\tTime 0.042 (0.045)\tLoss 0.1967 (0.4221)\tPrec@1 95.312 (86.962)\n",
            "Test: [70/157]\tTime 0.043 (0.045)\tLoss 0.1864 (0.4214)\tPrec@1 95.312 (87.192)\n",
            "Test: [80/157]\tTime 0.044 (0.045)\tLoss 1.0153 (0.4292)\tPrec@1 81.250 (87.037)\n",
            "Test: [90/157]\tTime 0.047 (0.045)\tLoss 0.5725 (0.4258)\tPrec@1 85.938 (87.225)\n",
            "Test: [100/157]\tTime 0.044 (0.044)\tLoss 0.1933 (0.4237)\tPrec@1 93.750 (87.423)\n",
            "Test: [110/157]\tTime 0.038 (0.044)\tLoss 0.3593 (0.4271)\tPrec@1 87.500 (87.387)\n",
            "Test: [120/157]\tTime 0.047 (0.044)\tLoss 0.3798 (0.4288)\tPrec@1 89.062 (87.332)\n",
            "Test: [130/157]\tTime 0.041 (0.044)\tLoss 0.5149 (0.4311)\tPrec@1 81.250 (87.226)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.8846 (0.4288)\tPrec@1 84.375 (87.323)\n",
            "Test: [150/157]\tTime 0.044 (0.044)\tLoss 0.5679 (0.4284)\tPrec@1 89.062 (87.283)\n",
            " * Prec@1 87.340\n",
            "Best accuracy:  tensor(88.8800, device='cuda:0')\n",
            "Epoch: [49][0/782]\tTime 0.271 (0.271)\tLoss 0.1978 (0.1978)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [49][10/782]\tTime 0.165 (0.175)\tLoss 0.1171 (0.2101)\tPrec@1 95.312 (92.614)\n",
            "Epoch: [49][20/782]\tTime 0.162 (0.170)\tLoss 0.3865 (0.2051)\tPrec@1 84.375 (92.560)\n",
            "Epoch: [49][30/782]\tTime 0.165 (0.168)\tLoss 0.2641 (0.1991)\tPrec@1 84.375 (92.591)\n",
            "Epoch: [49][40/782]\tTime 0.164 (0.168)\tLoss 0.1544 (0.2027)\tPrec@1 95.312 (92.492)\n",
            "Epoch: [49][50/782]\tTime 0.166 (0.168)\tLoss 0.1810 (0.2060)\tPrec@1 90.625 (92.279)\n",
            "Epoch: [49][60/782]\tTime 0.166 (0.167)\tLoss 0.2886 (0.2119)\tPrec@1 90.625 (92.187)\n",
            "Epoch: [49][70/782]\tTime 0.164 (0.167)\tLoss 0.3559 (0.2152)\tPrec@1 87.500 (92.165)\n",
            "Epoch: [49][80/782]\tTime 0.163 (0.167)\tLoss 0.1584 (0.2137)\tPrec@1 95.312 (92.052)\n",
            "Epoch: [49][90/782]\tTime 0.168 (0.167)\tLoss 0.2423 (0.2082)\tPrec@1 90.625 (92.291)\n",
            "Epoch: [49][100/782]\tTime 0.164 (0.167)\tLoss 0.1614 (0.2081)\tPrec@1 92.188 (92.358)\n",
            "Epoch: [49][110/782]\tTime 0.166 (0.166)\tLoss 0.2936 (0.2084)\tPrec@1 93.750 (92.413)\n",
            "Epoch: [49][120/782]\tTime 0.166 (0.166)\tLoss 0.2251 (0.2105)\tPrec@1 92.188 (92.317)\n",
            "Epoch: [49][130/782]\tTime 0.163 (0.166)\tLoss 0.2267 (0.2100)\tPrec@1 92.188 (92.354)\n",
            "Epoch: [49][140/782]\tTime 0.163 (0.166)\tLoss 0.1326 (0.2088)\tPrec@1 93.750 (92.387)\n",
            "Epoch: [49][150/782]\tTime 0.165 (0.166)\tLoss 0.2521 (0.2082)\tPrec@1 89.062 (92.436)\n",
            "Epoch: [49][160/782]\tTime 0.164 (0.166)\tLoss 0.3684 (0.2105)\tPrec@1 89.062 (92.304)\n",
            "Epoch: [49][170/782]\tTime 0.171 (0.166)\tLoss 0.1756 (0.2095)\tPrec@1 93.750 (92.352)\n",
            "Epoch: [49][180/782]\tTime 0.164 (0.166)\tLoss 0.2843 (0.2095)\tPrec@1 90.625 (92.412)\n",
            "Epoch: [49][190/782]\tTime 0.163 (0.166)\tLoss 0.3416 (0.2108)\tPrec@1 85.938 (92.367)\n",
            "Epoch: [49][200/782]\tTime 0.166 (0.166)\tLoss 0.1375 (0.2091)\tPrec@1 95.312 (92.405)\n",
            "Epoch: [49][210/782]\tTime 0.165 (0.166)\tLoss 0.2228 (0.2126)\tPrec@1 89.062 (92.284)\n",
            "Epoch: [49][220/782]\tTime 0.164 (0.166)\tLoss 0.3283 (0.2130)\tPrec@1 87.500 (92.272)\n",
            "Epoch: [49][230/782]\tTime 0.170 (0.166)\tLoss 0.2821 (0.2150)\tPrec@1 89.062 (92.242)\n",
            "Epoch: [49][240/782]\tTime 0.166 (0.166)\tLoss 0.1633 (0.2127)\tPrec@1 95.312 (92.337)\n",
            "Epoch: [49][250/782]\tTime 0.164 (0.166)\tLoss 0.2064 (0.2131)\tPrec@1 90.625 (92.337)\n",
            "Epoch: [49][260/782]\tTime 0.164 (0.166)\tLoss 0.1471 (0.2134)\tPrec@1 93.750 (92.301)\n",
            "Epoch: [49][270/782]\tTime 0.165 (0.166)\tLoss 0.2373 (0.2122)\tPrec@1 93.750 (92.366)\n",
            "Epoch: [49][280/782]\tTime 0.164 (0.166)\tLoss 0.1574 (0.2126)\tPrec@1 95.312 (92.343)\n",
            "Epoch: [49][290/782]\tTime 0.165 (0.166)\tLoss 0.2320 (0.2120)\tPrec@1 93.750 (92.365)\n",
            "Epoch: [49][300/782]\tTime 0.169 (0.166)\tLoss 0.1753 (0.2149)\tPrec@1 93.750 (92.265)\n",
            "Epoch: [49][310/782]\tTime 0.168 (0.166)\tLoss 0.2119 (0.2157)\tPrec@1 93.750 (92.248)\n",
            "Epoch: [49][320/782]\tTime 0.165 (0.166)\tLoss 0.1943 (0.2165)\tPrec@1 96.875 (92.251)\n",
            "Epoch: [49][330/782]\tTime 0.163 (0.166)\tLoss 0.2274 (0.2180)\tPrec@1 92.188 (92.178)\n",
            "Epoch: [49][340/782]\tTime 0.163 (0.166)\tLoss 0.2029 (0.2180)\tPrec@1 93.750 (92.183)\n",
            "Epoch: [49][350/782]\tTime 0.165 (0.166)\tLoss 0.2179 (0.2183)\tPrec@1 90.625 (92.179)\n",
            "Epoch: [49][360/782]\tTime 0.167 (0.166)\tLoss 0.2411 (0.2184)\tPrec@1 93.750 (92.192)\n",
            "Epoch: [49][370/782]\tTime 0.163 (0.166)\tLoss 0.1664 (0.2180)\tPrec@1 95.312 (92.196)\n",
            "Epoch: [49][380/782]\tTime 0.166 (0.166)\tLoss 0.2017 (0.2182)\tPrec@1 90.625 (92.171)\n",
            "Epoch: [49][390/782]\tTime 0.166 (0.166)\tLoss 0.2662 (0.2188)\tPrec@1 90.625 (92.148)\n",
            "Epoch: [49][400/782]\tTime 0.164 (0.166)\tLoss 0.1710 (0.2192)\tPrec@1 95.312 (92.145)\n",
            "Epoch: [49][410/782]\tTime 0.165 (0.166)\tLoss 0.2318 (0.2191)\tPrec@1 93.750 (92.157)\n",
            "Epoch: [49][420/782]\tTime 0.165 (0.166)\tLoss 0.1564 (0.2193)\tPrec@1 93.750 (92.136)\n",
            "Epoch: [49][430/782]\tTime 0.164 (0.166)\tLoss 0.3762 (0.2197)\tPrec@1 81.250 (92.115)\n",
            "Epoch: [49][440/782]\tTime 0.165 (0.166)\tLoss 0.3845 (0.2211)\tPrec@1 90.625 (92.102)\n",
            "Epoch: [49][450/782]\tTime 0.164 (0.166)\tLoss 0.1682 (0.2208)\tPrec@1 90.625 (92.122)\n",
            "Epoch: [49][460/782]\tTime 0.164 (0.166)\tLoss 0.2852 (0.2208)\tPrec@1 87.500 (92.110)\n",
            "Epoch: [49][470/782]\tTime 0.165 (0.166)\tLoss 0.1159 (0.2203)\tPrec@1 98.438 (92.134)\n",
            "Epoch: [49][480/782]\tTime 0.166 (0.166)\tLoss 0.3335 (0.2207)\tPrec@1 89.062 (92.126)\n",
            "Epoch: [49][490/782]\tTime 0.166 (0.166)\tLoss 0.2923 (0.2207)\tPrec@1 89.062 (92.143)\n",
            "Epoch: [49][500/782]\tTime 0.164 (0.166)\tLoss 0.1450 (0.2203)\tPrec@1 95.312 (92.125)\n",
            "Epoch: [49][510/782]\tTime 0.165 (0.166)\tLoss 0.2352 (0.2201)\tPrec@1 85.938 (92.132)\n",
            "Epoch: [49][520/782]\tTime 0.165 (0.166)\tLoss 0.1736 (0.2202)\tPrec@1 93.750 (92.140)\n",
            "Epoch: [49][530/782]\tTime 0.169 (0.166)\tLoss 0.1401 (0.2201)\tPrec@1 93.750 (92.129)\n",
            "Epoch: [49][540/782]\tTime 0.163 (0.166)\tLoss 0.2513 (0.2202)\tPrec@1 90.625 (92.141)\n",
            "Epoch: [49][550/782]\tTime 0.168 (0.166)\tLoss 0.4576 (0.2216)\tPrec@1 89.062 (92.097)\n",
            "Epoch: [49][560/782]\tTime 0.163 (0.166)\tLoss 0.2096 (0.2219)\tPrec@1 90.625 (92.076)\n",
            "Epoch: [49][570/782]\tTime 0.164 (0.166)\tLoss 0.1295 (0.2227)\tPrec@1 93.750 (92.056)\n",
            "Epoch: [49][580/782]\tTime 0.164 (0.166)\tLoss 0.2576 (0.2234)\tPrec@1 90.625 (92.040)\n",
            "Epoch: [49][590/782]\tTime 0.164 (0.166)\tLoss 0.1253 (0.2236)\tPrec@1 96.875 (92.034)\n",
            "Epoch: [49][600/782]\tTime 0.165 (0.166)\tLoss 0.2495 (0.2244)\tPrec@1 92.188 (92.019)\n",
            "Epoch: [49][610/782]\tTime 0.166 (0.166)\tLoss 0.1576 (0.2248)\tPrec@1 93.750 (92.001)\n",
            "Epoch: [49][620/782]\tTime 0.162 (0.166)\tLoss 0.2648 (0.2259)\tPrec@1 90.625 (91.946)\n",
            "Epoch: [49][630/782]\tTime 0.164 (0.166)\tLoss 0.3770 (0.2260)\tPrec@1 84.375 (91.937)\n",
            "Epoch: [49][640/782]\tTime 0.166 (0.166)\tLoss 0.4544 (0.2261)\tPrec@1 87.500 (91.941)\n",
            "Epoch: [49][650/782]\tTime 0.163 (0.166)\tLoss 0.2543 (0.2259)\tPrec@1 93.750 (91.952)\n",
            "Epoch: [49][660/782]\tTime 0.165 (0.166)\tLoss 0.2270 (0.2266)\tPrec@1 92.188 (91.916)\n",
            "Epoch: [49][670/782]\tTime 0.164 (0.166)\tLoss 0.1368 (0.2268)\tPrec@1 96.875 (91.927)\n",
            "Epoch: [49][680/782]\tTime 0.163 (0.166)\tLoss 0.4113 (0.2271)\tPrec@1 89.062 (91.935)\n",
            "Epoch: [49][690/782]\tTime 0.165 (0.166)\tLoss 0.2505 (0.2274)\tPrec@1 92.188 (91.930)\n",
            "Epoch: [49][700/782]\tTime 0.165 (0.166)\tLoss 0.1586 (0.2265)\tPrec@1 92.188 (91.953)\n",
            "Epoch: [49][710/782]\tTime 0.164 (0.166)\tLoss 0.1835 (0.2262)\tPrec@1 96.875 (91.972)\n",
            "Epoch: [49][720/782]\tTime 0.166 (0.166)\tLoss 0.1874 (0.2260)\tPrec@1 93.750 (91.982)\n",
            "Epoch: [49][730/782]\tTime 0.163 (0.166)\tLoss 0.6692 (0.2268)\tPrec@1 87.500 (91.959)\n",
            "Epoch: [49][740/782]\tTime 0.164 (0.166)\tLoss 0.2276 (0.2266)\tPrec@1 92.188 (91.975)\n",
            "Epoch: [49][750/782]\tTime 0.164 (0.166)\tLoss 0.1190 (0.2261)\tPrec@1 95.312 (91.988)\n",
            "Epoch: [49][760/782]\tTime 0.165 (0.166)\tLoss 0.1425 (0.2260)\tPrec@1 93.750 (91.992)\n",
            "Epoch: [49][770/782]\tTime 0.168 (0.166)\tLoss 0.2854 (0.2264)\tPrec@1 89.062 (91.975)\n",
            "Epoch: [49][780/782]\tTime 0.162 (0.166)\tLoss 0.3929 (0.2263)\tPrec@1 87.500 (91.973)\n",
            "Training accuracy:  tensor(91.9740, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.1060, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.113 (0.113)\tLoss 0.4263 (0.4263)\tPrec@1 89.062 (89.062)\n",
            "Test: [10/157]\tTime 0.044 (0.047)\tLoss 0.2989 (0.4423)\tPrec@1 90.625 (87.216)\n",
            "Test: [20/157]\tTime 0.054 (0.046)\tLoss 0.3137 (0.4527)\tPrec@1 89.062 (86.979)\n",
            "Test: [30/157]\tTime 0.043 (0.046)\tLoss 0.2699 (0.4292)\tPrec@1 90.625 (87.298)\n",
            "Test: [40/157]\tTime 0.044 (0.045)\tLoss 0.3586 (0.4407)\tPrec@1 89.062 (86.776)\n",
            "Test: [50/157]\tTime 0.049 (0.045)\tLoss 0.5294 (0.4344)\tPrec@1 79.688 (86.795)\n",
            "Test: [60/157]\tTime 0.042 (0.045)\tLoss 0.5849 (0.4230)\tPrec@1 81.250 (86.936)\n",
            "Test: [70/157]\tTime 0.044 (0.045)\tLoss 0.2179 (0.4205)\tPrec@1 90.625 (87.016)\n",
            "Test: [80/157]\tTime 0.045 (0.045)\tLoss 0.2775 (0.4226)\tPrec@1 89.062 (86.941)\n",
            "Test: [90/157]\tTime 0.044 (0.044)\tLoss 0.5757 (0.4390)\tPrec@1 76.562 (86.521)\n",
            "Test: [100/157]\tTime 0.043 (0.044)\tLoss 0.4732 (0.4311)\tPrec@1 84.375 (86.634)\n",
            "Test: [110/157]\tTime 0.041 (0.044)\tLoss 0.5176 (0.4283)\tPrec@1 82.812 (86.543)\n",
            "Test: [120/157]\tTime 0.039 (0.044)\tLoss 0.5016 (0.4276)\tPrec@1 82.812 (86.557)\n",
            "Test: [130/157]\tTime 0.050 (0.044)\tLoss 0.3630 (0.4236)\tPrec@1 84.375 (86.749)\n",
            "Test: [140/157]\tTime 0.043 (0.044)\tLoss 0.6452 (0.4246)\tPrec@1 81.250 (86.669)\n",
            "Test: [150/157]\tTime 0.042 (0.044)\tLoss 0.2976 (0.4257)\tPrec@1 87.500 (86.714)\n",
            " * Prec@1 86.700\n",
            "Best accuracy:  tensor(88.8800, device='cuda:0')\n",
            "Epoch: [50][0/782]\tTime 0.264 (0.264)\tLoss 0.1471 (0.1471)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [50][10/782]\tTime 0.165 (0.174)\tLoss 0.1957 (0.2107)\tPrec@1 93.750 (92.188)\n",
            "Epoch: [50][20/782]\tTime 0.164 (0.170)\tLoss 0.1923 (0.2176)\tPrec@1 92.188 (91.741)\n",
            "Epoch: [50][30/782]\tTime 0.163 (0.168)\tLoss 0.2833 (0.2290)\tPrec@1 89.062 (91.381)\n",
            "Epoch: [50][40/782]\tTime 0.164 (0.168)\tLoss 0.2592 (0.2287)\tPrec@1 95.312 (91.768)\n",
            "Epoch: [50][50/782]\tTime 0.164 (0.167)\tLoss 0.0810 (0.2189)\tPrec@1 98.438 (92.004)\n",
            "Epoch: [50][60/782]\tTime 0.164 (0.167)\tLoss 0.1707 (0.2162)\tPrec@1 95.312 (92.111)\n",
            "Epoch: [50][70/782]\tTime 0.164 (0.166)\tLoss 0.1177 (0.2141)\tPrec@1 96.875 (92.188)\n",
            "Epoch: [50][80/782]\tTime 0.164 (0.166)\tLoss 0.3722 (0.2144)\tPrec@1 87.500 (92.265)\n",
            "Epoch: [50][90/782]\tTime 0.163 (0.166)\tLoss 0.2941 (0.2194)\tPrec@1 90.625 (92.188)\n",
            "Epoch: [50][100/782]\tTime 0.164 (0.166)\tLoss 0.2674 (0.2202)\tPrec@1 90.625 (92.234)\n",
            "Epoch: [50][110/782]\tTime 0.164 (0.166)\tLoss 0.1804 (0.2168)\tPrec@1 95.312 (92.328)\n",
            "Epoch: [50][120/782]\tTime 0.165 (0.166)\tLoss 0.2149 (0.2162)\tPrec@1 93.750 (92.342)\n",
            "Epoch: [50][130/782]\tTime 0.166 (0.166)\tLoss 0.1944 (0.2131)\tPrec@1 95.312 (92.462)\n",
            "Epoch: [50][140/782]\tTime 0.163 (0.166)\tLoss 0.2435 (0.2152)\tPrec@1 89.062 (92.398)\n",
            "Epoch: [50][150/782]\tTime 0.165 (0.166)\tLoss 0.2324 (0.2187)\tPrec@1 90.625 (92.281)\n",
            "Epoch: [50][160/782]\tTime 0.166 (0.166)\tLoss 0.4072 (0.2192)\tPrec@1 89.062 (92.304)\n",
            "Epoch: [50][170/782]\tTime 0.162 (0.166)\tLoss 0.2260 (0.2173)\tPrec@1 90.625 (92.407)\n",
            "Epoch: [50][180/782]\tTime 0.165 (0.166)\tLoss 0.2562 (0.2164)\tPrec@1 89.062 (92.403)\n",
            "Epoch: [50][190/782]\tTime 0.162 (0.166)\tLoss 0.1717 (0.2175)\tPrec@1 92.188 (92.318)\n",
            "Epoch: [50][200/782]\tTime 0.163 (0.166)\tLoss 0.2147 (0.2165)\tPrec@1 93.750 (92.366)\n",
            "Epoch: [50][210/782]\tTime 0.167 (0.166)\tLoss 0.1591 (0.2176)\tPrec@1 95.312 (92.336)\n",
            "Epoch: [50][220/782]\tTime 0.162 (0.166)\tLoss 0.1114 (0.2161)\tPrec@1 98.438 (92.385)\n",
            "Epoch: [50][230/782]\tTime 0.164 (0.166)\tLoss 0.2209 (0.2167)\tPrec@1 93.750 (92.350)\n",
            "Epoch: [50][240/782]\tTime 0.166 (0.166)\tLoss 0.3597 (0.2159)\tPrec@1 89.062 (92.343)\n",
            "Epoch: [50][250/782]\tTime 0.163 (0.166)\tLoss 0.2087 (0.2176)\tPrec@1 90.625 (92.256)\n",
            "Epoch: [50][260/782]\tTime 0.165 (0.166)\tLoss 0.3367 (0.2183)\tPrec@1 87.500 (92.259)\n",
            "Epoch: [50][270/782]\tTime 0.164 (0.165)\tLoss 0.2929 (0.2184)\tPrec@1 87.500 (92.314)\n",
            "Epoch: [50][280/782]\tTime 0.163 (0.165)\tLoss 0.1450 (0.2180)\tPrec@1 95.312 (92.327)\n",
            "Epoch: [50][290/782]\tTime 0.166 (0.165)\tLoss 0.1267 (0.2186)\tPrec@1 95.312 (92.316)\n",
            "Epoch: [50][300/782]\tTime 0.164 (0.165)\tLoss 0.2971 (0.2187)\tPrec@1 92.188 (92.307)\n",
            "Epoch: [50][310/782]\tTime 0.165 (0.165)\tLoss 0.1993 (0.2197)\tPrec@1 93.750 (92.288)\n",
            "Epoch: [50][320/782]\tTime 0.165 (0.165)\tLoss 0.2258 (0.2200)\tPrec@1 95.312 (92.295)\n",
            "Epoch: [50][330/782]\tTime 0.165 (0.165)\tLoss 0.2735 (0.2202)\tPrec@1 89.062 (92.268)\n",
            "Epoch: [50][340/782]\tTime 0.162 (0.165)\tLoss 0.1527 (0.2204)\tPrec@1 92.188 (92.233)\n",
            "Epoch: [50][350/782]\tTime 0.166 (0.165)\tLoss 0.1686 (0.2205)\tPrec@1 92.188 (92.205)\n",
            "Epoch: [50][360/782]\tTime 0.163 (0.165)\tLoss 0.1741 (0.2206)\tPrec@1 95.312 (92.218)\n",
            "Epoch: [50][370/782]\tTime 0.164 (0.165)\tLoss 0.5132 (0.2212)\tPrec@1 82.812 (92.204)\n",
            "Epoch: [50][380/782]\tTime 0.163 (0.165)\tLoss 0.0722 (0.2213)\tPrec@1 98.438 (92.204)\n",
            "Epoch: [50][390/782]\tTime 0.164 (0.165)\tLoss 0.2108 (0.2206)\tPrec@1 92.188 (92.223)\n",
            "Epoch: [50][400/782]\tTime 0.163 (0.165)\tLoss 0.5364 (0.2215)\tPrec@1 84.375 (92.226)\n",
            "Epoch: [50][410/782]\tTime 0.165 (0.165)\tLoss 0.2061 (0.2210)\tPrec@1 92.188 (92.237)\n",
            "Epoch: [50][420/782]\tTime 0.164 (0.165)\tLoss 0.1907 (0.2208)\tPrec@1 93.750 (92.239)\n",
            "Epoch: [50][430/782]\tTime 0.165 (0.165)\tLoss 0.1253 (0.2209)\tPrec@1 96.875 (92.242)\n",
            "Epoch: [50][440/782]\tTime 0.164 (0.165)\tLoss 0.1582 (0.2215)\tPrec@1 96.875 (92.237)\n",
            "Epoch: [50][450/782]\tTime 0.165 (0.165)\tLoss 0.1451 (0.2209)\tPrec@1 95.312 (92.260)\n",
            "Epoch: [50][460/782]\tTime 0.164 (0.165)\tLoss 0.1614 (0.2201)\tPrec@1 95.312 (92.316)\n",
            "Epoch: [50][470/782]\tTime 0.164 (0.165)\tLoss 0.1963 (0.2205)\tPrec@1 89.062 (92.290)\n",
            "Epoch: [50][480/782]\tTime 0.164 (0.165)\tLoss 0.2205 (0.2208)\tPrec@1 89.062 (92.278)\n",
            "Epoch: [50][490/782]\tTime 0.163 (0.165)\tLoss 0.5729 (0.2221)\tPrec@1 79.688 (92.238)\n",
            "Epoch: [50][500/782]\tTime 0.165 (0.165)\tLoss 0.1529 (0.2215)\tPrec@1 95.312 (92.234)\n",
            "Epoch: [50][510/782]\tTime 0.164 (0.165)\tLoss 0.1341 (0.2220)\tPrec@1 96.875 (92.218)\n",
            "Epoch: [50][520/782]\tTime 0.164 (0.165)\tLoss 0.2546 (0.2225)\tPrec@1 93.750 (92.205)\n",
            "Epoch: [50][530/782]\tTime 0.173 (0.165)\tLoss 0.1390 (0.2226)\tPrec@1 96.875 (92.220)\n",
            "Epoch: [50][540/782]\tTime 0.163 (0.165)\tLoss 0.1770 (0.2229)\tPrec@1 95.312 (92.225)\n",
            "Epoch: [50][550/782]\tTime 0.165 (0.165)\tLoss 0.1405 (0.2227)\tPrec@1 95.312 (92.222)\n",
            "Epoch: [50][560/782]\tTime 0.169 (0.165)\tLoss 0.2616 (0.2225)\tPrec@1 90.625 (92.226)\n",
            "Epoch: [50][570/782]\tTime 0.162 (0.165)\tLoss 0.3044 (0.2225)\tPrec@1 92.188 (92.212)\n",
            "Epoch: [50][580/782]\tTime 0.164 (0.165)\tLoss 0.2821 (0.2233)\tPrec@1 92.188 (92.166)\n",
            "Epoch: [50][590/782]\tTime 0.165 (0.165)\tLoss 0.1923 (0.2231)\tPrec@1 93.750 (92.158)\n",
            "Epoch: [50][600/782]\tTime 0.163 (0.165)\tLoss 0.2227 (0.2249)\tPrec@1 93.750 (92.086)\n",
            "Epoch: [50][610/782]\tTime 0.165 (0.165)\tLoss 0.2452 (0.2251)\tPrec@1 93.750 (92.093)\n",
            "Epoch: [50][620/782]\tTime 0.165 (0.165)\tLoss 0.1874 (0.2254)\tPrec@1 93.750 (92.089)\n",
            "Epoch: [50][630/782]\tTime 0.163 (0.165)\tLoss 0.4745 (0.2260)\tPrec@1 84.375 (92.081)\n",
            "Epoch: [50][640/782]\tTime 0.166 (0.165)\tLoss 0.2739 (0.2264)\tPrec@1 92.188 (92.070)\n",
            "Epoch: [50][650/782]\tTime 0.163 (0.165)\tLoss 0.2293 (0.2262)\tPrec@1 92.188 (92.079)\n",
            "Epoch: [50][660/782]\tTime 0.164 (0.165)\tLoss 0.3232 (0.2259)\tPrec@1 85.938 (92.083)\n",
            "Epoch: [50][670/782]\tTime 0.164 (0.165)\tLoss 0.2340 (0.2257)\tPrec@1 89.062 (92.085)\n",
            "Epoch: [50][680/782]\tTime 0.165 (0.165)\tLoss 0.3369 (0.2258)\tPrec@1 85.938 (92.082)\n",
            "Epoch: [50][690/782]\tTime 0.165 (0.165)\tLoss 0.1945 (0.2257)\tPrec@1 90.625 (92.093)\n",
            "Epoch: [50][700/782]\tTime 0.169 (0.165)\tLoss 0.1866 (0.2254)\tPrec@1 93.750 (92.098)\n",
            "Epoch: [50][710/782]\tTime 0.164 (0.165)\tLoss 0.1100 (0.2254)\tPrec@1 96.875 (92.100)\n",
            "Epoch: [50][720/782]\tTime 0.172 (0.165)\tLoss 0.1336 (0.2254)\tPrec@1 93.750 (92.092)\n",
            "Epoch: [50][730/782]\tTime 0.164 (0.165)\tLoss 0.3875 (0.2252)\tPrec@1 85.938 (92.093)\n",
            "Epoch: [50][740/782]\tTime 0.164 (0.165)\tLoss 0.2844 (0.2246)\tPrec@1 92.188 (92.126)\n",
            "Epoch: [50][750/782]\tTime 0.165 (0.165)\tLoss 0.2379 (0.2245)\tPrec@1 90.625 (92.135)\n",
            "Epoch: [50][760/782]\tTime 0.166 (0.165)\tLoss 0.4952 (0.2248)\tPrec@1 87.500 (92.140)\n",
            "Epoch: [50][770/782]\tTime 0.163 (0.165)\tLoss 0.2753 (0.2253)\tPrec@1 90.625 (92.098)\n",
            "Epoch: [50][780/782]\tTime 0.162 (0.165)\tLoss 0.2701 (0.2260)\tPrec@1 87.500 (92.077)\n",
            "Training accuracy:  tensor(92.0740, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.1060, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.112 (0.112)\tLoss 0.5769 (0.5769)\tPrec@1 87.500 (87.500)\n",
            "Test: [10/157]\tTime 0.043 (0.047)\tLoss 0.4952 (0.4502)\tPrec@1 85.938 (87.074)\n",
            "Test: [20/157]\tTime 0.049 (0.046)\tLoss 0.5284 (0.4368)\tPrec@1 81.250 (85.938)\n",
            "Test: [30/157]\tTime 0.043 (0.046)\tLoss 0.1986 (0.4042)\tPrec@1 90.625 (86.895)\n",
            "Test: [40/157]\tTime 0.043 (0.045)\tLoss 0.7032 (0.4121)\tPrec@1 85.938 (87.043)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.4592 (0.4180)\tPrec@1 87.500 (87.071)\n",
            "Test: [60/157]\tTime 0.043 (0.045)\tLoss 0.1920 (0.4130)\tPrec@1 89.062 (87.244)\n",
            "Test: [70/157]\tTime 0.045 (0.045)\tLoss 0.2607 (0.4018)\tPrec@1 87.500 (87.544)\n",
            "Test: [80/157]\tTime 0.043 (0.044)\tLoss 0.6321 (0.4092)\tPrec@1 82.812 (87.307)\n",
            "Test: [90/157]\tTime 0.048 (0.044)\tLoss 0.5521 (0.4163)\tPrec@1 85.938 (87.139)\n",
            "Test: [100/157]\tTime 0.044 (0.044)\tLoss 0.2397 (0.4232)\tPrec@1 90.625 (86.866)\n",
            "Test: [110/157]\tTime 0.043 (0.044)\tLoss 0.3568 (0.4178)\tPrec@1 89.062 (86.965)\n",
            "Test: [120/157]\tTime 0.043 (0.044)\tLoss 0.6855 (0.4224)\tPrec@1 84.375 (86.880)\n",
            "Test: [130/157]\tTime 0.044 (0.044)\tLoss 0.5649 (0.4281)\tPrec@1 81.250 (86.784)\n",
            "Test: [140/157]\tTime 0.038 (0.044)\tLoss 0.2062 (0.4275)\tPrec@1 95.312 (86.846)\n",
            "Test: [150/157]\tTime 0.043 (0.044)\tLoss 0.3979 (0.4257)\tPrec@1 92.188 (86.972)\n",
            " * Prec@1 87.020\n",
            "Best accuracy:  tensor(88.8800, device='cuda:0')\n",
            "Epoch: [51][0/782]\tTime 0.272 (0.272)\tLoss 0.3449 (0.3449)\tPrec@1 85.938 (85.938)\n",
            "Epoch: [51][10/782]\tTime 0.165 (0.175)\tLoss 0.3430 (0.2983)\tPrec@1 89.062 (90.199)\n",
            "Epoch: [51][20/782]\tTime 0.165 (0.171)\tLoss 0.2599 (0.2921)\tPrec@1 93.750 (90.402)\n",
            "Epoch: [51][30/782]\tTime 0.167 (0.169)\tLoss 0.1519 (0.2656)\tPrec@1 95.312 (91.129)\n",
            "Epoch: [51][40/782]\tTime 0.166 (0.169)\tLoss 0.2394 (0.2475)\tPrec@1 90.625 (91.768)\n",
            "Epoch: [51][50/782]\tTime 0.166 (0.168)\tLoss 0.1364 (0.2372)\tPrec@1 96.875 (92.126)\n",
            "Epoch: [51][60/782]\tTime 0.165 (0.168)\tLoss 0.3406 (0.2351)\tPrec@1 87.500 (92.162)\n",
            "Epoch: [51][70/782]\tTime 0.165 (0.167)\tLoss 0.1760 (0.2291)\tPrec@1 95.312 (92.320)\n",
            "Epoch: [51][80/782]\tTime 0.167 (0.167)\tLoss 0.1754 (0.2278)\tPrec@1 93.750 (92.361)\n",
            "Epoch: [51][90/782]\tTime 0.166 (0.167)\tLoss 0.1649 (0.2265)\tPrec@1 95.312 (92.359)\n",
            "Epoch: [51][100/782]\tTime 0.165 (0.167)\tLoss 0.4588 (0.2259)\tPrec@1 85.938 (92.296)\n",
            "Epoch: [51][110/782]\tTime 0.168 (0.167)\tLoss 0.1911 (0.2268)\tPrec@1 90.625 (92.159)\n",
            "Epoch: [51][120/782]\tTime 0.166 (0.167)\tLoss 0.2679 (0.2251)\tPrec@1 92.188 (92.278)\n",
            "Epoch: [51][130/782]\tTime 0.164 (0.167)\tLoss 0.2205 (0.2229)\tPrec@1 92.188 (92.354)\n",
            "Epoch: [51][140/782]\tTime 0.163 (0.167)\tLoss 0.2811 (0.2233)\tPrec@1 89.062 (92.320)\n",
            "Epoch: [51][150/782]\tTime 0.164 (0.167)\tLoss 0.2136 (0.2224)\tPrec@1 89.062 (92.394)\n",
            "Epoch: [51][160/782]\tTime 0.165 (0.167)\tLoss 0.3250 (0.2253)\tPrec@1 93.750 (92.323)\n",
            "Epoch: [51][170/782]\tTime 0.164 (0.167)\tLoss 0.2149 (0.2250)\tPrec@1 90.625 (92.343)\n",
            "Epoch: [51][180/782]\tTime 0.165 (0.167)\tLoss 0.1800 (0.2267)\tPrec@1 92.188 (92.248)\n",
            "Epoch: [51][190/782]\tTime 0.165 (0.167)\tLoss 0.3825 (0.2247)\tPrec@1 89.062 (92.310)\n",
            "Epoch: [51][200/782]\tTime 0.167 (0.167)\tLoss 0.3103 (0.2236)\tPrec@1 89.062 (92.312)\n",
            "Epoch: [51][210/782]\tTime 0.166 (0.167)\tLoss 0.1240 (0.2237)\tPrec@1 96.875 (92.328)\n",
            "Epoch: [51][220/782]\tTime 0.164 (0.166)\tLoss 0.1342 (0.2217)\tPrec@1 95.312 (92.393)\n",
            "Epoch: [51][230/782]\tTime 0.165 (0.166)\tLoss 0.2030 (0.2217)\tPrec@1 90.625 (92.370)\n",
            "Epoch: [51][240/782]\tTime 0.163 (0.166)\tLoss 0.1794 (0.2221)\tPrec@1 96.875 (92.376)\n",
            "Epoch: [51][250/782]\tTime 0.166 (0.166)\tLoss 0.1125 (0.2220)\tPrec@1 96.875 (92.393)\n",
            "Epoch: [51][260/782]\tTime 0.167 (0.166)\tLoss 0.1524 (0.2228)\tPrec@1 90.625 (92.349)\n",
            "Epoch: [51][270/782]\tTime 0.163 (0.166)\tLoss 0.1377 (0.2226)\tPrec@1 93.750 (92.332)\n",
            "Epoch: [51][280/782]\tTime 0.169 (0.166)\tLoss 0.1852 (0.2218)\tPrec@1 90.625 (92.293)\n",
            "Epoch: [51][290/782]\tTime 0.164 (0.166)\tLoss 0.2435 (0.2227)\tPrec@1 89.062 (92.241)\n",
            "Epoch: [51][300/782]\tTime 0.164 (0.166)\tLoss 0.1916 (0.2228)\tPrec@1 93.750 (92.239)\n",
            "Epoch: [51][310/782]\tTime 0.166 (0.166)\tLoss 0.2005 (0.2238)\tPrec@1 89.062 (92.193)\n",
            "Epoch: [51][320/782]\tTime 0.164 (0.166)\tLoss 0.1836 (0.2225)\tPrec@1 92.188 (92.202)\n",
            "Epoch: [51][330/782]\tTime 0.170 (0.166)\tLoss 0.1301 (0.2213)\tPrec@1 95.312 (92.225)\n",
            "Epoch: [51][340/782]\tTime 0.164 (0.166)\tLoss 0.2187 (0.2223)\tPrec@1 93.750 (92.201)\n",
            "Epoch: [51][350/782]\tTime 0.165 (0.166)\tLoss 0.1805 (0.2228)\tPrec@1 93.750 (92.174)\n",
            "Epoch: [51][360/782]\tTime 0.162 (0.166)\tLoss 0.2545 (0.2241)\tPrec@1 90.625 (92.149)\n",
            "Epoch: [51][370/782]\tTime 0.167 (0.166)\tLoss 0.1773 (0.2231)\tPrec@1 95.312 (92.204)\n",
            "Epoch: [51][380/782]\tTime 0.164 (0.166)\tLoss 0.2267 (0.2229)\tPrec@1 90.625 (92.204)\n",
            "Epoch: [51][390/782]\tTime 0.166 (0.166)\tLoss 0.2931 (0.2244)\tPrec@1 90.625 (92.156)\n",
            "Epoch: [51][400/782]\tTime 0.166 (0.166)\tLoss 0.2391 (0.2248)\tPrec@1 92.188 (92.129)\n",
            "Epoch: [51][410/782]\tTime 0.163 (0.166)\tLoss 0.2457 (0.2253)\tPrec@1 89.062 (92.119)\n",
            "Epoch: [51][420/782]\tTime 0.164 (0.166)\tLoss 0.1025 (0.2252)\tPrec@1 95.312 (92.143)\n",
            "Epoch: [51][430/782]\tTime 0.164 (0.166)\tLoss 0.4416 (0.2264)\tPrec@1 84.375 (92.086)\n",
            "Epoch: [51][440/782]\tTime 0.169 (0.166)\tLoss 0.2179 (0.2268)\tPrec@1 92.188 (92.074)\n",
            "Epoch: [51][450/782]\tTime 0.165 (0.166)\tLoss 0.2620 (0.2270)\tPrec@1 89.062 (92.070)\n",
            "Epoch: [51][460/782]\tTime 0.166 (0.166)\tLoss 0.1462 (0.2266)\tPrec@1 93.750 (92.099)\n",
            "Epoch: [51][470/782]\tTime 0.164 (0.166)\tLoss 0.1179 (0.2268)\tPrec@1 95.312 (92.101)\n",
            "Epoch: [51][480/782]\tTime 0.164 (0.166)\tLoss 0.3015 (0.2280)\tPrec@1 89.062 (92.045)\n",
            "Epoch: [51][490/782]\tTime 0.166 (0.166)\tLoss 0.2316 (0.2278)\tPrec@1 95.312 (92.047)\n",
            "Epoch: [51][500/782]\tTime 0.164 (0.166)\tLoss 0.3209 (0.2279)\tPrec@1 89.062 (92.038)\n",
            "Epoch: [51][510/782]\tTime 0.166 (0.166)\tLoss 0.1940 (0.2279)\tPrec@1 93.750 (92.047)\n",
            "Epoch: [51][520/782]\tTime 0.165 (0.166)\tLoss 0.2602 (0.2283)\tPrec@1 89.062 (92.023)\n",
            "Epoch: [51][530/782]\tTime 0.167 (0.166)\tLoss 0.1974 (0.2279)\tPrec@1 92.188 (92.055)\n",
            "Epoch: [51][540/782]\tTime 0.166 (0.166)\tLoss 0.1709 (0.2282)\tPrec@1 90.625 (92.026)\n",
            "Epoch: [51][550/782]\tTime 0.163 (0.166)\tLoss 0.3630 (0.2286)\tPrec@1 90.625 (92.015)\n",
            "Epoch: [51][560/782]\tTime 0.165 (0.166)\tLoss 0.1490 (0.2279)\tPrec@1 93.750 (92.037)\n",
            "Epoch: [51][570/782]\tTime 0.166 (0.166)\tLoss 0.3032 (0.2279)\tPrec@1 90.625 (92.048)\n",
            "Epoch: [51][580/782]\tTime 0.164 (0.166)\tLoss 0.3318 (0.2277)\tPrec@1 85.938 (92.056)\n",
            "Epoch: [51][590/782]\tTime 0.164 (0.166)\tLoss 0.3028 (0.2284)\tPrec@1 90.625 (92.029)\n",
            "Epoch: [51][600/782]\tTime 0.167 (0.166)\tLoss 0.0949 (0.2293)\tPrec@1 98.438 (92.026)\n",
            "Epoch: [51][610/782]\tTime 0.164 (0.166)\tLoss 0.1714 (0.2290)\tPrec@1 92.188 (92.026)\n",
            "Epoch: [51][620/782]\tTime 0.163 (0.166)\tLoss 0.2995 (0.2292)\tPrec@1 89.062 (92.024)\n",
            "Epoch: [51][630/782]\tTime 0.167 (0.166)\tLoss 0.2277 (0.2288)\tPrec@1 90.625 (92.036)\n",
            "Epoch: [51][640/782]\tTime 0.164 (0.166)\tLoss 0.2840 (0.2290)\tPrec@1 89.062 (92.039)\n",
            "Epoch: [51][650/782]\tTime 0.163 (0.166)\tLoss 0.1025 (0.2281)\tPrec@1 96.875 (92.070)\n",
            "Epoch: [51][660/782]\tTime 0.164 (0.166)\tLoss 0.2418 (0.2280)\tPrec@1 92.188 (92.076)\n",
            "Epoch: [51][670/782]\tTime 0.165 (0.166)\tLoss 0.2961 (0.2281)\tPrec@1 92.188 (92.073)\n",
            "Epoch: [51][680/782]\tTime 0.165 (0.166)\tLoss 0.1993 (0.2280)\tPrec@1 92.188 (92.061)\n",
            "Epoch: [51][690/782]\tTime 0.164 (0.166)\tLoss 0.1968 (0.2283)\tPrec@1 93.750 (92.052)\n",
            "Epoch: [51][700/782]\tTime 0.166 (0.166)\tLoss 0.1535 (0.2286)\tPrec@1 96.875 (92.031)\n",
            "Epoch: [51][710/782]\tTime 0.164 (0.166)\tLoss 0.3082 (0.2286)\tPrec@1 87.500 (92.023)\n",
            "Epoch: [51][720/782]\tTime 0.165 (0.166)\tLoss 0.2612 (0.2289)\tPrec@1 90.625 (92.023)\n",
            "Epoch: [51][730/782]\tTime 0.163 (0.166)\tLoss 0.1656 (0.2289)\tPrec@1 95.312 (92.025)\n",
            "Epoch: [51][740/782]\tTime 0.164 (0.166)\tLoss 0.2145 (0.2292)\tPrec@1 93.750 (92.036)\n",
            "Epoch: [51][750/782]\tTime 0.163 (0.166)\tLoss 0.1675 (0.2292)\tPrec@1 93.750 (92.038)\n",
            "Epoch: [51][760/782]\tTime 0.164 (0.166)\tLoss 0.2264 (0.2292)\tPrec@1 93.750 (92.031)\n",
            "Epoch: [51][770/782]\tTime 0.164 (0.166)\tLoss 0.1897 (0.2288)\tPrec@1 92.188 (92.050)\n",
            "Epoch: [51][780/782]\tTime 0.162 (0.166)\tLoss 0.2833 (0.2291)\tPrec@1 89.062 (92.045)\n",
            "Training accuracy:  tensor(92.0440, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.1060, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.115 (0.115)\tLoss 0.3937 (0.3937)\tPrec@1 84.375 (84.375)\n",
            "Test: [10/157]\tTime 0.038 (0.048)\tLoss 0.4256 (0.4646)\tPrec@1 89.062 (86.648)\n",
            "Test: [20/157]\tTime 0.058 (0.046)\tLoss 0.1898 (0.4300)\tPrec@1 96.875 (86.905)\n",
            "Test: [30/157]\tTime 0.044 (0.046)\tLoss 0.5137 (0.4301)\tPrec@1 85.938 (86.895)\n",
            "Test: [40/157]\tTime 0.043 (0.045)\tLoss 0.4259 (0.4246)\tPrec@1 84.375 (86.928)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.6077 (0.4325)\tPrec@1 87.500 (86.857)\n",
            "Test: [60/157]\tTime 0.042 (0.045)\tLoss 0.3647 (0.4341)\tPrec@1 90.625 (87.013)\n",
            "Test: [70/157]\tTime 0.044 (0.045)\tLoss 0.2789 (0.4327)\tPrec@1 90.625 (86.994)\n",
            "Test: [80/157]\tTime 0.043 (0.045)\tLoss 0.3283 (0.4201)\tPrec@1 90.625 (87.346)\n",
            "Test: [90/157]\tTime 0.045 (0.044)\tLoss 0.3698 (0.4263)\tPrec@1 89.062 (87.139)\n",
            "Test: [100/157]\tTime 0.043 (0.044)\tLoss 0.4950 (0.4314)\tPrec@1 87.500 (86.959)\n",
            "Test: [110/157]\tTime 0.044 (0.044)\tLoss 0.3936 (0.4288)\tPrec@1 89.062 (87.021)\n",
            "Test: [120/157]\tTime 0.043 (0.044)\tLoss 0.7302 (0.4324)\tPrec@1 84.375 (87.061)\n",
            "Test: [130/157]\tTime 0.044 (0.044)\tLoss 0.4529 (0.4350)\tPrec@1 87.500 (86.999)\n",
            "Test: [140/157]\tTime 0.043 (0.044)\tLoss 0.2988 (0.4356)\tPrec@1 87.500 (86.902)\n",
            "Test: [150/157]\tTime 0.043 (0.044)\tLoss 0.4775 (0.4292)\tPrec@1 82.812 (86.983)\n",
            " * Prec@1 87.090\n",
            "Best accuracy:  tensor(88.8800, device='cuda:0')\n",
            "Epoch: [52][0/782]\tTime 0.261 (0.261)\tLoss 0.2450 (0.2450)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [52][10/782]\tTime 0.164 (0.174)\tLoss 0.1904 (0.2636)\tPrec@1 90.625 (91.619)\n",
            "Epoch: [52][20/782]\tTime 0.164 (0.170)\tLoss 0.1888 (0.2427)\tPrec@1 95.312 (92.188)\n",
            "Epoch: [52][30/782]\tTime 0.167 (0.168)\tLoss 0.3277 (0.2312)\tPrec@1 89.062 (92.288)\n",
            "Epoch: [52][40/782]\tTime 0.163 (0.167)\tLoss 0.2653 (0.2258)\tPrec@1 90.625 (92.416)\n",
            "Epoch: [52][50/782]\tTime 0.163 (0.167)\tLoss 0.1017 (0.2191)\tPrec@1 98.438 (92.616)\n",
            "Epoch: [52][60/782]\tTime 0.165 (0.167)\tLoss 0.1138 (0.2213)\tPrec@1 95.312 (92.546)\n",
            "Epoch: [52][70/782]\tTime 0.164 (0.166)\tLoss 0.2099 (0.2182)\tPrec@1 90.625 (92.606)\n",
            "Epoch: [52][80/782]\tTime 0.162 (0.166)\tLoss 0.1301 (0.2166)\tPrec@1 98.438 (92.612)\n",
            "Epoch: [52][90/782]\tTime 0.164 (0.166)\tLoss 0.1787 (0.2170)\tPrec@1 92.188 (92.531)\n",
            "Epoch: [52][100/782]\tTime 0.165 (0.166)\tLoss 0.3511 (0.2186)\tPrec@1 85.938 (92.497)\n",
            "Epoch: [52][110/782]\tTime 0.164 (0.166)\tLoss 0.0409 (0.2150)\tPrec@1 100.000 (92.680)\n",
            "Epoch: [52][120/782]\tTime 0.164 (0.166)\tLoss 0.0828 (0.2149)\tPrec@1 98.438 (92.665)\n",
            "Epoch: [52][130/782]\tTime 0.164 (0.166)\tLoss 0.3762 (0.2128)\tPrec@1 85.938 (92.688)\n",
            "Epoch: [52][140/782]\tTime 0.164 (0.166)\tLoss 0.2178 (0.2100)\tPrec@1 95.312 (92.797)\n",
            "Epoch: [52][150/782]\tTime 0.164 (0.166)\tLoss 0.1837 (0.2100)\tPrec@1 95.312 (92.788)\n",
            "Epoch: [52][160/782]\tTime 0.164 (0.165)\tLoss 0.1608 (0.2112)\tPrec@1 95.312 (92.760)\n",
            "Epoch: [52][170/782]\tTime 0.165 (0.165)\tLoss 0.3150 (0.2122)\tPrec@1 89.062 (92.736)\n",
            "Epoch: [52][180/782]\tTime 0.165 (0.165)\tLoss 0.3696 (0.2137)\tPrec@1 89.062 (92.671)\n",
            "Epoch: [52][190/782]\tTime 0.164 (0.165)\tLoss 0.2141 (0.2133)\tPrec@1 89.062 (92.613)\n",
            "Epoch: [52][200/782]\tTime 0.165 (0.165)\tLoss 0.2352 (0.2127)\tPrec@1 92.188 (92.646)\n",
            "Epoch: [52][210/782]\tTime 0.165 (0.165)\tLoss 0.2149 (0.2145)\tPrec@1 90.625 (92.528)\n",
            "Epoch: [52][220/782]\tTime 0.163 (0.165)\tLoss 0.0995 (0.2132)\tPrec@1 96.875 (92.527)\n",
            "Epoch: [52][230/782]\tTime 0.163 (0.165)\tLoss 0.1115 (0.2121)\tPrec@1 98.438 (92.620)\n",
            "Epoch: [52][240/782]\tTime 0.165 (0.165)\tLoss 0.2460 (0.2141)\tPrec@1 89.062 (92.538)\n",
            "Epoch: [52][250/782]\tTime 0.163 (0.165)\tLoss 0.1690 (0.2133)\tPrec@1 92.188 (92.573)\n",
            "Epoch: [52][260/782]\tTime 0.166 (0.165)\tLoss 0.3110 (0.2125)\tPrec@1 89.062 (92.577)\n",
            "Epoch: [52][270/782]\tTime 0.163 (0.165)\tLoss 0.2424 (0.2137)\tPrec@1 87.500 (92.505)\n",
            "Epoch: [52][280/782]\tTime 0.164 (0.165)\tLoss 0.2503 (0.2136)\tPrec@1 90.625 (92.471)\n",
            "Epoch: [52][290/782]\tTime 0.165 (0.165)\tLoss 0.2442 (0.2130)\tPrec@1 92.188 (92.504)\n",
            "Epoch: [52][300/782]\tTime 0.163 (0.165)\tLoss 0.2131 (0.2131)\tPrec@1 92.188 (92.489)\n",
            "Epoch: [52][310/782]\tTime 0.165 (0.165)\tLoss 0.1418 (0.2135)\tPrec@1 96.875 (92.454)\n",
            "Epoch: [52][320/782]\tTime 0.163 (0.165)\tLoss 0.1995 (0.2132)\tPrec@1 93.750 (92.489)\n",
            "Epoch: [52][330/782]\tTime 0.163 (0.165)\tLoss 0.3344 (0.2141)\tPrec@1 85.938 (92.466)\n",
            "Epoch: [52][340/782]\tTime 0.164 (0.165)\tLoss 0.4053 (0.2155)\tPrec@1 79.688 (92.421)\n",
            "Epoch: [52][350/782]\tTime 0.162 (0.165)\tLoss 0.1994 (0.2155)\tPrec@1 95.312 (92.428)\n",
            "Epoch: [52][360/782]\tTime 0.164 (0.165)\tLoss 0.2722 (0.2164)\tPrec@1 89.062 (92.391)\n",
            "Epoch: [52][370/782]\tTime 0.163 (0.165)\tLoss 0.3738 (0.2166)\tPrec@1 89.062 (92.394)\n",
            "Epoch: [52][380/782]\tTime 0.163 (0.165)\tLoss 0.3677 (0.2174)\tPrec@1 90.625 (92.339)\n",
            "Epoch: [52][390/782]\tTime 0.164 (0.165)\tLoss 0.2148 (0.2172)\tPrec@1 93.750 (92.343)\n",
            "Epoch: [52][400/782]\tTime 0.164 (0.165)\tLoss 0.2476 (0.2184)\tPrec@1 92.188 (92.312)\n",
            "Epoch: [52][410/782]\tTime 0.164 (0.165)\tLoss 0.1236 (0.2184)\tPrec@1 95.312 (92.286)\n",
            "Epoch: [52][420/782]\tTime 0.163 (0.165)\tLoss 0.2665 (0.2190)\tPrec@1 89.062 (92.251)\n",
            "Epoch: [52][430/782]\tTime 0.164 (0.165)\tLoss 0.2489 (0.2179)\tPrec@1 92.188 (92.289)\n",
            "Epoch: [52][440/782]\tTime 0.164 (0.165)\tLoss 0.2166 (0.2185)\tPrec@1 93.750 (92.248)\n",
            "Epoch: [52][450/782]\tTime 0.164 (0.165)\tLoss 0.1326 (0.2189)\tPrec@1 92.188 (92.233)\n",
            "Epoch: [52][460/782]\tTime 0.165 (0.165)\tLoss 0.2895 (0.2187)\tPrec@1 90.625 (92.252)\n",
            "Epoch: [52][470/782]\tTime 0.163 (0.165)\tLoss 0.4432 (0.2202)\tPrec@1 89.062 (92.188)\n",
            "Epoch: [52][480/782]\tTime 0.164 (0.165)\tLoss 0.2183 (0.2203)\tPrec@1 93.750 (92.181)\n",
            "Epoch: [52][490/782]\tTime 0.163 (0.165)\tLoss 0.3892 (0.2212)\tPrec@1 84.375 (92.149)\n",
            "Epoch: [52][500/782]\tTime 0.163 (0.165)\tLoss 0.2203 (0.2218)\tPrec@1 89.062 (92.128)\n",
            "Epoch: [52][510/782]\tTime 0.166 (0.165)\tLoss 0.1870 (0.2231)\tPrec@1 93.750 (92.102)\n",
            "Epoch: [52][520/782]\tTime 0.164 (0.165)\tLoss 0.2718 (0.2227)\tPrec@1 87.500 (92.119)\n",
            "Epoch: [52][530/782]\tTime 0.164 (0.165)\tLoss 0.2941 (0.2227)\tPrec@1 89.062 (92.114)\n",
            "Epoch: [52][540/782]\tTime 0.164 (0.165)\tLoss 0.3628 (0.2224)\tPrec@1 85.938 (92.124)\n",
            "Epoch: [52][550/782]\tTime 0.165 (0.165)\tLoss 0.1959 (0.2219)\tPrec@1 93.750 (92.148)\n",
            "Epoch: [52][560/782]\tTime 0.163 (0.165)\tLoss 0.3162 (0.2219)\tPrec@1 92.188 (92.143)\n",
            "Epoch: [52][570/782]\tTime 0.164 (0.165)\tLoss 0.2797 (0.2217)\tPrec@1 92.188 (92.171)\n",
            "Epoch: [52][580/782]\tTime 0.164 (0.165)\tLoss 0.1463 (0.2220)\tPrec@1 95.312 (92.179)\n",
            "Epoch: [52][590/782]\tTime 0.162 (0.165)\tLoss 0.0922 (0.2217)\tPrec@1 98.438 (92.198)\n",
            "Epoch: [52][600/782]\tTime 0.166 (0.165)\tLoss 0.1016 (0.2210)\tPrec@1 96.875 (92.229)\n",
            "Epoch: [52][610/782]\tTime 0.163 (0.165)\tLoss 0.2425 (0.2208)\tPrec@1 90.625 (92.234)\n",
            "Epoch: [52][620/782]\tTime 0.161 (0.165)\tLoss 0.0943 (0.2199)\tPrec@1 96.875 (92.276)\n",
            "Epoch: [52][630/782]\tTime 0.165 (0.165)\tLoss 0.1318 (0.2202)\tPrec@1 95.312 (92.277)\n",
            "Epoch: [52][640/782]\tTime 0.163 (0.165)\tLoss 0.1556 (0.2201)\tPrec@1 93.750 (92.268)\n",
            "Epoch: [52][650/782]\tTime 0.165 (0.165)\tLoss 0.2016 (0.2200)\tPrec@1 92.188 (92.260)\n",
            "Epoch: [52][660/782]\tTime 0.165 (0.165)\tLoss 0.2348 (0.2200)\tPrec@1 93.750 (92.266)\n",
            "Epoch: [52][670/782]\tTime 0.162 (0.165)\tLoss 0.2702 (0.2206)\tPrec@1 89.062 (92.246)\n",
            "Epoch: [52][680/782]\tTime 0.164 (0.165)\tLoss 0.1634 (0.2210)\tPrec@1 93.750 (92.227)\n",
            "Epoch: [52][690/782]\tTime 0.165 (0.165)\tLoss 0.3418 (0.2213)\tPrec@1 84.375 (92.194)\n",
            "Epoch: [52][700/782]\tTime 0.165 (0.165)\tLoss 0.2221 (0.2215)\tPrec@1 90.625 (92.185)\n",
            "Epoch: [52][710/782]\tTime 0.170 (0.165)\tLoss 0.1918 (0.2216)\tPrec@1 93.750 (92.177)\n",
            "Epoch: [52][720/782]\tTime 0.163 (0.165)\tLoss 0.2889 (0.2217)\tPrec@1 92.188 (92.192)\n",
            "Epoch: [52][730/782]\tTime 0.164 (0.165)\tLoss 0.1376 (0.2218)\tPrec@1 95.312 (92.192)\n",
            "Epoch: [52][740/782]\tTime 0.165 (0.165)\tLoss 0.2122 (0.2221)\tPrec@1 87.500 (92.169)\n",
            "Epoch: [52][750/782]\tTime 0.164 (0.165)\tLoss 0.1439 (0.2219)\tPrec@1 95.312 (92.190)\n",
            "Epoch: [52][760/782]\tTime 0.162 (0.165)\tLoss 0.1247 (0.2217)\tPrec@1 95.312 (92.202)\n",
            "Epoch: [52][770/782]\tTime 0.167 (0.165)\tLoss 0.2383 (0.2217)\tPrec@1 89.062 (92.200)\n",
            "Epoch: [52][780/782]\tTime 0.162 (0.165)\tLoss 0.2303 (0.2221)\tPrec@1 89.062 (92.186)\n",
            "Training accuracy:  tensor(92.1860, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.1860, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.116 (0.116)\tLoss 0.2719 (0.2719)\tPrec@1 92.188 (92.188)\n",
            "Test: [10/157]\tTime 0.042 (0.048)\tLoss 0.6085 (0.4445)\tPrec@1 79.688 (86.648)\n",
            "Test: [20/157]\tTime 0.054 (0.046)\tLoss 0.4805 (0.4633)\tPrec@1 87.500 (86.235)\n",
            "Test: [30/157]\tTime 0.038 (0.046)\tLoss 0.8295 (0.4815)\tPrec@1 78.125 (85.938)\n",
            "Test: [40/157]\tTime 0.043 (0.045)\tLoss 0.1786 (0.4754)\tPrec@1 93.750 (85.938)\n",
            "Test: [50/157]\tTime 0.044 (0.045)\tLoss 0.5362 (0.4743)\tPrec@1 82.812 (86.029)\n",
            "Test: [60/157]\tTime 0.043 (0.045)\tLoss 0.7331 (0.4848)\tPrec@1 81.250 (85.630)\n",
            "Test: [70/157]\tTime 0.043 (0.045)\tLoss 0.4392 (0.4671)\tPrec@1 87.500 (86.026)\n",
            "Test: [80/157]\tTime 0.043 (0.045)\tLoss 0.7070 (0.4727)\tPrec@1 81.250 (85.976)\n",
            "Test: [90/157]\tTime 0.043 (0.045)\tLoss 0.2126 (0.4673)\tPrec@1 95.312 (86.023)\n",
            "Test: [100/157]\tTime 0.039 (0.044)\tLoss 0.7846 (0.4713)\tPrec@1 87.500 (86.139)\n",
            "Test: [110/157]\tTime 0.045 (0.044)\tLoss 0.1623 (0.4637)\tPrec@1 93.750 (86.430)\n",
            "Test: [120/157]\tTime 0.045 (0.044)\tLoss 0.6284 (0.4610)\tPrec@1 82.812 (86.506)\n",
            "Test: [130/157]\tTime 0.043 (0.044)\tLoss 0.5286 (0.4623)\tPrec@1 84.375 (86.558)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.4675 (0.4605)\tPrec@1 85.938 (86.547)\n",
            "Test: [150/157]\tTime 0.043 (0.044)\tLoss 0.3730 (0.4643)\tPrec@1 85.938 (86.496)\n",
            " * Prec@1 86.480\n",
            "Best accuracy:  tensor(88.8800, device='cuda:0')\n",
            "Epoch: [53][0/782]\tTime 0.264 (0.264)\tLoss 0.3105 (0.3105)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [53][10/782]\tTime 0.163 (0.174)\tLoss 0.2152 (0.2130)\tPrec@1 93.750 (92.330)\n",
            "Epoch: [53][20/782]\tTime 0.164 (0.170)\tLoss 0.1460 (0.2145)\tPrec@1 95.312 (92.708)\n",
            "Epoch: [53][30/782]\tTime 0.164 (0.168)\tLoss 0.1795 (0.2127)\tPrec@1 93.750 (92.591)\n",
            "Epoch: [53][40/782]\tTime 0.163 (0.167)\tLoss 0.2139 (0.2245)\tPrec@1 92.188 (91.883)\n",
            "Epoch: [53][50/782]\tTime 0.165 (0.167)\tLoss 0.0719 (0.2193)\tPrec@1 100.000 (92.341)\n",
            "Epoch: [53][60/782]\tTime 0.165 (0.167)\tLoss 0.3329 (0.2144)\tPrec@1 85.938 (92.418)\n",
            "Epoch: [53][70/782]\tTime 0.165 (0.166)\tLoss 0.2761 (0.2144)\tPrec@1 89.062 (92.452)\n",
            "Epoch: [53][80/782]\tTime 0.165 (0.166)\tLoss 0.0499 (0.2101)\tPrec@1 98.438 (92.728)\n",
            "Epoch: [53][90/782]\tTime 0.165 (0.166)\tLoss 0.1173 (0.2061)\tPrec@1 95.312 (92.857)\n",
            "Epoch: [53][100/782]\tTime 0.165 (0.166)\tLoss 0.0973 (0.2057)\tPrec@1 98.438 (92.899)\n",
            "Epoch: [53][110/782]\tTime 0.162 (0.166)\tLoss 0.1506 (0.2036)\tPrec@1 93.750 (92.976)\n",
            "Epoch: [53][120/782]\tTime 0.164 (0.166)\tLoss 0.1669 (0.2036)\tPrec@1 93.750 (93.053)\n",
            "Epoch: [53][130/782]\tTime 0.164 (0.166)\tLoss 0.1941 (0.2055)\tPrec@1 92.188 (93.070)\n",
            "Epoch: [53][140/782]\tTime 0.168 (0.166)\tLoss 0.1260 (0.2073)\tPrec@1 93.750 (92.875)\n",
            "Epoch: [53][150/782]\tTime 0.165 (0.166)\tLoss 0.1580 (0.2060)\tPrec@1 93.750 (92.881)\n",
            "Epoch: [53][160/782]\tTime 0.164 (0.166)\tLoss 0.1441 (0.2062)\tPrec@1 96.875 (92.906)\n",
            "Epoch: [53][170/782]\tTime 0.164 (0.166)\tLoss 0.0956 (0.2039)\tPrec@1 98.438 (92.982)\n",
            "Epoch: [53][180/782]\tTime 0.166 (0.166)\tLoss 0.1259 (0.2063)\tPrec@1 93.750 (92.869)\n",
            "Epoch: [53][190/782]\tTime 0.163 (0.166)\tLoss 0.2221 (0.2056)\tPrec@1 93.750 (92.899)\n",
            "Epoch: [53][200/782]\tTime 0.165 (0.166)\tLoss 0.2141 (0.2072)\tPrec@1 92.188 (92.864)\n",
            "Epoch: [53][210/782]\tTime 0.165 (0.166)\tLoss 0.3013 (0.2075)\tPrec@1 85.938 (92.839)\n",
            "Epoch: [53][220/782]\tTime 0.164 (0.166)\tLoss 0.2026 (0.2092)\tPrec@1 95.312 (92.803)\n",
            "Epoch: [53][230/782]\tTime 0.166 (0.166)\tLoss 0.2969 (0.2111)\tPrec@1 89.062 (92.702)\n",
            "Epoch: [53][240/782]\tTime 0.164 (0.166)\tLoss 0.1981 (0.2111)\tPrec@1 90.625 (92.667)\n",
            "Epoch: [53][250/782]\tTime 0.166 (0.166)\tLoss 0.1437 (0.2119)\tPrec@1 93.750 (92.642)\n",
            "Epoch: [53][260/782]\tTime 0.167 (0.166)\tLoss 0.2390 (0.2135)\tPrec@1 89.062 (92.625)\n",
            "Epoch: [53][270/782]\tTime 0.164 (0.166)\tLoss 0.1956 (0.2143)\tPrec@1 95.312 (92.614)\n",
            "Epoch: [53][280/782]\tTime 0.163 (0.166)\tLoss 0.2598 (0.2151)\tPrec@1 92.188 (92.610)\n",
            "Epoch: [53][290/782]\tTime 0.165 (0.166)\tLoss 0.2730 (0.2158)\tPrec@1 92.188 (92.553)\n",
            "Epoch: [53][300/782]\tTime 0.165 (0.166)\tLoss 0.3128 (0.2167)\tPrec@1 87.500 (92.520)\n",
            "Epoch: [53][310/782]\tTime 0.165 (0.166)\tLoss 0.2706 (0.2177)\tPrec@1 85.938 (92.459)\n",
            "Epoch: [53][320/782]\tTime 0.170 (0.166)\tLoss 0.2857 (0.2193)\tPrec@1 90.625 (92.431)\n",
            "Epoch: [53][330/782]\tTime 0.166 (0.166)\tLoss 0.2163 (0.2194)\tPrec@1 92.188 (92.424)\n",
            "Epoch: [53][340/782]\tTime 0.166 (0.166)\tLoss 0.3272 (0.2190)\tPrec@1 90.625 (92.449)\n",
            "Epoch: [53][350/782]\tTime 0.167 (0.166)\tLoss 0.1845 (0.2178)\tPrec@1 95.312 (92.481)\n",
            "Epoch: [53][360/782]\tTime 0.166 (0.166)\tLoss 0.1976 (0.2175)\tPrec@1 92.188 (92.486)\n",
            "Epoch: [53][370/782]\tTime 0.167 (0.166)\tLoss 0.2255 (0.2180)\tPrec@1 92.188 (92.470)\n",
            "Epoch: [53][380/782]\tTime 0.164 (0.166)\tLoss 0.3714 (0.2206)\tPrec@1 90.625 (92.384)\n",
            "Epoch: [53][390/782]\tTime 0.165 (0.166)\tLoss 0.1639 (0.2195)\tPrec@1 92.188 (92.419)\n",
            "Epoch: [53][400/782]\tTime 0.165 (0.166)\tLoss 0.2390 (0.2198)\tPrec@1 92.188 (92.433)\n",
            "Epoch: [53][410/782]\tTime 0.165 (0.166)\tLoss 0.1858 (0.2197)\tPrec@1 93.750 (92.431)\n",
            "Epoch: [53][420/782]\tTime 0.165 (0.166)\tLoss 0.3268 (0.2191)\tPrec@1 87.500 (92.451)\n",
            "Epoch: [53][430/782]\tTime 0.164 (0.166)\tLoss 0.1853 (0.2184)\tPrec@1 92.188 (92.470)\n",
            "Epoch: [53][440/782]\tTime 0.164 (0.166)\tLoss 0.1810 (0.2185)\tPrec@1 92.188 (92.467)\n",
            "Epoch: [53][450/782]\tTime 0.164 (0.166)\tLoss 0.3148 (0.2177)\tPrec@1 87.500 (92.485)\n",
            "Epoch: [53][460/782]\tTime 0.167 (0.166)\tLoss 0.2383 (0.2185)\tPrec@1 90.625 (92.442)\n",
            "Epoch: [53][470/782]\tTime 0.163 (0.166)\tLoss 0.1371 (0.2186)\tPrec@1 95.312 (92.433)\n",
            "Epoch: [53][480/782]\tTime 0.163 (0.166)\tLoss 0.3053 (0.2187)\tPrec@1 90.625 (92.434)\n",
            "Epoch: [53][490/782]\tTime 0.165 (0.166)\tLoss 0.1772 (0.2184)\tPrec@1 90.625 (92.442)\n",
            "Epoch: [53][500/782]\tTime 0.163 (0.166)\tLoss 0.2548 (0.2185)\tPrec@1 93.750 (92.434)\n",
            "Epoch: [53][510/782]\tTime 0.164 (0.166)\tLoss 0.1709 (0.2179)\tPrec@1 93.750 (92.454)\n",
            "Epoch: [53][520/782]\tTime 0.165 (0.166)\tLoss 0.2288 (0.2180)\tPrec@1 92.188 (92.445)\n",
            "Epoch: [53][530/782]\tTime 0.166 (0.166)\tLoss 0.1450 (0.2180)\tPrec@1 93.750 (92.435)\n",
            "Epoch: [53][540/782]\tTime 0.165 (0.166)\tLoss 0.1732 (0.2187)\tPrec@1 93.750 (92.419)\n",
            "Epoch: [53][550/782]\tTime 0.164 (0.166)\tLoss 0.1646 (0.2183)\tPrec@1 92.188 (92.426)\n",
            "Epoch: [53][560/782]\tTime 0.164 (0.166)\tLoss 0.3356 (0.2197)\tPrec@1 85.938 (92.363)\n",
            "Epoch: [53][570/782]\tTime 0.164 (0.166)\tLoss 0.2942 (0.2203)\tPrec@1 90.625 (92.365)\n",
            "Epoch: [53][580/782]\tTime 0.165 (0.166)\tLoss 0.2993 (0.2211)\tPrec@1 90.625 (92.343)\n",
            "Epoch: [53][590/782]\tTime 0.162 (0.166)\tLoss 0.3268 (0.2212)\tPrec@1 89.062 (92.346)\n",
            "Epoch: [53][600/782]\tTime 0.166 (0.166)\tLoss 0.1890 (0.2207)\tPrec@1 92.188 (92.364)\n",
            "Epoch: [53][610/782]\tTime 0.166 (0.166)\tLoss 0.4131 (0.2218)\tPrec@1 89.062 (92.333)\n",
            "Epoch: [53][620/782]\tTime 0.164 (0.166)\tLoss 0.1580 (0.2224)\tPrec@1 96.875 (92.306)\n",
            "Epoch: [53][630/782]\tTime 0.164 (0.166)\tLoss 0.1717 (0.2226)\tPrec@1 92.188 (92.299)\n",
            "Epoch: [53][640/782]\tTime 0.165 (0.166)\tLoss 0.2701 (0.2225)\tPrec@1 90.625 (92.309)\n",
            "Epoch: [53][650/782]\tTime 0.163 (0.166)\tLoss 0.2703 (0.2221)\tPrec@1 90.625 (92.329)\n",
            "Epoch: [53][660/782]\tTime 0.167 (0.166)\tLoss 0.1492 (0.2225)\tPrec@1 92.188 (92.320)\n",
            "Epoch: [53][670/782]\tTime 0.171 (0.166)\tLoss 0.2409 (0.2227)\tPrec@1 93.750 (92.316)\n",
            "Epoch: [53][680/782]\tTime 0.163 (0.166)\tLoss 0.2700 (0.2228)\tPrec@1 90.625 (92.300)\n",
            "Epoch: [53][690/782]\tTime 0.166 (0.166)\tLoss 0.3445 (0.2224)\tPrec@1 89.062 (92.314)\n",
            "Epoch: [53][700/782]\tTime 0.165 (0.166)\tLoss 0.1939 (0.2227)\tPrec@1 92.188 (92.312)\n",
            "Epoch: [53][710/782]\tTime 0.164 (0.166)\tLoss 0.2529 (0.2228)\tPrec@1 92.188 (92.306)\n",
            "Epoch: [53][720/782]\tTime 0.165 (0.166)\tLoss 0.1377 (0.2225)\tPrec@1 95.312 (92.333)\n",
            "Epoch: [53][730/782]\tTime 0.163 (0.166)\tLoss 0.3077 (0.2232)\tPrec@1 92.188 (92.309)\n",
            "Epoch: [53][740/782]\tTime 0.165 (0.166)\tLoss 0.1563 (0.2230)\tPrec@1 93.750 (92.320)\n",
            "Epoch: [53][750/782]\tTime 0.165 (0.166)\tLoss 0.1808 (0.2228)\tPrec@1 95.312 (92.323)\n",
            "Epoch: [53][760/782]\tTime 0.164 (0.166)\tLoss 0.1096 (0.2225)\tPrec@1 96.875 (92.335)\n",
            "Epoch: [53][770/782]\tTime 0.163 (0.166)\tLoss 0.3395 (0.2226)\tPrec@1 89.062 (92.321)\n",
            "Epoch: [53][780/782]\tTime 0.163 (0.166)\tLoss 0.0466 (0.2223)\tPrec@1 98.438 (92.310)\n",
            "Training accuracy:  tensor(92.3060, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.3060, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.112 (0.112)\tLoss 0.3811 (0.3811)\tPrec@1 90.625 (90.625)\n",
            "Test: [10/157]\tTime 0.039 (0.048)\tLoss 0.5143 (0.4386)\tPrec@1 89.062 (88.636)\n",
            "Test: [20/157]\tTime 0.053 (0.046)\tLoss 0.3923 (0.4193)\tPrec@1 87.500 (88.170)\n",
            "Test: [30/157]\tTime 0.043 (0.046)\tLoss 0.2563 (0.4000)\tPrec@1 90.625 (88.105)\n",
            "Test: [40/157]\tTime 0.042 (0.045)\tLoss 0.4234 (0.4134)\tPrec@1 84.375 (87.767)\n",
            "Test: [50/157]\tTime 0.042 (0.045)\tLoss 0.5248 (0.4227)\tPrec@1 85.938 (87.684)\n",
            "Test: [60/157]\tTime 0.043 (0.045)\tLoss 0.3671 (0.4196)\tPrec@1 85.938 (87.679)\n",
            "Test: [70/157]\tTime 0.043 (0.045)\tLoss 0.4705 (0.4298)\tPrec@1 81.250 (87.368)\n",
            "Test: [80/157]\tTime 0.043 (0.045)\tLoss 0.2027 (0.4133)\tPrec@1 92.188 (87.712)\n",
            "Test: [90/157]\tTime 0.044 (0.044)\tLoss 0.5267 (0.4144)\tPrec@1 87.500 (87.637)\n",
            "Test: [100/157]\tTime 0.044 (0.044)\tLoss 0.6476 (0.4186)\tPrec@1 79.688 (87.485)\n",
            "Test: [110/157]\tTime 0.044 (0.044)\tLoss 0.2805 (0.4179)\tPrec@1 90.625 (87.458)\n",
            "Test: [120/157]\tTime 0.043 (0.044)\tLoss 0.5883 (0.4163)\tPrec@1 87.500 (87.565)\n",
            "Test: [130/157]\tTime 0.055 (0.044)\tLoss 0.3108 (0.4091)\tPrec@1 85.938 (87.715)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.2178 (0.4142)\tPrec@1 90.625 (87.699)\n",
            "Test: [150/157]\tTime 0.044 (0.044)\tLoss 0.3732 (0.4118)\tPrec@1 87.500 (87.738)\n",
            " * Prec@1 87.690\n",
            "Best accuracy:  tensor(88.8800, device='cuda:0')\n",
            "Epoch: [54][0/782]\tTime 0.260 (0.260)\tLoss 0.1641 (0.1641)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [54][10/782]\tTime 0.164 (0.173)\tLoss 0.2997 (0.2093)\tPrec@1 87.500 (92.188)\n",
            "Epoch: [54][20/782]\tTime 0.164 (0.169)\tLoss 0.3913 (0.2341)\tPrec@1 90.625 (92.039)\n",
            "Epoch: [54][30/782]\tTime 0.165 (0.168)\tLoss 0.1753 (0.2361)\tPrec@1 90.625 (91.935)\n",
            "Epoch: [54][40/782]\tTime 0.165 (0.168)\tLoss 0.0763 (0.2220)\tPrec@1 98.438 (92.302)\n",
            "Epoch: [54][50/782]\tTime 0.164 (0.167)\tLoss 0.1343 (0.2270)\tPrec@1 96.875 (92.218)\n",
            "Epoch: [54][60/782]\tTime 0.163 (0.167)\tLoss 0.2610 (0.2196)\tPrec@1 89.062 (92.444)\n",
            "Epoch: [54][70/782]\tTime 0.164 (0.167)\tLoss 0.3415 (0.2227)\tPrec@1 87.500 (92.364)\n",
            "Epoch: [54][80/782]\tTime 0.165 (0.166)\tLoss 0.1299 (0.2184)\tPrec@1 96.875 (92.535)\n",
            "Epoch: [54][90/782]\tTime 0.165 (0.166)\tLoss 0.1472 (0.2150)\tPrec@1 93.750 (92.582)\n",
            "Epoch: [54][100/782]\tTime 0.165 (0.166)\tLoss 0.1445 (0.2108)\tPrec@1 95.312 (92.729)\n",
            "Epoch: [54][110/782]\tTime 0.163 (0.166)\tLoss 0.1575 (0.2065)\tPrec@1 93.750 (92.849)\n",
            "Epoch: [54][120/782]\tTime 0.166 (0.166)\tLoss 0.2576 (0.2043)\tPrec@1 92.188 (92.872)\n",
            "Epoch: [54][130/782]\tTime 0.164 (0.166)\tLoss 0.1291 (0.2030)\tPrec@1 96.875 (92.951)\n",
            "Epoch: [54][140/782]\tTime 0.166 (0.166)\tLoss 0.1346 (0.2023)\tPrec@1 95.312 (92.963)\n",
            "Epoch: [54][150/782]\tTime 0.164 (0.166)\tLoss 0.2041 (0.2023)\tPrec@1 95.312 (92.964)\n",
            "Epoch: [54][160/782]\tTime 0.164 (0.166)\tLoss 0.2516 (0.2018)\tPrec@1 87.500 (92.983)\n",
            "Epoch: [54][170/782]\tTime 0.165 (0.166)\tLoss 0.2827 (0.2013)\tPrec@1 87.500 (92.982)\n",
            "Epoch: [54][180/782]\tTime 0.165 (0.166)\tLoss 0.2029 (0.2030)\tPrec@1 89.062 (92.947)\n",
            "Epoch: [54][190/782]\tTime 0.164 (0.166)\tLoss 0.2261 (0.2050)\tPrec@1 92.188 (92.858)\n",
            "Epoch: [54][200/782]\tTime 0.165 (0.166)\tLoss 0.1506 (0.2038)\tPrec@1 93.750 (92.926)\n",
            "Epoch: [54][210/782]\tTime 0.163 (0.166)\tLoss 0.3150 (0.2035)\tPrec@1 90.625 (92.950)\n",
            "Epoch: [54][220/782]\tTime 0.165 (0.166)\tLoss 0.2877 (0.2034)\tPrec@1 89.062 (92.951)\n",
            "Epoch: [54][230/782]\tTime 0.163 (0.165)\tLoss 0.3317 (0.2033)\tPrec@1 87.500 (92.938)\n",
            "Epoch: [54][240/782]\tTime 0.163 (0.165)\tLoss 0.1508 (0.2031)\tPrec@1 95.312 (92.985)\n",
            "Epoch: [54][250/782]\tTime 0.169 (0.165)\tLoss 0.1171 (0.2037)\tPrec@1 95.312 (92.966)\n",
            "Epoch: [54][260/782]\tTime 0.163 (0.165)\tLoss 0.3053 (0.2058)\tPrec@1 87.500 (92.906)\n",
            "Epoch: [54][270/782]\tTime 0.164 (0.165)\tLoss 0.1269 (0.2052)\tPrec@1 92.188 (92.879)\n",
            "Epoch: [54][280/782]\tTime 0.165 (0.165)\tLoss 0.1713 (0.2057)\tPrec@1 93.750 (92.866)\n",
            "Epoch: [54][290/782]\tTime 0.163 (0.165)\tLoss 0.4069 (0.2063)\tPrec@1 90.625 (92.853)\n",
            "Epoch: [54][300/782]\tTime 0.165 (0.165)\tLoss 0.2104 (0.2070)\tPrec@1 96.875 (92.852)\n",
            "Epoch: [54][310/782]\tTime 0.165 (0.165)\tLoss 0.2313 (0.2089)\tPrec@1 92.188 (92.775)\n",
            "Epoch: [54][320/782]\tTime 0.164 (0.165)\tLoss 0.2188 (0.2096)\tPrec@1 95.312 (92.738)\n",
            "Epoch: [54][330/782]\tTime 0.167 (0.165)\tLoss 0.2641 (0.2096)\tPrec@1 89.062 (92.740)\n",
            "Epoch: [54][340/782]\tTime 0.165 (0.165)\tLoss 0.1341 (0.2095)\tPrec@1 93.750 (92.760)\n",
            "Epoch: [54][350/782]\tTime 0.166 (0.165)\tLoss 0.2207 (0.2099)\tPrec@1 90.625 (92.735)\n",
            "Epoch: [54][360/782]\tTime 0.164 (0.165)\tLoss 0.2748 (0.2116)\tPrec@1 89.062 (92.703)\n",
            "Epoch: [54][370/782]\tTime 0.163 (0.165)\tLoss 0.2330 (0.2117)\tPrec@1 93.750 (92.701)\n",
            "Epoch: [54][380/782]\tTime 0.166 (0.165)\tLoss 0.3036 (0.2124)\tPrec@1 92.188 (92.680)\n",
            "Epoch: [54][390/782]\tTime 0.166 (0.165)\tLoss 0.1022 (0.2130)\tPrec@1 95.312 (92.639)\n",
            "Epoch: [54][400/782]\tTime 0.165 (0.165)\tLoss 0.4818 (0.2142)\tPrec@1 84.375 (92.597)\n",
            "Epoch: [54][410/782]\tTime 0.167 (0.165)\tLoss 0.1826 (0.2150)\tPrec@1 92.188 (92.560)\n",
            "Epoch: [54][420/782]\tTime 0.164 (0.165)\tLoss 0.3692 (0.2161)\tPrec@1 87.500 (92.540)\n",
            "Epoch: [54][430/782]\tTime 0.163 (0.165)\tLoss 0.1709 (0.2161)\tPrec@1 95.312 (92.532)\n",
            "Epoch: [54][440/782]\tTime 0.171 (0.165)\tLoss 0.3896 (0.2172)\tPrec@1 84.375 (92.499)\n",
            "Epoch: [54][450/782]\tTime 0.165 (0.165)\tLoss 0.2977 (0.2184)\tPrec@1 89.062 (92.485)\n",
            "Epoch: [54][460/782]\tTime 0.163 (0.165)\tLoss 0.3410 (0.2187)\tPrec@1 87.500 (92.465)\n",
            "Epoch: [54][470/782]\tTime 0.165 (0.165)\tLoss 0.1933 (0.2184)\tPrec@1 92.188 (92.463)\n",
            "Epoch: [54][480/782]\tTime 0.164 (0.165)\tLoss 0.1558 (0.2185)\tPrec@1 95.312 (92.483)\n",
            "Epoch: [54][490/782]\tTime 0.163 (0.165)\tLoss 0.2590 (0.2181)\tPrec@1 90.625 (92.487)\n",
            "Epoch: [54][500/782]\tTime 0.165 (0.165)\tLoss 0.3707 (0.2181)\tPrec@1 90.625 (92.481)\n",
            "Epoch: [54][510/782]\tTime 0.163 (0.165)\tLoss 0.1810 (0.2178)\tPrec@1 95.312 (92.493)\n",
            "Epoch: [54][520/782]\tTime 0.167 (0.165)\tLoss 0.3590 (0.2180)\tPrec@1 85.938 (92.490)\n",
            "Epoch: [54][530/782]\tTime 0.162 (0.165)\tLoss 0.2167 (0.2182)\tPrec@1 90.625 (92.482)\n",
            "Epoch: [54][540/782]\tTime 0.164 (0.165)\tLoss 0.2159 (0.2185)\tPrec@1 93.750 (92.462)\n",
            "Epoch: [54][550/782]\tTime 0.162 (0.165)\tLoss 0.1930 (0.2198)\tPrec@1 95.312 (92.417)\n",
            "Epoch: [54][560/782]\tTime 0.163 (0.165)\tLoss 0.2584 (0.2203)\tPrec@1 92.188 (92.416)\n",
            "Epoch: [54][570/782]\tTime 0.162 (0.165)\tLoss 0.2831 (0.2205)\tPrec@1 90.625 (92.412)\n",
            "Epoch: [54][580/782]\tTime 0.163 (0.165)\tLoss 0.2003 (0.2207)\tPrec@1 90.625 (92.416)\n",
            "Epoch: [54][590/782]\tTime 0.164 (0.165)\tLoss 0.1573 (0.2207)\tPrec@1 95.312 (92.423)\n",
            "Epoch: [54][600/782]\tTime 0.161 (0.165)\tLoss 0.1844 (0.2213)\tPrec@1 92.188 (92.411)\n",
            "Epoch: [54][610/782]\tTime 0.163 (0.165)\tLoss 0.2136 (0.2209)\tPrec@1 93.750 (92.433)\n",
            "Epoch: [54][620/782]\tTime 0.161 (0.165)\tLoss 0.1949 (0.2209)\tPrec@1 90.625 (92.411)\n",
            "Epoch: [54][630/782]\tTime 0.164 (0.165)\tLoss 0.1719 (0.2208)\tPrec@1 95.312 (92.415)\n",
            "Epoch: [54][640/782]\tTime 0.163 (0.165)\tLoss 0.2752 (0.2210)\tPrec@1 85.938 (92.392)\n",
            "Epoch: [54][650/782]\tTime 0.165 (0.165)\tLoss 0.3889 (0.2219)\tPrec@1 87.500 (92.356)\n",
            "Epoch: [54][660/782]\tTime 0.163 (0.165)\tLoss 0.1812 (0.2213)\tPrec@1 92.188 (92.374)\n",
            "Epoch: [54][670/782]\tTime 0.165 (0.165)\tLoss 0.1883 (0.2222)\tPrec@1 95.312 (92.337)\n",
            "Epoch: [54][680/782]\tTime 0.163 (0.165)\tLoss 0.1019 (0.2216)\tPrec@1 96.875 (92.357)\n",
            "Epoch: [54][690/782]\tTime 0.163 (0.165)\tLoss 0.2510 (0.2215)\tPrec@1 89.062 (92.348)\n",
            "Epoch: [54][700/782]\tTime 0.170 (0.165)\tLoss 0.2677 (0.2214)\tPrec@1 87.500 (92.344)\n",
            "Epoch: [54][710/782]\tTime 0.162 (0.165)\tLoss 0.1706 (0.2217)\tPrec@1 95.312 (92.337)\n",
            "Epoch: [54][720/782]\tTime 0.161 (0.165)\tLoss 0.1749 (0.2218)\tPrec@1 90.625 (92.322)\n",
            "Epoch: [54][730/782]\tTime 0.163 (0.165)\tLoss 0.2327 (0.2227)\tPrec@1 92.188 (92.275)\n",
            "Epoch: [54][740/782]\tTime 0.163 (0.165)\tLoss 0.2214 (0.2231)\tPrec@1 92.188 (92.266)\n",
            "Epoch: [54][750/782]\tTime 0.161 (0.165)\tLoss 0.1770 (0.2236)\tPrec@1 96.875 (92.254)\n",
            "Epoch: [54][760/782]\tTime 0.163 (0.165)\tLoss 0.1672 (0.2234)\tPrec@1 95.312 (92.268)\n",
            "Epoch: [54][770/782]\tTime 0.162 (0.165)\tLoss 0.1552 (0.2241)\tPrec@1 96.875 (92.254)\n",
            "Epoch: [54][780/782]\tTime 0.161 (0.165)\tLoss 0.3379 (0.2246)\tPrec@1 85.938 (92.234)\n",
            "Training accuracy:  tensor(92.2360, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.3060, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.111 (0.111)\tLoss 0.2688 (0.2688)\tPrec@1 90.625 (90.625)\n",
            "Test: [10/157]\tTime 0.042 (0.047)\tLoss 0.2233 (0.3320)\tPrec@1 90.625 (88.494)\n",
            "Test: [20/157]\tTime 0.051 (0.046)\tLoss 0.4148 (0.3522)\tPrec@1 85.938 (88.318)\n",
            "Test: [30/157]\tTime 0.044 (0.045)\tLoss 0.4007 (0.3431)\tPrec@1 84.375 (88.659)\n",
            "Test: [40/157]\tTime 0.047 (0.045)\tLoss 0.3224 (0.3513)\tPrec@1 92.188 (88.453)\n",
            "Test: [50/157]\tTime 0.042 (0.045)\tLoss 0.4273 (0.3565)\tPrec@1 89.062 (88.542)\n",
            "Test: [60/157]\tTime 0.042 (0.045)\tLoss 0.4523 (0.3526)\tPrec@1 82.812 (88.653)\n",
            "Test: [70/157]\tTime 0.044 (0.044)\tLoss 0.4043 (0.3542)\tPrec@1 89.062 (88.864)\n",
            "Test: [80/157]\tTime 0.042 (0.044)\tLoss 0.4093 (0.3583)\tPrec@1 87.500 (88.792)\n",
            "Test: [90/157]\tTime 0.041 (0.044)\tLoss 0.1460 (0.3510)\tPrec@1 93.750 (88.942)\n",
            "Test: [100/157]\tTime 0.044 (0.044)\tLoss 0.5497 (0.3579)\tPrec@1 82.812 (88.676)\n",
            "Test: [110/157]\tTime 0.042 (0.044)\tLoss 0.4107 (0.3666)\tPrec@1 85.938 (88.556)\n",
            "Test: [120/157]\tTime 0.043 (0.044)\tLoss 0.2116 (0.3663)\tPrec@1 93.750 (88.559)\n",
            "Test: [130/157]\tTime 0.043 (0.044)\tLoss 0.1739 (0.3675)\tPrec@1 95.312 (88.550)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.3823 (0.3672)\tPrec@1 87.500 (88.442)\n",
            "Test: [150/157]\tTime 0.042 (0.044)\tLoss 0.3454 (0.3646)\tPrec@1 89.062 (88.555)\n",
            " * Prec@1 88.610\n",
            "Best accuracy:  tensor(88.8800, device='cuda:0')\n",
            "Epoch: [55][0/782]\tTime 0.268 (0.268)\tLoss 0.1936 (0.1936)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [55][10/782]\tTime 0.167 (0.175)\tLoss 0.2259 (0.2150)\tPrec@1 92.188 (92.045)\n",
            "Epoch: [55][20/782]\tTime 0.163 (0.170)\tLoss 0.2493 (0.2310)\tPrec@1 90.625 (91.443)\n",
            "Epoch: [55][30/782]\tTime 0.163 (0.168)\tLoss 0.1564 (0.2183)\tPrec@1 95.312 (92.036)\n",
            "Epoch: [55][40/782]\tTime 0.164 (0.167)\tLoss 0.1377 (0.2087)\tPrec@1 98.438 (92.645)\n",
            "Epoch: [55][50/782]\tTime 0.163 (0.167)\tLoss 0.3089 (0.2184)\tPrec@1 92.188 (92.402)\n",
            "Epoch: [55][60/782]\tTime 0.168 (0.167)\tLoss 0.2039 (0.2109)\tPrec@1 95.312 (92.674)\n",
            "Epoch: [55][70/782]\tTime 0.162 (0.166)\tLoss 0.2314 (0.2075)\tPrec@1 90.625 (92.914)\n",
            "Epoch: [55][80/782]\tTime 0.162 (0.166)\tLoss 0.0814 (0.2107)\tPrec@1 98.438 (92.843)\n",
            "Epoch: [55][90/782]\tTime 0.163 (0.166)\tLoss 0.1934 (0.2090)\tPrec@1 95.312 (92.977)\n",
            "Epoch: [55][100/782]\tTime 0.166 (0.165)\tLoss 0.1864 (0.2099)\tPrec@1 93.750 (92.946)\n",
            "Epoch: [55][110/782]\tTime 0.163 (0.165)\tLoss 0.1517 (0.2092)\tPrec@1 93.750 (93.018)\n",
            "Epoch: [55][120/782]\tTime 0.167 (0.166)\tLoss 0.1614 (0.2087)\tPrec@1 95.312 (93.014)\n",
            "Epoch: [55][130/782]\tTime 0.166 (0.166)\tLoss 0.1950 (0.2079)\tPrec@1 93.750 (93.094)\n",
            "Epoch: [55][140/782]\tTime 0.162 (0.166)\tLoss 0.1176 (0.2079)\tPrec@1 96.875 (93.129)\n",
            "Epoch: [55][150/782]\tTime 0.166 (0.166)\tLoss 0.0986 (0.2083)\tPrec@1 95.312 (93.160)\n",
            "Epoch: [55][160/782]\tTime 0.167 (0.166)\tLoss 0.3051 (0.2097)\tPrec@1 90.625 (93.109)\n",
            "Epoch: [55][170/782]\tTime 0.169 (0.166)\tLoss 0.2593 (0.2100)\tPrec@1 90.625 (93.074)\n",
            "Epoch: [55][180/782]\tTime 0.168 (0.166)\tLoss 0.1770 (0.2098)\tPrec@1 95.312 (93.103)\n",
            "Epoch: [55][190/782]\tTime 0.166 (0.166)\tLoss 0.2030 (0.2102)\tPrec@1 92.188 (93.022)\n",
            "Epoch: [55][200/782]\tTime 0.163 (0.166)\tLoss 0.2699 (0.2100)\tPrec@1 87.500 (93.012)\n",
            "Epoch: [55][210/782]\tTime 0.165 (0.166)\tLoss 0.2107 (0.2090)\tPrec@1 93.750 (93.084)\n",
            "Epoch: [55][220/782]\tTime 0.168 (0.166)\tLoss 0.2213 (0.2082)\tPrec@1 95.312 (93.107)\n",
            "Epoch: [55][230/782]\tTime 0.165 (0.166)\tLoss 0.1864 (0.2074)\tPrec@1 90.625 (93.107)\n",
            "Epoch: [55][240/782]\tTime 0.166 (0.166)\tLoss 0.4472 (0.2100)\tPrec@1 89.062 (93.004)\n",
            "Epoch: [55][250/782]\tTime 0.167 (0.166)\tLoss 0.1657 (0.2122)\tPrec@1 95.312 (92.928)\n",
            "Epoch: [55][260/782]\tTime 0.168 (0.166)\tLoss 0.2015 (0.2123)\tPrec@1 89.062 (92.912)\n",
            "Epoch: [55][270/782]\tTime 0.164 (0.166)\tLoss 0.0968 (0.2123)\tPrec@1 98.438 (92.885)\n",
            "Epoch: [55][280/782]\tTime 0.166 (0.166)\tLoss 0.2090 (0.2127)\tPrec@1 92.188 (92.866)\n",
            "Epoch: [55][290/782]\tTime 0.166 (0.166)\tLoss 0.1969 (0.2122)\tPrec@1 96.875 (92.902)\n",
            "Epoch: [55][300/782]\tTime 0.167 (0.166)\tLoss 0.1052 (0.2127)\tPrec@1 96.875 (92.862)\n",
            "Epoch: [55][310/782]\tTime 0.170 (0.166)\tLoss 0.2228 (0.2128)\tPrec@1 89.062 (92.831)\n",
            "Epoch: [55][320/782]\tTime 0.167 (0.166)\tLoss 0.1343 (0.2124)\tPrec@1 96.875 (92.859)\n",
            "Epoch: [55][330/782]\tTime 0.167 (0.166)\tLoss 0.1573 (0.2114)\tPrec@1 96.875 (92.858)\n",
            "Epoch: [55][340/782]\tTime 0.166 (0.167)\tLoss 0.2815 (0.2105)\tPrec@1 90.625 (92.875)\n",
            "Epoch: [55][350/782]\tTime 0.163 (0.166)\tLoss 0.1640 (0.2099)\tPrec@1 95.312 (92.900)\n",
            "Epoch: [55][360/782]\tTime 0.167 (0.166)\tLoss 0.1977 (0.2101)\tPrec@1 93.750 (92.915)\n",
            "Epoch: [55][370/782]\tTime 0.169 (0.167)\tLoss 0.1446 (0.2093)\tPrec@1 96.875 (92.941)\n",
            "Epoch: [55][380/782]\tTime 0.166 (0.167)\tLoss 0.2855 (0.2092)\tPrec@1 93.750 (92.954)\n",
            "Epoch: [55][390/782]\tTime 0.166 (0.167)\tLoss 0.1982 (0.2083)\tPrec@1 93.750 (92.959)\n",
            "Epoch: [55][400/782]\tTime 0.168 (0.167)\tLoss 0.1702 (0.2088)\tPrec@1 95.312 (92.955)\n",
            "Epoch: [55][410/782]\tTime 0.166 (0.167)\tLoss 0.1570 (0.2090)\tPrec@1 93.750 (92.963)\n",
            "Epoch: [55][420/782]\tTime 0.165 (0.167)\tLoss 0.4662 (0.2103)\tPrec@1 82.812 (92.922)\n",
            "Epoch: [55][430/782]\tTime 0.166 (0.167)\tLoss 0.1463 (0.2112)\tPrec@1 93.750 (92.905)\n",
            "Epoch: [55][440/782]\tTime 0.164 (0.166)\tLoss 0.3298 (0.2121)\tPrec@1 90.625 (92.903)\n",
            "Epoch: [55][450/782]\tTime 0.170 (0.166)\tLoss 0.2052 (0.2126)\tPrec@1 90.625 (92.853)\n",
            "Epoch: [55][460/782]\tTime 0.166 (0.166)\tLoss 0.0872 (0.2123)\tPrec@1 95.312 (92.859)\n",
            "Epoch: [55][470/782]\tTime 0.164 (0.166)\tLoss 0.2376 (0.2121)\tPrec@1 93.750 (92.878)\n",
            "Epoch: [55][480/782]\tTime 0.166 (0.166)\tLoss 0.2119 (0.2128)\tPrec@1 93.750 (92.844)\n",
            "Epoch: [55][490/782]\tTime 0.164 (0.166)\tLoss 0.1386 (0.2135)\tPrec@1 93.750 (92.799)\n",
            "Epoch: [55][500/782]\tTime 0.166 (0.166)\tLoss 0.4034 (0.2141)\tPrec@1 87.500 (92.771)\n",
            "Epoch: [55][510/782]\tTime 0.165 (0.166)\tLoss 0.4618 (0.2146)\tPrec@1 85.938 (92.744)\n",
            "Epoch: [55][520/782]\tTime 0.165 (0.166)\tLoss 0.2137 (0.2148)\tPrec@1 92.188 (92.721)\n",
            "Epoch: [55][530/782]\tTime 0.168 (0.166)\tLoss 0.0974 (0.2147)\tPrec@1 96.875 (92.714)\n",
            "Epoch: [55][540/782]\tTime 0.166 (0.166)\tLoss 0.1460 (0.2145)\tPrec@1 96.875 (92.728)\n",
            "Epoch: [55][550/782]\tTime 0.166 (0.166)\tLoss 0.2442 (0.2149)\tPrec@1 89.062 (92.692)\n",
            "Epoch: [55][560/782]\tTime 0.167 (0.166)\tLoss 0.3249 (0.2150)\tPrec@1 92.188 (92.703)\n",
            "Epoch: [55][570/782]\tTime 0.166 (0.166)\tLoss 0.1512 (0.2150)\tPrec@1 93.750 (92.696)\n",
            "Epoch: [55][580/782]\tTime 0.167 (0.166)\tLoss 0.1429 (0.2145)\tPrec@1 95.312 (92.704)\n",
            "Epoch: [55][590/782]\tTime 0.166 (0.166)\tLoss 0.2367 (0.2145)\tPrec@1 92.188 (92.700)\n",
            "Epoch: [55][600/782]\tTime 0.167 (0.166)\tLoss 0.2256 (0.2145)\tPrec@1 90.625 (92.700)\n",
            "Epoch: [55][610/782]\tTime 0.165 (0.166)\tLoss 0.1873 (0.2144)\tPrec@1 92.188 (92.696)\n",
            "Epoch: [55][620/782]\tTime 0.167 (0.166)\tLoss 0.2409 (0.2153)\tPrec@1 90.625 (92.671)\n",
            "Epoch: [55][630/782]\tTime 0.166 (0.166)\tLoss 0.2229 (0.2162)\tPrec@1 90.625 (92.621)\n",
            "Epoch: [55][640/782]\tTime 0.166 (0.166)\tLoss 0.4092 (0.2168)\tPrec@1 85.938 (92.595)\n",
            "Epoch: [55][650/782]\tTime 0.165 (0.166)\tLoss 0.2150 (0.2178)\tPrec@1 92.188 (92.562)\n",
            "Epoch: [55][660/782]\tTime 0.169 (0.166)\tLoss 0.1210 (0.2183)\tPrec@1 96.875 (92.556)\n",
            "Epoch: [55][670/782]\tTime 0.165 (0.166)\tLoss 0.2845 (0.2182)\tPrec@1 90.625 (92.567)\n",
            "Epoch: [55][680/782]\tTime 0.164 (0.166)\tLoss 0.1960 (0.2185)\tPrec@1 95.312 (92.548)\n",
            "Epoch: [55][690/782]\tTime 0.165 (0.166)\tLoss 0.2463 (0.2183)\tPrec@1 93.750 (92.552)\n",
            "Epoch: [55][700/782]\tTime 0.165 (0.166)\tLoss 0.1726 (0.2182)\tPrec@1 93.750 (92.558)\n",
            "Epoch: [55][710/782]\tTime 0.164 (0.166)\tLoss 0.2093 (0.2180)\tPrec@1 92.188 (92.561)\n",
            "Epoch: [55][720/782]\tTime 0.166 (0.166)\tLoss 0.0969 (0.2182)\tPrec@1 95.312 (92.545)\n",
            "Epoch: [55][730/782]\tTime 0.168 (0.166)\tLoss 0.3722 (0.2190)\tPrec@1 87.500 (92.521)\n",
            "Epoch: [55][740/782]\tTime 0.165 (0.166)\tLoss 0.3198 (0.2193)\tPrec@1 85.938 (92.504)\n",
            "Epoch: [55][750/782]\tTime 0.166 (0.166)\tLoss 0.1312 (0.2199)\tPrec@1 96.875 (92.489)\n",
            "Epoch: [55][760/782]\tTime 0.166 (0.166)\tLoss 0.1841 (0.2202)\tPrec@1 92.188 (92.485)\n",
            "Epoch: [55][770/782]\tTime 0.163 (0.166)\tLoss 0.2219 (0.2203)\tPrec@1 92.188 (92.473)\n",
            "Epoch: [55][780/782]\tTime 0.163 (0.166)\tLoss 0.1880 (0.2204)\tPrec@1 96.875 (92.462)\n",
            "Training accuracy:  tensor(92.4600, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.4600, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.111 (0.111)\tLoss 0.3696 (0.3696)\tPrec@1 90.625 (90.625)\n",
            "Test: [10/157]\tTime 0.044 (0.048)\tLoss 0.5063 (0.3187)\tPrec@1 82.812 (89.915)\n",
            "Test: [20/157]\tTime 0.050 (0.046)\tLoss 0.3407 (0.3450)\tPrec@1 89.062 (88.616)\n",
            "Test: [30/157]\tTime 0.044 (0.046)\tLoss 0.5730 (0.3435)\tPrec@1 84.375 (89.113)\n",
            "Test: [40/157]\tTime 0.042 (0.045)\tLoss 0.1983 (0.3523)\tPrec@1 92.188 (88.872)\n",
            "Test: [50/157]\tTime 0.042 (0.045)\tLoss 0.3381 (0.3466)\tPrec@1 92.188 (88.909)\n",
            "Test: [60/157]\tTime 0.045 (0.045)\tLoss 0.1432 (0.3397)\tPrec@1 95.312 (89.114)\n",
            "Test: [70/157]\tTime 0.044 (0.045)\tLoss 0.3491 (0.3450)\tPrec@1 85.938 (88.908)\n",
            "Test: [80/157]\tTime 0.043 (0.045)\tLoss 0.5404 (0.3374)\tPrec@1 84.375 (89.333)\n",
            "Test: [90/157]\tTime 0.042 (0.044)\tLoss 0.1840 (0.3338)\tPrec@1 92.188 (89.406)\n",
            "Test: [100/157]\tTime 0.047 (0.044)\tLoss 0.2457 (0.3302)\tPrec@1 90.625 (89.403)\n",
            "Test: [110/157]\tTime 0.043 (0.044)\tLoss 0.1477 (0.3263)\tPrec@1 95.312 (89.583)\n",
            "Test: [120/157]\tTime 0.043 (0.044)\tLoss 0.2980 (0.3360)\tPrec@1 92.188 (89.385)\n",
            "Test: [130/157]\tTime 0.045 (0.044)\tLoss 0.3112 (0.3371)\tPrec@1 87.500 (89.229)\n",
            "Test: [140/157]\tTime 0.046 (0.044)\tLoss 0.3840 (0.3322)\tPrec@1 85.938 (89.317)\n",
            "Test: [150/157]\tTime 0.045 (0.044)\tLoss 0.6635 (0.3352)\tPrec@1 82.812 (89.259)\n",
            " * Prec@1 89.300\n",
            "Best accuracy:  tensor(89.3000, device='cuda:0')\n",
            "Epoch: [56][0/782]\tTime 0.265 (0.265)\tLoss 0.4180 (0.4180)\tPrec@1 81.250 (81.250)\n",
            "Epoch: [56][10/782]\tTime 0.165 (0.173)\tLoss 0.1817 (0.2843)\tPrec@1 95.312 (89.915)\n",
            "Epoch: [56][20/782]\tTime 0.163 (0.169)\tLoss 0.1558 (0.2391)\tPrec@1 95.312 (91.741)\n",
            "Epoch: [56][30/782]\tTime 0.167 (0.168)\tLoss 0.2150 (0.2268)\tPrec@1 90.625 (91.935)\n",
            "Epoch: [56][40/782]\tTime 0.167 (0.168)\tLoss 0.0722 (0.2140)\tPrec@1 98.438 (92.645)\n",
            "Epoch: [56][50/782]\tTime 0.164 (0.167)\tLoss 0.1639 (0.2076)\tPrec@1 96.875 (92.953)\n",
            "Epoch: [56][60/782]\tTime 0.164 (0.167)\tLoss 0.3438 (0.2057)\tPrec@1 90.625 (93.238)\n",
            "Epoch: [56][70/782]\tTime 0.166 (0.167)\tLoss 0.2459 (0.2058)\tPrec@1 93.750 (93.178)\n",
            "Epoch: [56][80/782]\tTime 0.163 (0.166)\tLoss 0.2134 (0.2035)\tPrec@1 89.062 (93.171)\n",
            "Epoch: [56][90/782]\tTime 0.163 (0.166)\tLoss 0.2035 (0.2030)\tPrec@1 92.188 (93.080)\n",
            "Epoch: [56][100/782]\tTime 0.164 (0.166)\tLoss 0.1550 (0.2012)\tPrec@1 95.312 (93.270)\n",
            "Epoch: [56][110/782]\tTime 0.165 (0.166)\tLoss 0.1863 (0.1988)\tPrec@1 93.750 (93.356)\n",
            "Epoch: [56][120/782]\tTime 0.163 (0.166)\tLoss 0.1759 (0.1975)\tPrec@1 92.188 (93.376)\n",
            "Epoch: [56][130/782]\tTime 0.165 (0.166)\tLoss 0.2439 (0.1984)\tPrec@1 90.625 (93.356)\n",
            "Epoch: [56][140/782]\tTime 0.167 (0.166)\tLoss 0.2486 (0.1978)\tPrec@1 93.750 (93.351)\n",
            "Epoch: [56][150/782]\tTime 0.166 (0.166)\tLoss 0.1754 (0.2002)\tPrec@1 95.312 (93.202)\n",
            "Epoch: [56][160/782]\tTime 0.166 (0.166)\tLoss 0.1983 (0.2008)\tPrec@1 92.188 (93.207)\n",
            "Epoch: [56][170/782]\tTime 0.165 (0.166)\tLoss 0.1804 (0.2005)\tPrec@1 93.750 (93.183)\n",
            "Epoch: [56][180/782]\tTime 0.165 (0.166)\tLoss 0.2630 (0.2014)\tPrec@1 90.625 (93.163)\n",
            "Epoch: [56][190/782]\tTime 0.163 (0.166)\tLoss 0.1168 (0.2012)\tPrec@1 98.438 (93.153)\n",
            "Epoch: [56][200/782]\tTime 0.164 (0.166)\tLoss 0.2283 (0.2024)\tPrec@1 90.625 (93.066)\n",
            "Epoch: [56][210/782]\tTime 0.164 (0.166)\tLoss 0.1835 (0.2041)\tPrec@1 93.750 (92.950)\n",
            "Epoch: [56][220/782]\tTime 0.164 (0.166)\tLoss 0.2974 (0.2066)\tPrec@1 89.062 (92.838)\n",
            "Epoch: [56][230/782]\tTime 0.166 (0.166)\tLoss 0.3212 (0.2061)\tPrec@1 87.500 (92.864)\n",
            "Epoch: [56][240/782]\tTime 0.163 (0.166)\tLoss 0.2867 (0.2082)\tPrec@1 90.625 (92.816)\n",
            "Epoch: [56][250/782]\tTime 0.166 (0.166)\tLoss 0.2749 (0.2096)\tPrec@1 90.625 (92.773)\n",
            "Epoch: [56][260/782]\tTime 0.164 (0.166)\tLoss 0.1686 (0.2101)\tPrec@1 92.188 (92.756)\n",
            "Epoch: [56][270/782]\tTime 0.163 (0.166)\tLoss 0.1748 (0.2107)\tPrec@1 90.625 (92.729)\n",
            "Epoch: [56][280/782]\tTime 0.167 (0.166)\tLoss 0.1478 (0.2110)\tPrec@1 93.750 (92.705)\n",
            "Epoch: [56][290/782]\tTime 0.164 (0.166)\tLoss 0.2067 (0.2118)\tPrec@1 90.625 (92.655)\n",
            "Epoch: [56][300/782]\tTime 0.164 (0.166)\tLoss 0.4059 (0.2131)\tPrec@1 84.375 (92.613)\n",
            "Epoch: [56][310/782]\tTime 0.168 (0.166)\tLoss 0.1813 (0.2134)\tPrec@1 96.875 (92.660)\n",
            "Epoch: [56][320/782]\tTime 0.171 (0.166)\tLoss 0.1702 (0.2133)\tPrec@1 93.750 (92.669)\n",
            "Epoch: [56][330/782]\tTime 0.165 (0.166)\tLoss 0.1133 (0.2132)\tPrec@1 100.000 (92.674)\n",
            "Epoch: [56][340/782]\tTime 0.166 (0.166)\tLoss 0.3522 (0.2137)\tPrec@1 84.375 (92.641)\n",
            "Epoch: [56][350/782]\tTime 0.166 (0.166)\tLoss 0.2026 (0.2132)\tPrec@1 90.625 (92.668)\n",
            "Epoch: [56][360/782]\tTime 0.166 (0.166)\tLoss 0.3358 (0.2139)\tPrec@1 90.625 (92.655)\n",
            "Epoch: [56][370/782]\tTime 0.165 (0.166)\tLoss 0.2434 (0.2145)\tPrec@1 92.188 (92.626)\n",
            "Epoch: [56][380/782]\tTime 0.164 (0.166)\tLoss 0.1596 (0.2139)\tPrec@1 95.312 (92.647)\n",
            "Epoch: [56][390/782]\tTime 0.167 (0.166)\tLoss 0.1888 (0.2138)\tPrec@1 92.188 (92.667)\n",
            "Epoch: [56][400/782]\tTime 0.165 (0.166)\tLoss 0.2230 (0.2134)\tPrec@1 85.938 (92.643)\n",
            "Epoch: [56][410/782]\tTime 0.164 (0.166)\tLoss 0.3593 (0.2138)\tPrec@1 87.500 (92.621)\n",
            "Epoch: [56][420/782]\tTime 0.164 (0.166)\tLoss 0.2648 (0.2134)\tPrec@1 90.625 (92.648)\n",
            "Epoch: [56][430/782]\tTime 0.163 (0.166)\tLoss 0.1741 (0.2135)\tPrec@1 96.875 (92.644)\n",
            "Epoch: [56][440/782]\tTime 0.164 (0.166)\tLoss 0.1406 (0.2125)\tPrec@1 96.875 (92.691)\n",
            "Epoch: [56][450/782]\tTime 0.164 (0.166)\tLoss 0.2799 (0.2120)\tPrec@1 84.375 (92.686)\n",
            "Epoch: [56][460/782]\tTime 0.165 (0.166)\tLoss 0.1809 (0.2127)\tPrec@1 90.625 (92.672)\n",
            "Epoch: [56][470/782]\tTime 0.166 (0.166)\tLoss 0.1068 (0.2124)\tPrec@1 93.750 (92.662)\n",
            "Epoch: [56][480/782]\tTime 0.165 (0.166)\tLoss 0.1151 (0.2122)\tPrec@1 93.750 (92.675)\n",
            "Epoch: [56][490/782]\tTime 0.165 (0.166)\tLoss 0.1503 (0.2120)\tPrec@1 96.875 (92.697)\n",
            "Epoch: [56][500/782]\tTime 0.166 (0.166)\tLoss 0.1711 (0.2116)\tPrec@1 92.188 (92.715)\n",
            "Epoch: [56][510/782]\tTime 0.164 (0.166)\tLoss 0.1934 (0.2121)\tPrec@1 90.625 (92.707)\n",
            "Epoch: [56][520/782]\tTime 0.165 (0.166)\tLoss 0.2520 (0.2120)\tPrec@1 92.188 (92.709)\n",
            "Epoch: [56][530/782]\tTime 0.164 (0.166)\tLoss 0.1349 (0.2115)\tPrec@1 93.750 (92.729)\n",
            "Epoch: [56][540/782]\tTime 0.166 (0.166)\tLoss 0.2015 (0.2116)\tPrec@1 90.625 (92.730)\n",
            "Epoch: [56][550/782]\tTime 0.165 (0.166)\tLoss 0.1722 (0.2112)\tPrec@1 93.750 (92.752)\n",
            "Epoch: [56][560/782]\tTime 0.167 (0.166)\tLoss 0.2468 (0.2128)\tPrec@1 87.500 (92.700)\n",
            "Epoch: [56][570/782]\tTime 0.164 (0.166)\tLoss 0.3476 (0.2131)\tPrec@1 87.500 (92.696)\n",
            "Epoch: [56][580/782]\tTime 0.163 (0.166)\tLoss 0.1396 (0.2135)\tPrec@1 95.312 (92.685)\n",
            "Epoch: [56][590/782]\tTime 0.166 (0.166)\tLoss 0.3322 (0.2145)\tPrec@1 89.062 (92.632)\n",
            "Epoch: [56][600/782]\tTime 0.165 (0.166)\tLoss 0.3308 (0.2152)\tPrec@1 85.938 (92.624)\n",
            "Epoch: [56][610/782]\tTime 0.164 (0.166)\tLoss 0.1833 (0.2146)\tPrec@1 92.188 (92.648)\n",
            "Epoch: [56][620/782]\tTime 0.168 (0.166)\tLoss 0.1491 (0.2147)\tPrec@1 93.750 (92.625)\n",
            "Epoch: [56][630/782]\tTime 0.168 (0.166)\tLoss 0.2619 (0.2152)\tPrec@1 89.062 (92.596)\n",
            "Epoch: [56][640/782]\tTime 0.166 (0.166)\tLoss 0.1560 (0.2149)\tPrec@1 90.625 (92.604)\n",
            "Epoch: [56][650/782]\tTime 0.166 (0.166)\tLoss 0.2972 (0.2152)\tPrec@1 89.062 (92.615)\n",
            "Epoch: [56][660/782]\tTime 0.168 (0.166)\tLoss 0.1326 (0.2149)\tPrec@1 96.875 (92.625)\n",
            "Epoch: [56][670/782]\tTime 0.165 (0.166)\tLoss 0.2112 (0.2155)\tPrec@1 93.750 (92.604)\n",
            "Epoch: [56][680/782]\tTime 0.165 (0.166)\tLoss 0.2025 (0.2155)\tPrec@1 93.750 (92.612)\n",
            "Epoch: [56][690/782]\tTime 0.165 (0.166)\tLoss 0.1391 (0.2156)\tPrec@1 96.875 (92.617)\n",
            "Epoch: [56][700/782]\tTime 0.164 (0.166)\tLoss 0.3643 (0.2154)\tPrec@1 89.062 (92.620)\n",
            "Epoch: [56][710/782]\tTime 0.165 (0.166)\tLoss 0.2332 (0.2156)\tPrec@1 90.625 (92.592)\n",
            "Epoch: [56][720/782]\tTime 0.167 (0.166)\tLoss 0.1289 (0.2151)\tPrec@1 95.312 (92.617)\n",
            "Epoch: [56][730/782]\tTime 0.163 (0.166)\tLoss 0.3493 (0.2153)\tPrec@1 87.500 (92.606)\n",
            "Epoch: [56][740/782]\tTime 0.165 (0.166)\tLoss 0.2008 (0.2160)\tPrec@1 89.062 (92.586)\n",
            "Epoch: [56][750/782]\tTime 0.166 (0.166)\tLoss 0.1821 (0.2165)\tPrec@1 93.750 (92.570)\n",
            "Epoch: [56][760/782]\tTime 0.164 (0.166)\tLoss 0.1430 (0.2166)\tPrec@1 93.750 (92.571)\n",
            "Epoch: [56][770/782]\tTime 0.166 (0.166)\tLoss 0.1582 (0.2163)\tPrec@1 95.312 (92.575)\n",
            "Epoch: [56][780/782]\tTime 0.162 (0.166)\tLoss 0.2437 (0.2161)\tPrec@1 93.750 (92.574)\n",
            "Training accuracy:  tensor(92.5760, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.5760, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.112 (0.112)\tLoss 0.3285 (0.3285)\tPrec@1 84.375 (84.375)\n",
            "Test: [10/157]\tTime 0.043 (0.047)\tLoss 0.5450 (0.3592)\tPrec@1 79.688 (87.784)\n",
            "Test: [20/157]\tTime 0.051 (0.046)\tLoss 0.4895 (0.3583)\tPrec@1 79.688 (88.021)\n",
            "Test: [30/157]\tTime 0.037 (0.046)\tLoss 0.5269 (0.3579)\tPrec@1 87.500 (88.155)\n",
            "Test: [40/157]\tTime 0.042 (0.045)\tLoss 0.3856 (0.3670)\tPrec@1 87.500 (87.652)\n",
            "Test: [50/157]\tTime 0.045 (0.045)\tLoss 0.3221 (0.3566)\tPrec@1 89.062 (88.082)\n",
            "Test: [60/157]\tTime 0.043 (0.045)\tLoss 0.2132 (0.3692)\tPrec@1 93.750 (87.654)\n",
            "Test: [70/157]\tTime 0.050 (0.045)\tLoss 0.3570 (0.3677)\tPrec@1 89.062 (87.896)\n",
            "Test: [80/157]\tTime 0.043 (0.045)\tLoss 0.1764 (0.3698)\tPrec@1 93.750 (88.002)\n",
            "Test: [90/157]\tTime 0.045 (0.045)\tLoss 0.4020 (0.3624)\tPrec@1 89.062 (88.101)\n",
            "Test: [100/157]\tTime 0.043 (0.044)\tLoss 0.2673 (0.3682)\tPrec@1 89.062 (88.088)\n",
            "Test: [110/157]\tTime 0.043 (0.044)\tLoss 0.4419 (0.3665)\tPrec@1 85.938 (88.204)\n",
            "Test: [120/157]\tTime 0.044 (0.044)\tLoss 0.3380 (0.3618)\tPrec@1 93.750 (88.404)\n",
            "Test: [130/157]\tTime 0.044 (0.044)\tLoss 0.3121 (0.3621)\tPrec@1 87.500 (88.430)\n",
            "Test: [140/157]\tTime 0.051 (0.044)\tLoss 0.1089 (0.3580)\tPrec@1 95.312 (88.652)\n",
            "Test: [150/157]\tTime 0.043 (0.044)\tLoss 0.2141 (0.3577)\tPrec@1 92.188 (88.566)\n",
            " * Prec@1 88.610\n",
            "Best accuracy:  tensor(89.3000, device='cuda:0')\n",
            "Epoch: [57][0/782]\tTime 0.262 (0.262)\tLoss 0.1251 (0.1251)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [57][10/782]\tTime 0.164 (0.174)\tLoss 0.1132 (0.1788)\tPrec@1 95.312 (93.466)\n",
            "Epoch: [57][20/782]\tTime 0.162 (0.170)\tLoss 0.4274 (0.1937)\tPrec@1 85.938 (93.006)\n",
            "Epoch: [57][30/782]\tTime 0.166 (0.168)\tLoss 0.1117 (0.1902)\tPrec@1 95.312 (93.397)\n",
            "Epoch: [57][40/782]\tTime 0.168 (0.167)\tLoss 0.3444 (0.1971)\tPrec@1 92.188 (93.064)\n",
            "Epoch: [57][50/782]\tTime 0.166 (0.167)\tLoss 0.3423 (0.2020)\tPrec@1 87.500 (92.953)\n",
            "Epoch: [57][60/782]\tTime 0.164 (0.167)\tLoss 0.1607 (0.1991)\tPrec@1 95.312 (93.212)\n",
            "Epoch: [57][70/782]\tTime 0.163 (0.167)\tLoss 0.3406 (0.1983)\tPrec@1 87.500 (93.244)\n",
            "Epoch: [57][80/782]\tTime 0.166 (0.166)\tLoss 0.2426 (0.2013)\tPrec@1 92.188 (93.113)\n",
            "Epoch: [57][90/782]\tTime 0.165 (0.166)\tLoss 0.1053 (0.1994)\tPrec@1 95.312 (93.166)\n",
            "Epoch: [57][100/782]\tTime 0.165 (0.166)\tLoss 0.1575 (0.1983)\tPrec@1 95.312 (93.224)\n",
            "Epoch: [57][110/782]\tTime 0.165 (0.166)\tLoss 0.1383 (0.1986)\tPrec@1 96.875 (93.328)\n",
            "Epoch: [57][120/782]\tTime 0.164 (0.166)\tLoss 0.1762 (0.1963)\tPrec@1 95.312 (93.350)\n",
            "Epoch: [57][130/782]\tTime 0.164 (0.166)\tLoss 0.0994 (0.1961)\tPrec@1 93.750 (93.297)\n",
            "Epoch: [57][140/782]\tTime 0.165 (0.166)\tLoss 0.1991 (0.1982)\tPrec@1 93.750 (93.273)\n",
            "Epoch: [57][150/782]\tTime 0.163 (0.166)\tLoss 0.2447 (0.1994)\tPrec@1 93.750 (93.243)\n",
            "Epoch: [57][160/782]\tTime 0.168 (0.166)\tLoss 0.2161 (0.1994)\tPrec@1 92.188 (93.245)\n",
            "Epoch: [57][170/782]\tTime 0.165 (0.166)\tLoss 0.3029 (0.1991)\tPrec@1 81.250 (93.193)\n",
            "Epoch: [57][180/782]\tTime 0.164 (0.166)\tLoss 0.1935 (0.1999)\tPrec@1 92.188 (93.154)\n",
            "Epoch: [57][190/782]\tTime 0.165 (0.166)\tLoss 0.2940 (0.2017)\tPrec@1 92.188 (93.079)\n",
            "Epoch: [57][200/782]\tTime 0.165 (0.166)\tLoss 0.2179 (0.2030)\tPrec@1 90.625 (92.988)\n",
            "Epoch: [57][210/782]\tTime 0.164 (0.166)\tLoss 0.1790 (0.2048)\tPrec@1 93.750 (92.965)\n",
            "Epoch: [57][220/782]\tTime 0.166 (0.166)\tLoss 0.2066 (0.2039)\tPrec@1 93.750 (92.979)\n",
            "Epoch: [57][230/782]\tTime 0.165 (0.166)\tLoss 0.3764 (0.2056)\tPrec@1 87.500 (92.877)\n",
            "Epoch: [57][240/782]\tTime 0.167 (0.166)\tLoss 0.2007 (0.2057)\tPrec@1 89.062 (92.829)\n",
            "Epoch: [57][250/782]\tTime 0.163 (0.166)\tLoss 0.1367 (0.2050)\tPrec@1 95.312 (92.835)\n",
            "Epoch: [57][260/782]\tTime 0.167 (0.166)\tLoss 0.2627 (0.2071)\tPrec@1 92.188 (92.756)\n",
            "Epoch: [57][270/782]\tTime 0.166 (0.166)\tLoss 0.1989 (0.2076)\tPrec@1 90.625 (92.729)\n",
            "Epoch: [57][280/782]\tTime 0.163 (0.166)\tLoss 0.2284 (0.2095)\tPrec@1 92.188 (92.677)\n",
            "Epoch: [57][290/782]\tTime 0.166 (0.166)\tLoss 0.2642 (0.2100)\tPrec@1 90.625 (92.644)\n",
            "Epoch: [57][300/782]\tTime 0.164 (0.166)\tLoss 0.2910 (0.2093)\tPrec@1 90.625 (92.701)\n",
            "Epoch: [57][310/782]\tTime 0.165 (0.166)\tLoss 0.1590 (0.2100)\tPrec@1 95.312 (92.670)\n",
            "Epoch: [57][320/782]\tTime 0.166 (0.166)\tLoss 0.1710 (0.2095)\tPrec@1 96.875 (92.679)\n",
            "Epoch: [57][330/782]\tTime 0.164 (0.166)\tLoss 0.1819 (0.2092)\tPrec@1 92.188 (92.683)\n",
            "Epoch: [57][340/782]\tTime 0.166 (0.166)\tLoss 0.2259 (0.2105)\tPrec@1 95.312 (92.664)\n",
            "Epoch: [57][350/782]\tTime 0.167 (0.166)\tLoss 0.3034 (0.2117)\tPrec@1 90.625 (92.624)\n",
            "Epoch: [57][360/782]\tTime 0.164 (0.166)\tLoss 0.2539 (0.2135)\tPrec@1 92.188 (92.555)\n",
            "Epoch: [57][370/782]\tTime 0.164 (0.166)\tLoss 0.1322 (0.2130)\tPrec@1 95.312 (92.550)\n",
            "Epoch: [57][380/782]\tTime 0.165 (0.166)\tLoss 0.0731 (0.2129)\tPrec@1 100.000 (92.532)\n",
            "Epoch: [57][390/782]\tTime 0.163 (0.166)\tLoss 0.3987 (0.2132)\tPrec@1 85.938 (92.535)\n",
            "Epoch: [57][400/782]\tTime 0.165 (0.166)\tLoss 0.2150 (0.2135)\tPrec@1 89.062 (92.550)\n",
            "Epoch: [57][410/782]\tTime 0.164 (0.166)\tLoss 0.2529 (0.2135)\tPrec@1 90.625 (92.530)\n",
            "Epoch: [57][420/782]\tTime 0.164 (0.166)\tLoss 0.1776 (0.2123)\tPrec@1 93.750 (92.555)\n",
            "Epoch: [57][430/782]\tTime 0.167 (0.166)\tLoss 0.2170 (0.2125)\tPrec@1 96.875 (92.565)\n",
            "Epoch: [57][440/782]\tTime 0.162 (0.166)\tLoss 0.1887 (0.2132)\tPrec@1 90.625 (92.517)\n",
            "Epoch: [57][450/782]\tTime 0.164 (0.166)\tLoss 0.1328 (0.2127)\tPrec@1 96.875 (92.565)\n",
            "Epoch: [57][460/782]\tTime 0.167 (0.166)\tLoss 0.2278 (0.2128)\tPrec@1 92.188 (92.554)\n",
            "Epoch: [57][470/782]\tTime 0.165 (0.166)\tLoss 0.2136 (0.2126)\tPrec@1 92.188 (92.569)\n",
            "Epoch: [57][480/782]\tTime 0.164 (0.166)\tLoss 0.1914 (0.2119)\tPrec@1 95.312 (92.597)\n",
            "Epoch: [57][490/782]\tTime 0.167 (0.166)\tLoss 0.2283 (0.2116)\tPrec@1 87.500 (92.579)\n",
            "Epoch: [57][500/782]\tTime 0.162 (0.166)\tLoss 0.3308 (0.2127)\tPrec@1 90.625 (92.524)\n",
            "Epoch: [57][510/782]\tTime 0.163 (0.166)\tLoss 0.3726 (0.2132)\tPrec@1 79.688 (92.493)\n",
            "Epoch: [57][520/782]\tTime 0.163 (0.166)\tLoss 0.1716 (0.2134)\tPrec@1 95.312 (92.484)\n",
            "Epoch: [57][530/782]\tTime 0.168 (0.166)\tLoss 0.3537 (0.2145)\tPrec@1 89.062 (92.432)\n",
            "Epoch: [57][540/782]\tTime 0.166 (0.166)\tLoss 0.2999 (0.2153)\tPrec@1 87.500 (92.401)\n",
            "Epoch: [57][550/782]\tTime 0.164 (0.166)\tLoss 0.3722 (0.2157)\tPrec@1 82.812 (92.377)\n",
            "Epoch: [57][560/782]\tTime 0.164 (0.166)\tLoss 0.2105 (0.2166)\tPrec@1 90.625 (92.355)\n",
            "Epoch: [57][570/782]\tTime 0.164 (0.166)\tLoss 0.1234 (0.2168)\tPrec@1 96.875 (92.354)\n",
            "Epoch: [57][580/782]\tTime 0.166 (0.166)\tLoss 0.1596 (0.2172)\tPrec@1 95.312 (92.352)\n",
            "Epoch: [57][590/782]\tTime 0.163 (0.166)\tLoss 0.0829 (0.2170)\tPrec@1 96.875 (92.351)\n",
            "Epoch: [57][600/782]\tTime 0.164 (0.166)\tLoss 0.1873 (0.2164)\tPrec@1 92.188 (92.372)\n",
            "Epoch: [57][610/782]\tTime 0.166 (0.166)\tLoss 0.2134 (0.2163)\tPrec@1 95.312 (92.387)\n",
            "Epoch: [57][620/782]\tTime 0.165 (0.166)\tLoss 0.2013 (0.2165)\tPrec@1 93.750 (92.389)\n",
            "Epoch: [57][630/782]\tTime 0.167 (0.166)\tLoss 0.1918 (0.2164)\tPrec@1 92.188 (92.393)\n",
            "Epoch: [57][640/782]\tTime 0.164 (0.166)\tLoss 0.1480 (0.2162)\tPrec@1 92.188 (92.390)\n",
            "Epoch: [57][650/782]\tTime 0.166 (0.166)\tLoss 0.1575 (0.2166)\tPrec@1 93.750 (92.380)\n",
            "Epoch: [57][660/782]\tTime 0.164 (0.166)\tLoss 0.1983 (0.2164)\tPrec@1 95.312 (92.407)\n",
            "Epoch: [57][670/782]\tTime 0.163 (0.166)\tLoss 0.1287 (0.2165)\tPrec@1 96.875 (92.420)\n",
            "Epoch: [57][680/782]\tTime 0.166 (0.166)\tLoss 0.1361 (0.2166)\tPrec@1 95.312 (92.424)\n",
            "Epoch: [57][690/782]\tTime 0.165 (0.166)\tLoss 0.1876 (0.2168)\tPrec@1 92.188 (92.409)\n",
            "Epoch: [57][700/782]\tTime 0.166 (0.166)\tLoss 0.2080 (0.2168)\tPrec@1 92.188 (92.397)\n",
            "Epoch: [57][710/782]\tTime 0.166 (0.166)\tLoss 0.1174 (0.2168)\tPrec@1 98.438 (92.407)\n",
            "Epoch: [57][720/782]\tTime 0.164 (0.166)\tLoss 0.2698 (0.2173)\tPrec@1 92.188 (92.409)\n",
            "Epoch: [57][730/782]\tTime 0.171 (0.166)\tLoss 0.2981 (0.2181)\tPrec@1 90.625 (92.384)\n",
            "Epoch: [57][740/782]\tTime 0.167 (0.166)\tLoss 0.2638 (0.2182)\tPrec@1 92.188 (92.384)\n",
            "Epoch: [57][750/782]\tTime 0.165 (0.166)\tLoss 0.2658 (0.2186)\tPrec@1 89.062 (92.379)\n",
            "Epoch: [57][760/782]\tTime 0.169 (0.166)\tLoss 0.2187 (0.2187)\tPrec@1 90.625 (92.381)\n",
            "Epoch: [57][770/782]\tTime 0.168 (0.166)\tLoss 0.1786 (0.2196)\tPrec@1 95.312 (92.354)\n",
            "Epoch: [57][780/782]\tTime 0.163 (0.166)\tLoss 0.1331 (0.2194)\tPrec@1 95.312 (92.362)\n",
            "Training accuracy:  tensor(92.3560, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.5760, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.118 (0.118)\tLoss 0.2408 (0.2408)\tPrec@1 89.062 (89.062)\n",
            "Test: [10/157]\tTime 0.051 (0.048)\tLoss 0.3712 (0.3835)\tPrec@1 87.500 (88.494)\n",
            "Test: [20/157]\tTime 0.052 (0.046)\tLoss 0.2424 (0.3889)\tPrec@1 89.062 (88.318)\n",
            "Test: [30/157]\tTime 0.043 (0.046)\tLoss 0.3074 (0.3609)\tPrec@1 85.938 (88.659)\n",
            "Test: [40/157]\tTime 0.044 (0.045)\tLoss 0.3623 (0.3729)\tPrec@1 85.938 (87.995)\n",
            "Test: [50/157]\tTime 0.044 (0.045)\tLoss 0.4780 (0.3650)\tPrec@1 85.938 (88.174)\n",
            "Test: [60/157]\tTime 0.042 (0.045)\tLoss 0.3193 (0.3686)\tPrec@1 89.062 (88.089)\n",
            "Test: [70/157]\tTime 0.043 (0.045)\tLoss 0.4431 (0.3727)\tPrec@1 84.375 (87.984)\n",
            "Test: [80/157]\tTime 0.039 (0.045)\tLoss 0.6416 (0.3907)\tPrec@1 78.125 (87.577)\n",
            "Test: [90/157]\tTime 0.044 (0.045)\tLoss 0.3435 (0.3922)\tPrec@1 89.062 (87.655)\n",
            "Test: [100/157]\tTime 0.043 (0.044)\tLoss 0.4287 (0.3995)\tPrec@1 81.250 (87.500)\n",
            "Test: [110/157]\tTime 0.044 (0.044)\tLoss 0.6853 (0.3976)\tPrec@1 81.250 (87.683)\n",
            "Test: [120/157]\tTime 0.042 (0.044)\tLoss 0.3767 (0.3927)\tPrec@1 87.500 (87.707)\n",
            "Test: [130/157]\tTime 0.043 (0.044)\tLoss 0.6543 (0.3946)\tPrec@1 82.812 (87.655)\n",
            "Test: [140/157]\tTime 0.045 (0.044)\tLoss 0.2492 (0.3944)\tPrec@1 90.625 (87.677)\n",
            "Test: [150/157]\tTime 0.042 (0.044)\tLoss 0.4824 (0.3923)\tPrec@1 85.938 (87.707)\n",
            " * Prec@1 87.690\n",
            "Best accuracy:  tensor(89.3000, device='cuda:0')\n",
            "Epoch: [58][0/782]\tTime 0.262 (0.262)\tLoss 0.3421 (0.3421)\tPrec@1 84.375 (84.375)\n",
            "Epoch: [58][10/782]\tTime 0.165 (0.174)\tLoss 0.2440 (0.2511)\tPrec@1 93.750 (90.909)\n",
            "Epoch: [58][20/782]\tTime 0.163 (0.170)\tLoss 0.1757 (0.2373)\tPrec@1 90.625 (91.369)\n",
            "Epoch: [58][30/782]\tTime 0.164 (0.169)\tLoss 0.2240 (0.2345)\tPrec@1 92.188 (91.381)\n",
            "Epoch: [58][40/782]\tTime 0.164 (0.168)\tLoss 0.2449 (0.2317)\tPrec@1 90.625 (91.387)\n",
            "Epoch: [58][50/782]\tTime 0.164 (0.167)\tLoss 0.1960 (0.2267)\tPrec@1 93.750 (91.667)\n",
            "Epoch: [58][60/782]\tTime 0.164 (0.167)\tLoss 0.1864 (0.2193)\tPrec@1 93.750 (92.008)\n",
            "Epoch: [58][70/782]\tTime 0.164 (0.167)\tLoss 0.1640 (0.2187)\tPrec@1 95.312 (92.077)\n",
            "Epoch: [58][80/782]\tTime 0.164 (0.166)\tLoss 0.2610 (0.2158)\tPrec@1 92.188 (92.303)\n",
            "Epoch: [58][90/782]\tTime 0.166 (0.166)\tLoss 0.3909 (0.2186)\tPrec@1 87.500 (92.170)\n",
            "Epoch: [58][100/782]\tTime 0.166 (0.166)\tLoss 0.0893 (0.2125)\tPrec@1 98.438 (92.389)\n",
            "Epoch: [58][110/782]\tTime 0.164 (0.166)\tLoss 0.0558 (0.2095)\tPrec@1 98.438 (92.497)\n",
            "Epoch: [58][120/782]\tTime 0.165 (0.166)\tLoss 0.1549 (0.2065)\tPrec@1 92.188 (92.588)\n",
            "Epoch: [58][130/782]\tTime 0.164 (0.166)\tLoss 0.3562 (0.2054)\tPrec@1 87.500 (92.641)\n",
            "Epoch: [58][140/782]\tTime 0.163 (0.166)\tLoss 0.0824 (0.2048)\tPrec@1 95.312 (92.664)\n",
            "Epoch: [58][150/782]\tTime 0.166 (0.166)\tLoss 0.2453 (0.2060)\tPrec@1 92.188 (92.653)\n",
            "Epoch: [58][160/782]\tTime 0.165 (0.166)\tLoss 0.2353 (0.2083)\tPrec@1 96.875 (92.653)\n",
            "Epoch: [58][170/782]\tTime 0.164 (0.166)\tLoss 0.2146 (0.2105)\tPrec@1 93.750 (92.571)\n",
            "Epoch: [58][180/782]\tTime 0.166 (0.166)\tLoss 0.1459 (0.2114)\tPrec@1 92.188 (92.593)\n",
            "Epoch: [58][190/782]\tTime 0.165 (0.166)\tLoss 0.2067 (0.2103)\tPrec@1 92.188 (92.588)\n",
            "Epoch: [58][200/782]\tTime 0.164 (0.166)\tLoss 0.1412 (0.2101)\tPrec@1 95.312 (92.646)\n",
            "Epoch: [58][210/782]\tTime 0.166 (0.166)\tLoss 0.1294 (0.2118)\tPrec@1 98.438 (92.624)\n",
            "Epoch: [58][220/782]\tTime 0.164 (0.166)\tLoss 0.1987 (0.2104)\tPrec@1 93.750 (92.654)\n",
            "Epoch: [58][230/782]\tTime 0.166 (0.166)\tLoss 0.3162 (0.2122)\tPrec@1 90.625 (92.607)\n",
            "Epoch: [58][240/782]\tTime 0.166 (0.166)\tLoss 0.1336 (0.2134)\tPrec@1 96.875 (92.577)\n",
            "Epoch: [58][250/782]\tTime 0.163 (0.166)\tLoss 0.1747 (0.2138)\tPrec@1 93.750 (92.524)\n",
            "Epoch: [58][260/782]\tTime 0.165 (0.166)\tLoss 0.2334 (0.2126)\tPrec@1 92.188 (92.553)\n",
            "Epoch: [58][270/782]\tTime 0.162 (0.166)\tLoss 0.3471 (0.2133)\tPrec@1 89.062 (92.510)\n",
            "Epoch: [58][280/782]\tTime 0.164 (0.166)\tLoss 0.1711 (0.2138)\tPrec@1 93.750 (92.516)\n",
            "Epoch: [58][290/782]\tTime 0.166 (0.166)\tLoss 0.2481 (0.2140)\tPrec@1 93.750 (92.510)\n",
            "Epoch: [58][300/782]\tTime 0.165 (0.166)\tLoss 0.2179 (0.2151)\tPrec@1 92.188 (92.478)\n",
            "Epoch: [58][310/782]\tTime 0.166 (0.166)\tLoss 0.1513 (0.2147)\tPrec@1 95.312 (92.519)\n",
            "Epoch: [58][320/782]\tTime 0.165 (0.166)\tLoss 0.1419 (0.2143)\tPrec@1 93.750 (92.528)\n",
            "Epoch: [58][330/782]\tTime 0.169 (0.166)\tLoss 0.2151 (0.2150)\tPrec@1 92.188 (92.523)\n",
            "Epoch: [58][340/782]\tTime 0.170 (0.166)\tLoss 0.2058 (0.2133)\tPrec@1 90.625 (92.577)\n",
            "Epoch: [58][350/782]\tTime 0.166 (0.166)\tLoss 0.3074 (0.2130)\tPrec@1 92.188 (92.584)\n",
            "Epoch: [58][360/782]\tTime 0.167 (0.166)\tLoss 0.2201 (0.2128)\tPrec@1 90.625 (92.551)\n",
            "Epoch: [58][370/782]\tTime 0.165 (0.166)\tLoss 0.0694 (0.2134)\tPrec@1 96.875 (92.508)\n",
            "Epoch: [58][380/782]\tTime 0.168 (0.166)\tLoss 0.2850 (0.2138)\tPrec@1 92.188 (92.516)\n",
            "Epoch: [58][390/782]\tTime 0.167 (0.166)\tLoss 0.1838 (0.2129)\tPrec@1 95.312 (92.571)\n",
            "Epoch: [58][400/782]\tTime 0.165 (0.166)\tLoss 0.2876 (0.2128)\tPrec@1 87.500 (92.589)\n",
            "Epoch: [58][410/782]\tTime 0.164 (0.166)\tLoss 0.2230 (0.2129)\tPrec@1 92.188 (92.587)\n",
            "Epoch: [58][420/782]\tTime 0.168 (0.166)\tLoss 0.1726 (0.2122)\tPrec@1 90.625 (92.607)\n",
            "Epoch: [58][430/782]\tTime 0.168 (0.166)\tLoss 0.2056 (0.2125)\tPrec@1 92.188 (92.594)\n",
            "Epoch: [58][440/782]\tTime 0.164 (0.166)\tLoss 0.2519 (0.2136)\tPrec@1 90.625 (92.563)\n",
            "Epoch: [58][450/782]\tTime 0.170 (0.166)\tLoss 0.2001 (0.2133)\tPrec@1 92.188 (92.569)\n",
            "Epoch: [58][460/782]\tTime 0.165 (0.166)\tLoss 0.2095 (0.2129)\tPrec@1 92.188 (92.591)\n",
            "Epoch: [58][470/782]\tTime 0.166 (0.166)\tLoss 0.2275 (0.2125)\tPrec@1 95.312 (92.592)\n",
            "Epoch: [58][480/782]\tTime 0.163 (0.166)\tLoss 0.2228 (0.2125)\tPrec@1 92.188 (92.607)\n",
            "Epoch: [58][490/782]\tTime 0.164 (0.166)\tLoss 0.2580 (0.2125)\tPrec@1 93.750 (92.614)\n",
            "Epoch: [58][500/782]\tTime 0.166 (0.166)\tLoss 0.3860 (0.2125)\tPrec@1 87.500 (92.584)\n",
            "Epoch: [58][510/782]\tTime 0.164 (0.166)\tLoss 0.3350 (0.2129)\tPrec@1 89.062 (92.573)\n",
            "Epoch: [58][520/782]\tTime 0.164 (0.166)\tLoss 0.5893 (0.2139)\tPrec@1 84.375 (92.532)\n",
            "Epoch: [58][530/782]\tTime 0.170 (0.166)\tLoss 0.3454 (0.2147)\tPrec@1 90.625 (92.514)\n",
            "Epoch: [58][540/782]\tTime 0.164 (0.166)\tLoss 0.1284 (0.2152)\tPrec@1 95.312 (92.499)\n",
            "Epoch: [58][550/782]\tTime 0.165 (0.166)\tLoss 0.1683 (0.2155)\tPrec@1 93.750 (92.482)\n",
            "Epoch: [58][560/782]\tTime 0.164 (0.166)\tLoss 0.1847 (0.2158)\tPrec@1 95.312 (92.449)\n",
            "Epoch: [58][570/782]\tTime 0.164 (0.166)\tLoss 0.2249 (0.2157)\tPrec@1 92.188 (92.453)\n",
            "Epoch: [58][580/782]\tTime 0.162 (0.166)\tLoss 0.2865 (0.2151)\tPrec@1 87.500 (92.481)\n",
            "Epoch: [58][590/782]\tTime 0.164 (0.166)\tLoss 0.3971 (0.2157)\tPrec@1 90.625 (92.476)\n",
            "Epoch: [58][600/782]\tTime 0.165 (0.166)\tLoss 0.3167 (0.2159)\tPrec@1 90.625 (92.468)\n",
            "Epoch: [58][610/782]\tTime 0.169 (0.166)\tLoss 0.2559 (0.2161)\tPrec@1 90.625 (92.438)\n",
            "Epoch: [58][620/782]\tTime 0.166 (0.166)\tLoss 0.1938 (0.2160)\tPrec@1 93.750 (92.437)\n",
            "Epoch: [58][630/782]\tTime 0.162 (0.166)\tLoss 0.2050 (0.2155)\tPrec@1 93.750 (92.457)\n",
            "Epoch: [58][640/782]\tTime 0.162 (0.166)\tLoss 0.1955 (0.2156)\tPrec@1 93.750 (92.463)\n",
            "Epoch: [58][650/782]\tTime 0.164 (0.166)\tLoss 0.1992 (0.2159)\tPrec@1 92.188 (92.452)\n",
            "Epoch: [58][660/782]\tTime 0.162 (0.166)\tLoss 0.1929 (0.2162)\tPrec@1 92.188 (92.438)\n",
            "Epoch: [58][670/782]\tTime 0.163 (0.165)\tLoss 0.1973 (0.2163)\tPrec@1 95.312 (92.432)\n",
            "Epoch: [58][680/782]\tTime 0.162 (0.165)\tLoss 0.1971 (0.2165)\tPrec@1 95.312 (92.426)\n",
            "Epoch: [58][690/782]\tTime 0.168 (0.165)\tLoss 0.3234 (0.2168)\tPrec@1 89.062 (92.429)\n",
            "Epoch: [58][700/782]\tTime 0.164 (0.165)\tLoss 0.1585 (0.2160)\tPrec@1 92.188 (92.453)\n",
            "Epoch: [58][710/782]\tTime 0.164 (0.165)\tLoss 0.0884 (0.2161)\tPrec@1 96.875 (92.460)\n",
            "Epoch: [58][720/782]\tTime 0.163 (0.165)\tLoss 0.3672 (0.2164)\tPrec@1 89.062 (92.469)\n",
            "Epoch: [58][730/782]\tTime 0.163 (0.165)\tLoss 0.1198 (0.2162)\tPrec@1 95.312 (92.480)\n",
            "Epoch: [58][740/782]\tTime 0.165 (0.165)\tLoss 0.2547 (0.2162)\tPrec@1 89.062 (92.485)\n",
            "Epoch: [58][750/782]\tTime 0.162 (0.165)\tLoss 0.1684 (0.2162)\tPrec@1 93.750 (92.497)\n",
            "Epoch: [58][760/782]\tTime 0.163 (0.165)\tLoss 0.1401 (0.2157)\tPrec@1 95.312 (92.506)\n",
            "Epoch: [58][770/782]\tTime 0.163 (0.165)\tLoss 0.0380 (0.2155)\tPrec@1 100.000 (92.508)\n",
            "Epoch: [58][780/782]\tTime 0.162 (0.165)\tLoss 0.2822 (0.2160)\tPrec@1 87.500 (92.490)\n",
            "Training accuracy:  tensor(92.4900, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.5760, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.109 (0.109)\tLoss 0.3590 (0.3590)\tPrec@1 89.062 (89.062)\n",
            "Test: [10/157]\tTime 0.042 (0.047)\tLoss 0.2372 (0.2804)\tPrec@1 90.625 (89.631)\n",
            "Test: [20/157]\tTime 0.047 (0.045)\tLoss 0.3277 (0.3290)\tPrec@1 90.625 (88.765)\n",
            "Test: [30/157]\tTime 0.043 (0.046)\tLoss 0.0873 (0.3012)\tPrec@1 95.312 (89.415)\n",
            "Test: [40/157]\tTime 0.043 (0.045)\tLoss 0.1886 (0.2995)\tPrec@1 89.062 (89.634)\n",
            "Test: [50/157]\tTime 0.037 (0.045)\tLoss 0.4153 (0.2998)\tPrec@1 84.375 (89.583)\n",
            "Test: [60/157]\tTime 0.043 (0.045)\tLoss 0.3270 (0.3248)\tPrec@1 90.625 (89.293)\n",
            "Test: [70/157]\tTime 0.044 (0.045)\tLoss 0.3747 (0.3269)\tPrec@1 92.188 (89.415)\n",
            "Test: [80/157]\tTime 0.043 (0.044)\tLoss 0.2714 (0.3223)\tPrec@1 90.625 (89.525)\n",
            "Test: [90/157]\tTime 0.044 (0.044)\tLoss 0.2608 (0.3205)\tPrec@1 96.875 (89.784)\n",
            "Test: [100/157]\tTime 0.044 (0.044)\tLoss 0.5557 (0.3283)\tPrec@1 89.062 (89.712)\n",
            "Test: [110/157]\tTime 0.044 (0.044)\tLoss 0.3086 (0.3288)\tPrec@1 92.188 (89.682)\n",
            "Test: [120/157]\tTime 0.040 (0.044)\tLoss 0.3925 (0.3281)\tPrec@1 87.500 (89.708)\n",
            "Test: [130/157]\tTime 0.043 (0.044)\tLoss 0.3070 (0.3312)\tPrec@1 85.938 (89.587)\n",
            "Test: [140/157]\tTime 0.045 (0.044)\tLoss 0.4801 (0.3304)\tPrec@1 84.375 (89.617)\n",
            "Test: [150/157]\tTime 0.043 (0.044)\tLoss 0.2929 (0.3291)\tPrec@1 87.500 (89.652)\n",
            " * Prec@1 89.660\n",
            "Best accuracy:  tensor(89.6600, device='cuda:0')\n",
            "Epoch: [59][0/782]\tTime 0.257 (0.257)\tLoss 0.2135 (0.2135)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [59][10/782]\tTime 0.162 (0.173)\tLoss 0.1410 (0.1948)\tPrec@1 93.750 (92.756)\n",
            "Epoch: [59][20/782]\tTime 0.163 (0.168)\tLoss 0.2123 (0.2108)\tPrec@1 92.188 (92.485)\n",
            "Epoch: [59][30/782]\tTime 0.166 (0.167)\tLoss 0.2569 (0.2179)\tPrec@1 87.500 (92.188)\n",
            "Epoch: [59][40/782]\tTime 0.164 (0.166)\tLoss 0.2320 (0.2070)\tPrec@1 93.750 (92.492)\n",
            "Epoch: [59][50/782]\tTime 0.162 (0.166)\tLoss 0.1950 (0.2023)\tPrec@1 92.188 (92.923)\n",
            "Epoch: [59][60/782]\tTime 0.162 (0.165)\tLoss 0.1723 (0.2054)\tPrec@1 93.750 (92.828)\n",
            "Epoch: [59][70/782]\tTime 0.162 (0.165)\tLoss 0.4076 (0.2076)\tPrec@1 89.062 (92.760)\n",
            "Epoch: [59][80/782]\tTime 0.164 (0.165)\tLoss 0.2776 (0.2082)\tPrec@1 90.625 (92.824)\n",
            "Epoch: [59][90/782]\tTime 0.165 (0.165)\tLoss 0.0723 (0.2101)\tPrec@1 98.438 (92.788)\n",
            "Epoch: [59][100/782]\tTime 0.170 (0.165)\tLoss 0.1696 (0.2106)\tPrec@1 95.312 (92.729)\n",
            "Epoch: [59][110/782]\tTime 0.164 (0.165)\tLoss 0.0704 (0.2101)\tPrec@1 96.875 (92.736)\n",
            "Epoch: [59][120/782]\tTime 0.164 (0.165)\tLoss 0.2387 (0.2113)\tPrec@1 92.188 (92.665)\n",
            "Epoch: [59][130/782]\tTime 0.163 (0.165)\tLoss 0.2864 (0.2144)\tPrec@1 90.625 (92.533)\n",
            "Epoch: [59][140/782]\tTime 0.164 (0.165)\tLoss 0.1160 (0.2151)\tPrec@1 96.875 (92.487)\n",
            "Epoch: [59][150/782]\tTime 0.163 (0.165)\tLoss 0.3593 (0.2157)\tPrec@1 85.938 (92.436)\n",
            "Epoch: [59][160/782]\tTime 0.163 (0.164)\tLoss 0.2769 (0.2161)\tPrec@1 92.188 (92.479)\n",
            "Epoch: [59][170/782]\tTime 0.164 (0.165)\tLoss 0.2074 (0.2143)\tPrec@1 90.625 (92.480)\n",
            "Epoch: [59][180/782]\tTime 0.163 (0.165)\tLoss 0.3563 (0.2143)\tPrec@1 84.375 (92.490)\n",
            "Epoch: [59][190/782]\tTime 0.163 (0.164)\tLoss 0.1397 (0.2135)\tPrec@1 95.312 (92.547)\n",
            "Epoch: [59][200/782]\tTime 0.164 (0.164)\tLoss 0.0898 (0.2112)\tPrec@1 96.875 (92.615)\n",
            "Epoch: [59][210/782]\tTime 0.165 (0.164)\tLoss 0.2501 (0.2107)\tPrec@1 90.625 (92.639)\n",
            "Epoch: [59][220/782]\tTime 0.162 (0.164)\tLoss 0.2753 (0.2114)\tPrec@1 93.750 (92.626)\n",
            "Epoch: [59][230/782]\tTime 0.162 (0.164)\tLoss 0.2641 (0.2134)\tPrec@1 89.062 (92.560)\n",
            "Epoch: [59][240/782]\tTime 0.166 (0.164)\tLoss 0.3204 (0.2135)\tPrec@1 87.500 (92.531)\n",
            "Epoch: [59][250/782]\tTime 0.162 (0.164)\tLoss 0.1152 (0.2149)\tPrec@1 96.875 (92.486)\n",
            "Epoch: [59][260/782]\tTime 0.164 (0.164)\tLoss 0.1925 (0.2132)\tPrec@1 92.188 (92.553)\n",
            "Epoch: [59][270/782]\tTime 0.164 (0.164)\tLoss 0.0917 (0.2128)\tPrec@1 96.875 (92.597)\n",
            "Epoch: [59][280/782]\tTime 0.163 (0.164)\tLoss 0.2019 (0.2133)\tPrec@1 90.625 (92.560)\n",
            "Epoch: [59][290/782]\tTime 0.163 (0.164)\tLoss 0.1646 (0.2136)\tPrec@1 96.875 (92.542)\n",
            "Epoch: [59][300/782]\tTime 0.164 (0.164)\tLoss 0.2817 (0.2130)\tPrec@1 85.938 (92.535)\n",
            "Epoch: [59][310/782]\tTime 0.168 (0.164)\tLoss 0.1931 (0.2127)\tPrec@1 93.750 (92.544)\n",
            "Epoch: [59][320/782]\tTime 0.162 (0.164)\tLoss 0.2433 (0.2126)\tPrec@1 90.625 (92.572)\n",
            "Epoch: [59][330/782]\tTime 0.162 (0.164)\tLoss 0.4200 (0.2136)\tPrec@1 85.938 (92.518)\n",
            "Epoch: [59][340/782]\tTime 0.163 (0.164)\tLoss 0.1979 (0.2138)\tPrec@1 89.062 (92.485)\n",
            "Epoch: [59][350/782]\tTime 0.164 (0.164)\tLoss 0.1835 (0.2134)\tPrec@1 95.312 (92.504)\n",
            "Epoch: [59][360/782]\tTime 0.161 (0.164)\tLoss 0.2010 (0.2138)\tPrec@1 92.188 (92.469)\n",
            "Epoch: [59][370/782]\tTime 0.163 (0.164)\tLoss 0.3668 (0.2138)\tPrec@1 84.375 (92.461)\n",
            "Epoch: [59][380/782]\tTime 0.163 (0.164)\tLoss 0.2375 (0.2160)\tPrec@1 90.625 (92.393)\n",
            "Epoch: [59][390/782]\tTime 0.164 (0.164)\tLoss 0.2008 (0.2164)\tPrec@1 95.312 (92.407)\n",
            "Epoch: [59][400/782]\tTime 0.164 (0.164)\tLoss 0.4304 (0.2172)\tPrec@1 79.688 (92.371)\n",
            "Epoch: [59][410/782]\tTime 0.162 (0.164)\tLoss 0.1357 (0.2179)\tPrec@1 95.312 (92.328)\n",
            "Epoch: [59][420/782]\tTime 0.162 (0.164)\tLoss 0.1610 (0.2173)\tPrec@1 98.438 (92.373)\n",
            "Epoch: [59][430/782]\tTime 0.163 (0.164)\tLoss 0.1016 (0.2174)\tPrec@1 98.438 (92.365)\n",
            "Epoch: [59][440/782]\tTime 0.164 (0.164)\tLoss 0.0886 (0.2176)\tPrec@1 96.875 (92.372)\n",
            "Epoch: [59][450/782]\tTime 0.164 (0.164)\tLoss 0.1646 (0.2169)\tPrec@1 92.188 (92.382)\n",
            "Epoch: [59][460/782]\tTime 0.162 (0.164)\tLoss 0.0951 (0.2154)\tPrec@1 95.312 (92.465)\n",
            "Epoch: [59][470/782]\tTime 0.163 (0.164)\tLoss 0.0938 (0.2153)\tPrec@1 96.875 (92.493)\n",
            "Epoch: [59][480/782]\tTime 0.164 (0.164)\tLoss 0.0977 (0.2158)\tPrec@1 96.875 (92.477)\n",
            "Epoch: [59][490/782]\tTime 0.164 (0.164)\tLoss 0.1886 (0.2151)\tPrec@1 95.312 (92.531)\n",
            "Epoch: [59][500/782]\tTime 0.163 (0.164)\tLoss 0.1490 (0.2145)\tPrec@1 95.312 (92.527)\n",
            "Epoch: [59][510/782]\tTime 0.172 (0.164)\tLoss 0.1554 (0.2144)\tPrec@1 95.312 (92.521)\n",
            "Epoch: [59][520/782]\tTime 0.163 (0.164)\tLoss 0.1454 (0.2138)\tPrec@1 93.750 (92.559)\n",
            "Epoch: [59][530/782]\tTime 0.162 (0.164)\tLoss 0.1230 (0.2135)\tPrec@1 95.312 (92.561)\n",
            "Epoch: [59][540/782]\tTime 0.164 (0.164)\tLoss 0.0843 (0.2136)\tPrec@1 98.438 (92.549)\n",
            "Epoch: [59][550/782]\tTime 0.164 (0.164)\tLoss 0.2442 (0.2140)\tPrec@1 89.062 (92.542)\n",
            "Epoch: [59][560/782]\tTime 0.164 (0.164)\tLoss 0.2666 (0.2137)\tPrec@1 92.188 (92.550)\n",
            "Epoch: [59][570/782]\tTime 0.162 (0.164)\tLoss 0.3130 (0.2140)\tPrec@1 90.625 (92.535)\n",
            "Epoch: [59][580/782]\tTime 0.164 (0.164)\tLoss 0.2662 (0.2143)\tPrec@1 89.062 (92.529)\n",
            "Epoch: [59][590/782]\tTime 0.164 (0.164)\tLoss 0.1933 (0.2147)\tPrec@1 92.188 (92.505)\n",
            "Epoch: [59][600/782]\tTime 0.163 (0.164)\tLoss 0.1315 (0.2146)\tPrec@1 95.312 (92.518)\n",
            "Epoch: [59][610/782]\tTime 0.163 (0.164)\tLoss 0.2236 (0.2155)\tPrec@1 90.625 (92.505)\n",
            "Epoch: [59][620/782]\tTime 0.162 (0.164)\tLoss 0.1446 (0.2163)\tPrec@1 96.875 (92.479)\n",
            "Epoch: [59][630/782]\tTime 0.163 (0.164)\tLoss 0.2692 (0.2170)\tPrec@1 93.750 (92.450)\n",
            "Epoch: [59][640/782]\tTime 0.163 (0.164)\tLoss 0.1260 (0.2179)\tPrec@1 95.312 (92.424)\n",
            "Epoch: [59][650/782]\tTime 0.163 (0.164)\tLoss 0.2248 (0.2174)\tPrec@1 90.625 (92.442)\n",
            "Epoch: [59][660/782]\tTime 0.164 (0.164)\tLoss 0.2036 (0.2173)\tPrec@1 95.312 (92.448)\n",
            "Epoch: [59][670/782]\tTime 0.164 (0.164)\tLoss 0.1632 (0.2171)\tPrec@1 93.750 (92.458)\n",
            "Epoch: [59][680/782]\tTime 0.164 (0.164)\tLoss 0.2648 (0.2169)\tPrec@1 93.750 (92.479)\n",
            "Epoch: [59][690/782]\tTime 0.162 (0.164)\tLoss 0.2834 (0.2169)\tPrec@1 87.500 (92.477)\n",
            "Epoch: [59][700/782]\tTime 0.166 (0.164)\tLoss 0.1832 (0.2172)\tPrec@1 95.312 (92.462)\n",
            "Epoch: [59][710/782]\tTime 0.162 (0.164)\tLoss 0.1148 (0.2173)\tPrec@1 95.312 (92.456)\n",
            "Epoch: [59][720/782]\tTime 0.163 (0.164)\tLoss 0.1599 (0.2170)\tPrec@1 93.750 (92.467)\n",
            "Epoch: [59][730/782]\tTime 0.166 (0.164)\tLoss 0.3297 (0.2172)\tPrec@1 87.500 (92.442)\n",
            "Epoch: [59][740/782]\tTime 0.164 (0.164)\tLoss 0.2116 (0.2167)\tPrec@1 93.750 (92.457)\n",
            "Epoch: [59][750/782]\tTime 0.163 (0.164)\tLoss 0.3099 (0.2168)\tPrec@1 95.312 (92.462)\n",
            "Epoch: [59][760/782]\tTime 0.162 (0.164)\tLoss 0.3490 (0.2169)\tPrec@1 92.188 (92.461)\n",
            "Epoch: [59][770/782]\tTime 0.163 (0.164)\tLoss 0.2965 (0.2172)\tPrec@1 87.500 (92.437)\n",
            "Epoch: [59][780/782]\tTime 0.162 (0.164)\tLoss 0.4428 (0.2179)\tPrec@1 87.500 (92.432)\n",
            "Training accuracy:  tensor(92.4280, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.5760, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.105 (0.105)\tLoss 0.5590 (0.5590)\tPrec@1 85.938 (85.938)\n",
            "Test: [10/157]\tTime 0.044 (0.047)\tLoss 0.3608 (0.4326)\tPrec@1 85.938 (86.222)\n",
            "Test: [20/157]\tTime 0.046 (0.045)\tLoss 0.3672 (0.3976)\tPrec@1 90.625 (87.351)\n",
            "Test: [30/157]\tTime 0.044 (0.045)\tLoss 0.3959 (0.4079)\tPrec@1 90.625 (87.399)\n",
            "Test: [40/157]\tTime 0.038 (0.045)\tLoss 0.2840 (0.4300)\tPrec@1 90.625 (87.309)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.3629 (0.4200)\tPrec@1 84.375 (87.439)\n",
            "Test: [60/157]\tTime 0.042 (0.045)\tLoss 0.3748 (0.4226)\tPrec@1 85.938 (87.449)\n",
            "Test: [70/157]\tTime 0.043 (0.044)\tLoss 0.2958 (0.4335)\tPrec@1 89.062 (87.280)\n",
            "Test: [80/157]\tTime 0.044 (0.044)\tLoss 0.3516 (0.4258)\tPrec@1 89.062 (87.384)\n",
            "Test: [90/157]\tTime 0.045 (0.044)\tLoss 0.2908 (0.4217)\tPrec@1 90.625 (87.517)\n",
            "Test: [100/157]\tTime 0.044 (0.044)\tLoss 0.0834 (0.4182)\tPrec@1 95.312 (87.608)\n",
            "Test: [110/157]\tTime 0.041 (0.044)\tLoss 0.4183 (0.4221)\tPrec@1 85.938 (87.401)\n",
            "Test: [120/157]\tTime 0.044 (0.044)\tLoss 0.4781 (0.4196)\tPrec@1 84.375 (87.474)\n",
            "Test: [130/157]\tTime 0.042 (0.044)\tLoss 0.2721 (0.4162)\tPrec@1 87.500 (87.619)\n",
            "Test: [140/157]\tTime 0.045 (0.044)\tLoss 0.1720 (0.4127)\tPrec@1 93.750 (87.766)\n",
            "Test: [150/157]\tTime 0.043 (0.044)\tLoss 0.6352 (0.4130)\tPrec@1 82.812 (87.738)\n",
            " * Prec@1 87.750\n",
            "Best accuracy:  tensor(89.6600, device='cuda:0')\n",
            "Epoch: [60][0/782]\tTime 0.264 (0.264)\tLoss 0.2163 (0.2163)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [60][10/782]\tTime 0.163 (0.172)\tLoss 0.0900 (0.1924)\tPrec@1 96.875 (92.188)\n",
            "Epoch: [60][20/782]\tTime 0.163 (0.168)\tLoss 0.2755 (0.2226)\tPrec@1 90.625 (91.815)\n",
            "Epoch: [60][30/782]\tTime 0.165 (0.167)\tLoss 0.2646 (0.2318)\tPrec@1 90.625 (91.683)\n",
            "Epoch: [60][40/782]\tTime 0.170 (0.166)\tLoss 0.0689 (0.2274)\tPrec@1 100.000 (91.921)\n",
            "Epoch: [60][50/782]\tTime 0.163 (0.166)\tLoss 0.1957 (0.2182)\tPrec@1 93.750 (92.218)\n",
            "Epoch: [60][60/782]\tTime 0.164 (0.165)\tLoss 0.1430 (0.2158)\tPrec@1 95.312 (92.367)\n",
            "Epoch: [60][70/782]\tTime 0.162 (0.165)\tLoss 0.1883 (0.2112)\tPrec@1 90.625 (92.672)\n",
            "Epoch: [60][80/782]\tTime 0.165 (0.165)\tLoss 0.4149 (0.2136)\tPrec@1 82.812 (92.593)\n",
            "Epoch: [60][90/782]\tTime 0.176 (0.165)\tLoss 0.1885 (0.2108)\tPrec@1 93.750 (92.634)\n",
            "Epoch: [60][100/782]\tTime 0.162 (0.165)\tLoss 0.2192 (0.2111)\tPrec@1 89.062 (92.574)\n",
            "Epoch: [60][110/782]\tTime 0.168 (0.165)\tLoss 0.2486 (0.2089)\tPrec@1 90.625 (92.680)\n",
            "Epoch: [60][120/782]\tTime 0.164 (0.165)\tLoss 0.2765 (0.2079)\tPrec@1 93.750 (92.652)\n",
            "Epoch: [60][130/782]\tTime 0.164 (0.165)\tLoss 0.3237 (0.2098)\tPrec@1 84.375 (92.545)\n",
            "Epoch: [60][140/782]\tTime 0.165 (0.165)\tLoss 0.2803 (0.2114)\tPrec@1 92.188 (92.553)\n",
            "Epoch: [60][150/782]\tTime 0.164 (0.164)\tLoss 0.1294 (0.2146)\tPrec@1 96.875 (92.446)\n",
            "Epoch: [60][160/782]\tTime 0.163 (0.164)\tLoss 0.1506 (0.2144)\tPrec@1 96.875 (92.450)\n",
            "Epoch: [60][170/782]\tTime 0.162 (0.164)\tLoss 0.2501 (0.2124)\tPrec@1 89.062 (92.535)\n",
            "Epoch: [60][180/782]\tTime 0.166 (0.164)\tLoss 0.1348 (0.2112)\tPrec@1 95.312 (92.671)\n",
            "Epoch: [60][190/782]\tTime 0.163 (0.164)\tLoss 0.1569 (0.2115)\tPrec@1 95.312 (92.703)\n",
            "Epoch: [60][200/782]\tTime 0.163 (0.164)\tLoss 0.2189 (0.2122)\tPrec@1 93.750 (92.708)\n",
            "Epoch: [60][210/782]\tTime 0.164 (0.164)\tLoss 0.1556 (0.2117)\tPrec@1 95.312 (92.706)\n",
            "Epoch: [60][220/782]\tTime 0.165 (0.164)\tLoss 0.1297 (0.2104)\tPrec@1 95.312 (92.824)\n",
            "Epoch: [60][230/782]\tTime 0.162 (0.164)\tLoss 0.0818 (0.2077)\tPrec@1 96.875 (92.904)\n",
            "Epoch: [60][240/782]\tTime 0.167 (0.165)\tLoss 0.1131 (0.2064)\tPrec@1 96.875 (92.933)\n",
            "Epoch: [60][250/782]\tTime 0.165 (0.165)\tLoss 0.1602 (0.2062)\tPrec@1 93.750 (92.916)\n",
            "Epoch: [60][260/782]\tTime 0.162 (0.165)\tLoss 0.1453 (0.2060)\tPrec@1 93.750 (92.870)\n",
            "Epoch: [60][270/782]\tTime 0.163 (0.165)\tLoss 0.1717 (0.2050)\tPrec@1 93.750 (92.914)\n",
            "Epoch: [60][280/782]\tTime 0.161 (0.164)\tLoss 0.2374 (0.2049)\tPrec@1 92.188 (92.916)\n",
            "Epoch: [60][290/782]\tTime 0.164 (0.164)\tLoss 0.1663 (0.2046)\tPrec@1 95.312 (92.945)\n",
            "Epoch: [60][300/782]\tTime 0.163 (0.164)\tLoss 0.2289 (0.2060)\tPrec@1 90.625 (92.888)\n",
            "Epoch: [60][310/782]\tTime 0.162 (0.164)\tLoss 0.1985 (0.2068)\tPrec@1 93.750 (92.866)\n",
            "Epoch: [60][320/782]\tTime 0.167 (0.164)\tLoss 0.2692 (0.2090)\tPrec@1 89.062 (92.776)\n",
            "Epoch: [60][330/782]\tTime 0.162 (0.164)\tLoss 0.2855 (0.2103)\tPrec@1 90.625 (92.735)\n",
            "Epoch: [60][340/782]\tTime 0.163 (0.164)\tLoss 0.2338 (0.2109)\tPrec@1 90.625 (92.710)\n",
            "Epoch: [60][350/782]\tTime 0.164 (0.164)\tLoss 0.2079 (0.2118)\tPrec@1 93.750 (92.677)\n",
            "Epoch: [60][360/782]\tTime 0.163 (0.164)\tLoss 0.1555 (0.2125)\tPrec@1 96.875 (92.620)\n",
            "Epoch: [60][370/782]\tTime 0.163 (0.164)\tLoss 0.2207 (0.2123)\tPrec@1 89.062 (92.609)\n",
            "Epoch: [60][380/782]\tTime 0.162 (0.164)\tLoss 0.1363 (0.2134)\tPrec@1 95.312 (92.581)\n",
            "Epoch: [60][390/782]\tTime 0.162 (0.164)\tLoss 0.3502 (0.2135)\tPrec@1 87.500 (92.591)\n",
            "Epoch: [60][400/782]\tTime 0.162 (0.164)\tLoss 0.3067 (0.2135)\tPrec@1 90.625 (92.601)\n",
            "Epoch: [60][410/782]\tTime 0.162 (0.164)\tLoss 0.2442 (0.2134)\tPrec@1 90.625 (92.587)\n",
            "Epoch: [60][420/782]\tTime 0.161 (0.164)\tLoss 0.1880 (0.2137)\tPrec@1 95.312 (92.585)\n",
            "Epoch: [60][430/782]\tTime 0.163 (0.164)\tLoss 0.1886 (0.2135)\tPrec@1 93.750 (92.575)\n",
            "Epoch: [60][440/782]\tTime 0.163 (0.164)\tLoss 0.1670 (0.2132)\tPrec@1 95.312 (92.606)\n",
            "Epoch: [60][450/782]\tTime 0.161 (0.164)\tLoss 0.3576 (0.2135)\tPrec@1 87.500 (92.593)\n",
            "Epoch: [60][460/782]\tTime 0.164 (0.164)\tLoss 0.2111 (0.2138)\tPrec@1 89.062 (92.574)\n",
            "Epoch: [60][470/782]\tTime 0.163 (0.164)\tLoss 0.1492 (0.2134)\tPrec@1 93.750 (92.596)\n",
            "Epoch: [60][480/782]\tTime 0.164 (0.164)\tLoss 0.2317 (0.2130)\tPrec@1 89.062 (92.603)\n",
            "Epoch: [60][490/782]\tTime 0.163 (0.164)\tLoss 0.1780 (0.2127)\tPrec@1 92.188 (92.592)\n",
            "Epoch: [60][500/782]\tTime 0.164 (0.164)\tLoss 0.3318 (0.2137)\tPrec@1 85.938 (92.587)\n",
            "Epoch: [60][510/782]\tTime 0.163 (0.164)\tLoss 0.0885 (0.2142)\tPrec@1 96.875 (92.542)\n",
            "Epoch: [60][520/782]\tTime 0.164 (0.164)\tLoss 0.2488 (0.2141)\tPrec@1 85.938 (92.547)\n",
            "Epoch: [60][530/782]\tTime 0.163 (0.164)\tLoss 0.2712 (0.2140)\tPrec@1 92.188 (92.555)\n",
            "Epoch: [60][540/782]\tTime 0.162 (0.164)\tLoss 0.1320 (0.2141)\tPrec@1 95.312 (92.560)\n",
            "Epoch: [60][550/782]\tTime 0.163 (0.164)\tLoss 0.2221 (0.2138)\tPrec@1 92.188 (92.567)\n",
            "Epoch: [60][560/782]\tTime 0.161 (0.164)\tLoss 0.1533 (0.2140)\tPrec@1 92.188 (92.558)\n",
            "Epoch: [60][570/782]\tTime 0.163 (0.164)\tLoss 0.3039 (0.2139)\tPrec@1 90.625 (92.582)\n",
            "Epoch: [60][580/782]\tTime 0.164 (0.164)\tLoss 0.2117 (0.2132)\tPrec@1 92.188 (92.604)\n",
            "Epoch: [60][590/782]\tTime 0.162 (0.164)\tLoss 0.1504 (0.2135)\tPrec@1 95.312 (92.603)\n",
            "Epoch: [60][600/782]\tTime 0.163 (0.164)\tLoss 0.1934 (0.2130)\tPrec@1 90.625 (92.601)\n",
            "Epoch: [60][610/782]\tTime 0.166 (0.164)\tLoss 0.2272 (0.2129)\tPrec@1 90.625 (92.620)\n",
            "Epoch: [60][620/782]\tTime 0.163 (0.164)\tLoss 0.2481 (0.2136)\tPrec@1 90.625 (92.590)\n",
            "Epoch: [60][630/782]\tTime 0.161 (0.164)\tLoss 0.3274 (0.2137)\tPrec@1 89.062 (92.581)\n",
            "Epoch: [60][640/782]\tTime 0.162 (0.164)\tLoss 0.4097 (0.2141)\tPrec@1 92.188 (92.582)\n",
            "Epoch: [60][650/782]\tTime 0.163 (0.164)\tLoss 0.1790 (0.2139)\tPrec@1 95.312 (92.586)\n",
            "Epoch: [60][660/782]\tTime 0.163 (0.164)\tLoss 0.1774 (0.2138)\tPrec@1 93.750 (92.575)\n",
            "Epoch: [60][670/782]\tTime 0.165 (0.164)\tLoss 0.2784 (0.2150)\tPrec@1 89.062 (92.523)\n",
            "Epoch: [60][680/782]\tTime 0.167 (0.164)\tLoss 0.2135 (0.2149)\tPrec@1 93.750 (92.529)\n",
            "Epoch: [60][690/782]\tTime 0.163 (0.164)\tLoss 0.1116 (0.2156)\tPrec@1 93.750 (92.511)\n",
            "Epoch: [60][700/782]\tTime 0.165 (0.164)\tLoss 0.2056 (0.2153)\tPrec@1 93.750 (92.526)\n",
            "Epoch: [60][710/782]\tTime 0.164 (0.164)\tLoss 0.1653 (0.2158)\tPrec@1 90.625 (92.513)\n",
            "Epoch: [60][720/782]\tTime 0.162 (0.164)\tLoss 0.0805 (0.2157)\tPrec@1 98.438 (92.517)\n",
            "Epoch: [60][730/782]\tTime 0.163 (0.164)\tLoss 0.3153 (0.2154)\tPrec@1 89.062 (92.530)\n",
            "Epoch: [60][740/782]\tTime 0.165 (0.164)\tLoss 0.2781 (0.2154)\tPrec@1 90.625 (92.523)\n",
            "Epoch: [60][750/782]\tTime 0.162 (0.164)\tLoss 0.1906 (0.2153)\tPrec@1 89.062 (92.512)\n",
            "Epoch: [60][760/782]\tTime 0.165 (0.164)\tLoss 0.2200 (0.2154)\tPrec@1 93.750 (92.508)\n",
            "Epoch: [60][770/782]\tTime 0.162 (0.164)\tLoss 0.2093 (0.2156)\tPrec@1 93.750 (92.506)\n",
            "Epoch: [60][780/782]\tTime 0.162 (0.164)\tLoss 0.1561 (0.2162)\tPrec@1 92.188 (92.488)\n",
            "Training accuracy:  tensor(92.4860, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.5760, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.109 (0.109)\tLoss 0.3143 (0.3143)\tPrec@1 90.625 (90.625)\n",
            "Test: [10/157]\tTime 0.049 (0.047)\tLoss 0.1361 (0.3070)\tPrec@1 95.312 (90.341)\n",
            "Test: [20/157]\tTime 0.049 (0.045)\tLoss 0.5101 (0.3262)\tPrec@1 81.250 (89.658)\n",
            "Test: [30/157]\tTime 0.044 (0.045)\tLoss 0.2530 (0.3446)\tPrec@1 92.188 (89.819)\n",
            "Test: [40/157]\tTime 0.042 (0.045)\tLoss 0.4042 (0.3302)\tPrec@1 85.938 (89.710)\n",
            "Test: [50/157]\tTime 0.044 (0.045)\tLoss 0.3181 (0.3210)\tPrec@1 92.188 (89.859)\n",
            "Test: [60/157]\tTime 0.043 (0.045)\tLoss 0.1906 (0.3179)\tPrec@1 93.750 (90.138)\n",
            "Test: [70/157]\tTime 0.044 (0.045)\tLoss 0.3111 (0.3221)\tPrec@1 93.750 (90.119)\n",
            "Test: [80/157]\tTime 0.049 (0.045)\tLoss 0.3398 (0.3280)\tPrec@1 85.938 (89.853)\n",
            "Test: [90/157]\tTime 0.045 (0.044)\tLoss 0.2907 (0.3333)\tPrec@1 90.625 (89.681)\n",
            "Test: [100/157]\tTime 0.042 (0.044)\tLoss 0.1686 (0.3370)\tPrec@1 90.625 (89.511)\n",
            "Test: [110/157]\tTime 0.044 (0.044)\tLoss 0.1750 (0.3377)\tPrec@1 93.750 (89.513)\n",
            "Test: [120/157]\tTime 0.040 (0.044)\tLoss 0.5070 (0.3347)\tPrec@1 82.812 (89.605)\n",
            "Test: [130/157]\tTime 0.045 (0.044)\tLoss 0.2783 (0.3354)\tPrec@1 90.625 (89.575)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.2740 (0.3359)\tPrec@1 92.188 (89.517)\n",
            "Test: [150/157]\tTime 0.047 (0.044)\tLoss 0.3645 (0.3351)\tPrec@1 92.188 (89.549)\n",
            " * Prec@1 89.560\n",
            "Best accuracy:  tensor(89.6600, device='cuda:0')\n",
            "Epoch: [61][0/782]\tTime 0.259 (0.259)\tLoss 0.2952 (0.2952)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [61][10/782]\tTime 0.164 (0.173)\tLoss 0.1719 (0.2077)\tPrec@1 95.312 (92.330)\n",
            "Epoch: [61][20/782]\tTime 0.161 (0.168)\tLoss 0.1934 (0.2115)\tPrec@1 90.625 (91.964)\n",
            "Epoch: [61][30/782]\tTime 0.162 (0.167)\tLoss 0.0970 (0.1900)\tPrec@1 96.875 (92.944)\n",
            "Epoch: [61][40/782]\tTime 0.162 (0.166)\tLoss 0.0833 (0.1933)\tPrec@1 98.438 (93.102)\n",
            "Epoch: [61][50/782]\tTime 0.162 (0.166)\tLoss 0.1795 (0.2010)\tPrec@1 89.062 (92.831)\n",
            "Epoch: [61][60/782]\tTime 0.162 (0.165)\tLoss 0.2463 (0.2033)\tPrec@1 92.188 (92.853)\n",
            "Epoch: [61][70/782]\tTime 0.164 (0.165)\tLoss 0.2538 (0.2072)\tPrec@1 87.500 (92.760)\n",
            "Epoch: [61][80/782]\tTime 0.162 (0.165)\tLoss 0.2874 (0.2042)\tPrec@1 92.188 (92.805)\n",
            "Epoch: [61][90/782]\tTime 0.165 (0.165)\tLoss 0.1692 (0.1998)\tPrec@1 92.188 (92.874)\n",
            "Epoch: [61][100/782]\tTime 0.162 (0.165)\tLoss 0.3723 (0.2003)\tPrec@1 85.938 (92.837)\n",
            "Epoch: [61][110/782]\tTime 0.164 (0.165)\tLoss 0.3088 (0.2038)\tPrec@1 90.625 (92.793)\n",
            "Epoch: [61][120/782]\tTime 0.162 (0.164)\tLoss 0.1951 (0.2017)\tPrec@1 89.062 (92.885)\n",
            "Epoch: [61][130/782]\tTime 0.164 (0.164)\tLoss 0.2571 (0.2027)\tPrec@1 90.625 (92.832)\n",
            "Epoch: [61][140/782]\tTime 0.164 (0.164)\tLoss 0.0980 (0.2004)\tPrec@1 96.875 (92.886)\n",
            "Epoch: [61][150/782]\tTime 0.167 (0.164)\tLoss 0.1476 (0.2000)\tPrec@1 95.312 (92.860)\n",
            "Epoch: [61][160/782]\tTime 0.163 (0.164)\tLoss 0.0677 (0.1989)\tPrec@1 100.000 (92.935)\n",
            "Epoch: [61][170/782]\tTime 0.164 (0.164)\tLoss 0.2189 (0.1997)\tPrec@1 92.188 (92.900)\n",
            "Epoch: [61][180/782]\tTime 0.162 (0.164)\tLoss 0.3574 (0.2035)\tPrec@1 87.500 (92.775)\n",
            "Epoch: [61][190/782]\tTime 0.161 (0.164)\tLoss 0.1577 (0.2037)\tPrec@1 92.188 (92.760)\n",
            "Epoch: [61][200/782]\tTime 0.163 (0.164)\tLoss 0.1770 (0.2028)\tPrec@1 93.750 (92.786)\n",
            "Epoch: [61][210/782]\tTime 0.162 (0.164)\tLoss 0.1479 (0.2028)\tPrec@1 95.312 (92.795)\n",
            "Epoch: [61][220/782]\tTime 0.167 (0.164)\tLoss 0.1085 (0.2030)\tPrec@1 95.312 (92.796)\n",
            "Epoch: [61][230/782]\tTime 0.164 (0.164)\tLoss 0.1413 (0.2038)\tPrec@1 96.875 (92.749)\n",
            "Epoch: [61][240/782]\tTime 0.164 (0.164)\tLoss 0.3708 (0.2063)\tPrec@1 90.625 (92.661)\n",
            "Epoch: [61][250/782]\tTime 0.165 (0.164)\tLoss 0.1975 (0.2075)\tPrec@1 95.312 (92.629)\n",
            "Epoch: [61][260/782]\tTime 0.166 (0.164)\tLoss 0.1084 (0.2077)\tPrec@1 98.438 (92.595)\n",
            "Epoch: [61][270/782]\tTime 0.165 (0.164)\tLoss 0.2852 (0.2081)\tPrec@1 89.062 (92.585)\n",
            "Epoch: [61][280/782]\tTime 0.162 (0.164)\tLoss 0.2399 (0.2106)\tPrec@1 92.188 (92.482)\n",
            "Epoch: [61][290/782]\tTime 0.164 (0.164)\tLoss 0.1371 (0.2119)\tPrec@1 95.312 (92.451)\n",
            "Epoch: [61][300/782]\tTime 0.163 (0.164)\tLoss 0.2439 (0.2109)\tPrec@1 89.062 (92.468)\n",
            "Epoch: [61][310/782]\tTime 0.163 (0.164)\tLoss 0.2714 (0.2110)\tPrec@1 87.500 (92.449)\n",
            "Epoch: [61][320/782]\tTime 0.164 (0.164)\tLoss 0.1813 (0.2111)\tPrec@1 92.188 (92.460)\n",
            "Epoch: [61][330/782]\tTime 0.162 (0.164)\tLoss 0.1739 (0.2121)\tPrec@1 90.625 (92.433)\n",
            "Epoch: [61][340/782]\tTime 0.163 (0.164)\tLoss 0.1234 (0.2119)\tPrec@1 96.875 (92.444)\n",
            "Epoch: [61][350/782]\tTime 0.165 (0.164)\tLoss 0.3215 (0.2116)\tPrec@1 85.938 (92.441)\n",
            "Epoch: [61][360/782]\tTime 0.163 (0.164)\tLoss 0.2375 (0.2112)\tPrec@1 89.062 (92.426)\n",
            "Epoch: [61][370/782]\tTime 0.162 (0.164)\tLoss 0.2685 (0.2106)\tPrec@1 87.500 (92.453)\n",
            "Epoch: [61][380/782]\tTime 0.163 (0.164)\tLoss 0.1686 (0.2109)\tPrec@1 93.750 (92.446)\n",
            "Epoch: [61][390/782]\tTime 0.163 (0.164)\tLoss 0.2403 (0.2115)\tPrec@1 89.062 (92.415)\n",
            "Epoch: [61][400/782]\tTime 0.163 (0.164)\tLoss 0.1552 (0.2108)\tPrec@1 95.312 (92.452)\n",
            "Epoch: [61][410/782]\tTime 0.163 (0.164)\tLoss 0.3398 (0.2110)\tPrec@1 85.938 (92.427)\n",
            "Epoch: [61][420/782]\tTime 0.165 (0.164)\tLoss 0.3018 (0.2117)\tPrec@1 87.500 (92.425)\n",
            "Epoch: [61][430/782]\tTime 0.164 (0.164)\tLoss 0.2570 (0.2121)\tPrec@1 90.625 (92.449)\n",
            "Epoch: [61][440/782]\tTime 0.165 (0.164)\tLoss 0.1999 (0.2127)\tPrec@1 89.062 (92.418)\n",
            "Epoch: [61][450/782]\tTime 0.164 (0.164)\tLoss 0.2894 (0.2130)\tPrec@1 89.062 (92.416)\n",
            "Epoch: [61][460/782]\tTime 0.163 (0.164)\tLoss 0.2143 (0.2127)\tPrec@1 92.188 (92.435)\n",
            "Epoch: [61][470/782]\tTime 0.163 (0.164)\tLoss 0.3183 (0.2127)\tPrec@1 87.500 (92.426)\n",
            "Epoch: [61][480/782]\tTime 0.168 (0.164)\tLoss 0.1900 (0.2122)\tPrec@1 93.750 (92.438)\n",
            "Epoch: [61][490/782]\tTime 0.162 (0.164)\tLoss 0.2490 (0.2135)\tPrec@1 92.188 (92.378)\n",
            "Epoch: [61][500/782]\tTime 0.163 (0.164)\tLoss 0.2936 (0.2132)\tPrec@1 89.062 (92.384)\n",
            "Epoch: [61][510/782]\tTime 0.162 (0.164)\tLoss 0.1219 (0.2130)\tPrec@1 95.312 (92.405)\n",
            "Epoch: [61][520/782]\tTime 0.165 (0.164)\tLoss 0.2045 (0.2125)\tPrec@1 93.750 (92.415)\n",
            "Epoch: [61][530/782]\tTime 0.163 (0.164)\tLoss 0.1389 (0.2125)\tPrec@1 95.312 (92.429)\n",
            "Epoch: [61][540/782]\tTime 0.164 (0.164)\tLoss 0.1209 (0.2125)\tPrec@1 96.875 (92.427)\n",
            "Epoch: [61][550/782]\tTime 0.163 (0.164)\tLoss 0.1505 (0.2123)\tPrec@1 95.312 (92.429)\n",
            "Epoch: [61][560/782]\tTime 0.162 (0.164)\tLoss 0.3130 (0.2120)\tPrec@1 90.625 (92.449)\n",
            "Epoch: [61][570/782]\tTime 0.164 (0.164)\tLoss 0.3960 (0.2132)\tPrec@1 84.375 (92.415)\n",
            "Epoch: [61][580/782]\tTime 0.164 (0.164)\tLoss 0.2309 (0.2129)\tPrec@1 93.750 (92.432)\n",
            "Epoch: [61][590/782]\tTime 0.162 (0.164)\tLoss 0.2159 (0.2134)\tPrec@1 92.188 (92.431)\n",
            "Epoch: [61][600/782]\tTime 0.164 (0.164)\tLoss 0.2916 (0.2138)\tPrec@1 85.938 (92.401)\n",
            "Epoch: [61][610/782]\tTime 0.163 (0.164)\tLoss 0.1381 (0.2141)\tPrec@1 96.875 (92.379)\n",
            "Epoch: [61][620/782]\tTime 0.161 (0.164)\tLoss 0.1501 (0.2139)\tPrec@1 93.750 (92.381)\n",
            "Epoch: [61][630/782]\tTime 0.165 (0.164)\tLoss 0.2665 (0.2146)\tPrec@1 90.625 (92.371)\n",
            "Epoch: [61][640/782]\tTime 0.162 (0.164)\tLoss 0.1386 (0.2148)\tPrec@1 93.750 (92.370)\n",
            "Epoch: [61][650/782]\tTime 0.162 (0.164)\tLoss 0.2208 (0.2145)\tPrec@1 96.875 (92.368)\n",
            "Epoch: [61][660/782]\tTime 0.163 (0.164)\tLoss 0.2780 (0.2146)\tPrec@1 93.750 (92.384)\n",
            "Epoch: [61][670/782]\tTime 0.164 (0.164)\tLoss 0.1470 (0.2146)\tPrec@1 93.750 (92.383)\n",
            "Epoch: [61][680/782]\tTime 0.164 (0.164)\tLoss 0.3018 (0.2147)\tPrec@1 90.625 (92.378)\n",
            "Epoch: [61][690/782]\tTime 0.162 (0.164)\tLoss 0.2657 (0.2146)\tPrec@1 90.625 (92.389)\n",
            "Epoch: [61][700/782]\tTime 0.165 (0.164)\tLoss 0.1945 (0.2144)\tPrec@1 93.750 (92.397)\n",
            "Epoch: [61][710/782]\tTime 0.162 (0.164)\tLoss 0.2595 (0.2145)\tPrec@1 90.625 (92.403)\n",
            "Epoch: [61][720/782]\tTime 0.163 (0.164)\tLoss 0.1217 (0.2150)\tPrec@1 95.312 (92.389)\n",
            "Epoch: [61][730/782]\tTime 0.163 (0.164)\tLoss 0.1835 (0.2150)\tPrec@1 96.875 (92.397)\n",
            "Epoch: [61][740/782]\tTime 0.163 (0.164)\tLoss 0.0860 (0.2149)\tPrec@1 100.000 (92.407)\n",
            "Epoch: [61][750/782]\tTime 0.161 (0.164)\tLoss 0.1671 (0.2145)\tPrec@1 90.625 (92.418)\n",
            "Epoch: [61][760/782]\tTime 0.163 (0.164)\tLoss 0.1333 (0.2143)\tPrec@1 96.875 (92.436)\n",
            "Epoch: [61][770/782]\tTime 0.164 (0.164)\tLoss 0.3317 (0.2144)\tPrec@1 93.750 (92.451)\n",
            "Epoch: [61][780/782]\tTime 0.162 (0.164)\tLoss 0.3124 (0.2149)\tPrec@1 87.500 (92.438)\n",
            "Training accuracy:  tensor(92.4400, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.5760, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.109 (0.109)\tLoss 0.3745 (0.3745)\tPrec@1 87.500 (87.500)\n",
            "Test: [10/157]\tTime 0.043 (0.047)\tLoss 0.1915 (0.3217)\tPrec@1 93.750 (89.773)\n",
            "Test: [20/157]\tTime 0.050 (0.046)\tLoss 0.4753 (0.3073)\tPrec@1 85.938 (90.104)\n",
            "Test: [30/157]\tTime 0.037 (0.045)\tLoss 0.1953 (0.2925)\tPrec@1 89.062 (90.423)\n",
            "Test: [40/157]\tTime 0.043 (0.045)\tLoss 0.5492 (0.3056)\tPrec@1 82.812 (90.244)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.2801 (0.3016)\tPrec@1 93.750 (90.288)\n",
            "Test: [60/157]\tTime 0.044 (0.045)\tLoss 0.2782 (0.3054)\tPrec@1 93.750 (90.010)\n",
            "Test: [70/157]\tTime 0.042 (0.044)\tLoss 0.2059 (0.3109)\tPrec@1 92.188 (89.833)\n",
            "Test: [80/157]\tTime 0.042 (0.044)\tLoss 0.3436 (0.3117)\tPrec@1 84.375 (89.815)\n",
            "Test: [90/157]\tTime 0.042 (0.044)\tLoss 0.4477 (0.3170)\tPrec@1 90.625 (89.784)\n",
            "Test: [100/157]\tTime 0.039 (0.044)\tLoss 0.3831 (0.3187)\tPrec@1 85.938 (89.805)\n",
            "Test: [110/157]\tTime 0.046 (0.044)\tLoss 0.2181 (0.3205)\tPrec@1 90.625 (89.809)\n",
            "Test: [120/157]\tTime 0.044 (0.044)\tLoss 0.3654 (0.3206)\tPrec@1 89.062 (89.734)\n",
            "Test: [130/157]\tTime 0.043 (0.044)\tLoss 0.2088 (0.3192)\tPrec@1 93.750 (89.778)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.2875 (0.3210)\tPrec@1 90.625 (89.838)\n",
            "Test: [150/157]\tTime 0.043 (0.044)\tLoss 0.5378 (0.3206)\tPrec@1 90.625 (89.911)\n",
            " * Prec@1 90.000\n",
            "Best accuracy:  tensor(90., device='cuda:0')\n",
            "Epoch: [62][0/782]\tTime 0.259 (0.259)\tLoss 0.0886 (0.0886)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [62][10/782]\tTime 0.163 (0.173)\tLoss 0.1200 (0.1745)\tPrec@1 93.750 (93.608)\n",
            "Epoch: [62][20/782]\tTime 0.163 (0.169)\tLoss 0.0908 (0.1815)\tPrec@1 98.438 (93.601)\n",
            "Epoch: [62][30/782]\tTime 0.163 (0.167)\tLoss 0.2683 (0.1780)\tPrec@1 90.625 (93.599)\n",
            "Epoch: [62][40/782]\tTime 0.161 (0.166)\tLoss 0.1216 (0.1833)\tPrec@1 95.312 (93.255)\n",
            "Epoch: [62][50/782]\tTime 0.164 (0.165)\tLoss 0.0528 (0.1862)\tPrec@1 100.000 (93.107)\n",
            "Epoch: [62][60/782]\tTime 0.164 (0.166)\tLoss 0.3465 (0.1862)\tPrec@1 93.750 (93.212)\n",
            "Epoch: [62][70/782]\tTime 0.166 (0.165)\tLoss 0.1211 (0.1839)\tPrec@1 98.438 (93.442)\n",
            "Epoch: [62][80/782]\tTime 0.162 (0.165)\tLoss 0.1180 (0.1831)\tPrec@1 95.312 (93.499)\n",
            "Epoch: [62][90/782]\tTime 0.162 (0.165)\tLoss 0.1358 (0.1836)\tPrec@1 96.875 (93.475)\n",
            "Epoch: [62][100/782]\tTime 0.164 (0.165)\tLoss 0.1013 (0.1820)\tPrec@1 98.438 (93.502)\n",
            "Epoch: [62][110/782]\tTime 0.165 (0.165)\tLoss 0.1005 (0.1844)\tPrec@1 95.312 (93.440)\n",
            "Epoch: [62][120/782]\tTime 0.164 (0.164)\tLoss 0.2807 (0.1842)\tPrec@1 85.938 (93.479)\n",
            "Epoch: [62][130/782]\tTime 0.161 (0.164)\tLoss 0.1434 (0.1818)\tPrec@1 95.312 (93.511)\n",
            "Epoch: [62][140/782]\tTime 0.162 (0.164)\tLoss 0.1196 (0.1836)\tPrec@1 95.312 (93.440)\n",
            "Epoch: [62][150/782]\tTime 0.162 (0.164)\tLoss 0.1703 (0.1858)\tPrec@1 90.625 (93.357)\n",
            "Epoch: [62][160/782]\tTime 0.161 (0.164)\tLoss 0.3611 (0.1869)\tPrec@1 92.188 (93.342)\n",
            "Epoch: [62][170/782]\tTime 0.163 (0.164)\tLoss 0.1757 (0.1907)\tPrec@1 92.188 (93.220)\n",
            "Epoch: [62][180/782]\tTime 0.162 (0.164)\tLoss 0.2061 (0.1912)\tPrec@1 93.750 (93.223)\n",
            "Epoch: [62][190/782]\tTime 0.165 (0.164)\tLoss 0.3869 (0.1939)\tPrec@1 87.500 (93.104)\n",
            "Epoch: [62][200/782]\tTime 0.163 (0.164)\tLoss 0.1096 (0.1949)\tPrec@1 96.875 (93.050)\n",
            "Epoch: [62][210/782]\tTime 0.163 (0.164)\tLoss 0.1761 (0.1976)\tPrec@1 93.750 (92.906)\n",
            "Epoch: [62][220/782]\tTime 0.163 (0.164)\tLoss 0.2300 (0.1990)\tPrec@1 89.062 (92.859)\n",
            "Epoch: [62][230/782]\tTime 0.167 (0.164)\tLoss 0.1801 (0.1995)\tPrec@1 95.312 (92.844)\n",
            "Epoch: [62][240/782]\tTime 0.163 (0.164)\tLoss 0.1567 (0.2002)\tPrec@1 96.875 (92.836)\n",
            "Epoch: [62][250/782]\tTime 0.161 (0.164)\tLoss 0.1761 (0.2002)\tPrec@1 93.750 (92.847)\n",
            "Epoch: [62][260/782]\tTime 0.161 (0.164)\tLoss 0.1895 (0.2001)\tPrec@1 93.750 (92.846)\n",
            "Epoch: [62][270/782]\tTime 0.163 (0.164)\tLoss 0.1626 (0.1991)\tPrec@1 95.312 (92.891)\n",
            "Epoch: [62][280/782]\tTime 0.166 (0.164)\tLoss 0.2665 (0.1980)\tPrec@1 93.750 (92.955)\n",
            "Epoch: [62][290/782]\tTime 0.163 (0.164)\tLoss 0.1944 (0.1990)\tPrec@1 89.062 (92.902)\n",
            "Epoch: [62][300/782]\tTime 0.163 (0.164)\tLoss 0.1838 (0.1990)\tPrec@1 93.750 (92.914)\n",
            "Epoch: [62][310/782]\tTime 0.163 (0.164)\tLoss 0.1202 (0.1999)\tPrec@1 95.312 (92.896)\n",
            "Epoch: [62][320/782]\tTime 0.162 (0.164)\tLoss 0.1303 (0.2007)\tPrec@1 93.750 (92.864)\n",
            "Epoch: [62][330/782]\tTime 0.163 (0.164)\tLoss 0.0618 (0.2012)\tPrec@1 98.438 (92.815)\n",
            "Epoch: [62][340/782]\tTime 0.163 (0.164)\tLoss 0.1867 (0.2009)\tPrec@1 96.875 (92.829)\n",
            "Epoch: [62][350/782]\tTime 0.163 (0.164)\tLoss 0.2719 (0.2016)\tPrec@1 95.312 (92.780)\n",
            "Epoch: [62][360/782]\tTime 0.164 (0.164)\tLoss 0.2013 (0.2026)\tPrec@1 90.625 (92.767)\n",
            "Epoch: [62][370/782]\tTime 0.164 (0.164)\tLoss 0.2650 (0.2038)\tPrec@1 87.500 (92.710)\n",
            "Epoch: [62][380/782]\tTime 0.162 (0.164)\tLoss 0.2813 (0.2056)\tPrec@1 95.312 (92.696)\n",
            "Epoch: [62][390/782]\tTime 0.165 (0.164)\tLoss 0.2311 (0.2067)\tPrec@1 90.625 (92.635)\n",
            "Epoch: [62][400/782]\tTime 0.160 (0.164)\tLoss 0.1371 (0.2066)\tPrec@1 92.188 (92.612)\n",
            "Epoch: [62][410/782]\tTime 0.163 (0.164)\tLoss 0.1721 (0.2082)\tPrec@1 90.625 (92.564)\n",
            "Epoch: [62][420/782]\tTime 0.164 (0.164)\tLoss 0.1416 (0.2092)\tPrec@1 95.312 (92.536)\n",
            "Epoch: [62][430/782]\tTime 0.165 (0.164)\tLoss 0.2442 (0.2092)\tPrec@1 90.625 (92.528)\n",
            "Epoch: [62][440/782]\tTime 0.165 (0.164)\tLoss 0.2021 (0.2094)\tPrec@1 90.625 (92.524)\n",
            "Epoch: [62][450/782]\tTime 0.162 (0.164)\tLoss 0.1185 (0.2085)\tPrec@1 98.438 (92.572)\n",
            "Epoch: [62][460/782]\tTime 0.166 (0.164)\tLoss 0.2474 (0.2087)\tPrec@1 89.062 (92.557)\n",
            "Epoch: [62][470/782]\tTime 0.163 (0.164)\tLoss 0.2238 (0.2078)\tPrec@1 93.750 (92.599)\n",
            "Epoch: [62][480/782]\tTime 0.164 (0.164)\tLoss 0.2152 (0.2088)\tPrec@1 92.188 (92.587)\n",
            "Epoch: [62][490/782]\tTime 0.162 (0.164)\tLoss 0.2006 (0.2087)\tPrec@1 93.750 (92.573)\n",
            "Epoch: [62][500/782]\tTime 0.163 (0.164)\tLoss 0.2040 (0.2087)\tPrec@1 92.188 (92.565)\n",
            "Epoch: [62][510/782]\tTime 0.163 (0.164)\tLoss 0.0877 (0.2089)\tPrec@1 98.438 (92.561)\n",
            "Epoch: [62][520/782]\tTime 0.163 (0.164)\tLoss 0.2017 (0.2096)\tPrec@1 93.750 (92.541)\n",
            "Epoch: [62][530/782]\tTime 0.162 (0.164)\tLoss 0.2301 (0.2101)\tPrec@1 93.750 (92.526)\n",
            "Epoch: [62][540/782]\tTime 0.163 (0.164)\tLoss 0.2062 (0.2103)\tPrec@1 90.625 (92.508)\n",
            "Epoch: [62][550/782]\tTime 0.165 (0.164)\tLoss 0.2213 (0.2107)\tPrec@1 92.188 (92.502)\n",
            "Epoch: [62][560/782]\tTime 0.165 (0.164)\tLoss 0.1293 (0.2107)\tPrec@1 96.875 (92.505)\n",
            "Epoch: [62][570/782]\tTime 0.163 (0.164)\tLoss 0.4013 (0.2114)\tPrec@1 87.500 (92.491)\n",
            "Epoch: [62][580/782]\tTime 0.164 (0.164)\tLoss 0.2349 (0.2115)\tPrec@1 92.188 (92.481)\n",
            "Epoch: [62][590/782]\tTime 0.162 (0.164)\tLoss 0.4614 (0.2115)\tPrec@1 84.375 (92.489)\n",
            "Epoch: [62][600/782]\tTime 0.163 (0.164)\tLoss 0.2594 (0.2130)\tPrec@1 90.625 (92.437)\n",
            "Epoch: [62][610/782]\tTime 0.162 (0.164)\tLoss 0.2796 (0.2139)\tPrec@1 89.062 (92.402)\n",
            "Epoch: [62][620/782]\tTime 0.163 (0.164)\tLoss 0.2342 (0.2143)\tPrec@1 90.625 (92.391)\n",
            "Epoch: [62][630/782]\tTime 0.163 (0.164)\tLoss 0.2272 (0.2141)\tPrec@1 93.750 (92.391)\n",
            "Epoch: [62][640/782]\tTime 0.162 (0.164)\tLoss 0.1890 (0.2141)\tPrec@1 90.625 (92.395)\n",
            "Epoch: [62][650/782]\tTime 0.163 (0.164)\tLoss 0.2652 (0.2151)\tPrec@1 92.188 (92.368)\n",
            "Epoch: [62][660/782]\tTime 0.162 (0.164)\tLoss 0.2169 (0.2150)\tPrec@1 92.188 (92.362)\n",
            "Epoch: [62][670/782]\tTime 0.163 (0.164)\tLoss 0.0705 (0.2148)\tPrec@1 98.438 (92.381)\n",
            "Epoch: [62][680/782]\tTime 0.165 (0.164)\tLoss 0.1306 (0.2145)\tPrec@1 95.312 (92.394)\n",
            "Epoch: [62][690/782]\tTime 0.163 (0.164)\tLoss 0.1898 (0.2143)\tPrec@1 95.312 (92.398)\n",
            "Epoch: [62][700/782]\tTime 0.164 (0.164)\tLoss 0.2190 (0.2148)\tPrec@1 92.188 (92.384)\n",
            "Epoch: [62][710/782]\tTime 0.161 (0.164)\tLoss 0.3037 (0.2147)\tPrec@1 92.188 (92.398)\n",
            "Epoch: [62][720/782]\tTime 0.162 (0.164)\tLoss 0.1657 (0.2151)\tPrec@1 92.188 (92.370)\n",
            "Epoch: [62][730/782]\tTime 0.162 (0.164)\tLoss 0.1063 (0.2150)\tPrec@1 93.750 (92.393)\n",
            "Epoch: [62][740/782]\tTime 0.164 (0.164)\tLoss 0.1645 (0.2155)\tPrec@1 92.188 (92.381)\n",
            "Epoch: [62][750/782]\tTime 0.163 (0.164)\tLoss 0.2723 (0.2154)\tPrec@1 95.312 (92.391)\n",
            "Epoch: [62][760/782]\tTime 0.163 (0.164)\tLoss 0.2077 (0.2159)\tPrec@1 92.188 (92.368)\n",
            "Epoch: [62][770/782]\tTime 0.164 (0.164)\tLoss 0.1384 (0.2158)\tPrec@1 96.875 (92.388)\n",
            "Epoch: [62][780/782]\tTime 0.162 (0.164)\tLoss 0.1435 (0.2156)\tPrec@1 93.750 (92.406)\n",
            "Training accuracy:  tensor(92.4020, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.5760, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.107 (0.107)\tLoss 0.3788 (0.3788)\tPrec@1 89.062 (89.062)\n",
            "Test: [10/157]\tTime 0.040 (0.047)\tLoss 0.1964 (0.3504)\tPrec@1 92.188 (89.062)\n",
            "Test: [20/157]\tTime 0.048 (0.045)\tLoss 0.3154 (0.3401)\tPrec@1 89.062 (89.062)\n",
            "Test: [30/157]\tTime 0.038 (0.045)\tLoss 0.2818 (0.3153)\tPrec@1 87.500 (89.970)\n",
            "Test: [40/157]\tTime 0.043 (0.045)\tLoss 0.4341 (0.3286)\tPrec@1 89.062 (89.672)\n",
            "Test: [50/157]\tTime 0.041 (0.045)\tLoss 0.5434 (0.3464)\tPrec@1 84.375 (89.032)\n",
            "Test: [60/157]\tTime 0.043 (0.045)\tLoss 0.2708 (0.3431)\tPrec@1 89.062 (88.934)\n",
            "Test: [70/157]\tTime 0.043 (0.044)\tLoss 0.5867 (0.3446)\tPrec@1 79.688 (88.952)\n",
            "Test: [80/157]\tTime 0.043 (0.044)\tLoss 0.3885 (0.3415)\tPrec@1 84.375 (88.889)\n",
            "Test: [90/157]\tTime 0.044 (0.044)\tLoss 0.2295 (0.3350)\tPrec@1 90.625 (89.028)\n",
            "Test: [100/157]\tTime 0.042 (0.044)\tLoss 0.2447 (0.3370)\tPrec@1 92.188 (88.939)\n",
            "Test: [110/157]\tTime 0.044 (0.044)\tLoss 0.1174 (0.3354)\tPrec@1 95.312 (88.964)\n",
            "Test: [120/157]\tTime 0.044 (0.044)\tLoss 0.4491 (0.3346)\tPrec@1 87.500 (89.024)\n",
            "Test: [130/157]\tTime 0.044 (0.044)\tLoss 0.3512 (0.3392)\tPrec@1 85.938 (88.836)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.2587 (0.3377)\tPrec@1 89.062 (88.763)\n",
            "Test: [150/157]\tTime 0.041 (0.044)\tLoss 0.5031 (0.3436)\tPrec@1 84.375 (88.659)\n",
            " * Prec@1 88.620\n",
            "Best accuracy:  tensor(90., device='cuda:0')\n",
            "Epoch: [63][0/782]\tTime 0.259 (0.259)\tLoss 0.1416 (0.1416)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [63][10/782]\tTime 0.160 (0.172)\tLoss 0.2978 (0.2299)\tPrec@1 90.625 (92.472)\n",
            "Epoch: [63][20/782]\tTime 0.162 (0.167)\tLoss 0.1984 (0.2262)\tPrec@1 93.750 (92.634)\n",
            "Epoch: [63][30/782]\tTime 0.162 (0.166)\tLoss 0.0418 (0.2235)\tPrec@1 100.000 (92.692)\n",
            "Epoch: [63][40/782]\tTime 0.164 (0.165)\tLoss 0.1754 (0.2225)\tPrec@1 92.188 (92.607)\n",
            "Epoch: [63][50/782]\tTime 0.163 (0.165)\tLoss 0.2581 (0.2139)\tPrec@1 87.500 (93.015)\n",
            "Epoch: [63][60/782]\tTime 0.162 (0.165)\tLoss 0.1433 (0.2064)\tPrec@1 95.312 (93.186)\n",
            "Epoch: [63][70/782]\tTime 0.162 (0.165)\tLoss 0.2052 (0.2039)\tPrec@1 93.750 (93.134)\n",
            "Epoch: [63][80/782]\tTime 0.162 (0.164)\tLoss 0.1402 (0.2019)\tPrec@1 93.750 (93.056)\n",
            "Epoch: [63][90/782]\tTime 0.163 (0.164)\tLoss 0.2089 (0.2019)\tPrec@1 89.062 (93.029)\n",
            "Epoch: [63][100/782]\tTime 0.162 (0.164)\tLoss 0.1989 (0.1994)\tPrec@1 93.750 (93.085)\n",
            "Epoch: [63][110/782]\tTime 0.162 (0.164)\tLoss 0.3137 (0.1974)\tPrec@1 89.062 (93.159)\n",
            "Epoch: [63][120/782]\tTime 0.168 (0.164)\tLoss 0.1757 (0.1968)\tPrec@1 92.188 (93.156)\n",
            "Epoch: [63][130/782]\tTime 0.163 (0.164)\tLoss 0.1474 (0.1969)\tPrec@1 93.750 (93.142)\n",
            "Epoch: [63][140/782]\tTime 0.161 (0.164)\tLoss 0.2008 (0.1968)\tPrec@1 93.750 (93.174)\n",
            "Epoch: [63][150/782]\tTime 0.163 (0.164)\tLoss 0.1369 (0.1979)\tPrec@1 96.875 (93.222)\n",
            "Epoch: [63][160/782]\tTime 0.162 (0.164)\tLoss 0.2286 (0.1970)\tPrec@1 92.188 (93.226)\n",
            "Epoch: [63][170/782]\tTime 0.163 (0.164)\tLoss 0.1545 (0.1968)\tPrec@1 95.312 (93.183)\n",
            "Epoch: [63][180/782]\tTime 0.163 (0.164)\tLoss 0.0960 (0.1967)\tPrec@1 96.875 (93.215)\n",
            "Epoch: [63][190/782]\tTime 0.163 (0.164)\tLoss 0.2146 (0.1970)\tPrec@1 92.188 (93.243)\n",
            "Epoch: [63][200/782]\tTime 0.163 (0.164)\tLoss 0.2318 (0.1964)\tPrec@1 95.312 (93.346)\n",
            "Epoch: [63][210/782]\tTime 0.162 (0.164)\tLoss 0.1147 (0.1963)\tPrec@1 95.312 (93.291)\n",
            "Epoch: [63][220/782]\tTime 0.163 (0.164)\tLoss 0.1499 (0.1987)\tPrec@1 95.312 (93.227)\n",
            "Epoch: [63][230/782]\tTime 0.162 (0.164)\tLoss 0.1326 (0.1973)\tPrec@1 96.875 (93.263)\n",
            "Epoch: [63][240/782]\tTime 0.181 (0.164)\tLoss 0.2630 (0.1982)\tPrec@1 87.500 (93.218)\n",
            "Epoch: [63][250/782]\tTime 0.162 (0.164)\tLoss 0.0993 (0.1986)\tPrec@1 96.875 (93.227)\n",
            "Epoch: [63][260/782]\tTime 0.162 (0.164)\tLoss 0.2114 (0.1966)\tPrec@1 95.312 (93.259)\n",
            "Epoch: [63][270/782]\tTime 0.161 (0.164)\tLoss 0.1262 (0.1961)\tPrec@1 95.312 (93.289)\n",
            "Epoch: [63][280/782]\tTime 0.162 (0.164)\tLoss 0.2291 (0.1965)\tPrec@1 90.625 (93.250)\n",
            "Epoch: [63][290/782]\tTime 0.162 (0.164)\tLoss 0.1486 (0.1976)\tPrec@1 95.312 (93.208)\n",
            "Epoch: [63][300/782]\tTime 0.166 (0.164)\tLoss 0.1595 (0.1978)\tPrec@1 96.875 (93.210)\n",
            "Epoch: [63][310/782]\tTime 0.163 (0.164)\tLoss 0.2308 (0.1979)\tPrec@1 90.625 (93.192)\n",
            "Epoch: [63][320/782]\tTime 0.162 (0.164)\tLoss 0.1749 (0.1979)\tPrec@1 93.750 (93.210)\n",
            "Epoch: [63][330/782]\tTime 0.162 (0.164)\tLoss 0.1677 (0.1991)\tPrec@1 96.875 (93.179)\n",
            "Epoch: [63][340/782]\tTime 0.162 (0.164)\tLoss 0.2507 (0.1981)\tPrec@1 90.625 (93.196)\n",
            "Epoch: [63][350/782]\tTime 0.163 (0.164)\tLoss 0.2419 (0.1978)\tPrec@1 87.500 (93.189)\n",
            "Epoch: [63][360/782]\tTime 0.163 (0.164)\tLoss 0.0883 (0.1973)\tPrec@1 96.875 (93.192)\n",
            "Epoch: [63][370/782]\tTime 0.162 (0.163)\tLoss 0.1802 (0.1982)\tPrec@1 95.312 (93.152)\n",
            "Epoch: [63][380/782]\tTime 0.161 (0.163)\tLoss 0.3142 (0.1997)\tPrec@1 92.188 (93.131)\n",
            "Epoch: [63][390/782]\tTime 0.162 (0.163)\tLoss 0.1294 (0.2004)\tPrec@1 96.875 (93.155)\n",
            "Epoch: [63][400/782]\tTime 0.162 (0.163)\tLoss 0.1641 (0.2002)\tPrec@1 90.625 (93.154)\n",
            "Epoch: [63][410/782]\tTime 0.162 (0.163)\tLoss 0.2152 (0.2018)\tPrec@1 92.188 (93.077)\n",
            "Epoch: [63][420/782]\tTime 0.163 (0.163)\tLoss 0.2318 (0.2027)\tPrec@1 92.188 (93.041)\n",
            "Epoch: [63][430/782]\tTime 0.191 (0.165)\tLoss 0.1703 (0.2025)\tPrec@1 95.312 (93.043)\n",
            "Epoch: [63][440/782]\tTime 0.165 (0.165)\tLoss 0.1092 (0.2023)\tPrec@1 96.875 (93.041)\n",
            "Epoch: [63][450/782]\tTime 0.163 (0.165)\tLoss 0.2140 (0.2020)\tPrec@1 90.625 (93.057)\n",
            "Epoch: [63][460/782]\tTime 0.162 (0.165)\tLoss 0.2348 (0.2022)\tPrec@1 90.625 (93.055)\n",
            "Epoch: [63][470/782]\tTime 0.162 (0.165)\tLoss 0.1527 (0.2019)\tPrec@1 96.875 (93.063)\n",
            "Epoch: [63][480/782]\tTime 0.161 (0.165)\tLoss 0.1905 (0.2017)\tPrec@1 93.750 (93.074)\n",
            "Epoch: [63][490/782]\tTime 0.164 (0.165)\tLoss 0.2596 (0.2021)\tPrec@1 92.188 (93.050)\n",
            "Epoch: [63][500/782]\tTime 0.166 (0.165)\tLoss 0.2573 (0.2025)\tPrec@1 90.625 (93.017)\n",
            "Epoch: [63][510/782]\tTime 0.162 (0.165)\tLoss 0.2374 (0.2034)\tPrec@1 93.750 (92.995)\n",
            "Epoch: [63][520/782]\tTime 0.161 (0.165)\tLoss 0.3679 (0.2038)\tPrec@1 90.625 (92.961)\n",
            "Epoch: [63][530/782]\tTime 0.163 (0.165)\tLoss 0.0976 (0.2049)\tPrec@1 96.875 (92.923)\n",
            "Epoch: [63][540/782]\tTime 0.162 (0.165)\tLoss 0.2846 (0.2050)\tPrec@1 90.625 (92.924)\n",
            "Epoch: [63][550/782]\tTime 0.162 (0.165)\tLoss 0.2924 (0.2056)\tPrec@1 90.625 (92.905)\n",
            "Epoch: [63][560/782]\tTime 0.163 (0.165)\tLoss 0.1420 (0.2062)\tPrec@1 93.750 (92.884)\n",
            "Epoch: [63][570/782]\tTime 0.162 (0.165)\tLoss 0.1519 (0.2063)\tPrec@1 93.750 (92.883)\n",
            "Epoch: [63][580/782]\tTime 0.162 (0.165)\tLoss 0.2865 (0.2068)\tPrec@1 95.312 (92.881)\n",
            "Epoch: [63][590/782]\tTime 0.164 (0.165)\tLoss 0.2185 (0.2071)\tPrec@1 90.625 (92.859)\n",
            "Epoch: [63][600/782]\tTime 0.166 (0.165)\tLoss 0.1788 (0.2075)\tPrec@1 95.312 (92.850)\n",
            "Epoch: [63][610/782]\tTime 0.162 (0.165)\tLoss 0.2043 (0.2084)\tPrec@1 89.062 (92.804)\n",
            "Epoch: [63][620/782]\tTime 0.163 (0.165)\tLoss 0.1964 (0.2083)\tPrec@1 90.625 (92.806)\n",
            "Epoch: [63][630/782]\tTime 0.162 (0.165)\tLoss 0.2637 (0.2086)\tPrec@1 90.625 (92.797)\n",
            "Epoch: [63][640/782]\tTime 0.164 (0.165)\tLoss 0.3466 (0.2090)\tPrec@1 87.500 (92.792)\n",
            "Epoch: [63][650/782]\tTime 0.161 (0.165)\tLoss 0.2238 (0.2088)\tPrec@1 90.625 (92.792)\n",
            "Epoch: [63][660/782]\tTime 0.163 (0.165)\tLoss 0.2230 (0.2090)\tPrec@1 90.625 (92.783)\n",
            "Epoch: [63][670/782]\tTime 0.164 (0.165)\tLoss 0.2061 (0.2090)\tPrec@1 93.750 (92.777)\n",
            "Epoch: [63][680/782]\tTime 0.162 (0.164)\tLoss 0.3450 (0.2097)\tPrec@1 90.625 (92.757)\n",
            "Epoch: [63][690/782]\tTime 0.161 (0.164)\tLoss 0.3011 (0.2095)\tPrec@1 89.062 (92.757)\n",
            "Epoch: [63][700/782]\tTime 0.165 (0.164)\tLoss 0.2651 (0.2097)\tPrec@1 92.188 (92.751)\n",
            "Epoch: [63][710/782]\tTime 0.163 (0.164)\tLoss 0.2796 (0.2095)\tPrec@1 87.500 (92.757)\n",
            "Epoch: [63][720/782]\tTime 0.166 (0.164)\tLoss 0.2910 (0.2099)\tPrec@1 89.062 (92.731)\n",
            "Epoch: [63][730/782]\tTime 0.164 (0.164)\tLoss 0.1110 (0.2094)\tPrec@1 95.312 (92.769)\n",
            "Epoch: [63][740/782]\tTime 0.163 (0.164)\tLoss 0.3342 (0.2097)\tPrec@1 89.062 (92.755)\n",
            "Epoch: [63][750/782]\tTime 0.162 (0.164)\tLoss 0.2236 (0.2094)\tPrec@1 93.750 (92.764)\n",
            "Epoch: [63][760/782]\tTime 0.165 (0.164)\tLoss 0.0586 (0.2091)\tPrec@1 100.000 (92.783)\n",
            "Epoch: [63][770/782]\tTime 0.161 (0.164)\tLoss 0.1659 (0.2098)\tPrec@1 93.750 (92.765)\n",
            "Epoch: [63][780/782]\tTime 0.160 (0.164)\tLoss 0.1495 (0.2099)\tPrec@1 93.750 (92.760)\n",
            "Training accuracy:  tensor(92.7600, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.7600, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.107 (0.107)\tLoss 0.2804 (0.2804)\tPrec@1 90.625 (90.625)\n",
            "Test: [10/157]\tTime 0.042 (0.047)\tLoss 0.2763 (0.2997)\tPrec@1 90.625 (89.489)\n",
            "Test: [20/157]\tTime 0.048 (0.045)\tLoss 0.2689 (0.3358)\tPrec@1 93.750 (88.467)\n",
            "Test: [30/157]\tTime 0.044 (0.045)\tLoss 0.6220 (0.3658)\tPrec@1 81.250 (88.054)\n",
            "Test: [40/157]\tTime 0.040 (0.045)\tLoss 0.4359 (0.3622)\tPrec@1 84.375 (88.643)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.4458 (0.3523)\tPrec@1 89.062 (88.756)\n",
            "Test: [60/157]\tTime 0.045 (0.044)\tLoss 0.1690 (0.3471)\tPrec@1 95.312 (89.037)\n",
            "Test: [70/157]\tTime 0.043 (0.044)\tLoss 0.4555 (0.3451)\tPrec@1 84.375 (89.151)\n",
            "Test: [80/157]\tTime 0.044 (0.044)\tLoss 0.3357 (0.3351)\tPrec@1 87.500 (89.487)\n",
            "Test: [90/157]\tTime 0.044 (0.044)\tLoss 0.1470 (0.3238)\tPrec@1 95.312 (89.766)\n",
            "Test: [100/157]\tTime 0.049 (0.044)\tLoss 0.2338 (0.3202)\tPrec@1 90.625 (89.821)\n",
            "Test: [110/157]\tTime 0.044 (0.044)\tLoss 0.4315 (0.3194)\tPrec@1 89.062 (89.794)\n",
            "Test: [120/157]\tTime 0.044 (0.044)\tLoss 0.3821 (0.3242)\tPrec@1 87.500 (89.527)\n",
            "Test: [130/157]\tTime 0.050 (0.044)\tLoss 0.5893 (0.3290)\tPrec@1 84.375 (89.420)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.3217 (0.3306)\tPrec@1 89.062 (89.406)\n",
            "Test: [150/157]\tTime 0.042 (0.044)\tLoss 0.4571 (0.3388)\tPrec@1 79.688 (89.114)\n",
            " * Prec@1 89.140\n",
            "Best accuracy:  tensor(90., device='cuda:0')\n",
            "Epoch: [64][0/782]\tTime 0.252 (0.252)\tLoss 0.1445 (0.1445)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [64][10/782]\tTime 0.166 (0.171)\tLoss 0.2861 (0.2449)\tPrec@1 90.625 (91.051)\n",
            "Epoch: [64][20/782]\tTime 0.162 (0.167)\tLoss 0.1776 (0.2099)\tPrec@1 90.625 (92.560)\n",
            "Epoch: [64][30/782]\tTime 0.162 (0.166)\tLoss 0.1911 (0.2033)\tPrec@1 92.188 (92.389)\n",
            "Epoch: [64][40/782]\tTime 0.164 (0.165)\tLoss 0.2352 (0.1986)\tPrec@1 93.750 (92.759)\n",
            "Epoch: [64][50/782]\tTime 0.162 (0.165)\tLoss 0.1820 (0.1878)\tPrec@1 95.312 (93.137)\n",
            "Epoch: [64][60/782]\tTime 0.168 (0.165)\tLoss 0.0484 (0.1885)\tPrec@1 100.000 (93.161)\n",
            "Epoch: [64][70/782]\tTime 0.164 (0.165)\tLoss 0.2045 (0.1858)\tPrec@1 93.750 (93.332)\n",
            "Epoch: [64][80/782]\tTime 0.161 (0.165)\tLoss 0.1647 (0.1838)\tPrec@1 95.312 (93.383)\n",
            "Epoch: [64][90/782]\tTime 0.164 (0.165)\tLoss 0.4316 (0.1904)\tPrec@1 87.500 (93.218)\n",
            "Epoch: [64][100/782]\tTime 0.161 (0.164)\tLoss 0.1755 (0.1935)\tPrec@1 93.750 (93.116)\n",
            "Epoch: [64][110/782]\tTime 0.163 (0.164)\tLoss 0.1523 (0.1956)\tPrec@1 95.312 (93.074)\n",
            "Epoch: [64][120/782]\tTime 0.162 (0.164)\tLoss 0.1821 (0.1978)\tPrec@1 93.750 (93.027)\n",
            "Epoch: [64][130/782]\tTime 0.162 (0.164)\tLoss 0.3047 (0.2014)\tPrec@1 87.500 (92.987)\n",
            "Epoch: [64][140/782]\tTime 0.164 (0.164)\tLoss 0.2295 (0.2028)\tPrec@1 92.188 (92.930)\n",
            "Epoch: [64][150/782]\tTime 0.164 (0.164)\tLoss 0.2694 (0.2025)\tPrec@1 90.625 (92.922)\n",
            "Epoch: [64][160/782]\tTime 0.160 (0.164)\tLoss 0.1307 (0.2031)\tPrec@1 93.750 (92.915)\n",
            "Epoch: [64][170/782]\tTime 0.163 (0.164)\tLoss 0.2947 (0.2068)\tPrec@1 89.062 (92.827)\n",
            "Epoch: [64][180/782]\tTime 0.164 (0.164)\tLoss 0.1823 (0.2064)\tPrec@1 92.188 (92.809)\n",
            "Epoch: [64][190/782]\tTime 0.162 (0.164)\tLoss 0.2524 (0.2053)\tPrec@1 90.625 (92.858)\n",
            "Epoch: [64][200/782]\tTime 0.162 (0.164)\tLoss 0.1407 (0.2065)\tPrec@1 96.875 (92.778)\n",
            "Epoch: [64][210/782]\tTime 0.163 (0.164)\tLoss 0.1411 (0.2064)\tPrec@1 96.875 (92.817)\n",
            "Epoch: [64][220/782]\tTime 0.162 (0.164)\tLoss 0.2060 (0.2074)\tPrec@1 92.188 (92.746)\n",
            "Epoch: [64][230/782]\tTime 0.164 (0.164)\tLoss 0.3926 (0.2070)\tPrec@1 92.188 (92.762)\n",
            "Epoch: [64][240/782]\tTime 0.169 (0.164)\tLoss 0.2244 (0.2058)\tPrec@1 89.062 (92.784)\n",
            "Epoch: [64][250/782]\tTime 0.161 (0.164)\tLoss 0.1143 (0.2039)\tPrec@1 95.312 (92.854)\n",
            "Epoch: [64][260/782]\tTime 0.162 (0.164)\tLoss 0.2062 (0.2032)\tPrec@1 93.750 (92.852)\n",
            "Epoch: [64][270/782]\tTime 0.163 (0.164)\tLoss 0.2107 (0.2021)\tPrec@1 92.188 (92.908)\n",
            "Epoch: [64][280/782]\tTime 0.165 (0.164)\tLoss 0.1720 (0.2029)\tPrec@1 93.750 (92.871)\n",
            "Epoch: [64][290/782]\tTime 0.162 (0.164)\tLoss 0.2510 (0.2031)\tPrec@1 89.062 (92.880)\n",
            "Epoch: [64][300/782]\tTime 0.161 (0.164)\tLoss 0.2180 (0.2033)\tPrec@1 92.188 (92.862)\n",
            "Epoch: [64][310/782]\tTime 0.164 (0.164)\tLoss 0.0825 (0.2037)\tPrec@1 96.875 (92.851)\n",
            "Epoch: [64][320/782]\tTime 0.162 (0.164)\tLoss 0.1231 (0.2039)\tPrec@1 95.312 (92.825)\n",
            "Epoch: [64][330/782]\tTime 0.162 (0.164)\tLoss 0.2128 (0.2033)\tPrec@1 93.750 (92.863)\n",
            "Epoch: [64][340/782]\tTime 0.162 (0.164)\tLoss 0.2911 (0.2037)\tPrec@1 89.062 (92.820)\n",
            "Epoch: [64][350/782]\tTime 0.163 (0.164)\tLoss 0.1439 (0.2051)\tPrec@1 93.750 (92.739)\n",
            "Epoch: [64][360/782]\tTime 0.163 (0.164)\tLoss 0.2426 (0.2046)\tPrec@1 95.312 (92.746)\n",
            "Epoch: [64][370/782]\tTime 0.162 (0.164)\tLoss 0.3034 (0.2050)\tPrec@1 89.062 (92.706)\n",
            "Epoch: [64][380/782]\tTime 0.163 (0.164)\tLoss 0.3640 (0.2059)\tPrec@1 87.500 (92.684)\n",
            "Epoch: [64][390/782]\tTime 0.163 (0.164)\tLoss 0.2017 (0.2058)\tPrec@1 92.188 (92.687)\n",
            "Epoch: [64][400/782]\tTime 0.163 (0.164)\tLoss 0.1861 (0.2060)\tPrec@1 93.750 (92.702)\n",
            "Epoch: [64][410/782]\tTime 0.163 (0.164)\tLoss 0.3877 (0.2058)\tPrec@1 89.062 (92.716)\n",
            "Epoch: [64][420/782]\tTime 0.163 (0.164)\tLoss 0.1048 (0.2054)\tPrec@1 96.875 (92.744)\n",
            "Epoch: [64][430/782]\tTime 0.163 (0.164)\tLoss 0.3623 (0.2060)\tPrec@1 87.500 (92.742)\n",
            "Epoch: [64][440/782]\tTime 0.164 (0.164)\tLoss 0.2421 (0.2058)\tPrec@1 90.625 (92.726)\n",
            "Epoch: [64][450/782]\tTime 0.162 (0.164)\tLoss 0.4453 (0.2059)\tPrec@1 84.375 (92.725)\n",
            "Epoch: [64][460/782]\tTime 0.163 (0.164)\tLoss 0.2208 (0.2064)\tPrec@1 87.500 (92.676)\n",
            "Epoch: [64][470/782]\tTime 0.162 (0.164)\tLoss 0.2422 (0.2074)\tPrec@1 93.750 (92.635)\n",
            "Epoch: [64][480/782]\tTime 0.164 (0.164)\tLoss 0.2574 (0.2074)\tPrec@1 89.062 (92.629)\n",
            "Epoch: [64][490/782]\tTime 0.161 (0.164)\tLoss 0.1891 (0.2075)\tPrec@1 92.188 (92.630)\n",
            "Epoch: [64][500/782]\tTime 0.168 (0.164)\tLoss 0.2277 (0.2080)\tPrec@1 90.625 (92.609)\n",
            "Epoch: [64][510/782]\tTime 0.163 (0.164)\tLoss 0.0548 (0.2082)\tPrec@1 98.438 (92.594)\n",
            "Epoch: [64][520/782]\tTime 0.163 (0.164)\tLoss 0.2369 (0.2089)\tPrec@1 92.188 (92.565)\n",
            "Epoch: [64][530/782]\tTime 0.161 (0.164)\tLoss 0.2094 (0.2089)\tPrec@1 92.188 (92.579)\n",
            "Epoch: [64][540/782]\tTime 0.164 (0.164)\tLoss 0.2424 (0.2091)\tPrec@1 93.750 (92.569)\n",
            "Epoch: [64][550/782]\tTime 0.162 (0.164)\tLoss 0.2920 (0.2091)\tPrec@1 89.062 (92.576)\n",
            "Epoch: [64][560/782]\tTime 0.163 (0.164)\tLoss 0.2015 (0.2098)\tPrec@1 95.312 (92.561)\n",
            "Epoch: [64][570/782]\tTime 0.163 (0.164)\tLoss 0.2613 (0.2096)\tPrec@1 92.188 (92.576)\n",
            "Epoch: [64][580/782]\tTime 0.163 (0.164)\tLoss 0.3247 (0.2098)\tPrec@1 89.062 (92.567)\n",
            "Epoch: [64][590/782]\tTime 0.162 (0.164)\tLoss 0.1540 (0.2098)\tPrec@1 95.312 (92.573)\n",
            "Epoch: [64][600/782]\tTime 0.162 (0.164)\tLoss 0.1790 (0.2097)\tPrec@1 96.875 (92.580)\n",
            "Epoch: [64][610/782]\tTime 0.166 (0.164)\tLoss 0.2638 (0.2099)\tPrec@1 93.750 (92.581)\n",
            "Epoch: [64][620/782]\tTime 0.163 (0.164)\tLoss 0.4588 (0.2108)\tPrec@1 85.938 (92.555)\n",
            "Epoch: [64][630/782]\tTime 0.164 (0.164)\tLoss 0.1423 (0.2110)\tPrec@1 95.312 (92.554)\n",
            "Epoch: [64][640/782]\tTime 0.164 (0.164)\tLoss 0.1589 (0.2109)\tPrec@1 93.750 (92.551)\n",
            "Epoch: [64][650/782]\tTime 0.162 (0.164)\tLoss 0.2081 (0.2111)\tPrec@1 90.625 (92.538)\n",
            "Epoch: [64][660/782]\tTime 0.164 (0.164)\tLoss 0.2363 (0.2114)\tPrec@1 92.188 (92.533)\n",
            "Epoch: [64][670/782]\tTime 0.169 (0.164)\tLoss 0.1510 (0.2121)\tPrec@1 93.750 (92.490)\n",
            "Epoch: [64][680/782]\tTime 0.163 (0.164)\tLoss 0.1353 (0.2120)\tPrec@1 96.875 (92.493)\n",
            "Epoch: [64][690/782]\tTime 0.163 (0.164)\tLoss 0.2937 (0.2121)\tPrec@1 89.062 (92.486)\n",
            "Epoch: [64][700/782]\tTime 0.165 (0.164)\tLoss 0.1338 (0.2119)\tPrec@1 98.438 (92.502)\n",
            "Epoch: [64][710/782]\tTime 0.165 (0.164)\tLoss 0.1368 (0.2114)\tPrec@1 98.438 (92.530)\n",
            "Epoch: [64][720/782]\tTime 0.165 (0.164)\tLoss 0.1703 (0.2111)\tPrec@1 93.750 (92.530)\n",
            "Epoch: [64][730/782]\tTime 0.163 (0.164)\tLoss 0.1742 (0.2108)\tPrec@1 92.188 (92.547)\n",
            "Epoch: [64][740/782]\tTime 0.164 (0.164)\tLoss 0.2047 (0.2106)\tPrec@1 95.312 (92.563)\n",
            "Epoch: [64][750/782]\tTime 0.163 (0.164)\tLoss 0.1162 (0.2103)\tPrec@1 98.438 (92.574)\n",
            "Epoch: [64][760/782]\tTime 0.164 (0.164)\tLoss 0.2504 (0.2105)\tPrec@1 89.062 (92.563)\n",
            "Epoch: [64][770/782]\tTime 0.162 (0.164)\tLoss 0.3578 (0.2105)\tPrec@1 82.812 (92.560)\n",
            "Epoch: [64][780/782]\tTime 0.162 (0.164)\tLoss 0.3568 (0.2108)\tPrec@1 93.750 (92.570)\n",
            "Training accuracy:  tensor(92.5680, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.7600, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.105 (0.105)\tLoss 0.1757 (0.1757)\tPrec@1 93.750 (93.750)\n",
            "Test: [10/157]\tTime 0.043 (0.047)\tLoss 0.8683 (0.4359)\tPrec@1 73.438 (85.653)\n",
            "Test: [20/157]\tTime 0.050 (0.045)\tLoss 0.4521 (0.4258)\tPrec@1 89.062 (86.979)\n",
            "Test: [30/157]\tTime 0.042 (0.045)\tLoss 0.4642 (0.4248)\tPrec@1 84.375 (87.298)\n",
            "Test: [40/157]\tTime 0.043 (0.045)\tLoss 0.5195 (0.4411)\tPrec@1 82.812 (86.509)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.5423 (0.4455)\tPrec@1 85.938 (86.458)\n",
            "Test: [60/157]\tTime 0.043 (0.045)\tLoss 0.3050 (0.4401)\tPrec@1 89.062 (86.501)\n",
            "Test: [70/157]\tTime 0.044 (0.045)\tLoss 0.7955 (0.4530)\tPrec@1 76.562 (86.224)\n",
            "Test: [80/157]\tTime 0.046 (0.044)\tLoss 0.4660 (0.4566)\tPrec@1 87.500 (86.497)\n",
            "Test: [90/157]\tTime 0.047 (0.044)\tLoss 0.3032 (0.4557)\tPrec@1 93.750 (86.521)\n",
            "Test: [100/157]\tTime 0.047 (0.044)\tLoss 0.5328 (0.4605)\tPrec@1 84.375 (86.278)\n",
            "Test: [110/157]\tTime 0.044 (0.044)\tLoss 0.3900 (0.4603)\tPrec@1 90.625 (86.374)\n",
            "Test: [120/157]\tTime 0.043 (0.044)\tLoss 0.3937 (0.4601)\tPrec@1 87.500 (86.234)\n",
            "Test: [130/157]\tTime 0.044 (0.044)\tLoss 0.3821 (0.4613)\tPrec@1 84.375 (86.236)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.1760 (0.4544)\tPrec@1 93.750 (86.359)\n",
            "Test: [150/157]\tTime 0.043 (0.044)\tLoss 0.3602 (0.4519)\tPrec@1 92.188 (86.341)\n",
            " * Prec@1 86.360\n",
            "Best accuracy:  tensor(90., device='cuda:0')\n",
            "Epoch: [65][0/782]\tTime 0.257 (0.257)\tLoss 0.1540 (0.1540)\tPrec@1 95.312 (95.312)\n",
            "Epoch: [65][10/782]\tTime 0.164 (0.172)\tLoss 0.1796 (0.2093)\tPrec@1 93.750 (92.756)\n",
            "Epoch: [65][20/782]\tTime 0.165 (0.168)\tLoss 0.3088 (0.2237)\tPrec@1 87.500 (91.890)\n",
            "Epoch: [65][30/782]\tTime 0.164 (0.167)\tLoss 0.1518 (0.2128)\tPrec@1 95.312 (92.540)\n",
            "Epoch: [65][40/782]\tTime 0.162 (0.166)\tLoss 0.1042 (0.2023)\tPrec@1 98.438 (93.064)\n",
            "Epoch: [65][50/782]\tTime 0.163 (0.166)\tLoss 0.1730 (0.1942)\tPrec@1 93.750 (93.382)\n",
            "Epoch: [65][60/782]\tTime 0.164 (0.166)\tLoss 0.1213 (0.1917)\tPrec@1 92.188 (93.468)\n",
            "Epoch: [65][70/782]\tTime 0.163 (0.165)\tLoss 0.2515 (0.1932)\tPrec@1 92.188 (93.332)\n",
            "Epoch: [65][80/782]\tTime 0.164 (0.165)\tLoss 0.2228 (0.1954)\tPrec@1 90.625 (93.171)\n",
            "Epoch: [65][90/782]\tTime 0.161 (0.165)\tLoss 0.2008 (0.1986)\tPrec@1 90.625 (93.063)\n",
            "Epoch: [65][100/782]\tTime 0.163 (0.165)\tLoss 0.2515 (0.2019)\tPrec@1 92.188 (92.915)\n",
            "Epoch: [65][110/782]\tTime 0.162 (0.165)\tLoss 0.1667 (0.2005)\tPrec@1 93.750 (93.018)\n",
            "Epoch: [65][120/782]\tTime 0.167 (0.165)\tLoss 0.2308 (0.1994)\tPrec@1 96.875 (93.079)\n",
            "Epoch: [65][130/782]\tTime 0.162 (0.164)\tLoss 0.2328 (0.1973)\tPrec@1 90.625 (93.154)\n",
            "Epoch: [65][140/782]\tTime 0.162 (0.164)\tLoss 0.3225 (0.2000)\tPrec@1 87.500 (93.063)\n",
            "Epoch: [65][150/782]\tTime 0.165 (0.164)\tLoss 0.1780 (0.1991)\tPrec@1 95.312 (93.108)\n",
            "Epoch: [65][160/782]\tTime 0.162 (0.164)\tLoss 0.2118 (0.1991)\tPrec@1 92.188 (93.080)\n",
            "Epoch: [65][170/782]\tTime 0.162 (0.164)\tLoss 0.1372 (0.2005)\tPrec@1 95.312 (92.964)\n",
            "Epoch: [65][180/782]\tTime 0.162 (0.164)\tLoss 0.1450 (0.2040)\tPrec@1 96.875 (92.852)\n",
            "Epoch: [65][190/782]\tTime 0.161 (0.164)\tLoss 0.2272 (0.2045)\tPrec@1 95.312 (92.834)\n",
            "Epoch: [65][200/782]\tTime 0.165 (0.164)\tLoss 0.2414 (0.2054)\tPrec@1 95.312 (92.809)\n",
            "Epoch: [65][210/782]\tTime 0.164 (0.164)\tLoss 0.1879 (0.2061)\tPrec@1 92.188 (92.780)\n",
            "Epoch: [65][220/782]\tTime 0.166 (0.164)\tLoss 0.1684 (0.2048)\tPrec@1 92.188 (92.788)\n",
            "Epoch: [65][230/782]\tTime 0.164 (0.164)\tLoss 0.1677 (0.2052)\tPrec@1 96.875 (92.790)\n",
            "Epoch: [65][240/782]\tTime 0.165 (0.164)\tLoss 0.2805 (0.2064)\tPrec@1 93.750 (92.816)\n",
            "Epoch: [65][250/782]\tTime 0.165 (0.164)\tLoss 0.1520 (0.2078)\tPrec@1 93.750 (92.791)\n",
            "Epoch: [65][260/782]\tTime 0.164 (0.164)\tLoss 0.1988 (0.2085)\tPrec@1 92.188 (92.750)\n",
            "Epoch: [65][270/782]\tTime 0.163 (0.164)\tLoss 0.1994 (0.2086)\tPrec@1 92.188 (92.753)\n",
            "Epoch: [65][280/782]\tTime 0.162 (0.164)\tLoss 0.1044 (0.2106)\tPrec@1 96.875 (92.699)\n",
            "Epoch: [65][290/782]\tTime 0.163 (0.164)\tLoss 0.1630 (0.2103)\tPrec@1 93.750 (92.724)\n",
            "Epoch: [65][300/782]\tTime 0.164 (0.164)\tLoss 0.1537 (0.2098)\tPrec@1 92.188 (92.748)\n",
            "Epoch: [65][310/782]\tTime 0.163 (0.164)\tLoss 0.2245 (0.2094)\tPrec@1 89.062 (92.745)\n",
            "Epoch: [65][320/782]\tTime 0.164 (0.164)\tLoss 0.2208 (0.2110)\tPrec@1 90.625 (92.674)\n",
            "Epoch: [65][330/782]\tTime 0.162 (0.164)\tLoss 0.1226 (0.2107)\tPrec@1 96.875 (92.678)\n",
            "Epoch: [65][340/782]\tTime 0.163 (0.164)\tLoss 0.1745 (0.2098)\tPrec@1 96.875 (92.714)\n",
            "Epoch: [65][350/782]\tTime 0.163 (0.164)\tLoss 0.2393 (0.2105)\tPrec@1 93.750 (92.695)\n",
            "Epoch: [65][360/782]\tTime 0.163 (0.164)\tLoss 0.2242 (0.2105)\tPrec@1 90.625 (92.681)\n",
            "Epoch: [65][370/782]\tTime 0.163 (0.164)\tLoss 0.2172 (0.2108)\tPrec@1 90.625 (92.697)\n",
            "Epoch: [65][380/782]\tTime 0.162 (0.164)\tLoss 0.2459 (0.2105)\tPrec@1 89.062 (92.700)\n",
            "Epoch: [65][390/782]\tTime 0.163 (0.164)\tLoss 0.1541 (0.2101)\tPrec@1 95.312 (92.723)\n",
            "Epoch: [65][400/782]\tTime 0.165 (0.164)\tLoss 0.1641 (0.2109)\tPrec@1 93.750 (92.686)\n",
            "Epoch: [65][410/782]\tTime 0.162 (0.164)\tLoss 0.2777 (0.2109)\tPrec@1 90.625 (92.682)\n",
            "Epoch: [65][420/782]\tTime 0.165 (0.164)\tLoss 0.1837 (0.2113)\tPrec@1 95.312 (92.681)\n",
            "Epoch: [65][430/782]\tTime 0.163 (0.164)\tLoss 0.1948 (0.2115)\tPrec@1 93.750 (92.670)\n",
            "Epoch: [65][440/782]\tTime 0.163 (0.164)\tLoss 0.2039 (0.2109)\tPrec@1 93.750 (92.691)\n",
            "Epoch: [65][450/782]\tTime 0.163 (0.164)\tLoss 0.1388 (0.2109)\tPrec@1 95.312 (92.686)\n",
            "Epoch: [65][460/782]\tTime 0.162 (0.164)\tLoss 0.1386 (0.2111)\tPrec@1 93.750 (92.665)\n",
            "Epoch: [65][470/782]\tTime 0.163 (0.164)\tLoss 0.2253 (0.2115)\tPrec@1 93.750 (92.675)\n",
            "Epoch: [65][480/782]\tTime 0.164 (0.164)\tLoss 0.0955 (0.2109)\tPrec@1 96.875 (92.681)\n",
            "Epoch: [65][490/782]\tTime 0.163 (0.164)\tLoss 0.2026 (0.2112)\tPrec@1 93.750 (92.652)\n",
            "Epoch: [65][500/782]\tTime 0.163 (0.164)\tLoss 0.2157 (0.2112)\tPrec@1 92.188 (92.655)\n",
            "Epoch: [65][510/782]\tTime 0.172 (0.164)\tLoss 0.1858 (0.2128)\tPrec@1 93.750 (92.609)\n",
            "Epoch: [65][520/782]\tTime 0.163 (0.164)\tLoss 0.0816 (0.2125)\tPrec@1 98.438 (92.622)\n",
            "Epoch: [65][530/782]\tTime 0.162 (0.164)\tLoss 0.2534 (0.2127)\tPrec@1 87.500 (92.608)\n",
            "Epoch: [65][540/782]\tTime 0.168 (0.164)\tLoss 0.1240 (0.2128)\tPrec@1 95.312 (92.606)\n",
            "Epoch: [65][550/782]\tTime 0.164 (0.164)\tLoss 0.2188 (0.2119)\tPrec@1 90.625 (92.633)\n",
            "Epoch: [65][560/782]\tTime 0.163 (0.164)\tLoss 0.1390 (0.2124)\tPrec@1 93.750 (92.605)\n",
            "Epoch: [65][570/782]\tTime 0.163 (0.164)\tLoss 0.2777 (0.2129)\tPrec@1 92.188 (92.595)\n",
            "Epoch: [65][580/782]\tTime 0.163 (0.164)\tLoss 0.2393 (0.2127)\tPrec@1 92.188 (92.586)\n",
            "Epoch: [65][590/782]\tTime 0.163 (0.164)\tLoss 0.1692 (0.2125)\tPrec@1 92.188 (92.576)\n",
            "Epoch: [65][600/782]\tTime 0.163 (0.164)\tLoss 0.1618 (0.2129)\tPrec@1 92.188 (92.559)\n",
            "Epoch: [65][610/782]\tTime 0.164 (0.164)\tLoss 0.1354 (0.2124)\tPrec@1 96.875 (92.592)\n",
            "Epoch: [65][620/782]\tTime 0.162 (0.164)\tLoss 0.1911 (0.2118)\tPrec@1 93.750 (92.590)\n",
            "Epoch: [65][630/782]\tTime 0.162 (0.164)\tLoss 0.1106 (0.2125)\tPrec@1 98.438 (92.579)\n",
            "Epoch: [65][640/782]\tTime 0.162 (0.164)\tLoss 0.1867 (0.2131)\tPrec@1 92.188 (92.543)\n",
            "Epoch: [65][650/782]\tTime 0.162 (0.164)\tLoss 0.1920 (0.2137)\tPrec@1 92.188 (92.512)\n",
            "Epoch: [65][660/782]\tTime 0.163 (0.164)\tLoss 0.3077 (0.2137)\tPrec@1 90.625 (92.516)\n",
            "Epoch: [65][670/782]\tTime 0.164 (0.164)\tLoss 0.3096 (0.2136)\tPrec@1 89.062 (92.502)\n",
            "Epoch: [65][680/782]\tTime 0.163 (0.164)\tLoss 0.1226 (0.2138)\tPrec@1 98.438 (92.502)\n",
            "Epoch: [65][690/782]\tTime 0.163 (0.164)\tLoss 0.1825 (0.2141)\tPrec@1 92.188 (92.500)\n",
            "Epoch: [65][700/782]\tTime 0.163 (0.164)\tLoss 0.1495 (0.2148)\tPrec@1 96.875 (92.493)\n",
            "Epoch: [65][710/782]\tTime 0.164 (0.164)\tLoss 0.3016 (0.2149)\tPrec@1 87.500 (92.480)\n",
            "Epoch: [65][720/782]\tTime 0.162 (0.164)\tLoss 0.1713 (0.2155)\tPrec@1 93.750 (92.454)\n",
            "Epoch: [65][730/782]\tTime 0.163 (0.164)\tLoss 0.1639 (0.2150)\tPrec@1 96.875 (92.491)\n",
            "Epoch: [65][740/782]\tTime 0.161 (0.164)\tLoss 0.1866 (0.2149)\tPrec@1 93.750 (92.495)\n",
            "Epoch: [65][750/782]\tTime 0.161 (0.164)\tLoss 0.1229 (0.2147)\tPrec@1 95.312 (92.516)\n",
            "Epoch: [65][760/782]\tTime 0.162 (0.164)\tLoss 0.3109 (0.2149)\tPrec@1 92.188 (92.506)\n",
            "Epoch: [65][770/782]\tTime 0.165 (0.164)\tLoss 0.2474 (0.2147)\tPrec@1 93.750 (92.516)\n",
            "Epoch: [65][780/782]\tTime 0.162 (0.164)\tLoss 0.3238 (0.2152)\tPrec@1 92.188 (92.508)\n",
            "Training accuracy:  tensor(92.5060, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.7600, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.119 (0.119)\tLoss 0.3522 (0.3522)\tPrec@1 89.062 (89.062)\n",
            "Test: [10/157]\tTime 0.046 (0.048)\tLoss 0.4294 (0.3719)\tPrec@1 90.625 (88.920)\n",
            "Test: [20/157]\tTime 0.054 (0.046)\tLoss 0.3163 (0.3778)\tPrec@1 87.500 (88.839)\n",
            "Test: [30/157]\tTime 0.043 (0.046)\tLoss 0.6948 (0.3791)\tPrec@1 84.375 (88.710)\n",
            "Test: [40/157]\tTime 0.038 (0.045)\tLoss 0.4684 (0.3905)\tPrec@1 85.938 (88.338)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.2355 (0.3783)\tPrec@1 90.625 (88.634)\n",
            "Test: [60/157]\tTime 0.043 (0.045)\tLoss 0.2938 (0.3799)\tPrec@1 87.500 (88.473)\n",
            "Test: [70/157]\tTime 0.048 (0.045)\tLoss 0.1753 (0.3631)\tPrec@1 89.062 (88.732)\n",
            "Test: [80/157]\tTime 0.044 (0.045)\tLoss 0.2795 (0.3683)\tPrec@1 90.625 (88.677)\n",
            "Test: [90/157]\tTime 0.045 (0.045)\tLoss 0.3578 (0.3647)\tPrec@1 92.188 (88.874)\n",
            "Test: [100/157]\tTime 0.044 (0.044)\tLoss 0.3087 (0.3620)\tPrec@1 89.062 (88.800)\n",
            "Test: [110/157]\tTime 0.046 (0.044)\tLoss 0.3126 (0.3543)\tPrec@1 87.500 (88.978)\n",
            "Test: [120/157]\tTime 0.044 (0.044)\tLoss 0.4059 (0.3542)\tPrec@1 85.938 (88.985)\n",
            "Test: [130/157]\tTime 0.043 (0.044)\tLoss 0.3270 (0.3483)\tPrec@1 89.062 (89.039)\n",
            "Test: [140/157]\tTime 0.046 (0.044)\tLoss 0.5759 (0.3493)\tPrec@1 90.625 (89.085)\n",
            "Test: [150/157]\tTime 0.043 (0.044)\tLoss 0.2705 (0.3516)\tPrec@1 90.625 (88.980)\n",
            " * Prec@1 89.080\n",
            "Best accuracy:  tensor(90., device='cuda:0')\n",
            "Epoch: [66][0/782]\tTime 0.249 (0.249)\tLoss 0.1942 (0.1942)\tPrec@1 93.750 (93.750)\n",
            "Epoch: [66][10/782]\tTime 0.162 (0.171)\tLoss 0.1201 (0.2038)\tPrec@1 95.312 (92.614)\n",
            "Epoch: [66][20/782]\tTime 0.163 (0.168)\tLoss 0.1775 (0.2096)\tPrec@1 93.750 (92.262)\n",
            "Epoch: [66][30/782]\tTime 0.163 (0.167)\tLoss 0.1198 (0.2021)\tPrec@1 96.875 (92.591)\n",
            "Epoch: [66][40/782]\tTime 0.164 (0.166)\tLoss 0.1781 (0.2060)\tPrec@1 92.188 (92.721)\n",
            "Epoch: [66][50/782]\tTime 0.166 (0.166)\tLoss 0.2094 (0.2012)\tPrec@1 90.625 (92.892)\n",
            "Epoch: [66][60/782]\tTime 0.162 (0.166)\tLoss 0.4189 (0.2012)\tPrec@1 84.375 (92.751)\n",
            "Epoch: [66][70/782]\tTime 0.162 (0.165)\tLoss 0.2289 (0.2036)\tPrec@1 92.188 (92.672)\n",
            "Epoch: [66][80/782]\tTime 0.163 (0.165)\tLoss 0.2241 (0.2040)\tPrec@1 93.750 (92.631)\n",
            "Epoch: [66][90/782]\tTime 0.162 (0.165)\tLoss 0.2560 (0.2081)\tPrec@1 92.188 (92.582)\n",
            "Epoch: [66][100/782]\tTime 0.163 (0.165)\tLoss 0.2270 (0.2089)\tPrec@1 90.625 (92.574)\n",
            "Epoch: [66][110/782]\tTime 0.162 (0.165)\tLoss 0.3207 (0.2079)\tPrec@1 87.500 (92.582)\n",
            "Epoch: [66][120/782]\tTime 0.160 (0.165)\tLoss 0.1345 (0.2059)\tPrec@1 95.312 (92.691)\n",
            "Epoch: [66][130/782]\tTime 0.162 (0.165)\tLoss 0.4510 (0.2094)\tPrec@1 87.500 (92.486)\n",
            "Epoch: [66][140/782]\tTime 0.162 (0.164)\tLoss 0.1326 (0.2082)\tPrec@1 95.312 (92.520)\n",
            "Epoch: [66][150/782]\tTime 0.162 (0.164)\tLoss 0.2654 (0.2068)\tPrec@1 90.625 (92.581)\n",
            "Epoch: [66][160/782]\tTime 0.163 (0.164)\tLoss 0.2794 (0.2050)\tPrec@1 89.062 (92.605)\n",
            "Epoch: [66][170/782]\tTime 0.162 (0.164)\tLoss 0.0773 (0.2025)\tPrec@1 98.438 (92.644)\n",
            "Epoch: [66][180/782]\tTime 0.167 (0.164)\tLoss 0.2182 (0.2025)\tPrec@1 92.188 (92.680)\n",
            "Epoch: [66][190/782]\tTime 0.165 (0.164)\tLoss 0.1872 (0.2007)\tPrec@1 92.188 (92.752)\n",
            "Epoch: [66][200/782]\tTime 0.165 (0.164)\tLoss 0.2270 (0.1999)\tPrec@1 92.188 (92.809)\n",
            "Epoch: [66][210/782]\tTime 0.163 (0.164)\tLoss 0.1212 (0.1980)\tPrec@1 93.750 (92.847)\n",
            "Epoch: [66][220/782]\tTime 0.162 (0.164)\tLoss 0.1207 (0.1977)\tPrec@1 95.312 (92.831)\n",
            "Epoch: [66][230/782]\tTime 0.163 (0.164)\tLoss 0.1794 (0.1972)\tPrec@1 89.062 (92.830)\n",
            "Epoch: [66][240/782]\tTime 0.163 (0.164)\tLoss 0.4307 (0.1982)\tPrec@1 87.500 (92.790)\n",
            "Epoch: [66][250/782]\tTime 0.162 (0.164)\tLoss 0.1287 (0.1992)\tPrec@1 95.312 (92.773)\n",
            "Epoch: [66][260/782]\tTime 0.161 (0.164)\tLoss 0.3296 (0.1995)\tPrec@1 93.750 (92.810)\n",
            "Epoch: [66][270/782]\tTime 0.163 (0.164)\tLoss 0.1940 (0.1999)\tPrec@1 92.188 (92.810)\n",
            "Epoch: [66][280/782]\tTime 0.164 (0.164)\tLoss 0.1767 (0.1998)\tPrec@1 93.750 (92.777)\n",
            "Epoch: [66][290/782]\tTime 0.163 (0.164)\tLoss 0.2059 (0.1998)\tPrec@1 93.750 (92.751)\n",
            "Epoch: [66][300/782]\tTime 0.166 (0.164)\tLoss 0.2116 (0.1987)\tPrec@1 90.625 (92.800)\n",
            "Epoch: [66][310/782]\tTime 0.164 (0.164)\tLoss 0.3780 (0.1994)\tPrec@1 90.625 (92.800)\n",
            "Epoch: [66][320/782]\tTime 0.162 (0.164)\tLoss 0.2421 (0.1989)\tPrec@1 90.625 (92.830)\n",
            "Epoch: [66][330/782]\tTime 0.165 (0.164)\tLoss 0.1732 (0.1982)\tPrec@1 95.312 (92.844)\n",
            "Epoch: [66][340/782]\tTime 0.163 (0.164)\tLoss 0.4414 (0.1996)\tPrec@1 79.688 (92.774)\n",
            "Epoch: [66][350/782]\tTime 0.162 (0.164)\tLoss 0.1794 (0.2001)\tPrec@1 95.312 (92.771)\n",
            "Epoch: [66][360/782]\tTime 0.164 (0.164)\tLoss 0.2047 (0.2009)\tPrec@1 93.750 (92.755)\n",
            "Epoch: [66][370/782]\tTime 0.163 (0.164)\tLoss 0.3104 (0.2014)\tPrec@1 89.062 (92.722)\n",
            "Epoch: [66][380/782]\tTime 0.163 (0.164)\tLoss 0.3766 (0.2024)\tPrec@1 87.500 (92.712)\n",
            "Epoch: [66][390/782]\tTime 0.166 (0.164)\tLoss 0.2323 (0.2036)\tPrec@1 95.312 (92.663)\n",
            "Epoch: [66][400/782]\tTime 0.163 (0.164)\tLoss 0.2846 (0.2037)\tPrec@1 89.062 (92.643)\n",
            "Epoch: [66][410/782]\tTime 0.162 (0.164)\tLoss 0.1171 (0.2028)\tPrec@1 96.875 (92.689)\n",
            "Epoch: [66][420/782]\tTime 0.166 (0.164)\tLoss 0.1577 (0.2031)\tPrec@1 93.750 (92.711)\n",
            "Epoch: [66][430/782]\tTime 0.162 (0.164)\tLoss 0.3396 (0.2046)\tPrec@1 89.062 (92.681)\n",
            "Epoch: [66][440/782]\tTime 0.162 (0.164)\tLoss 0.1772 (0.2046)\tPrec@1 93.750 (92.694)\n",
            "Epoch: [66][450/782]\tTime 0.162 (0.164)\tLoss 0.1873 (0.2046)\tPrec@1 93.750 (92.697)\n",
            "Epoch: [66][460/782]\tTime 0.163 (0.164)\tLoss 0.1085 (0.2038)\tPrec@1 96.875 (92.723)\n",
            "Epoch: [66][470/782]\tTime 0.162 (0.164)\tLoss 0.2110 (0.2043)\tPrec@1 92.188 (92.712)\n",
            "Epoch: [66][480/782]\tTime 0.161 (0.164)\tLoss 0.4480 (0.2048)\tPrec@1 89.062 (92.723)\n",
            "Epoch: [66][490/782]\tTime 0.165 (0.164)\tLoss 0.1251 (0.2041)\tPrec@1 93.750 (92.751)\n",
            "Epoch: [66][500/782]\tTime 0.162 (0.164)\tLoss 0.3641 (0.2043)\tPrec@1 87.500 (92.749)\n",
            "Epoch: [66][510/782]\tTime 0.161 (0.164)\tLoss 0.2292 (0.2044)\tPrec@1 95.312 (92.756)\n",
            "Epoch: [66][520/782]\tTime 0.161 (0.164)\tLoss 0.3119 (0.2047)\tPrec@1 92.188 (92.766)\n",
            "Epoch: [66][530/782]\tTime 0.166 (0.164)\tLoss 0.3495 (0.2049)\tPrec@1 85.938 (92.770)\n",
            "Epoch: [66][540/782]\tTime 0.163 (0.164)\tLoss 0.1384 (0.2044)\tPrec@1 95.312 (92.791)\n",
            "Epoch: [66][550/782]\tTime 0.163 (0.164)\tLoss 0.1214 (0.2045)\tPrec@1 93.750 (92.789)\n",
            "Epoch: [66][560/782]\tTime 0.163 (0.164)\tLoss 0.1138 (0.2042)\tPrec@1 96.875 (92.806)\n",
            "Epoch: [66][570/782]\tTime 0.163 (0.164)\tLoss 0.2840 (0.2039)\tPrec@1 89.062 (92.809)\n",
            "Epoch: [66][580/782]\tTime 0.163 (0.164)\tLoss 0.2044 (0.2036)\tPrec@1 93.750 (92.814)\n",
            "Epoch: [66][590/782]\tTime 0.165 (0.164)\tLoss 0.3698 (0.2042)\tPrec@1 84.375 (92.798)\n",
            "Epoch: [66][600/782]\tTime 0.163 (0.164)\tLoss 0.2876 (0.2044)\tPrec@1 90.625 (92.801)\n",
            "Epoch: [66][610/782]\tTime 0.162 (0.164)\tLoss 0.1198 (0.2047)\tPrec@1 96.875 (92.794)\n",
            "Epoch: [66][620/782]\tTime 0.165 (0.164)\tLoss 0.0721 (0.2047)\tPrec@1 98.438 (92.784)\n",
            "Epoch: [66][630/782]\tTime 0.164 (0.164)\tLoss 0.0987 (0.2051)\tPrec@1 98.438 (92.757)\n",
            "Epoch: [66][640/782]\tTime 0.162 (0.164)\tLoss 0.1730 (0.2044)\tPrec@1 96.875 (92.797)\n",
            "Epoch: [66][650/782]\tTime 0.169 (0.164)\tLoss 0.1021 (0.2048)\tPrec@1 96.875 (92.778)\n",
            "Epoch: [66][660/782]\tTime 0.163 (0.164)\tLoss 0.2602 (0.2059)\tPrec@1 90.625 (92.743)\n",
            "Epoch: [66][670/782]\tTime 0.163 (0.164)\tLoss 0.1698 (0.2065)\tPrec@1 98.438 (92.735)\n",
            "Epoch: [66][680/782]\tTime 0.162 (0.164)\tLoss 0.2088 (0.2063)\tPrec@1 90.625 (92.731)\n",
            "Epoch: [66][690/782]\tTime 0.164 (0.164)\tLoss 0.3482 (0.2068)\tPrec@1 87.500 (92.714)\n",
            "Epoch: [66][700/782]\tTime 0.163 (0.164)\tLoss 0.2902 (0.2073)\tPrec@1 89.062 (92.700)\n",
            "Epoch: [66][710/782]\tTime 0.164 (0.164)\tLoss 0.2878 (0.2069)\tPrec@1 90.625 (92.713)\n",
            "Epoch: [66][720/782]\tTime 0.164 (0.164)\tLoss 0.1525 (0.2064)\tPrec@1 95.312 (92.727)\n",
            "Epoch: [66][730/782]\tTime 0.167 (0.164)\tLoss 0.2612 (0.2063)\tPrec@1 90.625 (92.728)\n",
            "Epoch: [66][740/782]\tTime 0.163 (0.164)\tLoss 0.1468 (0.2064)\tPrec@1 93.750 (92.732)\n",
            "Epoch: [66][750/782]\tTime 0.163 (0.164)\tLoss 0.2268 (0.2064)\tPrec@1 92.188 (92.749)\n",
            "Epoch: [66][760/782]\tTime 0.163 (0.164)\tLoss 0.3364 (0.2064)\tPrec@1 87.500 (92.748)\n",
            "Epoch: [66][770/782]\tTime 0.164 (0.164)\tLoss 0.1946 (0.2065)\tPrec@1 93.750 (92.751)\n",
            "Epoch: [66][780/782]\tTime 0.162 (0.164)\tLoss 0.2811 (0.2064)\tPrec@1 90.625 (92.754)\n",
            "Training accuracy:  tensor(92.7540, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.7600, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.115 (0.115)\tLoss 0.2201 (0.2201)\tPrec@1 92.188 (92.188)\n",
            "Test: [10/157]\tTime 0.045 (0.048)\tLoss 0.2681 (0.2802)\tPrec@1 92.188 (91.477)\n",
            "Test: [20/157]\tTime 0.054 (0.046)\tLoss 0.2762 (0.2996)\tPrec@1 90.625 (90.327)\n",
            "Test: [30/157]\tTime 0.042 (0.046)\tLoss 0.1968 (0.2990)\tPrec@1 95.312 (90.272)\n",
            "Test: [40/157]\tTime 0.043 (0.045)\tLoss 0.3012 (0.3094)\tPrec@1 85.938 (89.710)\n",
            "Test: [50/157]\tTime 0.044 (0.045)\tLoss 0.3114 (0.3040)\tPrec@1 87.500 (89.920)\n",
            "Test: [60/157]\tTime 0.047 (0.045)\tLoss 0.3629 (0.3048)\tPrec@1 92.188 (89.985)\n",
            "Test: [70/157]\tTime 0.043 (0.045)\tLoss 0.4174 (0.3113)\tPrec@1 89.062 (89.855)\n",
            "Test: [80/157]\tTime 0.043 (0.045)\tLoss 0.3221 (0.3182)\tPrec@1 89.062 (89.699)\n",
            "Test: [90/157]\tTime 0.043 (0.045)\tLoss 0.2184 (0.3111)\tPrec@1 95.312 (89.973)\n",
            "Test: [100/157]\tTime 0.043 (0.044)\tLoss 0.1897 (0.3137)\tPrec@1 93.750 (89.821)\n",
            "Test: [110/157]\tTime 0.044 (0.044)\tLoss 0.3417 (0.3099)\tPrec@1 87.500 (89.921)\n",
            "Test: [120/157]\tTime 0.044 (0.044)\tLoss 0.4138 (0.3093)\tPrec@1 90.625 (89.902)\n",
            "Test: [130/157]\tTime 0.045 (0.044)\tLoss 0.3253 (0.3084)\tPrec@1 92.188 (89.945)\n",
            "Test: [140/157]\tTime 0.043 (0.044)\tLoss 0.1805 (0.3103)\tPrec@1 95.312 (89.960)\n",
            "Test: [150/157]\tTime 0.044 (0.044)\tLoss 0.2106 (0.3076)\tPrec@1 89.062 (90.035)\n",
            " * Prec@1 90.060\n",
            "Best accuracy:  tensor(90.0600, device='cuda:0')\n",
            "Epoch: [67][0/782]\tTime 0.259 (0.259)\tLoss 0.0955 (0.0955)\tPrec@1 96.875 (96.875)\n",
            "Epoch: [67][10/782]\tTime 0.164 (0.172)\tLoss 0.2438 (0.1726)\tPrec@1 90.625 (93.466)\n",
            "Epoch: [67][20/782]\tTime 0.162 (0.168)\tLoss 0.2548 (0.1884)\tPrec@1 92.188 (93.378)\n",
            "Epoch: [67][30/782]\tTime 0.163 (0.167)\tLoss 0.1982 (0.1942)\tPrec@1 90.625 (93.246)\n",
            "Epoch: [67][40/782]\tTime 0.165 (0.167)\tLoss 0.1573 (0.1879)\tPrec@1 93.750 (93.255)\n",
            "Epoch: [67][50/782]\tTime 0.164 (0.166)\tLoss 0.1433 (0.1891)\tPrec@1 92.188 (93.229)\n",
            "Epoch: [67][60/782]\tTime 0.165 (0.166)\tLoss 0.1913 (0.1868)\tPrec@1 93.750 (93.263)\n",
            "Epoch: [67][70/782]\tTime 0.164 (0.166)\tLoss 0.2161 (0.1801)\tPrec@1 89.062 (93.508)\n",
            "Epoch: [67][80/782]\tTime 0.163 (0.166)\tLoss 0.1403 (0.1762)\tPrec@1 93.750 (93.634)\n",
            "Epoch: [67][90/782]\tTime 0.172 (0.166)\tLoss 0.2305 (0.1786)\tPrec@1 90.625 (93.527)\n",
            "Epoch: [67][100/782]\tTime 0.164 (0.166)\tLoss 0.1224 (0.1773)\tPrec@1 96.875 (93.642)\n",
            "Epoch: [67][110/782]\tTime 0.163 (0.166)\tLoss 0.2348 (0.1769)\tPrec@1 93.750 (93.666)\n",
            "Epoch: [67][120/782]\tTime 0.167 (0.166)\tLoss 0.1578 (0.1759)\tPrec@1 96.875 (93.711)\n",
            "Epoch: [67][130/782]\tTime 0.162 (0.166)\tLoss 0.0877 (0.1788)\tPrec@1 98.438 (93.619)\n",
            "Epoch: [67][140/782]\tTime 0.167 (0.166)\tLoss 0.2374 (0.1835)\tPrec@1 92.188 (93.451)\n",
            "Epoch: [67][150/782]\tTime 0.164 (0.166)\tLoss 0.2037 (0.1837)\tPrec@1 92.188 (93.388)\n",
            "Epoch: [67][160/782]\tTime 0.162 (0.166)\tLoss 0.1281 (0.1853)\tPrec@1 96.875 (93.284)\n",
            "Epoch: [67][170/782]\tTime 0.168 (0.165)\tLoss 0.4326 (0.1865)\tPrec@1 89.062 (93.284)\n",
            "Epoch: [67][180/782]\tTime 0.163 (0.165)\tLoss 0.1811 (0.1867)\tPrec@1 92.188 (93.292)\n",
            "Epoch: [67][190/782]\tTime 0.162 (0.165)\tLoss 0.2878 (0.1882)\tPrec@1 90.625 (93.177)\n",
            "Epoch: [67][200/782]\tTime 0.163 (0.165)\tLoss 0.2472 (0.1908)\tPrec@1 90.625 (93.105)\n",
            "Epoch: [67][210/782]\tTime 0.162 (0.165)\tLoss 0.1379 (0.1909)\tPrec@1 93.750 (93.150)\n",
            "Epoch: [67][220/782]\tTime 0.165 (0.165)\tLoss 0.2514 (0.1935)\tPrec@1 89.062 (93.029)\n",
            "Epoch: [67][230/782]\tTime 0.164 (0.165)\tLoss 0.2249 (0.1936)\tPrec@1 89.062 (92.999)\n",
            "Epoch: [67][240/782]\tTime 0.163 (0.165)\tLoss 0.3205 (0.1961)\tPrec@1 92.188 (92.907)\n",
            "Epoch: [67][250/782]\tTime 0.164 (0.165)\tLoss 0.1251 (0.1966)\tPrec@1 96.875 (92.891)\n",
            "Epoch: [67][260/782]\tTime 0.161 (0.165)\tLoss 0.1516 (0.1962)\tPrec@1 95.312 (92.876)\n",
            "Epoch: [67][270/782]\tTime 0.163 (0.165)\tLoss 0.3026 (0.1977)\tPrec@1 84.375 (92.799)\n",
            "Epoch: [67][280/782]\tTime 0.165 (0.165)\tLoss 0.3954 (0.1997)\tPrec@1 90.625 (92.771)\n",
            "Epoch: [67][290/782]\tTime 0.162 (0.165)\tLoss 0.2239 (0.2028)\tPrec@1 90.625 (92.671)\n",
            "Epoch: [67][300/782]\tTime 0.165 (0.165)\tLoss 0.2473 (0.2027)\tPrec@1 92.188 (92.686)\n",
            "Epoch: [67][310/782]\tTime 0.165 (0.165)\tLoss 0.3662 (0.2046)\tPrec@1 92.188 (92.660)\n",
            "Epoch: [67][320/782]\tTime 0.162 (0.165)\tLoss 0.1648 (0.2048)\tPrec@1 92.188 (92.645)\n",
            "Epoch: [67][330/782]\tTime 0.162 (0.165)\tLoss 0.1956 (0.2045)\tPrec@1 90.625 (92.664)\n",
            "Epoch: [67][340/782]\tTime 0.163 (0.165)\tLoss 0.1860 (0.2053)\tPrec@1 90.625 (92.650)\n",
            "Epoch: [67][350/782]\tTime 0.163 (0.165)\tLoss 0.1969 (0.2052)\tPrec@1 90.625 (92.659)\n",
            "Epoch: [67][360/782]\tTime 0.163 (0.165)\tLoss 0.1130 (0.2049)\tPrec@1 96.875 (92.677)\n",
            "Epoch: [67][370/782]\tTime 0.164 (0.165)\tLoss 0.1505 (0.2040)\tPrec@1 95.312 (92.735)\n",
            "Epoch: [67][380/782]\tTime 0.163 (0.165)\tLoss 0.2408 (0.2042)\tPrec@1 90.625 (92.725)\n",
            "Epoch: [67][390/782]\tTime 0.165 (0.165)\tLoss 0.0891 (0.2032)\tPrec@1 96.875 (92.787)\n",
            "Epoch: [67][400/782]\tTime 0.162 (0.165)\tLoss 0.1523 (0.2049)\tPrec@1 92.188 (92.733)\n",
            "Epoch: [67][410/782]\tTime 0.164 (0.165)\tLoss 0.1304 (0.2061)\tPrec@1 95.312 (92.708)\n",
            "Epoch: [67][420/782]\tTime 0.166 (0.165)\tLoss 0.2455 (0.2072)\tPrec@1 90.625 (92.677)\n",
            "Epoch: [67][430/782]\tTime 0.163 (0.165)\tLoss 0.1624 (0.2068)\tPrec@1 92.188 (92.684)\n",
            "Epoch: [67][440/782]\tTime 0.163 (0.165)\tLoss 0.1424 (0.2069)\tPrec@1 92.188 (92.676)\n",
            "Epoch: [67][450/782]\tTime 0.163 (0.165)\tLoss 0.2741 (0.2070)\tPrec@1 93.750 (92.676)\n",
            "Epoch: [67][460/782]\tTime 0.163 (0.165)\tLoss 0.2170 (0.2077)\tPrec@1 90.625 (92.665)\n",
            "Epoch: [67][470/782]\tTime 0.163 (0.164)\tLoss 0.4294 (0.2073)\tPrec@1 81.250 (92.672)\n",
            "Epoch: [67][480/782]\tTime 0.162 (0.164)\tLoss 0.2957 (0.2072)\tPrec@1 93.750 (92.698)\n",
            "Epoch: [67][490/782]\tTime 0.163 (0.164)\tLoss 0.1842 (0.2066)\tPrec@1 93.750 (92.722)\n",
            "Epoch: [67][500/782]\tTime 0.164 (0.164)\tLoss 0.1986 (0.2060)\tPrec@1 90.625 (92.730)\n",
            "Epoch: [67][510/782]\tTime 0.165 (0.165)\tLoss 0.1961 (0.2055)\tPrec@1 95.312 (92.759)\n",
            "Epoch: [67][520/782]\tTime 0.163 (0.165)\tLoss 0.1719 (0.2049)\tPrec@1 93.750 (92.784)\n",
            "Epoch: [67][530/782]\tTime 0.165 (0.165)\tLoss 0.1226 (0.2042)\tPrec@1 93.750 (92.808)\n",
            "Epoch: [67][540/782]\tTime 0.165 (0.164)\tLoss 0.3802 (0.2042)\tPrec@1 92.188 (92.806)\n",
            "Epoch: [67][550/782]\tTime 0.162 (0.164)\tLoss 0.2021 (0.2033)\tPrec@1 92.188 (92.840)\n",
            "Epoch: [67][560/782]\tTime 0.163 (0.164)\tLoss 0.2376 (0.2031)\tPrec@1 92.188 (92.828)\n",
            "Epoch: [67][570/782]\tTime 0.163 (0.164)\tLoss 0.2434 (0.2028)\tPrec@1 95.312 (92.842)\n",
            "Epoch: [67][580/782]\tTime 0.164 (0.164)\tLoss 0.3400 (0.2034)\tPrec@1 89.062 (92.822)\n",
            "Epoch: [67][590/782]\tTime 0.161 (0.164)\tLoss 0.2206 (0.2037)\tPrec@1 90.625 (92.819)\n",
            "Epoch: [67][600/782]\tTime 0.163 (0.164)\tLoss 0.1828 (0.2041)\tPrec@1 92.188 (92.806)\n",
            "Epoch: [67][610/782]\tTime 0.163 (0.164)\tLoss 0.2497 (0.2043)\tPrec@1 89.062 (92.809)\n",
            "Epoch: [67][620/782]\tTime 0.163 (0.164)\tLoss 0.4126 (0.2046)\tPrec@1 89.062 (92.796)\n",
            "Epoch: [67][630/782]\tTime 0.164 (0.164)\tLoss 0.2527 (0.2054)\tPrec@1 89.062 (92.767)\n",
            "Epoch: [67][640/782]\tTime 0.166 (0.164)\tLoss 0.1259 (0.2053)\tPrec@1 93.750 (92.758)\n",
            "Epoch: [67][650/782]\tTime 0.165 (0.164)\tLoss 0.2083 (0.2062)\tPrec@1 92.188 (92.723)\n",
            "Epoch: [67][660/782]\tTime 0.162 (0.164)\tLoss 0.2535 (0.2062)\tPrec@1 89.062 (92.722)\n",
            "Epoch: [67][670/782]\tTime 0.163 (0.164)\tLoss 0.3817 (0.2068)\tPrec@1 87.500 (92.707)\n",
            "Epoch: [67][680/782]\tTime 0.164 (0.164)\tLoss 0.4288 (0.2080)\tPrec@1 84.375 (92.672)\n",
            "Epoch: [67][690/782]\tTime 0.166 (0.164)\tLoss 0.1649 (0.2081)\tPrec@1 96.875 (92.671)\n",
            "Epoch: [67][700/782]\tTime 0.162 (0.164)\tLoss 0.2893 (0.2083)\tPrec@1 92.188 (92.667)\n",
            "Epoch: [67][710/782]\tTime 0.164 (0.164)\tLoss 0.2813 (0.2080)\tPrec@1 90.625 (92.671)\n",
            "Epoch: [67][720/782]\tTime 0.163 (0.164)\tLoss 0.1868 (0.2082)\tPrec@1 93.750 (92.671)\n",
            "Epoch: [67][730/782]\tTime 0.164 (0.164)\tLoss 0.3209 (0.2084)\tPrec@1 90.625 (92.658)\n",
            "Epoch: [67][740/782]\tTime 0.161 (0.164)\tLoss 0.3307 (0.2084)\tPrec@1 89.062 (92.651)\n",
            "Epoch: [67][750/782]\tTime 0.163 (0.164)\tLoss 0.2092 (0.2093)\tPrec@1 93.750 (92.616)\n",
            "Epoch: [67][760/782]\tTime 0.162 (0.164)\tLoss 0.3952 (0.2096)\tPrec@1 82.812 (92.598)\n",
            "Epoch: [67][770/782]\tTime 0.166 (0.164)\tLoss 0.1231 (0.2097)\tPrec@1 93.750 (92.587)\n",
            "Epoch: [67][780/782]\tTime 0.162 (0.164)\tLoss 0.1676 (0.2101)\tPrec@1 95.312 (92.580)\n",
            "Training accuracy:  tensor(92.5820, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.7600, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.113 (0.113)\tLoss 0.4912 (0.4912)\tPrec@1 87.500 (87.500)\n",
            "Test: [10/157]\tTime 0.043 (0.047)\tLoss 0.3289 (0.4693)\tPrec@1 89.062 (86.080)\n",
            "Test: [20/157]\tTime 0.047 (0.046)\tLoss 0.3727 (0.4869)\tPrec@1 87.500 (85.789)\n",
            "Test: [30/157]\tTime 0.042 (0.045)\tLoss 0.3344 (0.4823)\tPrec@1 90.625 (85.635)\n",
            "Test: [40/157]\tTime 0.040 (0.045)\tLoss 0.3063 (0.4572)\tPrec@1 90.625 (86.357)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.6724 (0.4583)\tPrec@1 79.688 (86.275)\n",
            "Test: [60/157]\tTime 0.043 (0.045)\tLoss 0.3845 (0.4471)\tPrec@1 90.625 (86.603)\n",
            "Test: [70/157]\tTime 0.049 (0.045)\tLoss 0.1454 (0.4315)\tPrec@1 96.875 (87.038)\n",
            "Test: [80/157]\tTime 0.043 (0.044)\tLoss 0.3339 (0.4247)\tPrec@1 90.625 (87.211)\n",
            "Test: [90/157]\tTime 0.045 (0.044)\tLoss 0.2692 (0.4142)\tPrec@1 90.625 (87.414)\n",
            "Test: [100/157]\tTime 0.043 (0.044)\tLoss 0.1996 (0.4107)\tPrec@1 95.312 (87.608)\n",
            "Test: [110/157]\tTime 0.044 (0.044)\tLoss 0.5251 (0.4107)\tPrec@1 82.812 (87.683)\n",
            "Test: [120/157]\tTime 0.043 (0.044)\tLoss 0.4739 (0.4211)\tPrec@1 82.812 (87.332)\n",
            "Test: [130/157]\tTime 0.043 (0.044)\tLoss 0.4593 (0.4205)\tPrec@1 82.812 (87.261)\n",
            "Test: [140/157]\tTime 0.037 (0.044)\tLoss 0.4556 (0.4181)\tPrec@1 84.375 (87.367)\n",
            "Test: [150/157]\tTime 0.043 (0.044)\tLoss 0.3993 (0.4141)\tPrec@1 87.500 (87.521)\n",
            " * Prec@1 87.580\n",
            "Best accuracy:  tensor(90.0600, device='cuda:0')\n",
            "Epoch: [68][0/782]\tTime 0.261 (0.261)\tLoss 0.2743 (0.2743)\tPrec@1 89.062 (89.062)\n",
            "Epoch: [68][10/782]\tTime 0.164 (0.173)\tLoss 0.4455 (0.2261)\tPrec@1 87.500 (92.330)\n",
            "Epoch: [68][20/782]\tTime 0.165 (0.169)\tLoss 0.1681 (0.2016)\tPrec@1 92.188 (92.857)\n",
            "Epoch: [68][30/782]\tTime 0.163 (0.168)\tLoss 0.2548 (0.1962)\tPrec@1 90.625 (93.044)\n",
            "Epoch: [68][40/782]\tTime 0.162 (0.167)\tLoss 0.1505 (0.1932)\tPrec@1 93.750 (93.102)\n",
            "Epoch: [68][50/782]\tTime 0.164 (0.166)\tLoss 0.2167 (0.1921)\tPrec@1 90.625 (93.137)\n",
            "Epoch: [68][60/782]\tTime 0.162 (0.166)\tLoss 0.1071 (0.1857)\tPrec@1 95.312 (93.340)\n",
            "Epoch: [68][70/782]\tTime 0.166 (0.166)\tLoss 0.3831 (0.1841)\tPrec@1 85.938 (93.354)\n",
            "Epoch: [68][80/782]\tTime 0.163 (0.166)\tLoss 0.1818 (0.1845)\tPrec@1 93.750 (93.403)\n",
            "Epoch: [68][90/782]\tTime 0.162 (0.166)\tLoss 0.2720 (0.1820)\tPrec@1 89.062 (93.561)\n",
            "Epoch: [68][100/782]\tTime 0.164 (0.165)\tLoss 0.1136 (0.1793)\tPrec@1 92.188 (93.626)\n",
            "Epoch: [68][110/782]\tTime 0.165 (0.165)\tLoss 0.3365 (0.1848)\tPrec@1 89.062 (93.525)\n",
            "Epoch: [68][120/782]\tTime 0.163 (0.165)\tLoss 0.1725 (0.1897)\tPrec@1 95.312 (93.311)\n",
            "Epoch: [68][130/782]\tTime 0.169 (0.165)\tLoss 0.5154 (0.1926)\tPrec@1 78.125 (93.154)\n",
            "Epoch: [68][140/782]\tTime 0.164 (0.165)\tLoss 0.3018 (0.1930)\tPrec@1 89.062 (93.118)\n",
            "Epoch: [68][150/782]\tTime 0.162 (0.165)\tLoss 0.2565 (0.1928)\tPrec@1 93.750 (93.150)\n",
            "Epoch: [68][160/782]\tTime 0.163 (0.165)\tLoss 0.1617 (0.1918)\tPrec@1 95.312 (93.168)\n",
            "Epoch: [68][170/782]\tTime 0.161 (0.165)\tLoss 0.1303 (0.1939)\tPrec@1 92.188 (93.092)\n",
            "Epoch: [68][180/782]\tTime 0.162 (0.165)\tLoss 0.3378 (0.1936)\tPrec@1 87.500 (93.120)\n",
            "Epoch: [68][190/782]\tTime 0.165 (0.165)\tLoss 0.0874 (0.1930)\tPrec@1 98.438 (93.120)\n",
            "Epoch: [68][200/782]\tTime 0.162 (0.165)\tLoss 0.1326 (0.1928)\tPrec@1 93.750 (93.113)\n",
            "Epoch: [68][210/782]\tTime 0.161 (0.164)\tLoss 0.2019 (0.1912)\tPrec@1 93.750 (93.150)\n",
            "Epoch: [68][220/782]\tTime 0.163 (0.164)\tLoss 0.3237 (0.1914)\tPrec@1 87.500 (93.184)\n",
            "Epoch: [68][230/782]\tTime 0.166 (0.164)\tLoss 0.2069 (0.1907)\tPrec@1 93.750 (93.249)\n",
            "Epoch: [68][240/782]\tTime 0.164 (0.164)\tLoss 0.2041 (0.1915)\tPrec@1 89.062 (93.186)\n",
            "Epoch: [68][250/782]\tTime 0.161 (0.164)\tLoss 0.1008 (0.1922)\tPrec@1 95.312 (93.140)\n",
            "Epoch: [68][260/782]\tTime 0.164 (0.164)\tLoss 0.2605 (0.1917)\tPrec@1 93.750 (93.151)\n",
            "Epoch: [68][270/782]\tTime 0.163 (0.164)\tLoss 0.1729 (0.1922)\tPrec@1 95.312 (93.150)\n",
            "Epoch: [68][280/782]\tTime 0.161 (0.164)\tLoss 0.2529 (0.1911)\tPrec@1 90.625 (93.183)\n",
            "Epoch: [68][290/782]\tTime 0.162 (0.164)\tLoss 0.1397 (0.1917)\tPrec@1 90.625 (93.154)\n",
            "Epoch: [68][300/782]\tTime 0.162 (0.164)\tLoss 0.2224 (0.1926)\tPrec@1 93.750 (93.174)\n",
            "Epoch: [68][310/782]\tTime 0.163 (0.164)\tLoss 0.2285 (0.1923)\tPrec@1 93.750 (93.202)\n",
            "Epoch: [68][320/782]\tTime 0.162 (0.164)\tLoss 0.1578 (0.1931)\tPrec@1 92.188 (93.171)\n",
            "Epoch: [68][330/782]\tTime 0.165 (0.164)\tLoss 0.3563 (0.1937)\tPrec@1 89.062 (93.150)\n",
            "Epoch: [68][340/782]\tTime 0.162 (0.164)\tLoss 0.2457 (0.1938)\tPrec@1 92.188 (93.136)\n",
            "Epoch: [68][350/782]\tTime 0.164 (0.164)\tLoss 0.1311 (0.1942)\tPrec@1 95.312 (93.140)\n",
            "Epoch: [68][360/782]\tTime 0.161 (0.164)\tLoss 0.1585 (0.1945)\tPrec@1 93.750 (93.122)\n",
            "Epoch: [68][370/782]\tTime 0.165 (0.164)\tLoss 0.2429 (0.1948)\tPrec@1 90.625 (93.089)\n",
            "Epoch: [68][380/782]\tTime 0.165 (0.164)\tLoss 0.1213 (0.1951)\tPrec@1 96.875 (93.077)\n",
            "Epoch: [68][390/782]\tTime 0.171 (0.164)\tLoss 0.1488 (0.1952)\tPrec@1 93.750 (93.075)\n",
            "Epoch: [68][400/782]\tTime 0.166 (0.164)\tLoss 0.1560 (0.1953)\tPrec@1 93.750 (93.076)\n",
            "Epoch: [68][410/782]\tTime 0.167 (0.164)\tLoss 0.1034 (0.1955)\tPrec@1 96.875 (93.062)\n",
            "Epoch: [68][420/782]\tTime 0.163 (0.164)\tLoss 0.1875 (0.1958)\tPrec@1 93.750 (93.026)\n",
            "Epoch: [68][430/782]\tTime 0.164 (0.164)\tLoss 0.1664 (0.1959)\tPrec@1 98.438 (93.036)\n",
            "Epoch: [68][440/782]\tTime 0.166 (0.164)\tLoss 0.3545 (0.1969)\tPrec@1 87.500 (93.006)\n",
            "Epoch: [68][450/782]\tTime 0.162 (0.164)\tLoss 0.1127 (0.1972)\tPrec@1 95.312 (92.988)\n",
            "Epoch: [68][460/782]\tTime 0.166 (0.164)\tLoss 0.2453 (0.1983)\tPrec@1 90.625 (92.957)\n",
            "Epoch: [68][470/782]\tTime 0.163 (0.164)\tLoss 0.2813 (0.1996)\tPrec@1 87.500 (92.907)\n",
            "Epoch: [68][480/782]\tTime 0.162 (0.164)\tLoss 0.3018 (0.2006)\tPrec@1 89.062 (92.896)\n",
            "Epoch: [68][490/782]\tTime 0.163 (0.164)\tLoss 0.1400 (0.2005)\tPrec@1 96.875 (92.891)\n",
            "Epoch: [68][500/782]\tTime 0.163 (0.164)\tLoss 0.1835 (0.2013)\tPrec@1 93.750 (92.861)\n",
            "Epoch: [68][510/782]\tTime 0.162 (0.164)\tLoss 0.3507 (0.2026)\tPrec@1 87.500 (92.805)\n",
            "Epoch: [68][520/782]\tTime 0.165 (0.164)\tLoss 0.1078 (0.2031)\tPrec@1 96.875 (92.823)\n",
            "Epoch: [68][530/782]\tTime 0.163 (0.164)\tLoss 0.3292 (0.2030)\tPrec@1 90.625 (92.829)\n",
            "Epoch: [68][540/782]\tTime 0.166 (0.164)\tLoss 0.1409 (0.2042)\tPrec@1 95.312 (92.788)\n",
            "Epoch: [68][550/782]\tTime 0.161 (0.164)\tLoss 0.3266 (0.2039)\tPrec@1 90.625 (92.797)\n",
            "Epoch: [68][560/782]\tTime 0.162 (0.164)\tLoss 0.1912 (0.2039)\tPrec@1 90.625 (92.784)\n",
            "Epoch: [68][570/782]\tTime 0.164 (0.164)\tLoss 0.2413 (0.2046)\tPrec@1 90.625 (92.754)\n",
            "Epoch: [68][580/782]\tTime 0.161 (0.164)\tLoss 0.2159 (0.2052)\tPrec@1 90.625 (92.731)\n",
            "Epoch: [68][590/782]\tTime 0.163 (0.164)\tLoss 0.1742 (0.2056)\tPrec@1 93.750 (92.719)\n",
            "Epoch: [68][600/782]\tTime 0.163 (0.164)\tLoss 0.1604 (0.2056)\tPrec@1 90.625 (92.733)\n",
            "Epoch: [68][610/782]\tTime 0.161 (0.164)\tLoss 0.1493 (0.2058)\tPrec@1 95.312 (92.742)\n",
            "Epoch: [68][620/782]\tTime 0.160 (0.164)\tLoss 0.2811 (0.2063)\tPrec@1 84.375 (92.728)\n",
            "Epoch: [68][630/782]\tTime 0.160 (0.164)\tLoss 0.1790 (0.2062)\tPrec@1 90.625 (92.725)\n",
            "Epoch: [68][640/782]\tTime 0.163 (0.164)\tLoss 0.2138 (0.2058)\tPrec@1 93.750 (92.755)\n",
            "Epoch: [68][650/782]\tTime 0.162 (0.164)\tLoss 0.2118 (0.2057)\tPrec@1 92.188 (92.764)\n",
            "Epoch: [68][660/782]\tTime 0.162 (0.164)\tLoss 0.1381 (0.2048)\tPrec@1 93.750 (92.781)\n",
            "Epoch: [68][670/782]\tTime 0.163 (0.164)\tLoss 0.2453 (0.2049)\tPrec@1 92.188 (92.777)\n",
            "Epoch: [68][680/782]\tTime 0.165 (0.164)\tLoss 0.0972 (0.2042)\tPrec@1 98.438 (92.809)\n",
            "Epoch: [68][690/782]\tTime 0.163 (0.164)\tLoss 0.2389 (0.2044)\tPrec@1 93.750 (92.807)\n",
            "Epoch: [68][700/782]\tTime 0.163 (0.164)\tLoss 0.1964 (0.2049)\tPrec@1 90.625 (92.776)\n",
            "Epoch: [68][710/782]\tTime 0.163 (0.164)\tLoss 0.2563 (0.2050)\tPrec@1 89.062 (92.752)\n",
            "Epoch: [68][720/782]\tTime 0.162 (0.164)\tLoss 0.2664 (0.2054)\tPrec@1 93.750 (92.755)\n",
            "Epoch: [68][730/782]\tTime 0.163 (0.164)\tLoss 0.2000 (0.2053)\tPrec@1 95.312 (92.756)\n",
            "Epoch: [68][740/782]\tTime 0.161 (0.164)\tLoss 0.2125 (0.2055)\tPrec@1 92.188 (92.753)\n",
            "Epoch: [68][750/782]\tTime 0.163 (0.164)\tLoss 0.1782 (0.2058)\tPrec@1 92.188 (92.751)\n",
            "Epoch: [68][760/782]\tTime 0.160 (0.164)\tLoss 0.3227 (0.2060)\tPrec@1 85.938 (92.734)\n",
            "Epoch: [68][770/782]\tTime 0.164 (0.164)\tLoss 0.3026 (0.2059)\tPrec@1 92.188 (92.737)\n",
            "Epoch: [68][780/782]\tTime 0.160 (0.164)\tLoss 0.1517 (0.2068)\tPrec@1 96.875 (92.706)\n",
            "Training accuracy:  tensor(92.7060, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.7600, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.110 (0.110)\tLoss 0.4140 (0.4140)\tPrec@1 84.375 (84.375)\n",
            "Test: [10/157]\tTime 0.041 (0.047)\tLoss 0.2825 (0.3418)\tPrec@1 90.625 (88.494)\n",
            "Test: [20/157]\tTime 0.033 (0.051)\tLoss 0.5666 (0.3741)\tPrec@1 82.812 (88.095)\n",
            "Test: [30/157]\tTime 0.045 (0.048)\tLoss 0.2403 (0.3791)\tPrec@1 92.188 (88.004)\n",
            "Test: [40/157]\tTime 0.047 (0.047)\tLoss 0.2551 (0.3759)\tPrec@1 90.625 (88.300)\n",
            "Test: [50/157]\tTime 0.044 (0.047)\tLoss 0.4540 (0.3797)\tPrec@1 87.500 (88.051)\n",
            "Test: [60/157]\tTime 0.043 (0.046)\tLoss 0.3165 (0.3690)\tPrec@1 90.625 (88.499)\n",
            "Test: [70/157]\tTime 0.042 (0.046)\tLoss 0.5332 (0.3768)\tPrec@1 78.125 (88.314)\n",
            "Test: [80/157]\tTime 0.042 (0.045)\tLoss 0.4387 (0.3830)\tPrec@1 87.500 (88.252)\n",
            "Test: [90/157]\tTime 0.044 (0.045)\tLoss 0.4167 (0.3839)\tPrec@1 89.062 (88.204)\n",
            "Test: [100/157]\tTime 0.043 (0.045)\tLoss 0.2053 (0.3895)\tPrec@1 92.188 (88.057)\n",
            "Test: [110/157]\tTime 0.043 (0.045)\tLoss 0.5361 (0.3922)\tPrec@1 79.688 (87.908)\n",
            "Test: [120/157]\tTime 0.042 (0.045)\tLoss 0.2915 (0.3909)\tPrec@1 85.938 (87.991)\n",
            "Test: [130/157]\tTime 0.042 (0.045)\tLoss 0.4932 (0.3948)\tPrec@1 82.812 (87.917)\n",
            "Test: [140/157]\tTime 0.043 (0.045)\tLoss 0.5264 (0.3971)\tPrec@1 82.812 (87.799)\n",
            "Test: [150/157]\tTime 0.043 (0.045)\tLoss 0.4198 (0.3926)\tPrec@1 84.375 (87.873)\n",
            " * Prec@1 87.830\n",
            "Best accuracy:  tensor(90.0600, device='cuda:0')\n",
            "Epoch: [69][0/782]\tTime 0.269 (0.269)\tLoss 0.2107 (0.2107)\tPrec@1 92.188 (92.188)\n",
            "Epoch: [69][10/782]\tTime 0.165 (0.176)\tLoss 0.2341 (0.2194)\tPrec@1 93.750 (92.898)\n",
            "Epoch: [69][20/782]\tTime 0.167 (0.172)\tLoss 0.2233 (0.1948)\tPrec@1 89.062 (93.676)\n",
            "Epoch: [69][30/782]\tTime 0.162 (0.170)\tLoss 0.0788 (0.2007)\tPrec@1 96.875 (93.548)\n",
            "Epoch: [69][40/782]\tTime 0.162 (0.169)\tLoss 0.1696 (0.1953)\tPrec@1 95.312 (93.750)\n",
            "Epoch: [69][50/782]\tTime 0.163 (0.168)\tLoss 0.2505 (0.1952)\tPrec@1 89.062 (93.627)\n",
            "Epoch: [69][60/782]\tTime 0.166 (0.167)\tLoss 0.1661 (0.1987)\tPrec@1 90.625 (93.468)\n",
            "Epoch: [69][70/782]\tTime 0.167 (0.167)\tLoss 0.2962 (0.2000)\tPrec@1 92.188 (93.464)\n",
            "Epoch: [69][80/782]\tTime 0.163 (0.167)\tLoss 0.0741 (0.1999)\tPrec@1 96.875 (93.345)\n",
            "Epoch: [69][90/782]\tTime 0.167 (0.166)\tLoss 0.3130 (0.2005)\tPrec@1 85.938 (93.235)\n",
            "Epoch: [69][100/782]\tTime 0.167 (0.166)\tLoss 0.1617 (0.1995)\tPrec@1 93.750 (93.239)\n",
            "Epoch: [69][110/782]\tTime 0.166 (0.166)\tLoss 0.1791 (0.1990)\tPrec@1 93.750 (93.243)\n",
            "Epoch: [69][120/782]\tTime 0.166 (0.166)\tLoss 0.1713 (0.1964)\tPrec@1 95.312 (93.388)\n",
            "Epoch: [69][130/782]\tTime 0.166 (0.166)\tLoss 0.2038 (0.1963)\tPrec@1 89.062 (93.309)\n",
            "Epoch: [69][140/782]\tTime 0.167 (0.166)\tLoss 0.1943 (0.1950)\tPrec@1 96.875 (93.373)\n",
            "Epoch: [69][150/782]\tTime 0.166 (0.166)\tLoss 0.1279 (0.1940)\tPrec@1 93.750 (93.295)\n",
            "Epoch: [69][160/782]\tTime 0.168 (0.167)\tLoss 0.2616 (0.1936)\tPrec@1 87.500 (93.313)\n",
            "Epoch: [69][170/782]\tTime 0.166 (0.167)\tLoss 0.1651 (0.1956)\tPrec@1 93.750 (93.238)\n",
            "Epoch: [69][180/782]\tTime 0.167 (0.167)\tLoss 0.2813 (0.1978)\tPrec@1 93.750 (93.249)\n",
            "Epoch: [69][190/782]\tTime 0.162 (0.167)\tLoss 0.2739 (0.1963)\tPrec@1 87.500 (93.267)\n",
            "Epoch: [69][200/782]\tTime 0.168 (0.167)\tLoss 0.2641 (0.1959)\tPrec@1 90.625 (93.229)\n",
            "Epoch: [69][210/782]\tTime 0.167 (0.167)\tLoss 0.2418 (0.1974)\tPrec@1 85.938 (93.150)\n",
            "Epoch: [69][220/782]\tTime 0.166 (0.167)\tLoss 0.2710 (0.1973)\tPrec@1 89.062 (93.199)\n",
            "Epoch: [69][230/782]\tTime 0.167 (0.167)\tLoss 0.3343 (0.1988)\tPrec@1 90.625 (93.114)\n",
            "Epoch: [69][240/782]\tTime 0.166 (0.167)\tLoss 0.1872 (0.2009)\tPrec@1 93.750 (93.095)\n",
            "Epoch: [69][250/782]\tTime 0.163 (0.167)\tLoss 0.1890 (0.2001)\tPrec@1 90.625 (93.103)\n",
            "Epoch: [69][260/782]\tTime 0.163 (0.167)\tLoss 0.2960 (0.2000)\tPrec@1 90.625 (93.097)\n",
            "Epoch: [69][270/782]\tTime 0.164 (0.166)\tLoss 0.2856 (0.2016)\tPrec@1 89.062 (93.052)\n",
            "Epoch: [69][280/782]\tTime 0.163 (0.166)\tLoss 0.1087 (0.2030)\tPrec@1 95.312 (92.999)\n",
            "Epoch: [69][290/782]\tTime 0.164 (0.166)\tLoss 0.2820 (0.2030)\tPrec@1 92.188 (93.020)\n",
            "Epoch: [69][300/782]\tTime 0.165 (0.166)\tLoss 0.2119 (0.2034)\tPrec@1 93.750 (93.023)\n",
            "Epoch: [69][310/782]\tTime 0.163 (0.166)\tLoss 0.3105 (0.2025)\tPrec@1 89.062 (93.072)\n",
            "Epoch: [69][320/782]\tTime 0.161 (0.166)\tLoss 0.1576 (0.2021)\tPrec@1 92.188 (93.059)\n",
            "Epoch: [69][330/782]\tTime 0.165 (0.166)\tLoss 0.1426 (0.2017)\tPrec@1 95.312 (93.070)\n",
            "Epoch: [69][340/782]\tTime 0.163 (0.166)\tLoss 0.3765 (0.2014)\tPrec@1 87.500 (93.086)\n",
            "Epoch: [69][350/782]\tTime 0.165 (0.166)\tLoss 0.1085 (0.2014)\tPrec@1 98.438 (93.131)\n",
            "Epoch: [69][360/782]\tTime 0.166 (0.166)\tLoss 0.2307 (0.2018)\tPrec@1 90.625 (93.092)\n",
            "Epoch: [69][370/782]\tTime 0.164 (0.166)\tLoss 0.2422 (0.2005)\tPrec@1 95.312 (93.135)\n",
            "Epoch: [69][380/782]\tTime 0.165 (0.166)\tLoss 0.1840 (0.2004)\tPrec@1 92.188 (93.114)\n",
            "Epoch: [69][390/782]\tTime 0.168 (0.166)\tLoss 0.2077 (0.2003)\tPrec@1 93.750 (93.111)\n",
            "Epoch: [69][400/782]\tTime 0.166 (0.166)\tLoss 0.1751 (0.2005)\tPrec@1 93.750 (93.111)\n",
            "Epoch: [69][410/782]\tTime 0.164 (0.166)\tLoss 0.1292 (0.2001)\tPrec@1 95.312 (93.130)\n",
            "Epoch: [69][420/782]\tTime 0.166 (0.166)\tLoss 0.3520 (0.2001)\tPrec@1 92.188 (93.134)\n",
            "Epoch: [69][430/782]\tTime 0.164 (0.166)\tLoss 0.2333 (0.2004)\tPrec@1 92.188 (93.108)\n",
            "Epoch: [69][440/782]\tTime 0.165 (0.166)\tLoss 0.2680 (0.2012)\tPrec@1 92.188 (93.080)\n",
            "Epoch: [69][450/782]\tTime 0.164 (0.166)\tLoss 0.1609 (0.2015)\tPrec@1 93.750 (93.064)\n",
            "Epoch: [69][460/782]\tTime 0.167 (0.166)\tLoss 0.2631 (0.2013)\tPrec@1 90.625 (93.065)\n",
            "Epoch: [69][470/782]\tTime 0.162 (0.166)\tLoss 0.3439 (0.2024)\tPrec@1 87.500 (93.023)\n",
            "Epoch: [69][480/782]\tTime 0.164 (0.166)\tLoss 0.2068 (0.2030)\tPrec@1 93.750 (93.003)\n",
            "Epoch: [69][490/782]\tTime 0.163 (0.166)\tLoss 0.1153 (0.2031)\tPrec@1 98.438 (93.009)\n",
            "Epoch: [69][500/782]\tTime 0.163 (0.166)\tLoss 0.1427 (0.2036)\tPrec@1 95.312 (92.998)\n",
            "Epoch: [69][510/782]\tTime 0.165 (0.166)\tLoss 0.1481 (0.2040)\tPrec@1 93.750 (92.958)\n",
            "Epoch: [69][520/782]\tTime 0.164 (0.166)\tLoss 0.3822 (0.2051)\tPrec@1 85.938 (92.940)\n",
            "Epoch: [69][530/782]\tTime 0.164 (0.166)\tLoss 0.2331 (0.2056)\tPrec@1 87.500 (92.900)\n",
            "Epoch: [69][540/782]\tTime 0.164 (0.166)\tLoss 0.2246 (0.2062)\tPrec@1 90.625 (92.875)\n",
            "Epoch: [69][550/782]\tTime 0.164 (0.166)\tLoss 0.2050 (0.2064)\tPrec@1 92.188 (92.860)\n",
            "Epoch: [69][560/782]\tTime 0.164 (0.166)\tLoss 0.1716 (0.2068)\tPrec@1 93.750 (92.845)\n",
            "Epoch: [69][570/782]\tTime 0.162 (0.166)\tLoss 0.2552 (0.2069)\tPrec@1 92.188 (92.833)\n",
            "Epoch: [69][580/782]\tTime 0.169 (0.166)\tLoss 0.1582 (0.2070)\tPrec@1 95.312 (92.828)\n",
            "Epoch: [69][590/782]\tTime 0.164 (0.166)\tLoss 0.2054 (0.2075)\tPrec@1 93.750 (92.809)\n",
            "Epoch: [69][600/782]\tTime 0.162 (0.165)\tLoss 0.2150 (0.2079)\tPrec@1 89.062 (92.785)\n",
            "Epoch: [69][610/782]\tTime 0.164 (0.165)\tLoss 0.1261 (0.2076)\tPrec@1 96.875 (92.781)\n",
            "Epoch: [69][620/782]\tTime 0.162 (0.165)\tLoss 0.1210 (0.2073)\tPrec@1 95.312 (92.806)\n",
            "Epoch: [69][630/782]\tTime 0.164 (0.165)\tLoss 0.3601 (0.2077)\tPrec@1 90.625 (92.802)\n",
            "Epoch: [69][640/782]\tTime 0.163 (0.165)\tLoss 0.2686 (0.2079)\tPrec@1 89.062 (92.802)\n",
            "Epoch: [69][650/782]\tTime 0.165 (0.165)\tLoss 0.1518 (0.2076)\tPrec@1 93.750 (92.807)\n",
            "Epoch: [69][660/782]\tTime 0.165 (0.165)\tLoss 0.1806 (0.2070)\tPrec@1 93.750 (92.830)\n",
            "Epoch: [69][670/782]\tTime 0.166 (0.165)\tLoss 0.2381 (0.2068)\tPrec@1 90.625 (92.835)\n",
            "Epoch: [69][680/782]\tTime 0.164 (0.165)\tLoss 0.1360 (0.2064)\tPrec@1 95.312 (92.848)\n",
            "Epoch: [69][690/782]\tTime 0.166 (0.165)\tLoss 0.3074 (0.2064)\tPrec@1 87.500 (92.841)\n",
            "Epoch: [69][700/782]\tTime 0.166 (0.165)\tLoss 0.1388 (0.2065)\tPrec@1 95.312 (92.836)\n",
            "Epoch: [69][710/782]\tTime 0.166 (0.165)\tLoss 0.2095 (0.2065)\tPrec@1 93.750 (92.834)\n",
            "Epoch: [69][720/782]\tTime 0.166 (0.165)\tLoss 0.2194 (0.2060)\tPrec@1 89.062 (92.842)\n",
            "Epoch: [69][730/782]\tTime 0.165 (0.165)\tLoss 0.1410 (0.2059)\tPrec@1 93.750 (92.837)\n",
            "Epoch: [69][740/782]\tTime 0.166 (0.165)\tLoss 0.2453 (0.2063)\tPrec@1 92.188 (92.837)\n",
            "Epoch: [69][750/782]\tTime 0.163 (0.165)\tLoss 0.2155 (0.2064)\tPrec@1 87.500 (92.820)\n",
            "Epoch: [69][760/782]\tTime 0.162 (0.165)\tLoss 0.0804 (0.2062)\tPrec@1 96.875 (92.816)\n",
            "Epoch: [69][770/782]\tTime 0.166 (0.165)\tLoss 0.3325 (0.2065)\tPrec@1 90.625 (92.818)\n",
            "Epoch: [69][780/782]\tTime 0.161 (0.165)\tLoss 0.2597 (0.2070)\tPrec@1 89.062 (92.796)\n",
            "Training accuracy:  tensor(92.7940, device='cuda:0')\n",
            "Best accuraacy:  tensor(92.7940, device='cuda:0')\n",
            "Test: [0/157]\tTime 0.111 (0.111)\tLoss 0.2444 (0.2444)\tPrec@1 92.188 (92.188)\n",
            "Test: [10/157]\tTime 0.042 (0.047)\tLoss 0.4493 (0.3392)\tPrec@1 87.500 (88.636)\n",
            "Test: [20/157]\tTime 0.055 (0.046)\tLoss 0.2149 (0.3318)\tPrec@1 93.750 (88.690)\n",
            "Test: [30/157]\tTime 0.042 (0.046)\tLoss 0.2183 (0.3545)\tPrec@1 90.625 (88.306)\n",
            "Test: [40/157]\tTime 0.041 (0.045)\tLoss 0.1397 (0.3547)\tPrec@1 95.312 (88.453)\n",
            "Test: [50/157]\tTime 0.043 (0.045)\tLoss 0.5406 (0.3456)\tPrec@1 84.375 (88.879)\n",
            "Test: [60/157]\tTime 0.042 (0.045)\tLoss 0.3098 (0.3345)\tPrec@1 89.062 (89.216)\n",
            "Test: [70/157]\tTime 0.044 (0.045)\tLoss 0.1207 (0.3246)\tPrec@1 93.750 (89.547)\n",
            "Test: [80/157]\tTime 0.049 (0.045)\tLoss 0.6345 (0.3330)\tPrec@1 78.125 (89.333)\n",
            "Test: [90/157]\tTime 0.044 (0.044)\tLoss 0.3236 (0.3258)\tPrec@1 85.938 (89.457)\n",
            "Test: [100/157]\tTime 0.041 (0.044)\tLoss 0.3419 (0.3325)\tPrec@1 87.500 (89.310)\n",
            "Test: [110/157]\tTime 0.044 (0.044)\tLoss 0.3966 (0.3281)\tPrec@1 87.500 (89.428)\n",
            "Test: [120/157]\tTime 0.047 (0.044)\tLoss 0.1911 (0.3244)\tPrec@1 93.750 (89.527)\n",
            "Test: [130/157]\tTime 0.045 (0.044)\tLoss 0.1391 (0.3219)\tPrec@1 95.312 (89.671)\n",
            "Test: [140/157]\tTime 0.044 (0.044)\tLoss 0.1706 (0.3189)\tPrec@1 93.750 (89.683)\n",
            "Test: [150/157]\tTime 0.037 (0.044)\tLoss 0.2181 (0.3190)\tPrec@1 92.188 (89.756)\n",
            " * Prec@1 89.720\n",
            "Best accuracy:  tensor(90.0600, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ufkS5r163vr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCkFfb9i44bg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRAEQ4n8n7kk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F3K1iVAn72G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSwyzTvUn75c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}